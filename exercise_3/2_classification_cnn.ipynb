{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image classification with CNNs\n",
    "================\n",
    "\n",
    "The goal of this exercise is to implement a specific CNN architecture with PyTorch and train it on the CIFAR-10 image classification dataset. We will start by introducing the dataset and then implement a `nn.Module` and a useful `Solver` class. Seperating the model from the actual training has proven itself as a sensible design decision. By the end of this exercise you should have succesfully trained your (possible) first CNN model and have a boilerplate `Solver` class which you can reuse for the next exercise and your future research projects.\n",
    "\n",
    "For an inspiration on how to implement a model or the solver class you can have a look at [these](https://github.com/pytorch/examples) PyTorch examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from dl4cv.classifiers.classification_cnn import ClassificationCNN\n",
    "from dl4cv.data_utils import get_CIFAR10_datasets, OverfitSampler, rel_error\n",
    "\n",
    "#torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10 Dataset\n",
    "=========\n",
    "\n",
    "Since the focus of this exercise should be neural network models and how to successfully train them, we provide you with preprocessed and prepared datasets. For an even easier management of the train, validation and test data pipelines we provide you with custom `torch.utils.data.Dataset` classes. Use the official [documentation](http://pytorch.org/docs/data.html) to make yourself familiar with the `Dataset` and `DataLoader` classes. Think about how you have to integrate them in your training loop and have a look at the data preprocessing steps in `dl4cv/data_utils.py`.\n",
    "\n",
    "The `num_workers` argument of the `DataLoader` class allows you to preprocess data with multiple threads.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Note</h3>\n",
    "    <p>In this case we generated the `Dataset` classes after we applied all the preprocessing steps. Other datasets or random data augmentation might require an online preprocessing which can be integrated into the `Dataset` classes. See `torchvision.Transform` for examples.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 48000\n",
      "Val size: 1000\n",
      "Test size: 1000\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data. The preprocessing includes\n",
    "# channel swapping, normalization and train-val-test splitting.\n",
    "# Loading the datasets might take a while.\n",
    "\n",
    "train_data, val_data, test_data, mean_image = get_CIFAR10_datasets()\n",
    "print(\"Train size: %i\" % len(train_data))\n",
    "print(\"Val size: %i\" % len(val_data))\n",
    "print(\"Test size: %i\" % len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Examples\n",
    "------------------\n",
    "\n",
    "To make yourself familiar with the dataset we visualize some examples. We show a few examples from each class. Note that we have to revert (transposition and mean subtraction) some preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAHcCAYAAADyTy94AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvXmcZNlV3/m9b4l9yT2zMmvvWnurLrX2BaRGSJZkGyEw\nBmMbPMZj8Ap8GIM9NoM/YBuwMR4bbx+GMSOzGAYDAo9tgdQIpJbU+6Jea83KpXLPyIw94i13/jgn\nXkaVqquyVK2qEsTv86nuyHgv3rvn3nPvPfesxlrLAAMMMMAAAwwwwABfGZw73YABBhhggAEGGGCA\nr2UMhKkBBhhggAEGGGCAW8BAmBpggAEGGGCAAQa4BQyEqQEGGGCAAQYYYIBbwECYGmCAAQYYYIAB\nBrgFDISpAQYYYIABBhhggFvA14QwZYx5rzFm4U63Y4CvDMaYWWPM+6/x/XuMMa/d5LN+0RjzE29c\n6wa4WfxJG4M/TvQaY44bY54zxtSMMX/nTrfnVvF6a8ufRBhjfswY80vXuf6SMea9t7FJdw2MMdYY\nc+Sr+Y6vCWFqgD+esNZ+1lp7/E63427AYFMY4Dbh7wF/YK0tWmv/9Z1uzAC3D9ba+6y1n7nT7Xg9\nfK2vgQNh6o8RjDHenW7DG4U/TrQMcGMMxvu24QDw0rUuGGPc29yWuwID3rv78bUwRneVMKWS6d83\nxrxsjKkYY/6TMSZzjft+xBhzXlXVLxtjvrnv2ncbYz5njPkX+oyLxpgP9V0vG2N+wRizZIxZNMb8\nxN2yiBhj9hljftMYs2aM2TDG/Jwx5h5jzKP697ox5peNMUN9v5k1xvywMeYFoHEXM91brh7Xq823\n16LFGHPaGPOMjvWvAV/GD3cbbnYcjTH/GdgP/K4xpm6M+Xt3loIrcb0xMMb8aTUbbRljPm+MebDv\n2rQx5r9qP1zsNyupSeI3jDG/ZIypAt99W4m6Dm5A718zxpwzxmwaY37HGDPdd+0DxpjXjDHbxph/\nZ4z5Q2PM99wRIq4BY8yjwPuAn1M++xVjzL83xvx3Y0wDeJ+ujx/XMbtkjPmHxhhHf+8aY35G+fei\nMeZvGTGf3Ok15yFjzAva77/W2zNuMFbWGPM3jTFngbNG8LPGmFVjTNUY8yVjzP16b9rIfjJnjFkx\nxvwHY0z2DtHaa/8PG9m/aspz36CXUjp+NSNmvTf3/SbR/PTNv1/Te58xxpy6I8Rw7TVQx+ivGmPm\ngEfNNdx9rqLJNcb8A7MjGzxtjNl3jXe92xgzb95ok6e19q75B8wCLwL7gBHgMeAngPcCC333/Tlg\nGhEG/zzQAPbote8GAuCvAS7wfcBlwOj13wL+I5AHJoAngL9+F9DuAs8DP6ttywDvBo4A3wikgXHg\nj4B/dVWfPad9lr3TdNziuF5BC5ACLgE/APjAt+rY/sSdpumrNI7vv9PtvwY9rzsGwGlgFXib0v1d\nSkda5+bTwI/qMw4DF4AP6nN/TJ/zUb33ruDdG9D7CLAOvElp/DfAH+nvxoAq8DHAA/6u/u577jRN\nV9H3mV6bgF8EtoF36RhkgI8DnwCKwEHgDPBX9f7vBV4G9gLDwKcAC3h3kJ5ZZA2f1rXlFW3n646V\n/s4Cv6+/yQIfVH4dAgxwkp095WeB39F7i8DvAv/sDtJ8HJgHpvXvg8A9OqfawId1Pv4z4ItX9dX7\n9XNv/n2r8vkPARcB/w6PZa99B3WMPo6so1mu2i+u8Zv/DfiS9o8BTgGjfeN9BPhT2ndvfcPbf6c6\n7jqd+b19f38YOH+tTrzqd88B36Sfvxs413ctpx05BUwCHfoWbuA7EB+CO037O4C1Gy1MyObz7FV9\n9r/c6fa/EeN6NS3A19EnCOt3n+fuFqZuZRzvRmHqdccA+PfAj191/2vA1yMC1txV1/4+8J/084/R\nt7ndLf9uQO8vAD/d930B2ZAOAn8Z+ELfNaOL9t0uTH2875oLdIF7+77768Bn9POj9B08gfdzdwhT\nf7Hv758G/sP1xkr/tsAjfdcfQQTHtwPOVePYAO7p++4dwMU7SPMR5BDzfvqEH51Tn+r7+16gdVVf\n9QtT/YKWAywB77nDY3m1MHW47/p7ub4w9RoqB1zj2VbXn0vA/V+N9t9p9ey1MN/3+RJy4rgCxpi/\nDPwg0uEgE2Ws75bl3gdrbdMY07tnBJHCl/Q7ECbqf+edwj7gkrU27P/SGDMJ/J/Ae5BTkQNUrvrt\n3dD+G+GG43qN+6aBRauzoe+3dzNuZRzvRlxvDA4A32WM+dt911L6mwiYNsZs9V1zgc/2/X038u31\n6J0Gnul9aa2tG2M2gBm9Nt93zV5tkrhL0T8GY8j62D/HLiH0wVU0cveM33Lf5ybSzlFef6xm9ev+\n8XrUGPNzwL8FDhhjfhPR1mSQA/nTfXuGQXj5jsBae84Y8/2IQHSfMeaTyH4IX94XGWOMd/V6pOin\nP1Z+fb11+U7hZnhsH3JIfz18P3J4ePHWmnRt3FU+U4p+G+d+5JSYwBhzAPh54G8hKrwhxIRkuDHm\nEc3UmLV2SP+VrLX3vTFNvyXMA/uv4X/wTxGp+gFrbQn4i3w5rZa7H9cd1z7007IEzJi+VUx/ezfj\nKx3Hu3UMrzcG88A/6ZtLQ9banLX2V/XaxauuFa21H+57zt1I8/XovYwIkAAYY/LIpr2ov9vbd830\n/30Xo38M1hHtzYG+7/Yj9MFVNHLlnL7bcL2x6uEK/rPW/mtr7cOIRucYYjZaB1rAfX18XLbWFr7a\nBFwP1tpfsda+G6HRAj/1FTwmGT/1i9vL66/LtwPXWg/6v2sggi2QBEyM912fR8ydr4c/B3zUGPN3\nb6WRr4e7UZj6m8aYvcaYEeB/B37tqut5pIPXAIwxfwW4fzcPttYuAb8H/IwxpmSMcYw4Bn/9G9f8\nrxhPIIvVTxpj8kYctN+FaDHqwLYxZgaZ4F+LuNG4XgtfAELg7xhjfGPMx4C3fjUb+QbgKx3HFcSv\n6G7D9cbg54HvNca8TR1488aYjxhjikg/1NRRNqvOofcbY95yh+jYLa5H768Cf8UY85AxJo0IyI9b\na2eB/w94wBjzURWk/ybiWvA1A2ttBPw68E+MMUU9uP4g0Mtd9OvA3zXGzBgJnvjhO9TU3eB6Y/Vl\nMMa8RfnYRzbtNhBba2OEz3/WGDOh984YYz54W6i4dluPG2MeUbraiLAXfwWPetgY8zHl1+9HFA1f\nfAOberO40Rp4BtG0fUTH6R8i/nA9/F/Ajxtjjup69KAxZrTv+mXgGxAe/r43uvF3ozD1K4jAcwFR\n2V2RLM9a+zLwM8iitwI8gDg07xZ/GTFFvIyYWX4D2HPLrb5F6EL2ZxB7+BywgDjX/2PEiXIbWbB/\n80618RZx3XG9Fqy1XcSh97uBTaQ/7mr6b2Ec/xnwD41Exf3Q7Wvx9XG9MbDWPoUEevwcMpfO6X29\nfvjTwEOIY+s6stiVb2f7bxY3oPdTwD8C/isiMN8DfLteW0dOvj8NbCDajaeQDeprCX8bESYuAJ9D\n5u3/rdd+HpnDLwDPAv8dETyj29/M6+N6Y/U6KCH0VRDT5gbwz/XaDyO8/UUjkaefQpyc7xTSwE8i\nc2oZCaT6+1/Bcz6B8HcF+EvAx6y1wRvVyK8AyRqIOMZfAWvtNvA3kHVkEeHTflP6v0QE/t9DgkF+\nAXFc73/GHCJQ/Yh5gyNtexFudwWMMbOIc+Sn7nRbBhhggAG+UqjZZAH4TmvtH9zp9nw1YCTlzH+w\n1h644c0D3FUwxvwYcMRa+xfvdFv+uOBu1EwNMMAAA3zNwRjzQWPMkJpf/gHiE3cnzSZvKNRc+2Ej\n+d9mgP8DSTUzwAB/4jEQpgYYYIAB3hi8AzFhryOm3o9aa1t3tklvKAxirq4gZr5XkDxiAwzwJx53\nlZlvgAEGGGCAAQYY4GsNA83UAAMMMMAAAwwwwC1gIEwNMMAAAwwwwAAD3AJuawb0S0+etZ2uRApH\nUUQcS2qMflOjMQ6S2gMie2XyjP77Xtc8qV87VzzT4DgiNzqOwXGMfnbo5eZzHCe5B0jaBuB50k2H\n3nr8holBG42G7aer9xiDi+m91zgYx2rbdt4jbdPEusbF6Uu4Gys9/Q3ozysYxzbJbmbY6R/HMfSn\nH+x9H8cxQSBJcTudgKArn6f2jF2XxpPvPmT9vLR5bCxPqyrfuylLtybPrm7VcLMSLZ3PlRkbljxr\nmYJP4MlvXQ/yrkatNjKUM5IDrx21WWvWpF1hm0JG+iM/asgWikKfzXD2BUl0W6t1wZcmd9sdIs3z\nGxsYmZIUJNMHyvhZGdtf/tEnbjiG3/E9P2Cfe+FVeWarydy5lwAI25vcnXkmBa4rfRWG4Q1p7AaB\n/amf/lkAzl1Y5Yd++DsBWKp8kY2tNQDqjQ7r6zJfTZDid3/19wD44Mce4X2PSF3VwzP3MjMuuf9W\nV9f45z/zbwH4K9/9F7j35DFAeO7KHJg7ePJZ6ecf+6mf49u/VfJ5/qVv/fA1770KN6TxW37w7TZf\nVJ7xYlxfeC+XTpNOC280Gk2yWaljPDw8SrMpkeHZTIzvNgEoZzOYWO7vND0OpksATOZnMCnJ9NAN\nayxUJVnzmq1Q14wITssjFwv/u1mH5a0NABaWFhguDwPguS74wp++7xLHXQB+6vv+23Vp/PgPnbab\n25Jgvl0co668P1zd5PxWG4CVWki3LZ+9XJ6hvKxle/yIe/ZI0Ygwm2U06wMwXoz5zKurAFyYW+M9\nx6SNHeMRdaVv/GyWl9alb547u8poSvju4ekskwVtsp9mYUPurzfa7B2WuT41WmBkVD5/6EdfuOEY\nfuHx/2k//p//H+nX1S22NuW9mXye0akRAOJOTKDjlium6RrpPxtaRvKSZujQwUNsVoWvNzY3qTZ0\nfIgZzsn4HNx/gPzIkLa5Sq22LW2emmJ0VJ4zNFIkl08BUCqXiCPhqSCKGCrJPfVLa+yZkjyvk8dO\n3JDG7/2BH7fplKx/URRRHhJ+NK5hY1PGt9MJiDQBhWM8sllps3UMse6XnU6XTkfoSqdTZH1pZ9pz\nMUbWLUuU7K+OY8llZNyHhsqge0MQhsneU0yl8XwZ364LjY7wUtBsU8zLOH7/3/hfb0jjD/3L37C9\njej11gK9mNzT24/NzteA2Zn4xuDQ21MNrl5wHcMV63S/EGH6XtPbC21MpLfHsSWO5Y8ojpN99ye/\n/2M3pHGgmRpggAEGGGCAAQa4BdxWzVQcx4nGJ47jREtiY9MTErF9YmSMJe6TMPu1Rf1IntN3AjbG\nSSTYvmKHKnV+uYTcf8+XPXs3hWoUjuMkzzFmRysk3+nz+55nDH1aMye5aDGogEwUxYShHDuDICBU\njVIYhnienBqKpWKimZA2915ylZSevNfQU8QZw65pbNfaBJHcvO1WyZXkIfmRFO6wnGIPPlAmRk6Q\nYSeLQU4/YdSlkJcTvkeaoClqrShu45TyALQ2axgjp6tyLkNshNZ2NWZ5bgWAXDqDVeVLJ+yS9eQk\nF3XB8+VdnuvgduT72kaEn6/vjkAgalRp1kQ7Vhye4Mi9pwA4/9LjBJ3Gl91vINE6grk2H2H7z1TX\nxNX82P/59U5z/ff1a1ZvhJTv880fFQ3Qj//Tn+GXf1WSXB9+wCFU9d783CZzC5sAXL5UoVoT2p97\n5RUWt+X7Nz/wbv78hz7WI5JOW8a9o9oQgDgKcVxZaqI4JlBezqbTrK+vy0/jgHIxs/ObWI7hzeY2\nVmnPZ8v0eDnR4F4Hvu9SKAhfeWnohtJ+33PI+NIeN58jl1OtyfgYW1XhvTCu4SMajpzrMVaUqhWe\nk2W6o9rVmkt6ahKAdieilBLNxGXP4VIkZRfbrk/QlPZnMx6HDko1llTKwdWhS6fT1DpN7cIYx0vd\nkDaAzMQ9TBZFizTXslS2ZT5trrboOjIPMq5HTrVOTiZNISVtGcn5lAuiVTPpFK6rGpZui+G03DOc\n81ipSLvaNsXpg6I9CYzhlGpS8iaiVZOAxazvkfaEB4eKaYa1X5e3UmzVpS8vLNeYr8rnD+2Cxsce\ne4xKRbQz2WyBuTWhd6w4iRsKXWdfO8uhfYcAyGUKzEzKe1NeCt+KBiedSpNTbU4z12ZtQ7ROvudg\ndN4UCgUmJmU8g8UW6+tCV6vVZPGyfF5ehX37p/T+HLm88FcnDIlc0Y5tXr5EuCXrzeSxEzekMYwj\njM6JbrdN2ZH2j01M0O72tEXbBKFq01xLN5T2dMMAx1Fedr1EMxWFMY4WXgmDOJlPnu+TTgt/1RoN\nNrekb2PHoaRzpd1uY1R7Fdbr+Hp/04aEuj+7MTRvIk7VYjGJ6eR1VkJjkp3K6m8g2a2T/yZ7PLDz\nUJvIEFF8pTWmtzQbs2PhiSMS2SK6Yu/vt2iBdxPqptsqTEVxdJUwJd/HEYlqzfYRY40l7hOuXs+0\nd4Uwpd/FDlcIU71OdAxYuyNMXW8D6+H1hLhroV+YEuxssr1XiUmx30TX65Odz61OQL0ui3+1WmVN\nF5HLS0usrKzo97Wk/Q88cC+PvE+q4uRyuR2BzjE419iI4zjGdXdMC2aXSsqZYyMELXles9bAVxVw\nzh8mNyaCUhBt09BNKV/K4KRUP93t0mr37J5dwpp8f3zvw0xOyWY1lKoyOzcLwObGGrm8LJjtRkxK\n2TXuWuo12aw7nYBMIG1IuWlaNVn8m2FIq6bq/iWLuYnEvqZTx9bFHNOKA1JZoesbP/JnWV4QU86F\ns+dod2Q1aQdtbNDVX8f0FL796mnTJ9T2c8f1Tde9H++Yvt8w2Jg9+8Q8d/+pE/ze//xdAFqdgwyN\nyaK6sd4lioWWdiukN7u2tw0dQm3zy7zz9DsBmBkZJwhk3FvtBrHWVu1GXTLKa90wpFKXjWbUiZib\nnwOgmIEjB3tl3+LE1HXh0nM0A+mXe48+jKvm8Xx2+IYk7puewVdzXjuoY9RcX84XKBfFVNdut4lU\neGzX64RdHUcnxOihwUQG25B7KmcukY00qXkp5PB+qWS1PDeH2ZI5OnF4nEiFr0UTULPCq41OjZSR\njalczpMy0icjQyOsbonwVa3Xdn2wGbrnGEFXijeUL7xC+6w8Y7MVU1JzWybjYkN5j/UsnUDmgeul\niXRzDmyEm5W+2ag22DMh479nNEVlQ9ag//bEGkenpO3Hjg5zfl6+PzE9SrOtG3ujjbE6F50Uw3k9\n6BUyrFSl/6qtFi/MVndHILCxscnwkJgjN1frbK/KIWcuXCJbFhPuwrkVpsvCOw2vRi4n7zpy8j5s\nV8Z/s1alsi3902q3EtPuzJ4Jug1ZM1KpFEfukdJu5y++RnlYhM2ZvVNsbMh6YBzYu1dMeK7rE3R0\nXfEMcSyf0z7Ul1d2TaOf8um0VYiPIuYXJan3RmULo64QfjpDEKtbRtDBiY22wWEnAb1HNiNjF4Zx\nMl+jOKKrJlocD6MCWrMV0lJ+T1WqFPIiIBtjaDelT4I4Jt+bu1GXwMq7ipk8qVR/JZfrwxDj6GHf\nOOBcsS9eQ7nR/7cBY3vmPHaUAH17qjEGk5jtSA5g1tqkH4hJFBRxn0xgSSx+yTsAXHOlUHYjDMx8\nAwwwwAADDDDAALeA26uZiiIi9aIT52xVs0Um+dwvIsYmxjo7WqfdaaZUlIx2TvLGmMQh3RqwVjUH\nJkqk36tNKVeYT6Ldy5yu617fwU7b03t8txMlJ+Nms8XWtqif5xaWePW11wA4d+4cy8vLANTbLfKq\njh0aGqJSkdPWU888SbUqKttv+dZvIZPJ9Ai5Jl1i5ts53exWAh8q5enm5DRTni6TyskPQxvQqusJ\n2GYJ2/KehrWkC3rajyJUcUEUOORTWhIxniCnBd5nDudZXBHTT8u5nDhdZvIuRXX83NhoECq/NBsB\nTk7em02lEkfCbKZIrCfvmJDoJuqAxlFI0NjSdnaoVOS3b3rbm/i275TqCx6QTsv0WVtdYfbiLABn\nXn2V5555FoD5uVmiHsEYruUJmUrlGBoSLcnI6BjFopwOa7Ualy5dAkR7kmi13qC8cCubi3z2OdEK\ntdxhpvbdJ+3/0iJjZeGp2PWotTSYou0lanEDtNvCsxcuzvPZJyTJ9/vf+o7EIbfVbfAHT38agDAw\nvP2BtwHgexkuLb4MwBeeXObJp58C4PChvRzYL5qyOIpZWTkDwBPPP0YjUAfboIXvSf+88/R7b0jj\naHmIUM0brUaAJ0pOsukUedVMxFFAV0/8tWol0dwUS1nSRp3O1yKef0na7DU6FCfUlFyaollVbcfC\nRZxINFDVV0NKR6Reqx11mY9l7raiECUFN+UlFoqtrU06TZkjLm5yer4RPvv5z3HiuGhS9o+P0Ngj\nZsYvVJewakOMiGmpJi0VgdG1ZrsW02rKWpMvl8gF0h9PnV/mvoPynFP7ihTVmnr0QIvn50Sj2Aw7\nHJgUrc3CZjvRcE9NjeK0RKMRWUil1LzoOaQLomGJ3AJPXajtjkDgwN5pxnR+bPo1LuRmATjz2gJd\nK20eKedpqDkyXxqiVRVNWWV1kwP7TwIwv75Iravv9eDUg/L91MQIc+dknuWyWbYrooGK45Cyvjed\nTSW8Xy7kKRaFL1pKK0DWy+GrO4M3UqJ5dnbXNBrXpVoXPvI8D0eDdFbXN4hieWY2l8b1VDvjmUTr\n6zk+rqpqup0usWqsbGySACPHjQh7634QJWb8yLq4KbEFNtoBSyuiWZ0cKVPSwI2w1cLrmei7Ldrq\ngJ71Unhucdc0OjbEVdO849jEWuJgMKa3H19bExRaEho9x+CYfmuV/h/6XIL6XC3sVZaA3hpmSBzW\nr3Bqp8+WZO2VKqsb4LYKU2FkieKdTSERpiyJGaPfpBbT51clP+p72o6A0zPb7dxIsqkCGGNRmQzX\ngJsIFDYRKMTN6MvtpmCTDWI3cF23zyRzrSGCRqNBTc1RQdcmAtGZs2d5/PHHAXj13Fk2NipXPBfg\n5EP38+a3ShH7ifFxIu2vx/7wUX7pV38VgHypyCPvewSA9dVVpsZFTV4u7/icwI6PjeftCJg3wnpl\nE1/ltPGRITKy3tCuhnQbshFZC05HBJ+hoQyB+s/Mn+/gubI4DE+UKZVlY+x0Y1Yq4oNTaWxy7ryY\n0rpxE3KqSvY8OnWhdW2zTkfNLkQxbb+r92+Rm9QFjYjastzjplyGJ4Z2RR9AOwzYbsrGkYosgU72\nRx99lLOLIoA89KZTfMdHvxmAj3zwA6gLDtuNBmdnzwHw2Ucf48kvPgnAuXPnCTrSzvGJcU6clDqp\np089yL0nJOptYmKcUkk69A//8A/5kR/+EQAuXryQjJW1b0xN2edefJIvvSpC6/zCGqmcREZNje6j\nuT4LwNbyBWKdW1nj4Y6KsLNn+ghLq4sAbG6s8/SXvgSAHxtabTH/ZLJpPvei0N5utRgfmQDg4PQB\nLl2SSMxPf/qJJHruIx/6dvJZ2XCbzRZnLopA2grWabeF9189+yx7pu7ZNY0L85foLQ25QipZPjYr\nWzSa0s5cJp34TOWyeRptMUGlfQ+nJu+dfeU8zUXZiMdHhzhXkXsO7vcJlN7KxiZFNVWvLG/iqlnr\n0Nc/SDstfL4cNXF0Q3SdnVU+sJZ0SiZVKZ1ha3t3ZrD5L73I0rwIAvceO8XwiIzhvvFtMuqbGHQi\nutmemaOLFwmjWhNJSC1QyKQwKvTvndlDqiBtaYQhWfUJOrUv5JUl6YMnLrY5t6GHJTKodZ9CysdN\nK59i6Kovo+vAaFHm7lylie/sfoManxylWpO1wfUgrZGD9xyYYasmvNNuVFlblrWyE8SMTgpdYWuW\nE8dPSzsbVeJI7h8ZGaWgkWjptE9vILa3tjngHZT+vO8ocwvStyPDYwwPiS/VmTMvsbYqQkepXKal\n5rBarc7oqKyzuVKR5erufTTrjTqBtq0bdCiWpUP9tA+Bp/c0sMg9w8MlMmq+NnGM1cNAHFk6HV0f\nrI/n93jNJL6kUbzDd+lMjthV5UbUoVZXQbjT4sC0zNehsVGa6odlrU32G+O43Iwzcdp3+g7vLl7P\nT7jPYVeUDD2/4h3zX8pKBDx6pzU9f0l7hdmu9xzHODu+VzZm5yAKXs/VxvSZGq8QuCyJ55YF7O5p\nHJj5BhhggAEGGGCAAW4Bt10zFfQE5z4NmrVx4mge2Rjbc8g29iqt07VONP2So0O/FJo4s8c7Uqjv\ngNE2RCLmyi8dA9c4MVkLN+F/Lu9XNaTFwVGHzHq9yWvnLgKwuLxCqSRq8ma9zucfFzPJxvbOiXl2\n9iLtlqir9+zZk+Sl8j2P4SHRsrRbLYqqjn3X17+Xhp4g/suv/xahWtY8B+qHxGHywQcfwHV7Q74j\ngYv6dXdydWncJVBz3vqlgFxKPje2OqTVwbcThsRKd22tzsaG5o0KYGxC6A4aMVFBTlT3nbqHmUnR\nemxurBCrerqyWqOVkb700i6uRva5jktKVUF+x7B1WfrMGENVTzBRECdqdzflEKhafDeIfRc3ldLf\negRqm6lsbLL17AsAnDk/y1NPvwLAt3zTN/FNH5K8S4f2jvOW+yT67233naL+PTIQW1tbSRRmoVBg\nZEQ0UFfHpF2aF+fTT37ykyypadfzU4S9AX2DcGg6R7kkTruPpsu88IRogsJGlen7vg6AU29+G+M5\nMXucW9jGRhq51KySGZ0BYLo4xEhWNDIXFyqsb8uJ/Fd+5Xdo6sTJ5CP+3098AoDjBw/z7OOSt+v5\nx57l9HveDMDI1BBbqg1stjdYr4oD7/LKKsbpBR5UNYfM7lDvtkgpf/rpPIFGgNZaHZpBzwQckFON\nWLlUJtYcRXEnZmVO+Or5Jy+yt6xmrZV1Zhelbd/5QJFI+e2JC0v4K9L+g1PDNFdkHLMXRsgfl/7J\np0pYq1Gu3QZd1Qa76QJuLDSmvRRj5d1pUfdkHc4tSO6kLyx+gf3jvfxHWVzNc1XIZnByPdOPS1rn\njecasqqtyGY90o5oOg4dnKagmpGlCxdYbcoYHjkwzuS49MELa11+8/OitRmdzGFdMRXlVquM5NQc\nVioyXtD8cvk8flad3asBp46UdkUfQGmoTCYvzzm7OkdeIxO/4QOPsLkhpvhHH32MbdUWbqzX2K7I\nmnjPPcd/h5+GAAAgAElEQVQ5fEQ0mWfmXsauydg6xHjKR+1Wi7Y6f6+uribRcGPjQ6K9Aw7sO8zw\nsGidgqBFS9dl3+/S7Ur/tDtd6mr2K/o+YbD7gJfa9jye6a1VLsqy+K5HVjVxUezTVcdx10akNFoz\njmNMz17l22TtdByHrLp6OJ4h0mjBdqeTRFS7rqETCo2Rv/P8teoWeTXL7ts/RXdd+N3UIwrqhpAu\nlXDV2X03SDluEjUpOaH6Hcpt8n3PWdwAPf2SNYbgCmuPOtZHO5oyHAer5qh2axs3LbR7Xip5jusa\nPH2va/o0VjFXWcDkkTH2iuwCN8LtFabiOCFezHz9n9UTvz/iD5JwKIu9MqouEax2otWu8FW6yk+o\n5+kfxeD0zHmxsyP4WHCSx1/ZgXa3Tgz0wjWTlrFZEUHi0c98ludeFL+LrXqDoxo10m5UKaht/tjp\nB2k2ZAFfnZ/j/NmzAGxsrCWTfHx6D22dtJubm+pPA47vcvzEvfKuT/4+v/Wbsnn9qQ+8n5wmpevZ\npkH4xen723F3t0kVhn1c9RmJm0Uay9KujbUNXCU8X8oQZ2QxWZ6v0lbfJS/vsx2qebMW0NLQ81Od\nKrm0LIAVZ0egTOdzlEdkAe+0GgTqv5P2PEyskUJOlo5OtGa7g5eW7z3PT1jEwScMbiIsw1is24uA\n8vE1+V02VyCTVT8BN8XiurTzF37nf1DXvvzrH/sQB0rS33FsKajfSHHPRCKUh2FIp74TvZNRU+b5\nc+f4Rz8qdWN/+7d/OwlndvrTfOyeiusiW3A5rGkt1uqjzC+Iz9r24vnE3B15eUbG5J637L2Pxz75\n+wAsvfYioSOLqp/JshGIf9PEzH5OnHoLAE99/lGshvtnC6OkivL5/EubpHQTnzl2grSaFz/5+CJH\n94kPD84S55dlw9qspHCM8FJqwuP83Jenpng9xI6Lo35tnSgE04smSidrgMFLfEi2q5tJyHnaLTN/\nSUyZ586vktkn9+89MM7BozLPjpw8RUHH2mbLtJuyube6WRYrOo+feZWHp4RnMiUPdNOstsPEv8X1\nYqBn5glJ9Zy7boC1TkwhJ7xZNOArg6WxtNV82owNRU11kHaiZFl0nTRxKPd0upa2Hn6aF2YZG1cf\npabh6dcuA/DmE3sp6ebcCWIiK++958AUC+sqNHdrjA0LL19Y2aCp/Pumt58mXRZh5IHhaY4c3/0Y\nLq1ssrwiJrztWodYN8yos0EpJeM2WsxSqYhQaWPQj4wMz9BbjCcnxth7SEx16VSajCu0tNotSiUZ\nn5SbIaeCW6V2mZVlMYNHJwyNlvBmJuviuSLsOo5DsShCR2lomGpb1vpSKnNTvo25jMVx1I8p7CY+\nSum0j9VDYKvZIaOCpO+7eL2wfjdOXEAyvkdRBaVMJkuskbidIKCj0cyFvEs21xMiOkTq52ecFFbn\ninFKtHVOeFmXgwfl4FRtNGgFPcHHwbi741O539DbbkSm6gkvfdF2xLh6k+s4V/g0obzUDQOMHkJ8\nzyen8zhDC68owt0rK0uYlHyenD5At62CbRzjeCpYGSPMAsTGJP5W1sbsuG/vRPztisZd3znAAAMM\nMMAAAwwwwJfhtmqmgsgSRF/ugG6tTUx7UWwTTVBs+vy/+u+/ykW/X32YlIe5ynEsUeMZiBKPfku/\nhNxTZZirzv83lePHmETj0+mG/P5n/giAz37hCdKqISqPj7G8IcenUiZNWk98URRxaVZMgUEYktO8\nH0E3SBIdrq2t8qQ6qaf8FMu+nBzbQTcpe7NvZjpJCFgqFpLSA9VqPcmvIo6XvTbv5Ea6EaJulq7m\nVtm4tILRHE+mkKKu+YPSJkVenViHJmIq2zIWnaBLVfPENDF01Mxn3tPECfWEFFoeevjtAJw9/xzp\nvEYLxi6djtDXDCOsOmyGriVSh/i07+/kCPFJyj54rk8c7v6E4RvwdUyKkzNEvoyDmyuRzcqpfXtz\nk1xOo5WMwx98QaLS3nzvCWbeLmY+Q5jwbxTHCTO3qgFrc2I+C+Iun3v6DwH4V//mX/HySy9pK2yS\nkC620c0ElewKiysbfPJ3ngOgE/vkMqKZqqdybC+LCSe19yCfeUJMjWOFbUbU+btea7DdkJNiyk/h\nWS05021x7AGJkjp+4IOcnZXTvDtyAtsS3tjeWMGqCv7D7/kAx2eEf555ZY3FWdEEtNsdco485zu+\n+f0897z0ydmlCm5hz65pbEcRqOkiNFDIiQYimy6S0rkyOpJHpwSRbeFo8kobGZZXxXS0XQupVIU/\nZyx8+MOS7PT+hx6mF276zd/27cw9J+V2zs4vc2FNNFyd1Tp7HxAz+/DJAmqdoVQsYlVLZR2PRku0\nNbG1NDs7UWLXg+u4OGoGSmezlMqiJZkZy9HWAI3tdkheT+OFbIGsJsfNZzLUNmVM5jaaLGgGxlI+\nzcVNcfi+sNXmzJzMs8XaGkZN35c3moSa/HNlq8mKat+zqS5do5qakVH+6CVZmxbWHuPdp4W/9h+c\nJpPfXVJSgKVLG7z4vAQsRI2QjGp6C7ksxtMggmyE2ysh47q0Ne/V5z71GO2O0LLvyAgHp6fl/lyO\nbl3GLfYN01PiYrC2vMHSJTFp1Zs1JgtiBs96OdY3REvZDQKcUPp8aKyUaDVrzXpi2nPSDjbevZmv\nUCgkVpcwivC1tFDatzQ1Ua5HnGij3AgMPS1rlLgh+H4az5G+NQSk1Ek9nU0TakR6u9MkioS/XNfg\nupoLLoywqp30vZhcVp8TRUyMi0bv9P3388KXpPxTUKvR2WXQEoAxcWJuc4gTy5GBxGokmuMdC5VN\nSuBAWrVg2VRqJ9dcxmVUNYnZyKGte5i7f4S07p2TM2Osr/U0mwHNsLeXR0l7IruTTDy6au+/Wha4\nHm67MBVGvQ1iJ2Opjfu88mOSTSeyV2ZA7/lPSZqEnagmk9QachJBxutLBtafEdx13cQMF8U7g4qN\n+0Iir0yrcLP7mGM0ZH5thcefegaA/NAQM/tkcra7XdaXlwBJ2Lapi1ez3eL3PikL8tbiEqmU+orY\nmLQuZNXNTS6ck2ixkydPUtQ0CXuKk4wOi8lkpDxESevY5XIZKhXZ1Or1ZmLyGx4ZoqBq0X5z342Q\ny/mce06Y8+wLS+S1XX4mjaPmhEajw7Am1PP8gJTe06y26GjyuFTaxfM6+n0dzYvJ/j0T3HtIEiFu\n15epalj51GSZWJNkXj7bIIrkB2ErxFUTXhhAS6NZjBNTGpb+G5qIWZ/f/eIWxdBqyAYRXZ4l6vnV\npdL4BRGmOmFA0ZWNvVDIJj4bs/U6a+oINep6iVDrmJ20qNvVKhfVN+rs+df4F//6JwG4eOksrit9\nFUVBIty/wXIUAGMjZfYdE4Fl9vIW6V4EV6PEurYtWy4Tqzlkc7uKrq+UxifwCr0F0KOkfhTDE5Ns\na3LDVDZHUSOCtipVNi7IIpwvl9mzV/rt3mMlTh6U5++bKvOZz0oqkMgPcB0Zx3Z9mVPHxKxy75FR\ngpuIrA3iLjlf+N1L+6QyagIhi9NLj0IKoyYWY3YSHXY6rUTwCQ3UeqYCx2dsUjblF1+7wPiYmK+O\nP/gwS18SM+jGVpWtVq9eWsTKZYn+Kh/3iXTd8jyPtGY6j6xBzwkYazDO7swnxZxHqle/LOtTKMnz\nbBTQK1KZdfudFmI89ZnaCi0vbwlNr8w3WKzKBlsazjJUzikdXRwN3c0OTeLoPG4vzxNoiPzK2jah\nmgtzQ2miSJh/q9Ui0LY9P7vJZFmek7Ed0hpJtxu0t7ssaRb+PaNljh4WwWeiNIrpyPNnhjO8oqbg\nThzhqK/k8qXLfGpD+v7+tx4jp+b08YmYTrUXxWawLeHloNbliU/JQZXQsndG+DQT+qxHsh489fSz\nNDfl8+mH7+fUm2StcoyhoAk2HRxstPv04FIjVj43W3VMzzfUBJhY1sj9M3uJ9EC4VaklCVcjExH2\nzLu+Q16FiCgMEz8pL5Uind5JgxOoqS7lu/jKa516m4geb7oUC9JXuXSaUHl/enyC1IPat8trrG1u\n75pGiDHsuNT0khEY4yQJNuN4R5RJ+R5pre7hOpDWQ04mbSjoWkUcJv3jZYvMnZ8V2rshXkqE642V\nhUQA3wordLvy2bgOkSYsdRwX03MBiMNEPrBRlPThbjAw8w0wwAADDDDAAAPcAm5/NN818kxJxFxP\nvbdzDo+5Su3WX18vcSDtKxuDTUxyJt7RuHi+h69Or9hoJ1uXMYSqpneskzzTuU4Cz93A6ntXV9YT\nLdvRI/cwqXW8MJZZ1V44YczFCxcAOHf+PAsXZgHIei6+Jyed0fExDh08KM85dowDB7Qi+eQUQxrZ\nVywWkqRoNooSU6m1O07/QRCyrTlsWp0OqW2tSTYxRjGzu9IACxc3qW9Lnw2PDpPKyDsnD5UpaumX\nymqdqtZoK0367D8tdFeXC7z8tKjRg25IsyGn22effZn3vf0DAKyvLeErHfff+wCvrkl7jQmpbMl7\nXcdS0AiiVq2ZHL2DOKarGg3PcVldklNLpRIQB7vXaERWHEEB6pVVbNin1VLzkJcrsNwQM4mz2eKe\nt74bAOtn+a3fE+3i5U9/hpSaRD/yLR/j9DvfIfeU0qyk5PtPPPZp5rR8hOP4SVLbr44+agcXlit4\nRTl1HT6eIqX5gfaOjfC8ngiXF2ZZnhPePHHsOHG7lwTQIaO5k7rdMDlV16pVQkdOjd22Q7stWqrK\n5Tl87bfhmUOMjQvPep0Wl+eETyanZpielmSR//kXfwM0gu/I4b3QlhPw/n0zjGgun90gl01j9LTt\nECXOtsXyEC6aRDKKdkqs+GGS69e4AQePiab32ZEUWo4PL1dmUc0Gv/Qf/wvvfLskI/2r3/Ih6h3p\niM1KjTCUfrBRzNaWzrmgTEfLDhnjUkir1szxsRpQEUcx3V1GbpaHcpT11B25kFHzUBxEOPqMXLpI\n29N6mH7I+TVxkl9LjbMQi2Z6NawQqCZrq9bC0RJRYWBJa6RjOpfjoYfF8b6yUeXCRaEpjCNKedFC\nu/ksz18ULVKjVWV8j7oXuA4bOoWWqh3K7d1riRvtOi01S03sPY6vY7W+epkhpd12DA2NyKs6DnmN\nTAzaLVzVXr32+BmOHxKt1qHRPUwMyT3rKxusbcp45sIgCb6otSpsXpL5vTZ/ibYGBTz2+LMsL0sf\nPvPkGb7ru2TMP/JnH2GzIbTbkKSW6m7QarUxGv3UatdJZ6Q/49gQaVmlVrvO2OiE3t9MoqXd2KGp\n0YVp30+0OYG11DSYKYo6WJ0HxsSJI7jB4OleWMhmCFS3YqOQrJoI4zimpu4b3SBkfFTm6MzkFJcW\nL++aRskC1ZtcTtLPxob4uoCk037igJ7yLGXdT7JpH40Hot3pJFGoExPTZHXfWry8zIbWcMzns6xu\nyucgWOfAjDjQNyqrZH3h541mJ6nCUyjkCVVTvV2v4utYd9stduxfN8ZtFqZiwqgvgk8FHzHz9T73\n1ezrC0yUkMUdQSwZDGfH5hqHcd9g+Hga5dAJukm9o/mFOaanpVDl4cOHSCvTWNsftbeTPKxf6NsN\nbLxz//raJmVNwnjP/n1JksqU75LSxev8a+fxVOCaPXue6TGZMMdPHOVND78JgGNHjzE5Kd+XS6XE\n78lxnGTzdfqyuFrH2fE1M25ianJdP4kQC4OYF597EYCTx+7hwRNHdkWfa1KM7xW22d5o4GuKZC8d\ns74oC6zFJFmlO4td3KiXJd1NzJV+5GniN1isLnD2okSEFbOjrK/KJJ06OEGck4SWT33xWVbPNLQN\nLpEnG2Ot1qKjfRBhMT2OTkWJL5XBELR3Py1K5SGKGp5e3d4m6veZ662RzYiWOmiNT+7lne/9emnP\nwgof/3f/AoD64nne+VaJbnM8N4keKeXzvPKCpFj4zKc/TZxUBXhjEnLuBr/96JM79SqdDns0seue\nYZdUL2N9pkNBw9u7rQY5rVU2PLWPbF5q43U7HZpa9LjV7rK8JmbZjUqFIU0iGXZDhvYfAiDOBKxf\nlijVT7w0T6wdeuLEESZnROg2fpGMmqm7NkWjJTyz+vRZ9h2XNn/jLmgcGy7R6cpG4HsQBbLp5Ase\nKSPM0Wx3iUK5JyIgjtQPzjY5dFxovP/0AWafE58ZP1+m0ZVxeuq555nSwrjWuFQ1uWiMy0henl+J\nW7S7vaSyXdrqX+aYFFm7c3grFaWvWq0O1cbGLqiDg5NjSUHprO8nyUfTjoctyXtcN8VaV+diCKtW\n7vHyJTZfFB6sr28kSY4LhSKTY9KWFVPDy8taaRxY1c2zWqtzaL/STYOqHtAqpQyXNLFngS5/6hGZ\nu3sOTfE/PiXveuLTyxwdl3nw/l3Q6Kbgre+ROXTPwXvoasLMM7PrTBaFH5fjiIoKHV3rgxZKb3W7\nDGn4frdS59WnJJp6vJBNxifqdEhrmoxyKYej0ZmzwQYtjc4Muj4NNQVO50ZZi3oZ1ls8/vnnAfi2\n7/hmjBYEbm9tEga7n8udTodQBf1UyiVS01Wt0SJWk1xr6XKSPT+0MSlfD7/tmFD5sd1oEeo65zg+\nWRWEg6hLt5d4kyhZZ5ycBTWJToxN4WlfzV48n0RNbtfrSc0+J47YqspcHyqW2L9v9/6Lxu74jBJb\nMurrN14ukMvsKC56mc5z2Qxprf2XzqSTVBaVre1EUHUch7T6X1YqGzzztJhojx0/wT2HZT+rV7dY\n0TQlYafNkKZ8eOaFM9Q1Sen0+AixSmtRHFLQAuDdME4igHeDgZlvgAEGGGCAAQYY4BZwWzVTcRwT\nqlQcsxMlZ2y0k6izz6RmrYPtS2u4Y26zEO/kjuhF87mumzhDLm6ucElLLTz34pd4/kUpeYFrmNTT\n5MG9+3jXO7Ti/Z5pyik92RkvcdR0HPfLIgOvB+M4RKqK7nZDijl18o4jVualTEoUdYk1qsDD8IDm\nhxrKF3jTaSl/MHNwhqLmP0mnM0kq/jgId3JsxTaJSurXTBlnJ51+EIZYfZfruElOLgxMaRTL4uVV\n7jt2WO+5vnxtw4jL5yXqam2uhqMlCzzjYrQtftEk+Z7amzELl+SE5+VcxmdUfdyMWFmUE97qxjKf\nfVIi2v7M+76NvHqju4FLsSVt3Fp4hi1NCJlLpUmV5Pnl/Sm6y8oLnShR+8bGEqttxkk7ZHKZ69LV\nj5kH38VDKVENv/zE51g7+7QSH+CpJtP3hjETUhJm6sRbeeC0OKLeU4h4+5Tkijp0aJo9qgUt5fNY\n1cp6YUhDq8qHtdfPuWP6/n9TeWN3gWdefCkxpblYzqRF61DMOrT0VB1GPkdPPghAAZfCiMybiQPH\ne2lfGMnnqa6LNmrp/Ctsr4vmoFavMT6j0VDlEk1fo/kqS+yz8t71M+doqulw/sISJdWIOKVxRg9I\n9BeuQyovpoVwZZVLS2u7ptFNQVHLtKRzPl112t1srDKlWo19k/tY29CTbqqUJFZtNJcxmsfo9Ned\nZH1O6Gq0OmxqeZOxqTyFomppq1Wqym9dDBo7QrnssueAtH+oPEpQFS1ONjuemBC2q+tMZ+QebIqg\nu7vT8MToEJUtmUM27iQmv0y5RI9jbDukrsERT57dYLaqQSKti1TU/DgxXE6CRI6cOMS994sW8YXn\nXyVTkjFfXd3k+Zcl8CVdGOI9b5HgheHUFhs1Ifbi5QVOHpD+PnVohoful7m79+RR6lXRHDUW/ojx\nzO5P+8WhAs64aIuaccC2RikubgRsbsg6dGF5g4DeXmLpas/WgxaRrgfjo1k2VmXOPfP4M6TVyTvr\nO+T1nn0zU9xzSPkunmB+XkpHxWGHxpa8q5gqsGdIaFxe32KzKpq4LjC1R+hdanVuyprheR49lbrj\nBhJ8glgSeqtAqxOwqFq5TDZPWjVHbmgl7B3otAIyGvhTKJQo6udas5ZYXfyUm2imhoeGSKVE65Qp\nDJMtija+slEhVI3Y0toGI7rf5NNprO5tm5trFNS8++BDD92QRgnq2infMqbJpo8dmErsT5G1eGpi\ny+VyuLoHu47HmgZsbW9tJ4mqjTHJ3l+tbfPkUxJRXSyUOaxuMaury7z8igS/OH6aD3zjewEI8Xjm\nFYkS3djaZmREaE97ho6ayMvlkcTdYze4rcJUv/9OZPv9m+IrEnj2EF8RzWeuyICemPmMpaaRV0uX\nl3jtjHTca+df5uIlSTOwub2VmLe8TIbVdVmQv/TCCzzznETbHZjZz9EZmUin7z/F0aOios5m3Z0s\nq7tEr6ZeOutz4IBsKFubFfwk+3Aaq8lCTz10P5mMCHFve8dbkszemCiJyOm2mri68XlpL0nq5hjT\nsxxJzSLtn26nk9i5c7lckm09iiK6XU0W2eqypr4faysLtFoyIQoaavp6WNtoUNe+LO8bwmhW6cZm\nm1AXsWw5y6iqSjdsLQlxDcIuzU0tPNuMiXp+Y8ZlqSIL3drqZQ7s14Sm3TYnp0WoOf/Aeda2ZTEh\n7WE1NLtQLBE1pD9amSqumh0tLrFGmLe2gmRz2w1G953gxN6H5Y+xvTz1O3oAqLZIa3LF5tY6TkX6\nuP3aBdafFHX/R//CI0wc26dP2hFMwyhMss+fv3yRLzwrdetiGyTmP0EvZNgkYblX+gW+MSiYAtWu\nJlCNOjQ1NH9j20kSuKb8FKmMFpH2MuRLYvZaWlhgY0kWt33H72ViWni8U9/iiCY4PX/5HFuRjFdz\nu0ak0WLWcdizRwT3Q8fuZWlJVPCtTsjKmvhGzTx0Pw0VPF899xSjQyKQlstTrM6u7prGODR9n0ki\nd7fqW3iBCPhpMvgaQZnJDBOnehE+IXPLspkWJ8Y4evygtOfsORpZGceDJ/bQdUWYefHsy2wHYqpp\ndDtk1Kfl+KmDHL5ffByz6SLFjGwWQ8MHuLAwC4g5oWeuj2PI53ZXQHZ4ZIhmVyOWA4egJetFENdI\nqRAZpVN0NQXD7HaLS0saau977FWz6tRYnnvvlTk3OlwmpSb049ND7L9PhOmXzi3y4qsyhienD/L2\nd4qv2MREmm4oz/+j3/1Noor89sHDY3ia7qSx9BoPTonpcv/HSjjt3a+n03v3UhiTDX9qci/PPCbz\n7FOf+CxF9TOLmg3yuiG3CDBoclEbEbm9tAEpCtr3jc01uprdPM6nibs6L1vbFLJ6SCvk2dDw1WZ9\nG19Nh91GGz0nEjiWps6hZreNr2apXL6UpCjYDTptyGuUcKu9nRzki4USXTURxzam1ZH1phOFeMp3\nHiRVNmamDvKmN4tfZqMdcua8CAvVWkRsZV13nEwiTG01XVyNfm5XVjC+7Af1Vsz6lvCJdWL8TS0i\nnUkxqklBh7IO1epO7dgbwbHRFZHNvQoQ6UyGQM3Q+Vw2qTlY79apdWRfH8mMUh6WtSeXzyf7pZ9K\nJ37OrWaLivpJtdst1teE31bXN2lo2o9CKZW4yBw9fIAvPCsKFiedxtWxix1LW4XZTNjBuwnj3cDM\nN8AAAwwwwAADDHALuM1mvp2EnBitYA3imGZ6GoWdU4ukmu8V8yM5ngdhwMq6nIzPnT/DxYuigZq9\nNMfSopjSulEn0XxZx+Co+jAKwsTckk6lsKqaL6RzzOwRLcjY2BieRkXEcYy9iSrnYRgzvyDOqo5r\n2LNHTtVxtJP2v91uE6k5slgqEqjq1DgkdZZ8L52oPMFJSpFYoJd3zHN2tBextUnSzk63y9aWSOnd\nbpcNzf1z6dKlpMr5gcP3MD8vkVp790xhd5mAzTEeJ04eUlo7bK2qU3gWmqr1are6bBvRMgxNpPHT\ncpJYmq/QaPYab5M6SZkhh5FpodWjQaEoeXzy5Ni/X071733HN7C2KVqJxeocPWukbTpknZ5pr4Tb\nUafFXERbI+bqnZBmc/cRROnxIYYmRLt08kAZU5K2rb58mfq6mMPGggp5K07bY9kio72EekFESyP4\nfLNTjyp03MR3/dXZeTZVm1qaGINOz1QT09X8Pd3OTp6ar0Zc34HsDLaoifyigK5Wjw/i7SQqKbA7\np60oitiuafRitsRoL0KmVqVelVNmsTyWlAhqL2yxpZFjse3ia8GxwDFs1YUfJ6eOMKx5jPzKFlqG\nka7xqG4L/ywszyYmk+6wRyWs7prG8eGZxCzRCdusb8qaMTScxU3Ly5aqC7i+nv67FUkqBWRSEUN6\nGh51xpkvyJx+9MyLVFUzdeLhE0SquXtp8TxNTY5ZGiqxJydmu4fe9CAtff7CymWGR6ROn592JLIY\nGJ8YJ6O5cwJa7BnaXcSiF0NK51DkppMkjY2tbdYj6b/LrZCKlp9KD5c4XBCa9h+cZiovLggp2+L+\n0xLsQrNFty5m2+LeSQ7fexSAPTMnmBkSmsb27GfmgGi1HKeFrwvSQ4enmH1J+sl2Wzht1dwubhGH\nsk6kXAPO7p2z773vvqScSbFQ5rAGMmytrPPF//ZZAFbObVHSpI4p6xDHqhUyHmlde6rbTUqqLSdu\nJ8k2O8QQau6tVoPnNA/e0SMHaW5pMlLfMqWmvc2tFrNr0p/tIMJ3erkMYwJ6OfQyaqLbJSKPWNtg\nI59I98BGtcPoSFFpz7GwpH3bV4IlwDKje8zXve8RJlTr+7mnnqOq5uK2ze7kVgzcnfyLkcVXnulG\nAaHW6YvdLFbdIozr0tbNp1ZtUNDyObET4Zjdj6OxUeKrYFyHjJqVjXHRbVGi+nWxiyyEseaEMoaM\nOpq7jkmih+MwJGhrUt4wSILYHM+lnaypETk14+7fO524xZw8fphcRvOyWUu7KetKPpelrNaZnG/w\nbqIK2W0VpowxdHTDvTQ/x6KaClLZLNOanbZQKCQq726nRbstk7DVaiV16Obm5njiGTGTLF5eSJ6J\n3clYalwShrNhmJjA0ukc+2dko3zLww/ztjdLpMjh/QcZLsqmYON+tXt8U6kRGs1mEiF4aGycWP2t\nemkLQISpWCez75mELmstrg725kYlidjodAIaDWGObLZAUSOsyqUcTq+2YBxTqYjadXFxgfPnRVC6\ndBKZQfIAACAASURBVOkSs7OzACwsLCQC3ff/4A/y7ndJkdliLt9XmPP6vkVrFzeoXpZFstXu9Nxu\nGNtfxNd6XbXtFr0Y8/pWGz8vm0m6GNPo2euLeQ7tOQjA6ZMPcu9R8cFINT1GhkvaT63ENDMzs49T\np++Te5ZauGl5TmW2RvmQmJlCY6hWhV+ajTaB1lmbnMmRK+5+VpRLKQoT0g+lIwd435FvElrW2zR6\nflgGom35nI8iTh+XaEunkMHqAmscQ6C8s9Fs89SLUhj5137jt5JIlXJ5iO01FaC6nWsWSDW88QJV\na/UixpU2pEpj7FNTXRyMsOHKAt42MRk0i3ymwPyizFfr13ngbWLmaW1vU+kl6oy3qNXFhN6IKwQI\nXa6bSkycGd8jrSaNio1xh0S4yLgZutq3y5VlbKQZwbsdNjSCKMLZddoAkGzJOZ3Tla0tfI3gazW7\ndEuyIRrX0NSN3jjgajLYTq1NvqiFelNZ6rqxhq02W1qzreDnGBkS4SSIg0TAjGrbdDbq+nywGrkU\ntCMi3XDbnXpSay2KuswvL2gbXCy7C6uPoi6jmojyzOwyviaZ9IaLvHJRzOatdsR6XenzPE4elTaW\nR0axdZkfQddSGJE1MfKqZHPSZxk3xNXD3eTePexRHgnqGxgr/eG3KnRW5ICxevEsc4syVuN5iLLq\nOxpDGOqhIrS4dveCxsGDB5L6dwbDkK4Nf+cHvo/6RTlcLb86x5AjgpITG5qaiLJlPLoa3RZ0a7Qa\nWsPODYh7B9jIIfRVsGp3uLglAovn+HiaHXxsLEde3Qo8zyG9qoclGzBa1r7KZnbC6B0DN1GQ2zVu\nsl6OlIcJNOq0XqsS9ky+riXtCD+Ojs8QRrrw+ikeOCXr+NjkQc5dlDm6ttHC9UVYjppBso5G0U7C\nzDAME/+gbhgQ9oQR30sS3La7XQL1I6xXG8yrADV5bC9jE8O7pjGOo53afFbqCwJ4rntlJZSef5aX\nJe/vSFZxzwcwtknx8sjClu6L1WYzqXVZLpWpbstBrlws8eB94pO8trXN2Ii0uZArsl+TCtfrDbp6\nCMy4BtcIL40WMmwvze+axoGZb4ABBhhggAEGGOAWcNs1Uz2T1hNPPsnvP/opQJzcpvbIqWpoeDi5\np91q0Nbkj+1Wi5aqq5vNZpIKHm/HlEJfos2428WoKFwulDio3v3vetu7OP2gRMztm95LRh1mo25A\nuyUnaccxOPrMfml5N+i022TUyS1fKLCxLie1VCqdJA5NpVLEUZKzPtFkmT4f+y8++TQHD4nKttVo\nJ5qpsGvpqLbuPe9+G0ZPus89+wyvvCyaj4sXL7KqkR+1Wo1ATYphNySjuUd8z2VqXKKnLl64kNR9\nGh6+vvNrvdqm4XcSOnplOYLtkFi1ZN2qpaPvTKV8jk+K9mH/3inSgfTNwYn9nLpXtFF79x5h47Kc\nAJrpLmVtw/aFNeoa/VRtbkJKPg+NuoSqjZw6NcXXnf6zACytzPPyRXFQDaOIWk14JIpisrmb0Ndu\nLjM6KtEdh4ZHmRzTqvLjw9R03NabHdpa922smGVMT66uDejq95dWNri0JCaTsxfnePZZybUzf+Ei\nlSXRHNiwkzhRBkG3L9eUTbRRljdeM9Vu1klprh0vjlk4I86YuUKJjFaqHx4ZTkzHJlXgzItSZ3J5\nfokzr0jOnk5ji/sfkPl04sR+NqrKd60GBdWaRO3/n703DbYtye76fpl7OuM9d373vrneVFPX2IO6\nRaslgZEshDCNMAJPEYSDADsMQdgfHDYOB/gLDsLYWHywwxEgjAGBsYShhehGQVstWq2uHqq6a3z1\n6r1683Dne8989pDpD7l2nvNKVV3nuZoKOWL/P1Sdd+4+e+/MnTtz5fqv9V8GMy6zeDU7EoyO6XFj\n1/XJxtJZlHJ9Prh3k/HEPevERAQSoNrb2yGboT8/DO9cu8yalFhCQySRwzmWvgS3xknNe49DChYl\nA2rUKxgKJf7OzWs+oPWxExuce9yN2ydPnKMt2nG2yCmWhJ47OuT2fdeue3fvcuy8S2yZ6BoT0RNS\naY9YPFbd/oBDGedxFBCo+Z52NhjRkrljObHs3nVelV6YcEtKnpzYXKaQtrbjCF2492b73jYLUlpq\n8+Q5AvFS1toNFO451GMIxdtsmBBKMHdx9DY2lQDf7S2++TVXBuhLX32Nesed/1in5j1QtUZCOd1h\nDfVH4E7a7QWQOc5Yg1ISFD4csL/r2lsPLGU2S6w1UVmrNdSMpV8jPSYbl9RVQTGSc47wmdI5OZPU\nPZ/rt+7y+CXnxVtZXeNA9NPCOECSUUnikJqM8ZSMVOY8q0CF82cstlpNrzPVbrWx4kHttDueGoti\nzYVzjs477I7ZkWSN6/d2+dZ3JMsy+KeMMxFujWvem5OOBp7mc4lekhleFDNzjPWeKbT23vU0T8tk\nQZS13G64dj15+jgq/MHJSrOw1vrSLK1GjXTi5uZut0tdxqEOpskv1iq/nocqpBAmxxQ5E8kALgjp\n9ty80g4jvvAZl1290FBsi7f0p37qZ9Cy7v7jL/9LFsUz9cd+9qd59kmnRfXK916nKaXNWs06sfRD\nOk7Z358/yP5jzuaztFpu8vmJL/wE3YEb6C99/7e5dsMZAlzn4dSlMlhoNqNOKa/SC8pTZoBXWl4/\nfpInL7nOffHZ53jqovu8vr5JEjfLGyIvVZ0tnmLjvZOZmv/l10HgMxN3trcZDN1LYoqu56qLwnhl\n5iQOuSOT4OrKCusi23Dm7FmOSybbrZu32RQRyRvXb/Pqa27hq9VCWpJd8cu//A85EgXY3BR+9dVK\nEwl/H9ZCvzjWkoS7t1y20t/5W7/EF//oHwPggkz8H4SwFqKkzpMy0O+79g2HEzpSRLWRJJw57trx\nEy9+lidFdmG1s0iz6VyoSaNFKqrFd+7cJBejubNyklC4w6WVVVJfy9Gwtii1r+I2xrhF79T6aZQu\nDdYDnrq4JMcrn95r85TwESbw7t4OqcSWrHTabErNs2UdsCrPbbMZkbVF8f3giJd+0wnGvfba69zb\nd8bu7e0dIklXX1lcYEf6+8T6KitSn+zmzWtkIgIYDgPySTmWZ6IH/w3wfDZZ8C5+MxpSE2rpsZWI\nVBamgbZk5THZmGOnXPza1p3bPLjijFYVRSTNL7j7ry9wKLEH2WRCXsZC5AoK14eNWoueiOUZAm4+\ncGM/qS2xVHfjZ3+w4zMcAwICof+GjJlIhtg82N478FUQjm2uMpAMpThpMEpdnxsV0AjdnNRJAtak\nosCd7r6fwA+OhvSleO7jTzzGz/6cK3S8vHHCb1RqUUwhRmgtGxMO3dge9Ib0RcV/1Bh7ccAgH1Kv\nuzF82IM9SbEPtfWK0B+GB9sHNGRxW4wU3T13jjf2dziSjLl2d58FMdp0ve6VpJ98/BKrx4QWTJYI\npUCxNiNvCKh6h0JW0nD/NuM9lx2W796mJ/P13/tXd/i/XhJqN7UcW5Y4sAVLLlbH+U1LoyEGTqT9\nHDQPFPjMZGsVtZYzjsfjjH7PLXQBKUpoZBVY2iJeilFkMq+YICNPS8maEVaELidmquBvAkNPNqo0\nAtbkmd/d2ueBFEAuGg0C2YRMTN9XXLi1c4+ebMbX4paP35kHR8M+gaS6TUzuqxFgFUoKFKtIY8pQ\nkSBibcOFxby70+PqO04CSBOSSCH2sN3GynhcbNUJfAUQgxFKMQhrXuQ6K3JfIy+qxYRy/CifYEMp\nvBzGrDXce6zjhMPBfAW5AUaDPoUU8O40IgZSPSKbjLwBlRCT2rIuoaYkzvqjPrqsZFAUPtZ2eLhN\nU6STnnniDIH+/QC8fXWfQuK/4mJMT6ReGvU670qG/9bOFk894WwCrRRR4dbORhRSSAygqjX9M50H\nFc1XoUKFChUqVKjwEfCxeqYA77bcPHaMn/+i84acf/Is3/2uE9za2t72AW+mKCjEitZa+wyMfrdL\nXtJ81tCsOzfhyRMn+cRTLtjs2aef5fxZ5xFZ6nQISv0eGzjhS1wgXilSqWZvbgZ2Rg9rHrz+2uvo\nsMwm0aRiFZv3VLuPZPd3uL/H3/mlXwLgM5/5DH/4534OgBMbx3jrDVfu5cG9LbTsvIyCxy4471EQ\nBtOsjiz3nq8oCL0+V5EXnqbUQUAsJQ/CMOLuTee6/vY3v8unXvzMXO3rrNQJxAWs45BW3e0U242E\nE6dcts+l4+f45BmXHXTq2Emy0scfBJQulvGw6yncZmuZtcedns2g26VfBszGMaND587O7BbL667P\nWsWGvwerM7qZ25m1OiFh4O7HWD0j35TBh4iRzqLZaNISuscElq6UxqmFAYkt3S2Qiufr7/ztv8ff\n/Gv/PQD729ssHXfjLk4iEvEKnDl31ovN7ezvenHaMxcuUJOd9KDb9946hZp6SGcdFT8kD9Wof0gm\n2VZJXONJ0Rl64uwJvv32DQByrQhsGUxvaS86z1GUBPTE/X3q9PMsSzbR/uF9Rj3xsBQh44GIf9qC\nLHffm9DSkp1oMNa+DuNgdMRC09HB3VHPJ18UykBR1rOD4BE8jPXGMt2++23cG7IrVe6jcMKlp1ww\ndaBqqExKc6Rw/ZrzHh4d7WPF+3142KPZdm1vrrQ4ITXeavUlxiP3vBbbHS8vHKuM+1JjM4oMxxed\nl/adtM+RBMbGy22MCKFlWUpTyueE2vid8Ydh76jL3sAdu6YCv2M32OmOukg4KR6orSxgmJW6SxGt\nltRIbK1SpOX3C1CUXrIQ+q4/sv2rGMSjn7S5tu3O/4039xjKb2Nt6fWEBu8brLxziYJmKMc0LVF9\nfg2m0ajHgXigbBAjSadEjYQlGXd7l7dIkIDpbIiW/jOpYSRzelJYRj2h9rLUv1uBhUzKyUww7Mka\nc2f7gL4k6+yGuxzuOe/b43/ox2hKRmn+9n26ffc8L7/+Gosr7jln68cwk/m9Nusnj4OIiMb10Huq\nVaRZWBSNQFJ2Sk9c3PJi1qfOn8GWnr5C0RBNwfrSEgPJGG7XEh9KYoxhIqVlAq3R5fqR54TiRQ+T\nmNKFOS4mGHmOoQpYEUHlRqeFCuafUx/cu+VCGoCNtSWW2s4brAAra/lkNES3pF7k/QccCtNiC8P6\n5jF/b0YSDLa6Rwwk8/ioN+Ltq+65/OZXv8Heofv+xPFTfP4nf8Kdf9gnENZof++Q73/vFQDSyZhb\n4rH6/KeeIpeA+KPDA9Y/JOxlFh+vMaUUQZmWaWFFFFc//6nP89R5ZwT1uj1GUrgxw2DlgQ0GA156\nSaiU732PltTYuXD+PM994hkAPvHkU5zYcBNHK2m5LAnA5nY6ILSeGlZKPVTQeBalAWJmBEXnwa/8\nyq9wWoy4Fz/1acbjmUxDNb1uKO16sPXAyxhcu3aN7S3nTq63mmysOePk9IkTPmV0lI58NI2yyqub\nX7h4ke+94gRItZrW7FMKEonhisLQi5bFcUJH6KvjmydJ4vkUwv/EL3yauigYq0CzKCrt9SRmSbvJ\n7ezSc7SaLn5knGdoiW+a9LuMR27Ap7mhveYWpfUT5xiP3Iv/4P4d1k+49OfBaMLWvjOUTPMWSsQE\n46Tm4+Em+QQjzzlTylMkWlvGeWmYgDHzZ4EtLi17Y6pRj0hlcuumlgalhIPiy1/5TQD+1v/2t9nf\nlpiKICAduEU7yEL6IgD3xv4OazI2m8uLXgj2zt17Pl138+QpDnddplj36IBcfosGXzzth2RNBYEm\nLak0ZbBC5924e5+uLLi1Zo1IivFm4GmDzVPHqcuk2lluYDJnlHX7h/QPZcJPlZ+oIzWtS2gmGQPr\n+keZnJpMjIPeAWlbBCUNxFlJuWsvBhsqS705X0FugDBRDEWK461rNxmJ8b6xXGe95Sbn0WDEHVHG\n3lKaQozHVqNDb8/d52h7wIuPOYpz8/xTtBtu3mq0lqiJyGcShZ4a2Uge44UfcZRDpxmiF1277u9t\neepwMrLkIl8wHO2zKZIJq0vL9Pc/WBV/FgGWnkh+bJvUF7+NGhFnxUB/5vlnOXXWZcFevnWHA5G3\nGJNQGNfHjSD0sUgmzQilNtzo9ncJD9wiY2wf3Xbv9GT/Jl/5jvTZfkYssVS5LViSDMWzyyGnlqQW\n5UJOZ8XdT20hIE/nLwJ8NOjxQLJFcwKimkixGMuZ59yacfPVm2T7khEdJHSHUhy4MPTL/laGQLIX\n1xoNn9bfGw1IrTs+SwK2hmVx9DH1mmzSF2ImsnFKOoskexK3NxmCUIGxUQyFjryTTVyc0pwwcYiS\nzeHQZuSyeQuDkLGSeUsXjOS52BSyvDQAc9ZPunWiFtXIyrWqbqmV2elp5kSggSgISEphZuvmMcCF\nzoRlndXYh9Gk1DBBGdYR0BZB0YPuAUU8f1yYUpZCxJ5rSeKzKfcP9tiWqgk3b9zi5Cm3Jnz/tdfY\nfuC+P31ig1TmvWG/z0TWvL29ffZ2nJG7d3hAX2IxjTE0JZbtK1/9Kk9IbO6P/+hnuXjebRqPH98E\nmV93Htzl5nWX/f7sEyfoynkKlRDr+U2kiuarUKFChQoVKlT4CPhYPVOBwtMzKgz8bju0IeurTvNh\nY23D02pGK+7LrvHrl7/O0Y5z3X36k5/m+edc+ZMnHn+CZXFtxkGIFY9MnuZo0aPQ76F4Sq/TB3ml\nfjfmpxaiMKZ75Lws/d7god+W96G19vcwGo95QqjJ8+fOsSP1pi4sdtiQLLjOQsd7Mu7dv89QshoV\nikCyEZ968knefssFhaZpSij0ibXTaiWDwYg4LjMHFacfcwHuf+4//XOsrM4nFHjyseMzpVm0r+m1\nGpzkwrLT7MrSgvsPnKcmjmu0RBcrrDWoi+u8EcYk4pm8c+sG46HUuMphIBTFMOsTtp0nywQjX7+q\nSHPv9VBKEYgWEgYkYYTCFljxWIVRjHoEfaLFxQ6dBeeGXgg0bTl/bDWRBGMWueHl74rW2c13fIAk\npmAyct6ZSDd9zclBb0RTXNuj8YhQqOAoib23IEszAhFqXV1d95pKg9GAiWSW8QiZpT8IjdVTFKUO\nm8nojt0ubbB3BIl7n6J6k1BKN6RoYvF2HDtzhmXRHFJhyFiCwnuTLt2h87Zoq32mZ0hIKM8uH6ZM\nRFdtMh6SSxsXl5fJJEB4kA1KHUViFfomKxuQPYJnLstHDGUsjUcp5d7RorlxQwQQjaEnXoSJCcgl\n2D2hw7133dgrtsZsPO12/49ffIIwFHHM4ZBAPMxWGYZjCb5PB5y54MQum0nA5dvfcvcwzFhecu/0\n4eGEVDLrcpMxHDrv9J7NCOx8WVKp1RxKCZlmu8kokzGuYp4SKvL80y+wvOSylvYHfWIR3lxcuUBN\nKJV6XCNpOHo8P7yDarkwAsVZsoYbs/HoXQoRzX3pG29y5ar7fOlsnZUTLhh6mKZsaqdz9GOXQh47\n4x7i4rE6cfmKhgXRI2zhd/cPuXHDeacLQqLIjUFLweIJ5wmnVePOVdHpihNSGTCFtdRkvhmYnO3M\nzTE6NbRK0chOgwtPOc/d0unj3PrSr7v7PMj9PDtZqLN6yq1PcT1BScZfS1lqQhn09rpkkXjNmnUf\nAD0PMjOarosUJPKemaJgVJb/KiaeaYnjmECysuN6wZo802cuPU1PWJ2bu1sMJGMuHWc+yD4MQk/P\naYvvH5Tya1JhjUtiwgW+5EKJaq0RjVrGkwEx89O1rSRCqvZgsOz33LvyG7/1Nc+oHB31aYhY6Nbu\nPi0J37l9/zbbonG3d3jEirAGB/0BmXgMa/W6VwFYW1vhuNCC6WTIzpYbq//hn/oFJnJMHEWckgz/\nXr/LcdGcun7zAYc999xfeP45+lv9udv4sRpTofI1GbFaobxjLPLxUEWee/MjS3P2tpwbb6He5Oe/\n+EUATp06TavpXJiBDinXsaKwPhNMB1OjyVr7kOE0+3lqWD18r+UxQRD4CXMenD9/nq7E/HS7PTZF\n8iHLsvfUHZQYhTj2gqW1ep3tbdfeSxcu+IVzd3eHmzfdhLK8vMppKSCbJDV6kvp78cIFFhZcn9y9\nc/ehjJkFWcTr9TpnpIDs4dGhX9wXlzte5PMLX/j0D2zf0WRCVJSFpRXHYvciH198klBqnJlwQkMM\npTCKiZLIf87F2smNYSRijCvLqySn3X3duXWLgcTyDLhBmDjjUgeRF8UzylGcAJGyKImLiIKIQgz0\norBeKDLUGqvnFwpcbUYckyypNoqmKKwXGu5Lf//Kr36JL3/pS64fimm6cW4NgaRyR3HAoCeSFtmY\nQykIvLS8zMHelu+TMq6u0WgykrEznox8DSptA9/eH1ZSXzAz4E0YkgZuEtMqIUzKibpFUMYuTVJP\npwZJjbCs2ddsoSVb9MH2DTLrJn9daN8nRRD5d10p5RnLdDzytSKTWpudvbKY8JA0kSxbNFquWw8S\nT4HMA2sgid2EnMRNr4o8yQpu3HOTc5LEdCUj9ag3ZkGmxJwak113/6vt40yk/3Ot6Q6F1hwOfTbU\n2tIi+3suHbvb26PddkbT2TNnGQuddufeLp3M9e0kdTGMAHmh2drflbveYX357Fzte/12j7EIPLYC\nOBR7O1lZJpC09bjRZjJxhlrW26PRcPfVbjZotSXDcqFD1nPSJNngKsmSq0sZ6gbFgTvp5WtbfOeb\n7wDw6qt7PHbajZennznJC5909eDU8B51MUzPnE6or7pjLBbjNzMBev6a4+zvHNDddfePjWgIrZqa\nlJHUXAvikLG8c/0sZSL2QWwsZ1uuvXFmqS25TcLpC6c5edIZYsfPnqKz6eYwEwU8e9sZZV/9f16i\nkDFbaydsnnVzbmd9mbVVl+m7tlBnbUko31qbnSOh6Cdj6o+QAQ7jqVQOFi21FK2xBDJvJbpOSwzb\nSAXUxNCI84wliXW6uLZGTQRxG9drXJG2jGwwjZvV2odIBAoWRAVcK+XjaY+Oun6djsOAzIhUUZF7\nB4glwj4CsRWYCR2h6EMzYEekC27dvMG9e+7z0vIKVoy4ZqPmQwmwlo4I6CqlWJT4xf4kZZKVMj2R\nr1rSaDS8QKixlm1xUNTqdR97PBwNPc337DNneP55t07fvjFm+xVX2L53dOA39vOgovkqVKhQoUKF\nChU+Aj5ez1QgYlwAKILS/DXG75QLNaXAwiDk2ScdBfbME0/68xhjvNAexviA8kgHaDW18N8fD3ul\nZim/90v4mp8KdNjc3KR31Xl5ut0un3jmmfJiPotiPB57ccZ6vc4x0ZZKkoQrV64ATouq2XQ7kStX\nvs/f/bt/F4A/8e/+As8+4zLfsiz3GQ/1RoNTp9zuqd/vsyq0XZIkPossDEMfTP+VL3+FZTnm6jvX\naEndqj/9p3/hB7avERoo9XSCOseazqsW29hnEIKiLlpUx89fpL/vvG3Dfg8lXoxAGaLGNOCxXnO7\njdZynVHP9V86uYFNy8xOfIBkHMVTz5uxnmKzdlp2oLCWTOik0FricP7A5cUQVoTOU7ny2R17/RH/\n7Ne+DMDf+B/+OnfedmKFwQeMteFw6J+5Uop+z1FgeZb652CMq+cIkE/GtMW7OBwN/PHS0Lnvfx7E\nzRb5fbfLby8soaX/w3qDIJZg4eYCoYxBnfdotKUUQ2vZB8crpTk8cgHCD+5fx5RtMdZnyhozcUqG\nuHqVuZo+IyVUwWDQZyw01cLCAkr6fzJKp1m8KiMy81MLk0lG79BdK8sKanUJqi0KlOj6hElAIYHb\n/e6IFyWrdEUvcadwXpkv/PhPUcudFzVVmv2+ey7jdEwh1GSRjpgM3THDcZfuwD335fVNWkvOC7Kz\n12OkBtLGZXZFWDOIpmWHJumAbHdrrvb9y+/usdAQ+v9eyhOn3XNr2wm1pvOYTA73uX7NBZFfefsy\nl55zx6w2M+ricTf9bcyV3wScFk9+4DwF1994hd/5mhNq/cZrd9m+6+jrF58/zo+96MbC8eaAzbaU\n11nqempGJRFqUtKYFivvvTYz9MQcGB71qIvXtFVfoCniohMzYSJexzObJ7gduXnz0PR44fOu1FGj\nsGy/Iu9omvLJT/8oAJ/5Q5/HlKVKCMglOFsrzXNPu3Xmpd961XslxmmKlsD6zvoKp8+5ZIS3l9sc\nk4zCuNmgnbt3hUHPeyznwSyLkOe5r5EXxwlGPEFJXGNB3sUizUiFrsptwc6BG3dvvH2Z85eeAKDZ\nbtMSGhcUQ/HimaIgEp410Gqq56YDljpuDegdHZEIDdpuJPRFeyufFExkvOeoR6IyA12w0HTtvHfn\nGq++6cZkp5FwQShpg2V7y7VlY32VTLzWB/s9jCmfkWUgnuE0TSlkHe0NuiwuuDG/0Kp7gdDxZMJN\n0ff79re/QyTt6h4d8Tu/9Zvuuhok54atB3vcunUDgLt37tCqz89ofMzGlAL7u939GOtjgnKlfDFk\npRRWhN8KU/jvjTLk5eJiDaE42LSPAgGlwg8whOzD2XnlPWhmTIGZPz9ijEq5GALcu3+PLYkdSpLE\nvzRRFGHtlP8uY6miKKJ75Gikw8MjlkW9udlscSBG01tvXebFF10tpizLvIxAOkl5/HH3ItXrjamK\n/Hjs27C9vc23v+3ifPK8IJbikaPRhD/yR744V/viIPQDO7IBOi8Vd5WrpYcTRQxCd+6dBw+mtZeC\nGkZcxsMsp9t3i0kvLQjHbgHZP3yFNHeTc4QmiBpy/gK5LKFVGBHdy4ucWDIR86JgIhIUaW4ITRlX\npRmk8xc6jrHEuSxuStGX+/9H/+TX+V9+8RcBuHvtbUp+uTDG14QEKIS2G6RTvt2NRXc/o9FoWmzU\n/weXyizxCXEcMh7PUFo/pFipEjqOaS05I77eWoKaM7ijZtNn8EX1FgjNF8UpYeIm80arTSqp38PB\niOt3LgMwHvQwZTcrg5bCv53FGrnIkQwHxtekS0cFRSb9EBsCiXcMiQllnoiDmKxUcmaMzeY3KseT\nlP1dqe05SHn+eSfS12o1GWVuoaw16yShu+mlZI0/+gf/hPt+qGkr167P//i/Re/ATch3dvZ4oYtw\nqwAAIABJREFUcNdR7r1Bl8VGqYBeoGSA9kdDL3w5zgynzrr4qROnLnIwcotIEIc+pm88LqZzoQrp\nj+aL0zgcwuqC66fto5TBNdeX54oDJk23KJ2/9AwLIpTcjpukXWcQ1ZtN7FgyOL/+fzO85+JWwvXT\nfPOf/jYAr798lXtbrv8WG4Y/+Em3EP3kF9a5eMZda0HvY1ZE9iJpg8xrqlC+IrtWilwywozSkM9v\naORpTl3EXFWkORSxVWUNRgrQn3j8LMe/KzFN44TPfdrRlCcfO85X9K8C8PWvvcw5kbGYqJRMFuEo\nSnwYRxgGnH7aGUrnnj7NgzedgdYbFBxI/NH97iFHMm/FzZhcpDq2BrvUZQPQCCOUnj/TTYeRnw9y\ni6/oEYaxz9zWUURROhy0ZiRyAlmg/Ptx5d5t9mTe180Gpb55GAUUIi+S5TmIwrrVmkFaClom5JIh\nmOcpSjY8k5SH5p6yrp9CzdRo+HA8uL/D3p4bk4PxkJ6IdrYbISvLzohLM8Orr7k+39jcZHXTrX9X\nr99mIJIro+Gk3JcxE11BrgImWTlfKr+JTdOcr3/TxSy+/OqbyCOi2+/Rk1q2YVybqQ+YlmUSyTE0\n4s7cbaxovgoVKlSoUKFChY+Aj9czpQOnkoZzqQYzekmlZ0qD9xxpNQ2WM6bwwpeFKQhF5MwqixZL\nUhnjM9eUwv921kFl7bTqmS2/kHvQpcn7aMzew20MQ0+r3bx9l13RSDHF1CUaxzGxBA0Oh0MCCURd\nW1sjFB2Pu3fucfqUC8o+tr7Bc8+67MU8N9y54zKRms2mp013dna5K2Vp7t2757W66vW6p/w6nY7X\nn9rf3ycSj86li0/QWZjPAs/yjFC8FVZruqmjPJKkRzMRXZNYs7PlAnzz1LC06IL70iyl23Uetnvb\n24Sy42zYjL2db7p+yvZoC50URZHfJRRMPYdpbkhlF1XkGZHsKmpRDYzrV1VMs6UyixekmwfWhgQi\nijcajfiX33D39st//+9z/fU33PnzyUM7s4f2aO+zYXuvh/P9PZ6WgZRY+l34MPb6EdFcOIZJy6BU\nRW3RBepGjYRIMu9UGHp9szipU2+455vUm6RC54zTB+zuOK/NeDyhJlpLKtAsL8n4urDK9r7bid66\nc0Qmu3xlAi9WqE1MkU3fb4aSdao1kbwfdR15rZp5UK83aNRFfLC/z7lTTr/s2aee5sYd8S5Nhty8\n7oKvW7rJqXVH89RGE+ynXBuDeo104Mbq0fgeV0XgL44VC1IWKIhCknhZztlHS9JCHNepi9dvobNK\nr3AU2nA8omRJ8iLASlJH0kg8zfNh+K/+7I+wseiOPTgY8bXXRYS1nrMlVMW9rRfYXHHzyO/7wiZX\nr7oyQLt3rrGo3XP4F1/9Gl3xxI73v82NO84btbYa8HOfde340RcTHr/oPFP1uDst77HUwTbdXNPf\nPSCOS5FXjZKyK1lR+Awya2AymT+oN4xCxhJkPJyM6Av1ZiYTAvFw6pUm8bIbmyeLBVqN0psdsCn1\n19KvfZ+DgSR3pGNSK3X0IkNLdJeKyYSlRfesfvbnfoJ/JGPk1u0HNE67cIb13sTXVDz92HE2Ntzc\nauqRL02GwsW0zIsZL1YUxVM9Qh0QyLVyA92SqrOGvBRlRvnacwNT0N9yTEihNbWa1N7U2r831hrS\n0qtlC3Lx0GldcCRzcxgqCqHxR6N8pnQbDyVjPYqY9cQWPsheBzUWOrLObR+we+DWkMFghJHyTJcv\nXyaRjMV+v08qzIIKtJ8Kw2BaQxelGA7d8905OPJMwYPtXYwwFEcHPa+Vd3RwgJZM+HZLU0ukzFq9\nxVA8to2kxvrGsbnb+LEaU5EOUaWxo5VXgdYUpXeYhABvd+gAq8qCw9pnghmjQM2kdMoPirzwLkA3\nQEvX3TT2ybzHOTnD8nmDTs1k/6mZlNF5YIzxcgFhGLCy4jJFFtptBvIy9/p9PxCDIGB/37k/FxcX\nOX/OiYrt7Oz6AVSrNfiTf/JPAY6SazbdxD4ej7l/3xkt//rrX+ell74BQDbJvOJtHMfckEzAPM+9\n4dbpdFgWxd5jGxv+PB+GLC/QYhCP7Iidwi2kw7xLKAN7MB6xvODit548+Vm/sBweZaSyOuukSb0j\n8Q/2OioRl3S9zaQs/GtSbwlHcX3qRs0z2rGjLo7SMakULR0OxiRyraQe+7ie3BRk2SOkKlvFvtzn\nd6/e4pf/wT8G4M2Xv4U1ZaHdH3KxvBLvd1r1w79cENeIZLJKkpiFNWfwEoY+3kOFiZ+IwiAmkViq\nMEqIEjcGrx6+ytHBfblNRVkmM7JweOgWvldevUcuRlNU16xsCr3ch6NdMXiLDCRTL6kFiK3GeJwz\nFOHbWlijNqe4LEAjjogTEdWs1XnnXZeNlgQZNaEyn7v4PKt1F/dy7coVL6C7Qp2FRbdA98c9n7l0\n0D3krtQTPHvmJKoM4QpDCjHAj/oj6rWynpkTmAQIiDjqujmg3VlCyzhfXFBEWmpKqpzhYDZW7oPx\n8//2aU+9qoUTfG7LvYt3v/8mg4m7/v7rv8nbMnhe/PxPc3LVbZoa6R7RopNG2eoF1KWfPvfZFX5G\n4udOHku4eFKEPReni2GAAqnDaaIca/akjwtf3y0zBkTmg1hRjMuUa4Uq5l92gij0tFqa517EuZGE\njGVhNK2IkRSxnmwN6Ms8G0zqHDvjaLu41aAni+3RURclRp9NDRM5XmlNS+bWE8dXOHfpLAB3vnmF\n/SPXP+NxwZJUAlg/vcGCKGSffOJxHtx3/dC7e++RjKmisL7YslIBuqzfGMYoef8mWerXNqs0RWlD\nEPgMNas1Vuhxkxsm8t4UgfIOhSDQ09hg4+I3XbsstZpskjEYMbKM1WgxE2q1Opkcr3LjN+bzYGV1\nfVrn01hCMZrq9YT1dbeRy/NpFQ9jLWMx+p57+nHCUsIB6zPhi6Igl3tI05zRqMzK7fvwl4VWjViM\nzSzNKKTj6snaTGWQ0Pe/VrC5LvIhCx0fPzoPKpqvQoUKFSpUqFDhI+DjFe0MppazUgotFqa1asrF\nBRpjSiE87YM0LRYTlpSfeVizSSzzIsh9LT+D9pt5a+xDAcL+p4qZQOCpxat5rxbV/G2cFQjd2tri\nS//MaRE988wnWOy4bINmq0lTXMthqD09d3Bw4LWibl6/zdYDF5QdxbGn7XZ2drkl2QmXL1/mdaGd\n7t+7RSrBmXrGbTzrlUvimLZkbKyvb9JecLvhojDs7u7P1b4sT33JOFRIUHO7n0G65/upUzvOZux2\nhIlK6Emw8n56n62u0xLCrFDgdg8Ze77MRqEsseyKwiLAlF6wfEhY7vy7Y9655vpmOE55TuqshaHF\nCLVnQkUgbgMV4MfFPBhZw5Urzovxv/8f/5Bv/qt/DcD46NBnMv5wc+s+BP8GnGCTcd97EZpLq8Rt\ntxtTYTjNLrKK4ajMnBl7PakgtwxEZPXa5e+QibhhoALsRBIfTIGaSMJFEtJedB4llRn6e+6YNFPo\n0lOpFUoCilcXAs6ccMfv7k+4c9eNhywfU4znTySoBZo4cU9qdWOVUe7G2zt3XqWunHehplZp1tw7\nN0qP+NbrXwfgJ5/8/QRCkwyH+yD15wbDI++ZVSpgIqV0jvp94rJm2PYOC23XJ7u7t1nouHe9EbUY\nDspMxpxm7M5Tj4co3A744DDnwZ2Dudr3/Tf26I6dV3BrcIsX1x1F3NJdapG7zmLjgJp4Bc2DDm0p\nJ9VurWCazjP9B55f4lOfdu/WxoU2uu8SQKyBUHb+1gCS8UtDUxj3/MmHaMryUjGZULWmACtR9bqw\nXv9taxd+57vOg/AX/+iHt7HAkpfJSZhpzVFlKTNSAq2w4onfnRz4TNB8Mvb6bLVWi1SYjSiOiGpC\nZaPJxUuSZRNUKvU/2w3OP/sJAK59/w7xspsra50FdODOs3A8ZCDzyq3b93yWYnt5keEjlFqxSlMK\nIxlAi1Ziq73gNRTzfo9JycwosHJMaLUPSTBK+2eBMihbUnuFX16VcvqA4DxxgWhaxVHoM8zdXZTM\nycOJXOX6ZjE8ysSU54Vfl6Io8MwJ2BkPl6IuSVFJEhPIPGSMnRG8Vp72N9aQztTxLROjJmnGZDJ9\npqV2VZYXnkLPsoxcgvULM/WoaqXLsoQopQnD36PZfEGgMWJMaaV8vI/5AFFNR/GVo0D7wpnW2vet\nl1cUgc9iK9PZwSUQvp9Qp/zL3cPM+dT7aSTMieE489Tk3v4+r7/qihXfvnmTJ55w2URBEHqabzIZ\n+5f51IlT7EvGw5tvvcaWCJsFYcCNGzcA2Lr/gH3JQpjMZOoppYjkwesgIJFBWas1prIDrZY34pJa\nzQ/uMAy9QOSHIWnUCeSaea58BoUJDJFy5zjVeYrNtUuu3Q9uszNxNOP+6Co7IgJ4tLfO4kDuvX7I\n/pFrU54BInIYaeXdzUVuvbHW7Y24c9/RMVprnnrC/WFzaZkyyKewlkQmt8IWTB5B7PHt27f48led\nAfVb//zXOLzn7l+b7JEyWH4vI5sM0TJeas1FtChLG2t8jbfCFD5Dc39vi0NJwQ6jJjduvgrA7Vuv\nz8yphd+0KB1gJA4nKwqOhLK2cYEW2YwgCrxkQqgUWoIfJ2PD5XfdeDAYcl1WRLCODpwT167eJpRs\nu+HoiEjiIrqDCYcTZwwc7P0GUeCMqcPhNgstFw91bv2urwowSceQivJ9NqFeLpR5TjaWjNTJHo3I\nXSsdTxhJ+vnuwS7Hxi71ezwuiEP3Lva6Q5aPl5m/im7PURrbD7oUk/nG2K9//T4Hh45aalHw/E+6\nd3t5PSGTbKawFRNlMp/l1zF6Xdqxwb23XNbe2RMha8dl45EfEVqJSypi8sKNkUnQRsl4SeyIsFzY\nbeBr/OUp2Fxo+Sj27+7OXszXX3GG3r/4+oDvvePmgL/4N+dppcIIRZ+Ox9Bw1zocjDGyMOog8mM5\naLdQEuOjtWJPakUWyrCwIsZgFKFkoW41mkxkoxqGGXWZBzOrCJqOwhsFirhTVgLIfEZbo9MmLcV6\ne0NfpLzTrlM8ynZLB77QtQYfztJstEhFGkYNh76+HjgpA3BSE6UckJsf3XVDrVBidCitp2UwlKOy\nwK3BdaGxohlaUmmNksk2iAIvgKmV9crohSmwj0BlDscTX482DHN0KRwaBJ4eUxpSiY+zGMqyhEVu\nqUtIQhiG5KWgttY0JB7AWOPb2AlCbCkYnOdMRGIhDEPft5NJ6o2p0Xg0DfFBeaOsyN8bFPSDUdF8\nFSpUqFChQoUKHwEfq2dKB4rAloF2M/SZedime28tPQfrK2tbmAamM/VqWa1QJVVnHy4nU55TKTWj\nKWG8R8oaZlyh7xH2fB8v2Afh8KjHnlBm+/uH7Ow4l3me5T4bsds9oiu1iQaDASeknMxzzz7P9raj\nwW7cuMHLL78s92acPgiAmfZPo970tfaiKCYRWqJRq9MQD1StVvc6THEcE0kwXhzHxOJqrdfrM27X\nH4zJoJjuBoyhkKw6J+Dhzt0fG96UWlm3Dr8Nids9T9IxfcnkOuhu8a5ocNlwiElL3TCFKYPOg4Cg\n1BGxBWk+DYqsR65NncUakQSvWxX6XSlmKn6HUdPEhDnw8nde4au/7mp07dy8ijZl9lHBTNWH/18j\nCCMiET1UcTz1MOaZ78/JZEy/72is8WhMmroxe9R9ixs3vuOOyQbEkhVDAcgwqtcCYinimE4sheyq\nVzZqrK666w57hr0dyVAyGi0eju3dPjYsvYrGKZvidrFlTcN5sLObsn5SSuBEU9d/P8toNd333ckW\nAxGV7Swu0TOuve/svEvUKgNXJ2TicWm2E9bXXNbe4c4262uOHtVqwuU3bwBw+eqbPPmsywostGUi\nmWOH3R7DvgilduokNXf+oohI05ICafOHf+Yn52rfH//pGrdvuLnjsY1l2pF7nxq1IYhnuigKKEtu\nTPqMCtd/u1s7jA8lSLe9TDF272isMozci85jro9cYsK33hmSGOdR+vwLARtL4r20GmPEA6IMWqjO\nGw8m/Pa33Xj5ta8O+P5VN74CY7m0Mf+yE9br03c3UkyE5o2KkCAoA6YtC1LiZX9vxHDgxpStwdtX\nrgFQr9U4fcr1VT5WnvoxZuSzvgkTBkJTHu0ece+ao1BXF9f8ujLaOcTIXDnE+ISeZrPuPw8mBjWa\n3xOOjny/aTtNWMjSwutJGQuxjP2HmBwXk+I+KmYCqbUPx3AZeOU6l6HkfYrDgLqsDUop8rImLtbP\nwUZZlIQ2WDOlVqHAqvnXxSzNph6lIPCCvkFg/DwRgF9rTVFMWRcsExEOTZX2ZFUQBJ4SdWyM65/C\nZL5UE4qH2JuyDE9Sq/tnmuXT8CBrrV83iiJ/pPCQjzebL9LegJql2maNp4fq6NmHY51mVzCr7cxX\n5WJqiWT11Vb7bEFjjDcigkB7l54pjKfYlLXeMauUmhpo9tGIneFgxP37Lp4nHaesrTm3eqvVotuV\nrJQ09zWXGo0mg757+V966Vs+s+/woOvVb4Mg8vX1aknTu6IbjakRVK83qIkrtJbUfJ2lKAx922v1\nmqf/kiTx3zv19/lctokOqImLfCGKCaxzT6tQ+yK91ih++xWnFL7yWJ9UwivevrLFoOfa1AzX/DnH\nE0sjKgswWy+HEFrls4YLrWhItsliO2Zlxb0UG+tNVjpucUuNxRQjf17PoU8mTNLhXO0DONzZJ5UM\nIle/SV6uqe7m7wlj6lEzTWcRJE20uPhHaUE6dAZjFGqMTOD9fp/ukaNTB/0eR4ducXmwfZXhyH2v\nrCYPShe5q1oAzqUexaXSsmUii5QyyhtNJp1ml+ZpQWmpWq1RYkypfKpqn2N4hAQiGq01DrvOONrc\nbJOLIZ+lEVGtVN9PCWVBWVla4nDgjIqd4RaTwmW7DUZdbt53BtfYDjh7wdF239nbJVNuvC0uBly5\n5dS2VU2RLLj3L9UTepMjf57yebWaMTdFYmGhVac/EAqtNqV2PgwXTy2wvubeozR4jNtX3gTguPke\nK4vybocRgcwFKimoCUWZPHiHVk/EEjtNxpLRRhH5uLeb3Q7//BtuLjvsZzQlg3M4GPHFn3af81HB\n8FBqHvYtb73t2vrtdwy3e+6YIGzyk0+49+lHTuR88tJ8hZwBFjoN2g0p/l2royQOMiKmkLl+bDL4\nrKS5L9SoSZxc2xacarkxXn/8NB2JI6uNBywnbt5KrJ5uzMPAZwvGzYLja5JhefEMSgy3YgwtkcOo\n1UNsKe2hCxpRWby8jto8PncbAx14hXLygljm0X5/wERobWsMYbmGMV0/C2umxoXW/v2zWB/YqZTy\ntJq12scmNuo1IomZyvL8IedDuXbmpvCxzYUx3ghVWHftOfFQpp4xFGUMVKG89AUWX18via2fG8Jg\n6gDRaiqSY22BMZJdqDWZnCedpD7uM0kSP1XneTZTczcs92hoHfj1zxjjjwnDqTTTPKhovgoVKlSo\nUKFChY+Aj5nmc1QfOOvXu9Ds1KZ7OBDdTjPHsA/vwu3v+oBSUrIGl1k0pfPUjI7HlM4zWvmyDxrI\nyqB1PRUGc/+cnyMajcZeB+rFFz/pgwNDPa05aJkGvOd57kXU7ty572m+tbUNGiI+12o1vXZVkjRI\n4tIbNetpqhHJziiOI39MHEeE0TTQ/P1K7BhjPoBa/d2IdEgo5SDCGC/GN7GGIHX3stU9YPl4WVoG\njGRknj6zyOjQ7eQ6yTr3D0VYbXdEVg5FM6bdEAqv3WBZdFwIjRd6W+nUfcC8sSGFdTsSzTRbNM9S\nmuI+jqgx7E09Vh+GYX/A4EDEMxXTXdRMUKl9hDHxbwrv9aA+Sh3J1GqfCZN2e9TECxoGgdeDOTrY\n4v4tl9V4cHCHwz3npciLCVYy2sgMk4mU+AgUVqgIazWZBP03OxGBUPkHD8bs3HdeQlNIeRGgSAtI\nS4rCEohwqNYxue9/66mIeTAaWxqSSRcnEUjpmkgFZGVNPWsp5P3DTMjFgzmYHFKrSciAgd2xo9Cu\n3XiD2h2pJ5iNub4jJTJyy9pjInxaDyjiTI7p8mDPZd9mtu81isbDQ0Yj5w2q15r0xBMadhIOSq/o\nh+Arv3qLupSNCRt3qTXccxgQs7ws73ykGA3F26I0Sc09t40Ny50d523rWcXRU/8OAHvDbd5953cA\n+J3v3+L69V05f5OtA9cH31OWMwvO89IIQx5suXdxZwBF4DKWf+xzbU6tyj2Mx3AomcmqSxLOv4e/\nsHaC7bsuGaR37V0v6jgscrTME62VRS6I2PF6PefouqP2gtzwjJQjG8YWu+0SesK9bQYyF4+GqQ+/\nULWYRPSz6sttnhKh38dOLDKW6wYP7pH0XL9FeUG2J8lA/R6FjNlkdY34EdqYRLHX6CuCwse/pHk2\n1ZyKIk9dBXrKuth86sWMosjP47MJVcZY740KwoBIvFdxnPiYdoudXkuF3kscBJqg1HScuZZR6n2T\nwD4I762D6z1rxjBDRJFnM4yTmrkH8RwFgZ4G0OupfpYyhf+ttYWPt8+zmXCfXJOO3fut0EwkAB0V\neJYG8J+1Dh7J8/+xGlNOe7DsRMiKkoYrfKHjIFBe1MBa612Y1k4Jv9kHY7HTekFKzWTiWZSa7Yhp\nTM7UADOu2CNAqH36rkuTLB+qwer5uQVrFZ2OpNHWGzPUQubv2RjjswryvPCf260Oy0suBiOMAm9A\nRWE4TQ0NIy9gFifJVJwzSnwRxyiKvItUTDdpylT+wRozbeIHZEe+HzKlmfgU1JwinKadrmiX/TTK\nDqk13X2FgcHKMaZWY1ITZfZanVbfGUpLKwOWV9znZkPTELd+qAPqYhSGaCxiNIUBqdRWs0VELkKa\ntbBOqKcL4Hjk+r7AOnX0ORFYMy1KPEMPPjwKfg/wfDjVfIClpWUODuaTtwC4c+cagWTwNdod6gNn\ndFilaLfdgnh4sMWt6y42ythpzJ8y07R3cuu7Qtcir2IehQU1kVLIugU6lN+GYMWuzYrCKzMHCpTE\nW+VZTmjkuYc1tNQPQxXo2vz93mx3CCN3sTzPMRL3NBpO6I7c820vNIjKGnnDLtovskde2b1R02SR\nFHtNDPsiqtkbDhGbibrp0Vh3VPw4H9HPnUF089677IscSHfwgExiDBst2CyL5EYLyDSB1Yb+ZD5K\nWqUpi0vO6F9ZGrG+KYvd+iWUtElnDyhE0TkcpwQSo1bokEAy49KizlidAeCN19/hy79xFYAH96fy\nGRz2aYsQ6fnjbd54Tc7ZrEPoxtGlx89yYVM2dN3L2IHIoBRj8lDmu0wxGM2/CK8vbsLQ/fbw5n0a\nEmeWxDGBKPj3d7qMpOagHQ5pShbe8rHjfk4cDvoUfh5XhPJ9fLxDe8mN9zCOGEpm39H2NsM9d//J\nYEAshatNkTG0ru0jFdFZdHPe5uY52iIdMcpzto/uzd3GgGmoS6GKaTUQHfo1IEvTmRgifCHi2fgp\nY4zPZg+09uuiKYynoHSgZyg/M3U4GOPlGbRSPnNeKeVVz/M894be7Bo8P2TtLzIKMxPbVa7B1m1u\nXLvwjog8nyqvu01jKZOgvaMj0NrbEFjrw7DTtPBrfBCG03u21q+7ACOpPDFJU+o1NxfWG03fJ/Og\novkqVKhQoUKFChU+AtT/1wDWChUqVKhQoUKFCpVnqkKFChUqVKhQ4SOhMqYqVKhQoUKFChU+Aipj\nqkKFChUqVKhQ4SOgMqYqVKhQoUKFChU+AipjqkKFChUqVKhQ4SOgMqYqVKhQoUKFChU+AipjqkKF\nChUqVKhQ4SOgMqYqVKhQoUKFChU+AipjqkKFChUqVKhQ4SOgMqYqVKhQoUKFChU+AipjqkKFChUq\nVKhQ4SOgMqYqVKhQoUKFChU+AipjqkKFChUqVKhQ4SOgMqYqVKhQoUKFChU+AipjqkKFChUqVKhQ\n4SMg/Dgv9lfvDu3dUQxArZYThwYApWN/I4GGKFQARAFoPf0eLABaQRQo+V4RGPd9MHMtay3Wymeg\nMNPvSyil/OfcGqxyFzNWkebuuDy3ZHL+v7QaT3/wAfj3/oOftkM5qnvYZ2HxMQBObJ5nPLgLwOBo\nmz/zH/3HAHz2sz9KnLg+ubtzk7/2i38VgM89/kkunT0PwLX9MReeeBqA4vAqd3ffducfp4xGrmFn\nTp5jPHT3+fKrb/Kpp18A4MK5x+i0mgAsRBFRvQXAjmrw7pVX3P3cepONxP32Mz//F35gG//X/+6P\nWy0dHWhNoJX0pUY+olAoW37GPwdlrf/HQ8/HWv9cLBYw8r3BlI9LPXxbtjwGS2Hd3wprMPKgjbEU\nRj4Xlly+/y//+m986DP84p/9b+z1GzcAaDaaHFtZAmBz4xi//c1vAnB4dETcaAPQWV7jaH8PgGH3\niOc/8RQAR70B3337LQAeP3sRIyN0OBlRS9xYiwLNJ5/9FAC/9uUvY4scgCSIKEzhjrcFm5vHAfjs\ncy9w+9Ztdw+DHibLABhNCnZ2dwHYfvVLH9rGz/34j9l+vw9Ar9cjzVIAdBISRfKATcGJzTUAnn7y\nCa7fveXurdmgFiUA9HsDDvcOAPgDv+9z3L/5LgCnzj7G9dtuvPeGI3StDsDOYMjuzo67VqAZDUf+\nPKF150yS2nveU/f/tRNLrK4tu776pV/50Db+T//tn7eF9KfWmk6nI9dVBNLEMAyp1xv+OqZwfd4/\nPGB31z3TxZVVjh0/CUCt0fLjPJsM+P4rLwPw7juX+fHP/z4Ajq2vkqWp9G2f3mgMQLO9gFLuwpPU\nYIwbA1mWoWWiG41GZLm757/wl//nH9jG//Ev/Rn76pvXAXj1zVvsyP2uLtbZWF0E4Ggw5mjgrn9s\nYZF2ZwGAly6/zuaCO2Y5bLB74MZOVI9RQXlZTRDV3L0vNPiDP/MFAM6dXuON734fgM988vO8fd09\n5+29XT73whnXl5Mur19x4+XY+U3OnNoAYKd3k1defgOAv/aL3/jQZ/iN67dt2TcK0MgJC9qxAAAg\nAElEQVRPZuYMYwqMmZ1XphP/7DFkEwDybo9c5oag0SCsuXFHoFHyjgazq4mdjkGtQMsAsLZckcAE\nyq8nSil/3R+9ePZD2/iX//rft4U8c3eNcv7LKWQ8WmsJg/Lepud/73o2nSaVv0+l9ENrXfkbpZQf\nd9bah47x96L1Q79T4n8JgsT/7T//z37+Q9u4s/eODcKO3FmMtdM5PgojANqtFjC95/fe73threVv\n/M9/A4DN4xusrKwC8LNf/PfJpd+0Mpg8lS7RpSFBGITk8v0LT13il//PfwBAo1kjx31vVMC3XnLz\n95/6uT/8oW38WI0pHYZoGRAqsP6lVTrAv76a6fcB0wVaQ7nIKqXQcozW04Gu/H9AWTDlgDN2Oshm\nnotSyh+vrcaUDxLlFn6c606b+dvYWFqk3+8CkAUFCrfYLa2uchj1ANg/uEHYdJMaUZNc2nL17hbN\nmhtw5x67SBS5x6PSLuneFgCJ6dKqu8GXZzXW1tyCfuHkBZLaCgCdxTPYkVuk2u1lFlePuabnlqjj\njo8Pd4nHbgJNVlcYmvkaGYbTlzQINFoGvdbKuzmd3Vv2ZWkgIQaWTETG+mOstRgrkwaADfyZ/ONS\n00c3fTLucyB/KKyh0FNjKiiNKW3Q7zNRfBACpf2Cf/ITG1C4Z/jWW6/T67lnmGUF+cD1sYq7DMfu\ns81yHts4AcA76W1qMlGcWl8ljJzR/Oa1aywkzrj47IsvsLVz6C6cpzz/jDPEDvcPuHHzJgCdhQUu\nntgE4OzaChtNN/k3202GgwEA97YPefmtN+duY1EU5DKBZ2nqJ+3F1SXaHWdwj/o94sjdfxQExDIB\nbnY6hKG7h8HBgHbLLcoBIU9feByAWnuBVNaH2sICr7zp7q2eJJw86QyTbq/H7o4bgxaLkeeVZRlh\nKGNfKf8eWBOCjeZuIzPnbLWavr2qsCTthr+WMc6oRMG+GCQ2H/HEExcAiOsNOovufY3iGmHoxqfJ\n6+zJc7lx7W1u3nLPa2Nj3c9nYRSix2Ls5wXlGpHnOUHgxkNhMsqtYGFyChlvH4bVEyf4qcfOAbB3\n+M8ZDYcAnFw/Rrvhzn1v75AHR/sAdNo1zm24DVrz3To7911bu+EB44kbvxvJKsticO0cHZHU3Hme\nvHSWs2fdPHLjzXe4uOnOs9xu8elnXD/96j95g8tvuYWoVYu4KkZ//USb8di1aWV5g3r73lztAwiC\ngIeMqYc2ae4fhVIo5XfLfp5QVuYZINeW/qEz+rfeep39BzvSh6c58+QlAGqdNmHgzqNt6g1rYxU2\ndP1ggmS60FvrnzMz04uC9zVMPgjW2IeMI0shfzEPGRLleqbsdFwzc61Zg0gpsH5+NQ/dz+zn9zuP\nec9a8EFt+QAb532RDg+pt2TTogPfFoDSkByPx9RkY2MBa6br/ftBKUUtccZ+EAQcO7YOwH/x5/+T\nqXGtrH/ndBD4Dba7huvnF55+kiRx85m2mgZyD4Xm3LHjc7exovkqVKhQoUKFChU+Aj5Wz5Q1BcqW\nu0wDpqRqzEOUnC3EQgZvVWItqKlVmZeeCaW8/8KiUHpqpU9dvIbpHmLGKremdHZhFBRyDwbtrXNj\nlbfwH9p+fABWjh1jZ+i8F0SQ585zsFaDk0vOyr115ZtkW1fdMfca2Mi1pXvtVR4/4WjBzY1TaHE3\n2nduMth2LvPlzRqT0HmgoqiFzd199nYPySJn4Z9b6VCLHDVVq2sS7b6fFBlmLC0ZHxBkbke+eOwk\n+/mc7rcZ75Lz4cmnGVe4uJdmPtr3/B7ZOk37s/Qc2ZlDLDPWvlIY4Q5nn4J9yGU1Padyo8F/X9KR\n8yDLMgq558X2ApffehWAd2+9y/rGKQDqrY6nBDbWN3l34iiEIs9ZFPpkcaFHJJzoYyeOU6u7XdS1\nW9e5ePo0AGvtBba3nHem1Uh45smLALz+vVe5jXtuJ46tUpfb/8S5M3TE66ADCIVu+85rV3iwuz13\nG8fjMfv7zmMxHA4JxGPc7/VpNdzObHV5lUXx4CRRDNLGM2vr9EfO0xCpgDR3n7NJweNCRy9tbPB8\nw3nf3r17l6t3nDdisL9HJtTkZDL296NQ/jFq/TAtUVK0Ww92GQymv/kwWGup1909hGHE3p7zxERx\n6HelxhjvBZtMJty547wpF8+dYvOE88QUuSEQj2c67hLI7jkKAjaOORr00uOXuHfPtfGg26UZi9cp\nL3xbsjzz9KLWmsHQzQ2HhweearTWkgkd9WG49MRztDturG3d6TI8dB7OhYUmzYYba2vLS3SW3VzQ\nOzygN3Bz0zNPXeRb3/wOACuPnWRddvWXNjaJE5kL6hEtoUZrccKNNx2Fe//uPhuxo1S2r16lq9w8\ncmxzkULeiZ1ulwvnnceHcZOvf82FJnzhR17g2MKpudoHEGpN+cZrFMGMB6co54wZestiKGMDLFOv\nhspSotERAOu6S9Z3XsThuzvoVeftXGucJJE5JtaGiXHzb3diGAaun217c+opm6HzlM1nxqz9QGrq\n/WBM8RCdV3rZAj2l2fI89/OomqH5yt+U/y+PL9/n2b+X91xey9GCM+yArHlaa/+bLMtnaM0pzWeM\nfoiK+zCMej3C2DE2cVIQRY4hKYrpytzv9wnFkx9F8fS+f5Bnqlbzn0+dcuPqr/yV/9r3lZl5FmbW\nawlY6edJv09ahocoGKXu/WuZgpPnFudu48dqTDFj7Gitp4bSzMugA43yvtzpCu2Onbp71cyS6g0x\n/bDL0w+hmRfyoSFuFVZNY3XK+JzZTrdKQTD/QryyukZ7+z4Ao0kfLS9ksX2VcEHiIrpDtq452mO4\nFFGIC5luj9PH3AS00F4iityis9ZZoF3L5PtVCN0CMZhYQunEhjUc3HTxE4U2JBLrYu0Cw/4DAMIC\n0n3XsuFkQk0WuzhJGA4P5mpfoPX0hdXad41W6iGXdxnbMOuOV/bh/rflj63x1J6xeKPZKvuQ4eT5\n/Zn/gnth3GmmtKMx1sdPaQqUnf8ZDvo9f/7FVosHd5wh2zs6YKHjFpF23CCUW1hqNCjjyFQtZjh2\ndMvy4qI39JUt6DSEnqsljIQurIchTz/hqLEr775NTSik8aBHTeit42srnD/lqMOnLpyjv+8o32PH\nVohjFw93++4Wa7JozoPbt28zEeMoDMPpgj9JKTKJM7JTY3bj2AbN4EV3/0mddOLa1Ww0CCLXzydP\nnSSVZ/3tl1/m1SvvuHNqjZK4wM3NTQZCTdbrdX/de3fue7d+HMeekisnfoC0KBhKjNU8mEwmvo2z\ni4jOFanENCml/MLz/7L3Zj2SJel14DG7q+9b7BG5RK6VmbWv3c1eyCbZYFOkKEESOARIQBo96IWP\n+hHzqhGEwUCaoQYiQGJGGsxwJ9Ube2Oxa6+s3DMjI2OP8H29+7V5+L5r7lnT7PRCA/UU9pDl5fBw\nv3bNrtln53znfIPBADbD/Wvr60gTvQrA4FNXnERQMQV0brGMlWWaD8FzVzHifnW6XZTX6OD0FI2C\n6UHAtk39ecsy4Tg01q7rot+fbyOOJzF6PgUIpXoDV156ia5lPEAuR30qlXK49XAbAOXwdYeU6/Sl\nN9/C6jrNqV/59W/i7AWiXjfrNdhWxosI7Iwo0L/7+AGah48AAM+fv4pSke6T4RiwbdoYdz+6CwUK\nyjYvbmJlI6PDinBQ5Hs8Qqs5mat/AAXr2RxJ4hhptt6YBgSPiQEJI2P5UqHvuVIpBK8BYb+JekKb\nea4MJHm6x7utE4x279P3FBPkijRPy5UCAsX5fN0uhgMKsktrMRKLKWLTgVPktAnT0DmOUkpNM83T\n4hnKHdBpPYCEDvTjJJ5SVOofovbE0wDCT8kP/nTQNPv+bP7U7N9GUUa3AVIwGKISzMRrz2y5XBlJ\nxCkSiCAE3WfDcJHwQT5JUgx4XbQKJUiDAiszBWyR5UvP5IsBMMzpXpTRsoN+/yk6T/INTRQQ8xhB\nKaR8oDKSGKlB/QoPW/jwP/1HAECpvYvcWaKz1/+nf/fMPp7SfKfttJ2203baTttpO20/R/uckanZ\nNos6iBklGGagpk8RSjOfEVqpAK0cgxAzFJF6GgV56r/TfzNVQQrMIFNTBoqi9PlRDduyUSyQ4uj4\n+BiJQSfgZtjDQoMSNTc2L8BYpcTRdP15rfI6Yy/DUBTfjic9GDLR31lnOsGpNlCUNGx5YUAFdKI5\nfPQIR4yInVtfRiT4pBMPYTHaEafp9D4oBcnJxZ3uCe4/IYXNN778T39m/0i1lyWdTxV8cgYyhpqm\njgtM75/41L3UIzRDHdIIZqclTJFJIfSp9NN/q8F1AQgxhXczTIPQsc8whkhhsApsbbGGmGmXJInR\nPtkDAIyHbdhMsZ09uwCXhZ7ScjEc0gn40oVNFBy6x6lIceEMoRV5w4A38bmPCo7FCf1IUS/RSTdO\nfVSq9HqhVML5s5To7DoCosLUW87Wc79azuPs2sLcfUySBJY1TebOXpeKRRSY5rMtC6FP83dpYQEq\nJHR07/AY+RIlKW+sraLH/bXyFt6+ScjHvYeP0OzT+5VqHU6BEDTDtWAxBVav1zGeZCjFkb4G27bh\nsvpvPB5rFClNlaYc5mmGYTylXMq+xzAE4jg7hU9P8EmSYI0RJcN04TOVaZtSHztFkiJgRMm1LY0c\nLC42sMBU2WA81kIbw5Az6FQ6Rd3TFCafqldXl1Euc4K7ZaHE6ttntft3HuB7P/47AMDjw0NcvPw8\nAMC0K3i4Rahgu9eCnaP7vdFYwPEhUcF7+we4cpbWoFEQ4LBN89prHaFQJhTp7bffxQ6rMy8/t4HF\nVVrXxmmMxy2iFP00RDcc8TU0cYET4hdXLkPk6BrqCwkqC3Q/Or0+Lrx4da7+AUA49pCt14VyEZGi\nMTzY30a9wkhsnGDUo2sYD0cYDmjejcdjxEwlByd7KMUsDBp0sbdPSPwkTBGk2wAAJwqwwX0Mq0Xk\nGHpeSGIkEc3T/ff+CoFJv3s0lghcGrerb72GhcWMDfjpyrif1TS6BCDLPUmTFJl0WkDopO10Bq3F\nzLprGFJvnUmSPIVYZe3T1/bpZPPsb7MmZ5iIp9gepZ763LNadfUKxh2iwfvdQwCUYlBfOgPBFGqo\nFPpDus9/9PYdjExah9ZKJfybVyktwjFtTNXegJ2tr4aJWGT0QKKjiwRT2lSlAkpl7EY83TgMAYMF\nUOPeAHs7xEScefAAjpg/RPpcg6mnpfHTwOepHBj1dBCkB17MvDurnJidHHLWDmFK4WVb9PQ3ss9k\nAvtPU0dihqcVUD/1Sn96ixGgwBvi0uIiEs4n2fEjLAraIL74la+idoY2x7BYgmPTpmynEwzapDIZ\nH54g8mgTt90C/JgmykmvhyiDPC0Hjx8SXdhuHaO+QgvBnvKxx2oVyzZgZKOsBBKm06I4pjwY7taI\nN81nNSmnaj4ppLaumA2mhIKG4Gf5/afUfJhJpVICGcqdqlRTZqYlp/NlNljDp4Ljp3Ikss1TATPP\nuqFmZ8DPbnnXgcsbuxQKIVNFlmViMqRNxJsMkWOK7eTwCAVW58WpQKtP1MsXGzVUq5Rz0ul3USzQ\nZxbqdUw8ut/twQCTgBaQSrkCmynfIIpgctAhFKYBcRKjxJudEgqOS4NruwLFgj13H8lqge5JGEaa\nZijk8igX6fvLxTw8VqaOhkO8/e6HAID+cIgG20WcP7+B9TXK4ds+fILb+5SL0vZGcDgoG3s+3Dzd\nq9F4jJSh/HK5rNWCjmNDhTSZCsWiDqyqtSqesE2FSFMIOT+Yns/n4Ps0drOBVRzHEEZGDU8pjVwu\nhwrnuykloTJ5vBIwMnojUYhi+s4g8GC71MdisYT1NaLN7t27pzcp13XRG1HwlcSRDrKGoxGKvE7k\ncjkdlI3GI2SWFc9q79z5GO9t3eXvBqwnFBA5ZoLGAgV2h902mC1B0bFgclDe6hzgC5cpx+TOrVto\nTqjf1lgiHGSKxgRnajTOm7Vl7B/TXHjU3EGJ6S0gRppQwNJoLEGCXu/cv4mJT4FYfVWg2qDnYOQb\nKLjZ3z67dZsn+Mn3vg8AePnFF3DC1/aj730b6zVa77zeCHuPaaM+Pu5izM+rF3qI44zajWAzxWPA\ngsW5NvV6CUHE8840EAzp3lsyQYntS0pFFxYHpCXpASGNVethG7eeEA36/q1P8I//xT8DAJzbPP+p\nfJKf3WKVIFW0TzgQSHnPiNMEggOWKAbAwULFTnVu0SRMEWdrWxjAyOgqCE1NAwpJttWLKXBB+99U\nBZnOrMf6XKySqbWNgM49VSL+TH00DAOlyjL3JcIR26zk8xO4BVpvDMRw+FD6ytoi/vQdylXdKTXw\n5hKN15c21xExgCAsqeMC2wohBT1nSKb5a1aaggX1vOdkB/VkBkgxAMG5V4hxJsvZrlXx5OHjuft4\nSvOdttN22k7baTttp+20/Rztc0WmzhoKIlOWwYRiNELKVFNaAgLCmCZApgyLG0Igc6MSKoVMs4Q0\nhuwAOkEyjCdSgVirPdTU7A1K+0kpqJkEvOl1iplPCymeQjie1bZ2drG4SCe+r1z5OoZtOoXff7CD\nQZdOTNdeuYoin3T6vQ4MPm3bloVqvc79BXKMdhTcMpBwYrWIEbAPTaIMXHvxy/Q6TZ7qS8zJs0LG\nAJ96wghIDZdfR7CcLAnQxFv1i3P1T87QfEIKrcKTEpCZQEDMYHgKU1RRCW2WJ4QC2LQwDhT6Y7o3\n/cEIMVNsC4tFLNRz/Lsz3iRiFlGcnk5SpWYQzFlTUGi0a55WrVZRYlrKtm3EbGhZr1bR6xI9IA1T\nG2Zu3b6POptqBkLA4hOk7ThYWiDqrdvp6NN8uVTEOCSEa7/dnh7wDBsTRlK63QHWzpGyM0qUTqQe\nj0dwTL62nIWQaY92p4lyOT93Hx3XQcqndtt2kB0zHceBzx5lF8+fwwn3fTwa47BN12w4OYz4OhUS\n2Ix8HPe6cNgssgBg2KG5Hw59DPnE3/WGGoUpV8rIswji3PnziD1O+q9UdX+Pjo60AV+5XMLqxsrc\nfby0uYajE0IOokQLdzEJPJg8OQxp6ZQB1ylAGoQS+0mMosxMhQWyv46VQBDz52MDZkJj7Zo21hbp\n5H28u4+E54aVc7TQQiQCKVOlKoxgM4rQ7/axu0cUvRISbfa6elYzcxZWzhMClYYWxIi++7i5j/oC\nUX5nzlzAo0c3AQDdSRMG32+3VsbJiIQMDdfG4wMSqWwuLSHHCdYLi3U02Yz2Wz+8DQH620q5glQz\nBgkke6y9eP48rl45BwDY2rqJcY/p2dEVDFiUka8qxDz352kLizUUGSH6b3/wn9A9putcKdjoPSZF\ndKczwZM9Qs2a/QB2lZ6P5197DhevTte1HUYZDu9vIeJrnkwG2D2iMSw4BYCNY2U8gj8ihHmhkUdt\nieb149YEj1p03x7veYhiGsPu+7fw//Cc+r1//a/QYNRsnpbMIFOmYWFthdBDlQYAz6PhOMA4YCQl\nTlBmL7CFqoXAo3vr+QI9n9ZOJY2pkOdTqLym9lSagV1Qavq+IS2kvAYrJFqgoRRmkuzVZ0KJ261D\nVEr0fNQXz8HN0f0sFvKI+Z4XigV4IaFLvyBdTC7QmvrH7RDf+oTED6+eb6DF87aUW0ACh/tbgh/R\n3iYx9a5KJTTLpKA0W5WmM0iciGFKQlS7kwHCX//HAIDdb/0ZKrt7c/fxcw2mfr3hoskD1lMp/JQm\nyihJMGZIPVApQv5MkgKSFyt/FCJk/rtcb0AxDUDM0ZQ6ygIlSMB8Kjcqy6XRf/W0kRmmarFUSagk\n26AF0s+AZyZRAa+/9DUAwI3nr6N9RPDztasdnFmnIGuxUoTFAaOh9OUgXy7C92kyKQUU2GHbMAwd\nI0gjRcQwsOcnsAxa+OIw0X20HRs+54dY0tfGoWFqI2UeOowTRCozpQPyxpw0n5jaGMgZB92n3p+l\nQ2f5PKmQ4400SoDHh5lruAc/zhZnA5Lh1+1HJ/B8opDOnSvBSLNxFlrNmSo5E6wpUgYCwKdypD6L\nwVwQBFoNkiSJ9swI/UC79SZJopUh7d4JemyMaBZKKDhTqX2Rc4sOD3bh+zR/B4MBeh6Nc3NnDMn9\nCrwJPvyYNr4oVXA4b6jT7emFrtVuQ7BC1C2swmflnR/GqJbnX8ArjTrGTLeNPQ8FthAIgwmOB7TZ\nndvYwFfY1Xs87CKO6JpN10K1RPSPkyvhsEcbmXILqLIaKoqAkxbdk+JCBe0TtmEIYiQTnr9hCtum\njaBcLiHPi3azfQiXnfrDOIHg9yfhGH44vxJsabECg+fbk70j/RSPJhPYvJLmc0VEfG/zhomIAzdD\npRA2/a5pQJvKpoCW/yfKgEo5p0UaKHOwXC2XdX5WsZSHyYcWxIDFBwgjb2A0GHEfUzzZpkW72lhA\nPjP0fUZ75bnn0ahTsO5PJG6+8w4AoGCb6PbpuxvVDZzdoGvx+ycYM+XhFhZwzKxIPufCmNC83h90\nkQkmbz8ew2BlnzTyqBVos3IsAw4HgkGsEEf0B/1JiMeHvH45DWzcoICusXQdSzWi+Xa3v4/d41tz\n9Q8AcvkcGhsUXHQmPbx5lYK1ZaToM50+GgWIeUxiJeDwSDeqBayt0DytLy/g9Tfpet77/o/wydt/\nD4AOlROPnoOdgxzSlPolkwm8Hn1/KgRqbInS6Qd48pjeV6IAgxGBOIrw/vtUUeL81cv4rd/4jbn7\naBkCQtIcuX7lKq5fPA8ACEZtbN+mHMS1vINJSP36ZKuJMedzXbh2Bcd8z+PUBpiyjKMIcWaxgKmr\n+uyeJ4UAMkuGVAGci5uqZGqiPGP4KYTQwZShjJ+ab/UPtU77GP/lD/9vAMC585tw2bojGA+xtUMB\n8osvXMP15yj4FUGEX3qd1Kn//cf30DyiXL98amPNobXhsHcHNmgPaZh5rLhZv1JEEdOjUmnnb6FS\nnfBDakdWNaYmkoC+85MnbbzzhNa/weav4X94/njuPp7SfKfttJ2203baTttpO20/R/tckSk39uCM\n2eDNtmBwEmgsJMD+LgmgvWoiNY0qW6qFhyeU3LpQNhAYBOV6hgWkWRa/QMQvY6QwOfI0UyBhPFPN\nmDk+BVYIoUGNVKmpckIpHcHOc7uWqquATzGqgwIqJUILquUlFFymZ5BAZdShSmBktGZi6vpkcayA\nlE4rSgpMuL5XFAUaoQuDBLbJx0uVIl9g479UIQmZNk08gKmgQCkomSFDKRj0QyKAMJr6nPysJg2p\nE9BNacCYKV+ga0HRRdMfCDUFjlKBkU/38qTn4aP7dNo4OuyQnxeAxmIDywt0Sig4DnZ2KJHetoD1\nNa6tBoFUe47NJLhDaT+p2X+VmpYfmqcpBRweEe3yne98FwmPvyslhmy0mCQJ6lwnDhK4fI5OVL3+\nGN6QTktHB3soc+mXrWEH+ztEMyxU8hiyV9Hjg2O0jgi1iYMQbkrjUCxV4LP/iowDRDw+ecdFyBRb\nrz/EJKBxDv0Upcp8KjAAqC02UK4T1D4YDNA6obFwRYyFBr1///49XDpH/kPVioNqieaj5Ug0qvQZ\nIR1EbMA3CQMMW03dl0y1VygX4DC9ZB51cHJCnwmDUCf3h94EeU4+DcMY5Ropo6qLdZyrkkKsP2l+\nSkrys9uHH32C0YS+fzD0YTHCFQahVvUU8yaMzM/GNiGtjMK2NOqkDBIEAIRkZMBrksRIOMUgVikM\nXsPK9Trax4RIF2tVOFw2xg8CTa0nSYiIqZR6o4HzfD3tTnfuPm6snYNj0DPxN9/5W5QbdM+ee/FF\nrK+T+qnV9JGyuMQ3FPKcXKuMPGIuzdMcKCjFaQfeFCo3rZlnOg0AybCWtABeX+JJrGnPj+7dQ2WP\n6JjX33oOm9dp3ByzhM3zdJ3DcYBBMr/xajgc4xYjPq+//hp+8Y0XAQC3//u3EA0ZkbFMRDKrpxYj\n5gTld/72fbz7A6qdWG5U8PVvfgUAsFArYoPp6EG7iRFTS3HQRbvPZWMAqID61WwP8VxC8+j6uQae\n7NPnj4cRRoyUeoEPL6BrePcnf49f+tpX5+5jIe8iZTq9mHd1fU5LpnDYuFn6AfLsmfXq2RJc9rvL\nF8toh4SePNrZR5kVjgZSzdJIw4DBY2rblhabxHEEc2ZZzOpYCjlVS88aeAJ4atP8LMakB7vbODgi\n9PWHb7+NziAzj72Kn7xPhq6HJ01cOHceAHDcbeJclSjsqNWBx8ra//m77+pyS4fdDjpt2ivc/gjf\n90mMoRKlWRIHBkTG58mpxp+03txfw0CXp+RPHg1xwvqPr10KETbOzd3HzzWY2hkc4q++9WMAQCHf\nwGKVHv6tO7fxy195AwDguO5UPZACVVaTVIWNtfXzAIBUGkhY3TRCiogXCE8BXYYzB3IKxz8tx59O\nAuJQ6f0UUrtezxquSQGY2lDt2bfrtVdeAHszIo58pLwJ5go5dLg2lC2AWokmQRz7yAwrhSjAQMZV\nK3S7tMl+dPsOHtzfBgC0W02Ms9p/UQLBcHsun8eN69cAAF/76le0ZDSKA03zRYaLlGHpRCqozMwM\nKVS2UD6jSUPqHC85mzMlhDZhnZJwDBPz7YxShSdHBJE/PhjhhHPIjkcB7AxiFiM4rLRZOrOIV1+k\nRSMetRH5rLoqWtMEGCGfGs/swXlqQ5qKSOdq4yBCu0vBxbe/39IFMYNeE9fO0cP1K1/9MmoNCiIG\nkwFyBVqcnxyc4EcsVz85uI3LLLVefP081JiM/37pRh1fdygf4LB9Htt79FvDQKDdofsz3Gpi6xHl\nhKyfOYtRVhC4N9JO6s3tI4wHtLB7kwj7h/ND0kdHRzrnoZDPa0rxwpmzaDCFd3LYxPf/lpRUv/Pb\nvwWL59pCvY7lZa7TdngIn5/Fk9YJFNNb+UIeG/WpVDxzFV6t5FBiB//mSRMhv69iidQiekvapqay\nl+slnL9IgcHIq3ymgbz/YAsLi5RjZVuWdk93TWf6uwn0BmG7buYOjK3tXdh8f6ZfbDgAACAASURB\nVIpLNUQc/AZhBGlmyiiyQQCA3YMj1FkaX19eRYfd6OM40TmXo8EIIRvxNttdVDivxs3lUcjT9580\nTyDUfAebWr2OO7dpjtiOgxdeoA38xeuXMemSWmrQvI1en+ZFmsQwHA64TRt5lvVbERBlha4NAwGr\nS5F4WpVbyJvwWMlqxSmKtRK/X4P0afyr+QiNIvXj6nNreP5NelbG7Rb2tumZ8OMuRGG+lAIAON7f\nQ5UtQv7Rb34TvUMqqvz+k119WA7SCUo5ph0nCrFH9288jrQVxWTk4W//8jsAgIvrC6hx4JsrlGAq\n2ti9dISxxwdYw4XguRxEJsKQnr9y1cLyKj1/tzp7GPHcGaoULlucLBRzGHTny3sDgFq1gjFT69tb\nj7DP5stLtQJyeRqjxBtD8Lg0HIW186QcReMMrD1aM1q9u7jIhx/btbDL1FgUTmtd5l0bPNQYR4Eu\n5zy1QMWMxv3px23W8POztub2IxTZCmTU7SHmdJaFpSXYZTp42LarTTjHowmaTZq33//222hx4PzH\nfzEG4ixAcKaH9jgEIo6IpARiGi/TKSFm+xXTMqDGvL+6EganWoiSi4hzGYXlIlem+fZVTPDDe/Q9\nv/4v/8dn9vGU5jttp+20nbbTdtpO22n7Odrnikz1jh9jeETeIzI/gMmwfuvJHfSu0knXtIRGi8aj\nAAdbdIIwDQcJc2PFah4vvUZwrx9N0B1Q5BlYOVRY0bSfCAwUnbYjJXW0TWVjpmnoGZ2nqMw2XdtM\nZG4aJoZtUgRhYeOZfTy3sQ7HyBJUI8qiB+CYEtsd+h6RClRZLYaZk7GKU4AT/I6abfyff/5dAMB7\ntx5i0CXs0fPGSLMSNWmMhJGYJFH4zo8oqdL3ffzGr32DvjQMAIOi7lQkWgkoxAx+lD5dtuVnNVMY\nGvqncjKZmk/OlFCaKS2jpl5RjqHw/AVCmnK2xFGbkDcJAZPx5kbNwZWzdML/6td/Dc9foJPZR9/+\nf/GkQ2hCqZrTZRpn89uVmjW/U1NIWn42ZOqDjz/USphExShzfbo3Xr6O3/+XvwsAePn6JfzZX/wJ\nAGDUHaPdp5PlxuIqvvGLXwIADMcdFHqMTFqGTkq2HRcFLmexVFvEixcpwbY/GMNn2mv/xhLe/phM\nD2XOxe4eUdyBJ3B+8zwAoN09ghSEQJ70Rtg5JJTi9/GzjVcBmiM9TuBdWV5GkY0i290eLl8kU8WN\n1XOY9OiEHXohrl8l5LOxvIp7d+m3Hu7tAZy87nkTlBk160085HMz5YrYOykOAzguowKOBSNDDrwA\nHquVTMfIxKs46hxB0tegUC6hVpu/ZA6BwjQfCvkCEi6LkbguFCfBp/E0WdX3I3QHdBJ9772Ptc9b\nybkBzkVHCqHFKUGYoNkhtPkn776P1Q1CYr721S/DztH9DIMYir9fKIGAkep2b4BChQ0ioxgTVmTl\nHEsnBT+rnewfweSyPm9cvwRhEGL98KMfo9+lpN7Hjx4ijmicg0DBljQ+62vrkBZdY6IAn3+/32tr\nk1oIoVHZwSCFYH+t62c3cGaDKZhYoD+gZ9S2E9TqXDbo3Hm0D4meO3hwF4MmoQDdaIjAnp/ms20L\n//y3/wUAYG19GX97+xMAoGeJUYxJ4MOtEdJvJwH8Dv2WEcewXRq4XMmCYCQiagEO+14trK+imhB6\nudtsos/3wZAAWDfgRQFavAds1l288hLtAzvjHt6+uw0AGAYeHE4lKZkGRDAfugiQ+WthkdDaquVo\ndLozSeDwVCi6dRgFWhdH8QS+ZOPeJMZqidaAN1+8hrdepX3RsQQKTJE0eyMoVu6KNNXMQq1Sxgqr\nxwejEQ5YRRqkMQT3RcyYc4oZwdGsKeg8rVqrYXCL1rBSpaIV+K5tYzKk/hbyOa2szTkuDBb7yHwF\nMqTrsRIzy5NHGkWa9UhtG9JiJkq6kLHL7zuw5dQ42eB1PUYKxR59ibCILgJgJCniMc35YTDE6PBg\n7j5+rsHUt/78bRwf0qRM6jFUSPBqqerg0Q4FWU4eKBbpRuTcEiZseCdTC4M+D3ZoQU3o4RGTHo54\nkKzCCi6/TnRhSVjY58CkmSiMszJRT9X0m6nBl6aQKgsSDO0yKwF0ttm46+qzgylgaguQhiEEX4M/\nHiJnM9Tq5JBmMCSiKc2nYoQMN/7Njz7Aj28TLeRNIjSZToiTWEO2fhxCZAWKlWBpIHD38TZ+gWHm\nxZzUm4UQMWRME0vIKV0nlECazvdgkCNuFkAJSPYcMD5tqqmjl2kJ21Qq2DwOi40KznIh2ZP2EDUO\ngn/167+EV994CwBw4coVyAHVzYqtPCIOIoU0Ycqp4nP6m6kOskR2T0DxnPwMwdTezkNYfM0Xz6/j\n7CptHN/46pdw5QwtvKnfx4tclHihvoAJ56WctLtw67S5PDkZwWO6yrRdHHBekuXGqCsuljvuo8zm\nljKZoMLBiKq7ePkSzbdQGRiykuf9u7dxj+m8giuQspS/N5xge2d/7j42m03UqhSYFApFnbfXOu7g\nL/7yrwEA51bO4MIq9ffB3Qewcw6/vodH20QjtfsDuFwMN1fMg303MQkCtLmobq1WQz4ryHvUQvM4\nk5wvI5cdZnp9DBiCR6Tg6gKvAfKsIltaXf5MxVXdfBGSF1LHdlDgYsJRMNF2DkkcYtihsdveO9EF\nnB9u7SPmMd1YrONsFjwk09OP3xnh5k2an+99eAerLXqmnVwFNteBK1kWTF79C7kCmhzATvwAW9u0\nbk0mE12PzRRi7sl6+/13IDnYEWmCKpsiPm73cHtrGwBweNLRhZPTRCDi9bTf70MZ9L7MFbQibzLp\nw0jZlDQKIHmTqRTziPqcy4MQlqC8t2KxgcmQ7lllUeELv0gB987WNk4OaD7m8g5EgXMlm08gnPnH\ncHNzE9Uy26MAkAFd59Vz5/CA+6gsF9/4Z/8EAGDnF/C9Pyc67/GHH8Pk9IVKycBGkb5ns1pE3px6\npSzxHDcKeezs0ppr5l14bJRcyBlY22AHbtfCeo2e79/+J7+K2g9JbXfQbCENKUjcP9jHOJifyrRN\niS4XHXerNTQ4sIqjCClTqImQOofSdurYPqQgvjqOsN6g63n1pRf0vuVNhijyYSbnFlHJHPZNI4tB\n4bo2lmr0XHpBgB+9S/llnzza03XxxKdq9qXa2kZ8pmDKcgv6+r0oRJcVwBICF9bo/n/li29ouvng\n4AD3dmmdmygDGSGZusVpdRJzmuZCBY058pQ52Dm6/limEF42/2MgYDAhURBZH9MUivM74SdQJn2+\n1ugjGs/fx1Oa77SdttN22k7baTttp+3naJ8rMnXn7iFu3qSMe9u2YecpGsw5eViSkCk3n6DEsGWt\n2oBtM3ybN7UqrZg30WEfFdcSmAw4kizFWGWTxHK5CsHJe0I62AWdbqOZitik7GPlijKJZgMQ+BNY\nfALOFUqYdOZPJhwOxxhmsKgcw2SkpFKrIs/Rrwp9DPusyJsMUGRfGSdfxONdgud/cvsJhmyS12jY\nUBn9d9KCxcmTY38yLXsjDYwYgWoOhnj0mFQ19WvnkWaqpDCEynx0bBtxQKfUFIDgk+mzmiGlTjoX\nYlp1XM68hlJanadm6DYhprSqLQWW6zS21y6fxdIynU5efv461hSdepOPbkNJuq7VkoNgwChYIoDM\nuydJZmg+MUM1Kp2baBifjeZL/TFuPPccAODG+VWEHlNUYw8R00NKKjTqlATaHcaQ7NOVJkp7P+0d\nH8PhE3Dg91CwaQ5WSi4KTHVFkwkUo1cTL8Lh4319nzNfKtt28dw63Z8kDvHjT6jMQmSXMrtadPtD\neHwCm7c5jIJZlqnHzsnlcNgkJWM43MKkyfTG2gLYggfDMNQIquvmYPBRcTQZwxc0v0zThMUIc2RQ\nnTEAWNm4hEeP6Fk/6flT/7fYRInL4Tg5C/0xIThXNjaxwWVavDBCFM9Pn5i2C5PrJwoIuPz8rSwv\noNnhJGU/QYvrzN28u42QxSxBGOEx07L37j/EIqu/UqXg830+OuzgY17Pjo77GIY0diftv8Hzm/T5\n129cg2BvqWazjX1WO5YqFRwc0H1unhyjVibKrVIqYHVpvhqLrdY2NjaIpomkgSf7tE7df3iAnV0a\nN8O0YTL9ESQ+JKPXY68Lw6L1ZdDcR5qZMQroBPuCU4WbZ3+tZKQVjYP+AI9HhLLWiguIGFlfWdvA\neEC0SDKeJur79gRQdM/iKILrzV9ORolUq5dVmOgUjEkYoMcK541Ll3Dj5ZcBAHa+iuYR9f1w5wn8\nHpfVMiWK+Uy1qRCzonBwPMARm9HKnIMSo68DP8CIEb2NhUW4GuWxoTiNw44FvvnW6wCA8mIdD/bp\nnvxff/EtSGf+rbVWqWpU4+D4BEZKiMxqvY4crxMiVUhYBKGSBC2mAj3Px8oKrQ2TiY8B0+lJksAy\n6fmr5vOoMjLVqJVQYHrLMKDrQ0axhTWe4w+2DxHrK0qeSjoXM2kdnyUZfffoEC32muuctPHCtRsA\ngDdefQ3//J9SGZ6VpQaOWLhx9+5d/P3HdwAAYf0XEGdqbCGhommqiswg3VTqvUUIBZWxJ1CIM6PO\nRCCJp5R7wkyRkApGVroLiTZjPrNawdrafJ5vwOccTP3rf/W7uHmTZJB37z9Cm9Vq0UQhYDe5YaeP\nQZd464MnQ+1InMhUO5ZGM9xOPp9H3ib4vuAc4Ns/oiDCqeSRW6ZFqXhxE9XXaNI7tRrCOIOrgYip\nCMsPccLUxbf/8q9x6QIVJX7lzTcQ7M/vgpoIB5Y9LU6ZuYLHarqjqwRIeKFxClV4IV3PB5/cw0d3\n6bea3ZEuMrt89gyunKUN5e/e/glGXAzSlgYcNj+LoTAY0aJw0mni3hZtWNF4gISh07MXzkNY9Lum\nbSFkKWycJFP56DPaLLxrzKj5KAdLf2iG64R+LQDE/DvldIxrnDuxtFJAxaI+hW//Cbr8ulLJwWZo\n3h2OUWfoXIkaUraZ8L3RTPFmAf18K0U28vzLnyWYUkGAMvNA6/Ua8iXKaVpcWkKWSKGEhRLTW/vH\n76HFcv8vvPUWtp/QPLKlpQsmb2wsoMxjlZMCMfclTgX2jgmy7/fHqDDlt7xUw3Lm0uwnWKrRc7Cx\ncAZpQn/7R9/7BGMO3AI/gsCUunhWW1pawohNO9Mk0ZuFYdva0sCIBcol6mOxUITHiibXdjBki5NE\nGlBjej8xFfocoFuWjRzbIYhSCtvkQqK+wAKrsw4PDjWF4JomJLtAR5MQLj837aM2Wg3aHJVrzF23\nDgAK5bIeozSMtA1+qViFz5TMYNyB49A9T5IEoxEXQ7ZcLXXfOTrEhNV/lm3B501t9/AIJx26nnyl\nAZ8TvTqDIaTBKs6VZdy/Q2vSB7duI+bn/mpjCZcv0RoTh4GWwy806shxDcdntcnEw0GTNtVbW3tI\n2OskmMTIsSI2VyxiPKFrzOVycNkIOExiqIRtPvyerulWrtW0ojEKRhCKPpMzDUz42YqiGJOAneK9\nDs5cos3ca41xwgePXKWEJ0cU3FUWy7h+4wsAgO29Hrqt+XOmpAEU+H7cev99fO8nVB/y3mET179C\n6sW3vvJVrCxxzcHeAOc2yWBzZXURw4DopLqUMHjfGIcBcnzIMYVCl3M3E0vC4GBqFCsUuP7kpSuX\n4XBwVKkUMGQriN3tHdT5YOvYErfuUR5hd+KjyPUz52mGcOHYHGCqnqayO4Mh1pZpncvlXETx1K6g\nwhS9YRiYcNH0e/fv64C3WqlggYGFfC6vDXp3d/tYYlqwwLYtANF/mXGvVIlWtAsxtZ75tBVClm4y\nT2t1O/jNb/4mAGBhaRlvvvYaXb9jws7qjkYBAn7OGo0GnmfT1/f2FSSPi4olRHZKVkIHtkinCm7K\n8+L0ilBpNb8RJUiyPJAohsFGqUmktA2GShJwBgmCXhNJYf419ZTmO22n7bSdttN22k7bafs52ueK\nTH3lK2/iVVYb9Ad9dFnddnS4A8+jE1aUeDrROI4SBGxKOPYCjCesLBn6GPFpOAhDjIYUmQ/HHloH\ndBoaPVZIJUWzpQ8f47WIIs9rv/aLGDHsVzAtPHyPTjof/uVfIWbodPfeIwwqfAL61rfRY6gY//b3\nn9lHZblIOeHUmjECjSAhufK8MBTANfKkIdFkg78//m9/hp0+XVt3OILvEdI0GZVRq3BdrFpRe/bk\nhAvBSXdxEsN1KIqOogCPGB35/re/pw0Wf/f31uEy0hP6EorvT5ROS6M8q1EJmSm1p5EpOa1o+NQJ\nRkAjU2rGwcRUAV4uMzqQ+gh4PIumC4eVUNIwNKTrd3sAK5dc24EqkbIlCiYamUr/f/DT1LTTmP+A\nAaTAcYvoVrf4EsD+Ma3eMY7bhBwuryyhw+VAup1D1GqU/Lu5eUUbRdaPD1B26fWZ5WU9/mZq47hP\nc//J0T7CCd37syvrKDDdMxyHKHE19WIOumROGAV48zp5VHnjFv7rdylpdDywILKs6jmaFBIuoxeD\n/gBDNtErVPJQjBZVag24TE0Oe0MUueZZnMZYWKL73xmOYMSs8IkD1Cr0vm3ZmpJTwwCVCs21YX8P\nNpeCWitJTeEIYYDFfBj7oTZlHSfAsM113RZyiL35UY3+oI/zZ0lhl4QhfPbqCqIYAnQNpUIFhk33\ndmNtBfEejbuTKyOOGH0TAhOmB4qWQ3XPAEQCENyXheqiLuGZzwFXn2NxwsoStnbo+S4vLEC6hILZ\nto1za4SmjMdjtFqsGBYG9tgf6FltEiXoMp0X+1JTPErFyPNc8IMJOizcyVk5eCHd5CiVyBcIDXHd\nvK4N543biOKMkhtioc6ITGERxTOEaNQaCmsrlGh+dHiECSfBd9r7mt5vem0sLxHy9vy1L6LMatFr\n5zq4vfXJXP0DgEKxCIPv9wcf3cR336W/ffmN1/D13/wtAMDiYgOHTJmmUFhcIjTyyuV1jGJCpsoq\nQbVEa1/JtSC4v90wBLNeMB0Lk0yUU7Bw+Xm+/pdeALr0/Z2Rj5sPiIa7ud3B1TMkTHjn4QG+9wHR\nUrWzZ1DlxO55WrPZxYS9kO7f20KlTM/cylJNJ21btoDFXnCWZWqWwzCM6Xobhfr9Tqejy+3k3ByK\nbOicswyNBjtuDoVM/CIU8i4hNZtn17C1T/Nq4gdPlZNRP+1352hnb1zE179EyJQJUknTDyfweA2w\nLRspI9ut/ggPm7TWxu0CUiszbzQgxzSmwq5A8ThCGDoBXRgG1ITR1dTWCvk0UVCZ8CtVMPqs6k8V\nYp7zTmpC5OhvrVyEW3vzl6/6XIOpVCVwGbLNl/LYWKfFBJaHd3giujkTNs/ugpWD5MBEwIfFsKJl\nOdpizDBSBJzvEwQxLJMmsT9x0GnTgJ2c9KE6tKCpYRMRw7dCWAhOiGJ58HfvIc+0UNUwkAxowI47\nbaRy/krHB+3bWlaac1xdE6kYlWELlqq2DzUXXnaLkEwLNpZq+NEd3hw9aNn4kye7ONmn4CiNYiyz\n0/VwMNAO0nSPaAHtdH28c0yLzqsXz+Hrv/yr1HdpweOANDUkUu5vkkoEc/LfUnzKqHP29T9gsJAV\nlxRCImVKcxzEkGW6B4uuRJpwAGUZsPLTQDPkRcYQCpkAJ54MybYdVBNNanhXYOqHMM3V+qw5UxAC\nDiu/Lly8jAYvjJVSCUWmwCZjDzbD5K+8/BpMDo7Hkx6EoAe8VCwgx5YPk7GHpWWiH/b2Wtg7POFr\nTnHpHAVHtuGgyoFv3rUBpn4KhRxGXHx4MJpAcC2xN164gN02zdO//sEDJMn8CiLTNlDJasAZQgc1\nlmVjZYk22fXqImI2iHWLOVg8ACKKcfEcqZtWgwiSx8JMgXqZNrJCzkEUZM9lCDeXPbtregF3XVfn\nhUGaiPke7h+38M4HNH8HXgSvz3SUEWI0HMzdx2gS4GCPFuRKtQowxR37gd7chWFCDek6z22sIGBq\n1UsNmGUai3KlDj+Y2qaMOG/OzRVRq7JKykjhsoJoc3MF5/j+OLaD5QbncRYKiLJAtVJGsUjB8ng8\n1s9Rr9dHGM83jo8PWnCZW3CcHGKmLsMUUJwK4BTyOoj0kwnAbuwLKxu6mDeiCKZF78fJCBOumWrb\nEooPs5aS+OrXKFWi7x3gLteM83sjNOp0EfV6EZOUgotuCEhFOWS9uIWQUw0Oe30MhvPnvRkCGPVp\njd56cA8eu/8jVRh06ZB7fLCNmOdgfWkBKyt0v2+8cA0fc5A1aB7D4UN6CSkSvse2KXF2idRzhuPg\nYZ/ml5V3cIHNYuMwxM2PyKbk490tfPSIftdDAUOmgm9tP0Hfp3v166+9gaXi/HlhYRih35/O60eP\nSeV5eHSEVosCogvnN1FjytqAhK4xLA29L8Lz9DwyTQtBlmuWKnisBm9Ui7h4gdYhy5LauDcJA1RL\nNB++/rVfgP8dMll99GTvp9J5pOqen9h696O7+NLrdK9ypkTMlR7e/fv38MUvEAUspETCdgi9xINF\n3UX6g4/h9KgviZVoO5hI+dMdJ021ejtJYySs4rUQIuV910hNIOIcaWHowF8aCQSrPpPIh1OhA9jJ\njg0/Wp67j6c032k7bafttJ2203baTtvP0T5XZKo58hFzQnmcpsgzLRUai3j/Y6483mlpf4x8rgTT\n5Cr0cRcGZ4alcQTJp/9K2YZpsULMNbG2wpn4a6u4cZlOSZZaxcSn392JB+i2+TRsVuGwr0zFdmEI\nipZTP9K+L4WchTCeX7Xw4YNvaVjatAwIrhlVcRdQyVNS6oPtexo1Wastoijp/UdP7uoachcvXkHK\nCa1JOsA4YM+pUQfeiJO1w4DKVQDI5ZZQqm0CoArvyiDko1Aqo89lNEqpRDHHSXcq0iUNpSEgk/l4\nMKL26PWsiRuEmFHtfQqh0t5AKSymRcZxih6LDhYreZhMkli2DZORiyT0kX2pYQjY/D1B0IfXYWTH\nsiEzeFdAm20KQNfpU0ro8ZynCcPQCsutrT2kK/T9qy+tw+OSDkEQodMjhCiXd1DJkqr3HmMvq8FX\nq2PcY8WkkhiO6VR90uujwKjAxtIqzrKS0XZLKPCJ1jElIqZzA9+Dx6V0KqU8BoyaGkrh2iYJE378\n/iP0vPkh6fpyRdN8iQwxGjKFajiw2HNsOGrCZTg+FAIJU65SGBCMiJaV0LRdariIGOFUQR9FRnRd\nW0HxSbQAgRKPhYUERU4sPbuxAYuRWPuVa3jjhesAgP/yX/8Mu48JFXCGRTg8f+dpq0tLuH3rNl+b\nwOZlom2WKkWkrHxtN49hc1J2MWdhoU6ve15M5WUASOmg2aKxzudSDEe0Vll2DhfP0zMXeyMUcnT9\nF1ZryGdqTT/EaoMNGfM5PGTvJXnurD7xB0GgaR7fD5Cfs4/n1jZw994t/r++9orLF+qQOeqHYVlw\nbVpP42iEOGWULx4gTqh/tmUjiIkiLBVzWOSyOMG4DxUTRXjubB4Xz9H7P35vH9tbdF/PrBRRrNH8\nPXvtDZRW6H7sDZsoFukeHLV20N6jOdvp9pDLN+bqHwB4/S6GLWIVNjcW8MWXKSl51GlhxGjO+rmz\nKNcIxjANEymjRUmiIHlOBYGP+zuUNnFPxCgw73+lUcdKle7DSChIVpRWFxtImaZ+/8Nb+OQOjdud\n1hABl47yBh7u3CHGIE59nOcSS6+/eEPvAfM0KRXyrGxfXKxTGgiA3qCPh4xSHRye4PwZ8p3bPLuB\nSoXWJ9c1YTAmUiyVEEes9B6P4XByvGVa5LEEQEpDI1a+H6NWZSGUZaLCSfOjIIaR1V81zacQKK2+\n/YxlZZ7sdvDhR6RCfuuVl7SI6n//3/4A66u0htm2jT1Ws2999DGMVZrD5sISxiaNdZozYRVo/tij\nPmSWRN4fQbFvVBqOYTjsQzmONGIkvWNktd6iMIZw+LnwQlhgdFIew2LXAKPrYWHzxbn7+LkGUx88\nPkbCqgUr58LhxdaSJdx4gaC+B7duaSfGMJbwU1bzpXW43HkvGCJNmEKIFYKIBkYYCU7atFjsH27h\nzBptuNcunoHNZpXezQO8/xOiEBJVxPE9dpaOPJj84BkmEDNlEgUJdHGtOVrPP9YPsIxTSJtrBQYn\nOB5QkOCbASTf+m6Y4tETWiwePmnBdNf42qRW50RJHjHob4UVQbCyRCLUxaJTswjF8OckDLUce/e4\nhVFC/W2OfHz5i68AADbXVzXHHKeAN54vF0UaUrvUCjljhwAxtWmYMeoUABQHwUoRtAwAbj6HIOOy\nTROCN2rDsTTtGYdUQxAAlJSwWcoqLSDwCf5WVk3nQyVpqhcWIWeCqXRKNc7TlFIYsvVGrzPEPTaY\nO24fw2FzUUMCCQcvtUoOFy+eBwBUS0VcuUC2CiN/gv4J5w0piZFHc+q4eYAiq9tWyw5sm+b48tIS\nAqa9JqMhbJa0510HYcg5R+OJft+xC2jk6ToXajX0JvPZWwCAYznIc/6OqAmcHLJkvzYNBDpHe1hl\n5c9Ju63l1YVcQdeyAgRiHl8v8SH4MLC4kEeex8VLY+3srmBCsa1Fmk5VhKk/xoSVYJZt40uvk9Q9\nkTb+/X/8AwDAYNDDYm5p7j7mc3ksLdPnTzptHB7QczbuuahyEJdKiZg3mmIxj8UFthroDHTw2+mO\nIE2imlaWbV1c2p/4yHMeS6mSxxK7f6+t1GEwJZrGMcq67uE6xpySYJmGDoqPT45hMb1RLFmarntW\ne+n5a7h5k1zGgzjWpqQiCZDwfPGljXyVgp1gfIRkQkHhZNCHwTmTA1gos21AMV+E4LVv3O8jl+dc\nxqoBK0dBxNUr19FqsmraAWoXKfBdvvo6er0sT6eEzfNXAACHRhP94TYAoFYtoM+03TwtSRUkB4Nf\n/ZVv4NUv0vW3ewPYnFNoOxI+U8pJlMBmVWulXMKldaL8BukQj0+4/l3fR8KBsijlEGT5U5HCKkv2\nL7z1Fjyul/fBvR+i1W3p79w8TwWc333vE12Afq2YxwJT3NVyGXN6IAMAjhopWwAAIABJREFUSuUC\nLHYzHo4GWHVpvKRpoMOu5MPJGHfu06Hi4GAfm0wjnzt7Bkus2huPxgjZzoEOa2zzEQSwmMaNkgQP\nH9Fhb3GhAcOie+iNh9h+TArwT+4+QI4LKZ9ZW8E2q9nTFMgk9VLSAXHe5k9ijFkBXK1U8D2u+fnj\nH7+N3/md3wNAlG7MppqrBQdVk+4DPn4fFh9KA2lC8Bof2VJTe1IJbeBpIEHC+58sO1AbNKZBsQAr\nK+ZcsHSRcrcEpFy/UnW2oDgg/cMfAL+9Nn8wdUrznbbTdtpO22k7bafttP0c7XNFpraPOvBNjgYL\nRRiKovpi7CPHaMS5jTWYDNf1gxgHbTqJDDohQlDEKK0iUk5WDS2FUHGCmZnC51NJdxTj5GM6JfW7\nR7i8Rp/ZvvkQ7bcJGk+dCsacmGfIFAlHxYlMAJXBoimQfoaESdtEyp9PIWFwX6IwQcRKAmlaOooO\nwzy2d+iklhpLkNzHdquJhMsZqBSA4DIjytL2SYadIma4NVUKgyH5pcTK02DaSctHZZEi/Ju376LT\noQj8t77xi7h0huDVNIwQsA/Js5qQM8jU7PtC6BODmKlzqKC0b0qaQic8SsvGuEenqLFn6URaI46R\n52RlaRQgmI6ReQUz4+oMCVNkqFoCwSiABCVb6otjyk8KqdHCeZoUErt7XMn8a0VcZiptv7uP2w8I\n5ZNpjKsbBLv7fgyPUZVzZy+gVqPr/9O/+hN0WaVVKlfhRTTOIvVw9SJRTsv1JYDrpfWHE3SZvgy8\nCVxG4lzH1qifENAJ3HGUoFqs8O9uYJfVqPO0/e1D7UVULJVQYHPcg70j5FnBNx4OUeLfqpdryPH7\nKkxhZmNtSEhzWosy77BKzrWQudjkHEtTSgZSqCRT4ChYWfmZ8QgMjsAbDeEPCRV49aUbePMNQql+\n8vAOClwncZ7WHfQ11VEtV6Z1OJWEkaP+uoajk+Atx0aR6ZPouAffozk2HAawXfrM4oqAx0nqo8EI\ngo1Pc6aD2gJRBY3FxSzPlTxrGMV7bnMTxQUar8NWF8fH9CwGfgCzwAn6pgm3NF/ycqs1xNkzpBq0\nXBsjrgfneZ6maXqjAfKZV1hpGQELQCajMWxJ97i+2MASi1qk14cKCQ25tFZCziVkr2ZuQkTU10vX\n1mCXfwkA8IPvvY/BkMbfdRYBn9VnQYz2E5rL1UIJZ1Yo6TmRAe4/mX+eKmnAKdN9NfNF2EzDLa2v\nQQlCrPxYIWFBkiUN2EyxuSqF3CUErRz0YfBkK26UcPY6qRE3rBAnN4l+OvEibC4QM/D8jVewz4ro\nam0RncMjvqIYwZBL8gw9Xb6lLAxUeX2yXQdaxj1HGw+HGA6z8irQSJPrurr2aa/bRcD05cgPcesO\nmcXu7e7g4nlCqRZXlmE7NEbtbl/TyKViAQ6jwZ3mCXa3uXSbbSHgxP1uv69raS6vrOB5Ni0ehz62\nD4i9idIUFourUhVDpfNjMb1mC2//6EcAAOV7+A//y/9K19Puot2ifYvWbnpwXvjyF/F4l33w1l+G\nOkd9sZsnCA/v8fekWnykTAOCzWPjOEbCu5O1/BqMbD+OIkTMhhmphOC9M5YWwPN/JSjCjGh8Tzqe\nFgDM0z7XYGrY66OT0AbqFjyImGiSUjxE+z6p+YbdHl56+VUAwIs3XsAGUyPvvf0edrhGnmnlNcRo\nhBKCaQYjTRGzsdkIEUxePLd22vCZtrl5+w7CkH7XtV247MwrLANDprrixNcFMos5d+4cBgCI45E2\njjRNOzP+RTSO4GTGeMUyFEPpgyOFVovpuQiQPJCB50/LLadAmhVqThVkFjCoFDFHTSoFUlbhKMTI\nqg62Yx8Xk8v8eYmHW7RAvPP2B1jlvKBEQDt1P6sJIacctBQzslmpg6mnPw9tmka1/Pi15SBUmftu\nCotrgCmhIOpc9FoJSEFqHCcqIeHACn4Kl6mu0DJ1TpaQ5JjMnUVmgS4lpvdsriYx5Hn3R3/6J/jm\nL3+ZflYE2DogyPsLL9zAYoNySC5fuITLV4nSaLVaePuddwEAW/tbKNr0IFdKFeQiml+NK+ewzvWo\nlHKx9YT6KE0TrTZtsKNhH47L6rCzG6iy+iyMFYpFUqPu7R/pYtElF6iX5nfrbR42ETOdnndcFMu0\ngUdRin7IxpvSwgGrXZUSWCxmBpgTJNlmkcTaNDdvCyyyrBtJqGvMuZYJxfPLkMCElYlxGCD0WWEX\nTJBm9HWYoswqwlgJPHftIgCgDR9eML/LeywULKZQbT9ANVNDOQ5yrJoU4xHSjB6QEtGA+j4Zh5Bs\n0GpZOVTrtKGXamV0OkSJBkGIgOm5/niincANt6DVUxIC4ZjWG8u1ceUiUUQw9+CyA7kQQlMgvu/D\nMAtz9W9peQUPH9LG2B+MIXi+1BtLMPjw5U48REynJ0YRLhvQpqoD28pUmF2Me2y2aadYXqLrqpZc\niJBziOwqWqyMbPd9VLl+3MbqMnJF7vdgF9fZqV9EdfQzu4dgDJNzRyMnQvHMmbn6B3BuTlZNQViQ\nDtGwqTBgmDS2eUdqibxKE2QLcLHRQIWtMeLjx1jmHK71zcvYfIsVZN0T7N6m+oq+SmFy8G2bAouL\n9FsXbjyHB1tEsQ0GE4x7FFz0+mOAx7+dCJxlGtwp5nQh33maSFJU2KZisdbQ19BYWNCKy5NmE0M+\n8EZhhNGANvmhN8GjHbqeu1uPcOkSrfVnZu7x2PMRc/5XbzDA+sYZ7ktPG5ZWaiW8+AJRWhcvXkSH\nTYgPDw5gZHmrSFFkajVKQvhBhHnbpRUDf/h//GcAwH/4d/9e18idVYBLKWDzgW3iVnCHU3DMmo00\npr6rxQXIAeWvicjTaQVJMO1joVxDnKP5mUYd4BOyObLwdMLOjO4bZp7W1MnKc0gOiDpPkwDNz0BJ\nn9J8p+20nbbTdtpO22k7bT9H+1yRqWgywZiTZFWcwBJ0yvSCFtZXKAIvXVzF+lk63SysV3Ap860x\nffznBxQxjgcChsVQuOFohZiBCGOm0oa9Q4iEkS8nxq7gWkZBout1GSJBkRGRxVxJQ31JFGi0y7IN\nGPb8yoxQBRDscRH5HtKYIu2yWdEJv0EUQDKNOOh66LX52lIBi5GbMPAoMxyERiWsXoRS2u4eaYqY\nk8hTCKjMe0kIxIwADjwfXptNAN0FKCZf9o6auPOAyh80GtW5TS0NOa1/J4UxQ/lNE9AFpjRfds0A\n5S5mn7fyJfhMtSQWkDIEL6o1iJUb3A8HYEWjjHyEfHoOhh0EXFvLKBqYmnNOSwcolWrKTwj1mTxR\nFISmJg8PdnF3i+5TruhgpUoQ/Jdf/QLefJEQVNMtwuM6bo/2mjhiavrll17CyQ7RgpNhEzZzmbVK\nHZZN83rnqIN7T+jEn7MssMAVUSpQdNgkU0kMGDWV0pzC/aMR1pboRFWoVbG9P5/ZI0AlQfKcsFws\nFeFzIm29UdXeZY5to8BoxzgMdIK7k6ZIk8yLyIDDY5ezXNSYhplMJrCZInRsS1eDN0wblsX0qyHh\nZtdQLEDxmI4nASZsQBkJA9t72/SdwURTivO0Wq2MDCCYDAaElgFw7QIcpiODSYpxn+gu03bR7tBr\nL4hg8SnZtC04nJTvjT3YWb0/KbSBbqJSDBiBiuIECZf5UdKEYPotjhPULxIqcPXaRYQ8ps1WG4+3\n6RR+fHyMRM0neKlWG1qUc3/rMWxGXpJqCsnoVqG4AIMR2s54hNjg0lt1GzIh9G/Q3kWtygbH9ToM\nXgyOWx42GiyISek5AgA3dWGx+efLL5zBIPNA652gnKP5eNBsIc+vm902YodLESkXw5P5UgoAKnU0\nU6cKkn2yFKDTKaAUDL42QwCK6bbEMVHbJGSqeb8Kv0djW5MGLE6/GKUG+mzrJR0HNq/1x81DZNjF\n5vUruPCY1qQffu9ttPosfvIiWG5mlKwQRdl6nWj13DxtdXlFMwlRGAFZvTyV6rXWtgyNZgspNQoz\nGg6xw8jUaDDCBx8SZbmzu4fNTVJWntk4g4jpyG6vjxELH0rFPC5cpPuzuLSohS0/+OF3cY/RusXF\nFVznlIT9o0Ntlh2pFMlnqJNZrizhjVephMytm7dx3CFETAqBJKtlK4RWCe4dHkNlRt4njwFG9Y18\nA8kaIdX2yWOYjGYPJr5e40vVBfT5O+PjHYD7lcQpDL0PiJl9SSFJWeEYtBGxGArSwv7u/HV5P9dg\nyh+PMerSzDWlhGAKJAgnuPIi0SSvvPImkuyy5NRMcnPzDMoleuA/uPuJflBT6cJg+wTXUEgielBF\nOsKFs7Txxd4A3WO2ByjXUK0SfJsr5uE4U/phsUSbe8mUiHmRVKbEMJmfIur2Ihi8EdvKRo45bNso\narMxLxjCYUnnyy+8DDUh2PKj2/fhsZJHxT5SXpCTOIbBdIVr2xixsy2SBAkDl4lKkCRZjpCAy2ql\ntbV15Jhu6fkTBFyt1k8UctUK3+YUY95EntUMw5gJpqQOOiCnpp0C+JRLZkZLCm22ajsOwiJRLRMx\nhsvS4KS6hNig95XhIpS0Kag0xoBzFbyJj4DVLyUoSKZp0mRKh0oBpCJTnih8FiWvgtS10jY21nDx\nElEzo0EPb954CQCw0ljF3/2EDFb9ROKkS/fvuNPBhx/TQrR+VMZqjfp1MgrgcrAbhxKTgBaT+092\n8YQh9eVqFS89dxUA0Om24eaznBCgz/XVVpaWUM7TPXn5hedh8MKbWDbusyp0npbLO1hgqiaOY0Rj\nei4LJlDgWnVKpUhYLapsA12em0XTgJMtUCqFy2aYC5U8CpzvFicJBNugwJCwMnNAJVGq0e9KKfVB\nSNo2xqyem/gJHjygXJfKpYsYsCuyYZuQn8HKftBuIuW8w9DzkDpczNlMMW5TDkzBMlDMlFSTCXpd\nWj+CKEEiqL8nreP/j703C5LsOu87f+duuWftS1d1d/UOoIEGGiBAENxASyQlURpZtizL4xiPQ+MZ\njz0TMW+eJ4ftt7HDyzjsCEeMbdmWPRG2JGuhaFNDUuIiAiQIElsD3Y3eu6u6uqprzcrK5eZdzpmH\n892b1eLSCXcEnu6fEUR21s1779m+853v/y04knx1434pzxSd6ISeRJGVfNgXBbC71yGW8HMdeCCU\nsV8K8vqAvqcoCTHguk0qVTvHjizN0+2OFpU5NjbJ7KxVdup37+bJi3udFsa3z4ycCs0xS5sfHptk\ndc1SyoqUMfGTi9lhYjIreu3Qbdv7rK6GnDpio3+nDk0ys2jn43Zrldt3Lf3x7W+/lW9QP/vnz1Fd\ntFTR5vqrVEUR3wuqecTqxNQszurlkdoHWI4+16YMiaQmCXw/978EQySRtVutXTY37Xqq1mt4IgN2\nTcDtHSmM3O6xIAk89/o9NqW2XTsa8PrrNlnln7z+KiXxKTx37hzHz1iF4rXvv0O0ZeejiRNcTzbk\nQcyOZK4fdHp5UftR0O518jQlYRLT2rZ9u98ZJvLs7bdxhFo/fOQIZYkQTY3Ja9beDG+QyKFuY2uH\nllDWt++scGTRzpNjJ04Ni0V32ty8dRuAdy5cyPePnZ1tSkJBT01MEwtl/cSJ46xtW+r21uo66YhV\nMwA6vRLLt6yLSb1UZVPZNnqelysvrusSSzLV61cvk8q+4acDlC9+omELRxSrfrdnSyRg97ya9Mn+\n7jZ+xc6ZuNulKtRkkiT2N9iDd+ZPubi4yNqalZ0vnz/B69+180drzZVLb47cxoLmK1CgQIECBQoU\neAR8qJapTnuXnS2rbZcqTu4NZrThftdqoe+v7hJKHpcojenLiaPu1ZgU58nu7qsgEThOyQWJ4AuT\niOeePQbAx55/hhkp9fCdV17n0nvWgXCpNk9vV7TTvQ7HT1mzey+OqYslqOkYXEnctb2fsjUY3TKl\nHQ9P2VNJJaijxHm9NdjD71ptOSh7qJ79/mMvfYzPf8pGzLz93nv8x9/6fQBu3VkmkfIE4cBQCjJn\nWB8jlF9KRJpFJCQJc4ckadxHPsLhRRtpdmxumtUrEq2yuoeWyLHWXjsv1TNRL9OXZIIPw8HcUtYy\nlWfwzGk+B4befQwTvTnOMOLP0Zpyw1oXt3ZCfFfqhDkNnD1xMPTrpHLS6nb67LTtuPU7vZySrTMs\nb2OUO7SOKYWSyA2lh7TdaFBUhaJ6/rln8kSdk2PjfPS5FwD4va98jR+8Yx0bf+ZzP8fXv20jVX5w\n4RK90L7zJ549zeKUtTj0eyaPfjFOn719e4rVcUpTTqXdTp+eFKjb7w5YWbVWhLGxBkFGpVVqTIll\n1YM891Y/HTA/N3o9sDNPns6NhysrKyQyp/a7O0xI+ZxqpUIsSWFdz2U3kRNhqpiRWl9lx2FMyqJU\nS27+PuPTc3npj8RoSmKZcP0KE+NZOSfFxqbth83WNpFYVsxA0+rb03C3uYUS624l8EmT0U/Dg0FE\ntWxlwPj4OEFumXLQMq+qXoUTR60MuHl3i65YKeI4IZZo463tLfaEIgpKAVWJjKrXalmMA8p4dKQs\nTWunjZ8Fxbg1ukKhetVyXsLCBmYkco1iWvJbTUxNEoajOdn71YDxSfu7er2KlrI7rk6tmwDQcfYg\ns/6pKlOSlHRnd5+q1JNM3W28SXv9ykYbFdr2HV1c4smn7PydPzxBS2r8feu1Cxw+ZS01j330I+ys\nWivDwpEzdDft52ZP096x9HVZu8wJnVSuTjAze2ik9gGY7dWcAkuSmJvXrRyfmprMy/E4SrEh8uv9\nSxe5c8fSXhOTU2hxubj+/k129+w6vnftfQZ128aq8uiJ1Xp1c5vOlp2PnTTJc9Mt37rDExI4UPOh\n28sSn2rijElIXdbXbPDI2995lWces/L35KknHtrGH1x4O7eS7Ozs0GnZPlw8NM+z520ka/lAPT4d\n9ukI5T4xM8+ZU9aaTUpej6/dbud759r9DTa3rLXlzp07nJaxWDp6hClJ0Lrf3s9zo/V7PbbEMb29\nvUMilqmTS4eZnLEO7ve2W/T6oweD3Lq+wvKKHReFk+9bz58/z8SElQdf+cpXhmMdD/LSR5MLx/nF\nX/3LAPzuf/h1StrOw23fR0kQgun3c2f9xAsoSSLvWHV4+dMvA9DtdvjWN79luypNWZQ98smzZ/Gk\n7R956jQX37UJaRcX53jm7NLIbfxQlSlMREc2EZOO51x+msZcuWUXw827u2QGM61StPj+zJbHiCXi\n5cSROZ55yg7q0tIs779vI1qWb1/nC3/GZsg9c2KG/V17vWtidvat8JxTpZz732tvU5csutVak1Si\ncXw3yfnXS++8z1vXR6dPIr+D44sy6KZEoQiyyORm/YZqsLdqJ+ib33+HX/mVXwHgv//zX2B3xy6k\nP/rjb+b1rFbvrRGJghkPBlSy2nVOObeAO8rh5U9/GoAv/NzPcXTRhvO/+d1X2BefELTOfcF2dnZ5\n74JNEXHohSdxRi107Lq5AuUq50CezgM+U8bkCTMf4KYdBbK5OYMedYmEieOIq3ftYm+lZSb3ZZEa\naLcyk3ePTl+oJbfGeEmSvwZBfn/lKByd72554WWthhGfo8EwPSv11JpNkMz4zzx5jo4IlkRBU2hS\n0hhffC1am2sEEl7/2Y+d45Mfsb4WFbdOIH46K2vLrEhk1JkTi+xJpGm7E9JuWUHR2t3JKaQwCofF\nOqOQ8bod/6mxZh6x2O32ub85euRJuVHK/RPGphu0wyxMfpoFUcq1IaelglKFniggd2/fpqZtW6bK\nFSJJFeDVGkQSeh/70JP8AI6v8pDq5sQ0iSi2URTRlgoEWzttAqHcJ6pN0p7th6s3b5PUZA1hbJHX\nETE2McnkmKUUq+Uy+1lkTpqyIMqL0VCq2883V1s5NZKkOieXoiiiIxSeUoqmbOILcwt5VKNLmW5H\nCq7vd5mfEJ/OMCZOhMZoVHPqQmmTbyhGDykHo5wfW+Pyh9o3OcbcjB2rZrlJZz+jThwiUejD1hZK\nHMdaGwMC8cOrN6eoSYQolSW2e1YWVKYWefmFnwbgpRfOo8SP7ea1W0R79j7zzZOIxwLPfOokty9Y\n+dje3eDuTUufjgU+rYHts1KpRqdjr0no0V7P0gw8HN3L38xlsTYG5IBx98YgD/evliuUxRfzbD3l\n9BnbJ73BgIt37L6y09pkK6t2sT1g/aalGp/7yEt89DNWbkavfoe9tqWxDvnkNFZTh5R2raJ0uOHx\neu5r45BkCrHj5HUjX/3KlxjfOgbACz/3lx7axjtr99BZxGWSkhGElUqVQOZFrV5na8PunTNjY3mR\natd1mZAowjNnztATRc9gWF21bV9fW6cjkYA7rT3eeNMeri9dep/5eavYHj16lFlZK82xaQ4fscqj\nGfTztDWHlw4RicvImeNLXOhfeWjbMmxv3OdTL9uo6HYn5J133wXg9JkzLC5YCvLVV1+l07XveXzp\nKP3QjteJk0v44t93YukIVy7Z30b9BCNuDiVj8nXT2W8zJi4M1WaDlvhnKaVyOrXf7zMu8vvtt99i\nfMLKgKtXrtDatQqp48Bjkj5oFBQ0X4ECBQoUKFCgwCPgQ7VMVcoe05P2NFT2UxxxAtTRgLaYyNN0\nePr0fUUU2dON9jQ7m1JnK95m576cSpwu9+/ctt/3++ytW238yt4KjiTz9I1LUMqijLqUJALAVYbW\njj2JrK3eZ9Cw1zz+0dOI3y2H5me5cP3uyG0sR7U8Eqlv2jgDcRx3A4ycCokG9Dr2VPqVr/0xt+T0\n9NHnnqPiWc35zKlT7Mspoxf2qQnV0en2aEldo0qtTpRRCJ7PxIS1pqwsr3Lloj1p/snXvkxNIhW6\n1ElKWc4QxfvvW0fpY3UHX41muXEcNy8Vg1LkBqiDFJ6jhiyfUXnKfxdNIkdaVW1C1/b91NQsfckP\n9u77N6iPWZop8BxaWb4e5dOs2b5sjs+xsDCdv0OWIE8dcDo3alhZ3TEa9QHqK6J0nq9KeQFHZuzJ\n6fEzj7MpkZHnT57i5LSlZ2MUHzlrS2roJCaRPGY1L0XJKbbeCKiJQ3lzfIlGzZ66quUK80/bBHn3\nNzYJxblye7rErtRri8KYmpvlEGpQKUm5pcE2Xamp9ycXVvjOG9dGbqJR5JFxru+SFVzs9HskJqOO\nUxI9kGs8XFmXTimgLRGFm7i4jn3P1FFMSxBHOIjYEbpqUPXoSrt6aj93mN1rtfKadO1eyqGmHfeJ\nWpOt0I57J+qSqMxp283zlI0Cx/Pzcdxp7eR5ygb9Pu0tax2pN8YIBvaeWzstIjHQKs/DE6tcvdFg\nZ3sY1TMl60wpJ8+Z5bmaUPokjhOaFYkM3urmFg5/qkksvg3egQCNJE1y+rJSrzxAkf8kLJ1eItq3\n8+joxSNs7Nq5GcY9Uikr0u21CZNhzqu1fStrJqdmGRcn3akZnydPfhyAz33m80xM2He/evsWt6/Z\nOVWONYenLB0631S8+p1vAnBvdYOXXrAJPMfKNdLY0r/+TIW5Q7bvVy5epXXDPuvp5z/B4snRab7+\n5nKefNJxPRpiYS55oBPbRqef5GaBkuNQll3NTw2nZiVqdrNDu2MtFKdnx3luyVqvnjh1GLJab7SJ\nt6yTdMMbWtRdz0PLA3rX42HQhGMoS/Tq6SdPsn7X9q1nYsofJM+U62Yp2VCuQkktml4Y0xKrdRhF\nVCWZqxOUcrmbpgO0OI4HriYUuv748eOcPmHHa3n5Lteu2RyN91bvEYolOeqEtK7fBuD6ndWcNh0b\nH2dCLF8T9RqelL66s7nG/Lztq0995CluifP6KPi//sHfI+xldU0j/uW/+Q3AurNcuSK1N0sVpqTG\n4m/8+r/mD7/2RwB853vf53f/028DcPjoEQ6J1exnnnyahljlcJKh+wku+21r4frmK99mU4KrqtVy\nPnZhOMCVEjuRURiRMe/fWubzP/tZQNyP9oZBAA/Dh6pMOWga4kPk6CiPTkj7HehJ6LQ2uEGWhDFB\nRdbkNnAGtLYtnbe9tU0oNaD2t6bpSsHcnZ0tblyyi2FpYQJj7KRxgYm6na29nWV6MvkmJ+pE27aj\n27ttzJLdNLudPZDQ78mqz/lToyeZ++SxX2S7Y4VaqvsoCdF0Sy5Rlmk5dNjCmuTbccpX/tjyuF//\n2iscOWzNilNz0+xKCGs8iOlLBEacxrnfhecFeSqI7e1Nfu/3vmifGycM+va3U2WHRamv1sXBd7LQ\n4mGKzcDzLUc9ApRy8o3XOCrPhG0VqKwenyJP7anIs9SmWuFJZJaujOM3rUC7t7HNvS3b3+fPPEFN\nirrt9wccnbfhwLVShY5QF1du3OXEvPjd4IDKIrwUTlas2knyjTHFR3tZPu4R4Kg8O3W72+fcz34U\ngK++8ipGxuGx40u8c92mTNiPI+YkqePZYyeZFn8ut6S5etsK2Lvr25TF7y1KIjY2rIKuTMyJJYkI\nw8mieDk0NUbVFWqvXs4Xvuu43Ftel/sk7EgB5D/4xve4eW/nA7QRQok4S41mfNIqMjpN2W7buRkE\nJfqiLNzbWMuLMBuTsi/h/mjYl+R9kdJ5As/UGG4KnTPQISWJiI3Tm9QkuiYM+3kFgonJCcpCsU0k\nhlR8HtxGHT+2ArBccjEfILP0/n43zwTe7/aIxQexUvK4v27b6G60mZoT2dCPSZMsdTmUpChqxank\nUVKDKBpSKTohESreGEW/l9FaPr5QmfubO3kyzShw8IXaU0mSh4RjhmNRqlbxROA/DNpLOfuspZGv\nXLrI6xfelHc0uQJnTMy++FJVSgGBKOXhziY15xgAH3/xJf7My9avJI5ifv3f243uq1/7E3xZRL/w\n0z/NqSN2jkT9PFKdvY09FhaW5FlQF7+0yckKiSgU6ysRvdu2b3a7u1TT0X1tutvtfAP0fJ9UDkW+\n6+Q0tYkjulF2qHTyqLQkHhCIYjLmO0xKeosp11Dt2PEfrK1SXrT3P9pwoG/Hv4TJfQpjJ2ZL5nsU\n9jEybo7rMT5hZetLn36Rb3/9m9I/W7gfINJNp3roqqBNntLl7t1Upx7LAAAgAElEQVR7rN+3a8j3\nHebEv8k/4LeqtWZOCiw/ceZU7vahGCZUnhob5+iC3Vdu3ryZ+5Td39jIkxOnWtMSd5Cd1i63TaYw\nejiORN3HXZ6VqPvnnn2aBYkQHAU//9/9PDvihrC7s8O3X3sdgK2dXYwcJN6/fJk/I5TrCx//OPcl\nQvqV177Pyz/1WbnmIn/37/0dAD7/2c9RE99NnAO+ucBtaeMv/blf4clnbIRpNAhZPGQV+XffeTdP\nWvzplz/D6vJtAP7JP/pnnJPkpXGcsrExOiVd0HwFChQoUKBAgQKPgA83aecgyutyJYM+SrT3QbuN\nlhOwq8CJResmJI2sua4fRuxuWGtU2FUENasHDiKTOwEa17C2JnXu+hGOlEtwyiWeWJJ08d0Bnlgy\nxhs1HKnv5MyOsTAn1JHRuZVlphEwde74yG1cHD/L8Tmr2TYaNUoS3aQC8CJJeHZ7lTfu2wSknd1V\nHjttzZZukhJKhMRbb76RR41opXDFcc71AxLR5Dv3VojFKpBEIZ29jHJwGGtKEtR6iZZYdEylQZCV\npRlENOTkrY3OT3wPQ1o/hBHrVmoSUqFjVDTILS9BtU6lLPmh0IQSOOAqByNWxwE1ekJpdv2E3cha\nanb7hokFG2UxMeXjS06fIPDZvbUCwEZrwL6241avN4nl9BklEYlY/5JwQCeSBKGNSbrx6KUPUA6R\nWFK+9o1vc/GqzXl0e+V2nr/rF37mc5w/a3NOba7dpyW15NrdPS7esRYrLygxM2OpQN912dm0VNHO\nzg6hRNrUKj7VijXBH5ke47BUua80SniSZDKKI/aEQtpvh4ShJIFMHa7fs8998/o6oR7d+nZ/9x6u\nnPj9ustEzZrX0yRlIGYHbVL8uoiIRONWJenoeJOyRIKqOMURa07XDGgL9aIw7HTsenXrLj1JBHqv\n1YGWvY/n+9QlAmdquk5PfrvZjogb9v4lt4Qr1HA46KE/QKJAbWBf5t7c9Ayp0Hnd/oDKpD1VV4KA\nqkSV+kEnTy6K5xHLs5qNBtNiFYjimLrMydbebh4kkqQqp0QnJpqEYnHb29hi/qyNfBsog5brnQPt\ncF2XKMoowhhfKP2HYXPnHicXbMDNiy9/iq9/608AuPz+OqnUQHWVQ11yBiVxQlmSFD//9Bl+8ads\nSZVnzj+L6djn//N//i/4nS9/GYBy1WdGAj3WltcIT9vxnJ6ocO7sOQBqc9PE4mpgfE1LnPwbnsue\nREYeOvQ4k+MSPJIGhB+ghqRb8/GynE1mePbXKs6TmyovwJfILwVEEoltPDe3kNfKAU1x9fB0CmIJ\nTDodlFjlq75LX/anfhzjSYCMMYDIj4pnqIvT855KKUl+vPlD81QkCnZv916ewHUkaI3SmVVlmBQ5\nTRMGUtcxSQZsS0TezevXc+pTG5M7cI816nl9vdu37+BK8tL5uTkOL0jpq5NH2RBH9jvLy6ys2Xuu\nrN7LqezBIMr3v0qllEdfahNz/Lidy7gBUxL8MAqSJGFiyjp5N8aanHnMRiC+97u/l0f6GmP4pV/+\nZQC6ccKsWNNWVu4yJnRep9vlccnFp4nYkOwAjuNSkQTArmeoSQLbkyeP5e3SScynP/UpAEpBiW/I\neplfOERf5kO1WmdXHNCnpiY4+gFKH32oypRJYlIxK2rHZ79jFaV7t5bRgywz+gAJeqJSVaRCY/Vb\nIb5kw56fqlPOam45Cc1p+/nowiLTwvXWKyWqkuSzVPM5umgHQyfgyybuGHBlQXqOAvG3Ue7QxOsr\nJ6cKRmojBt8b1vRSsoDHHJ/uqh2kO2+tsC2Rhmvr90ikwaeWjlKTenlvvvcW2zvip6EUOq9v5+bm\nTIzJsxUfObxIaUrqt/XDPNuz1h6DJEtl4OWKRyXwmJ2yiz+JB1mi8Yein4DGCh+dJHkEUzqIaEpd\nNs916JiM1tEMeraPJ5p1Ikkbcf3eKtG+7YNADzOXb3djxrNUFCpBpeIvkRpuycLZD2P2Yyl86Y+z\nJ4IrDBPCrihrPUNZ0gmEvQFXl0dL/QDihiUh1Z1BytWrVtnBd4ladpP84pe+wm2pHXVs4TDas8ro\nbnuPW6tWMbyztpdH3UxNTNCViJqZsQpzU5nJPsCTDa46cZivvv4OAHf3tpgft9ShMil7Ukh5MEhI\nZTz3Oz12RIGOVYURg8AAOPX0aVJJTGoTKto+P5hED8gpuSga4MrmUqvW81qHvlF5gfCo1cYkkjG9\nPcCRKLwT507hycstuUHuZ9Tr9qiIH5ky4A+y5KsqZ25VlNLNogUPpF4YBZVyib5kUe52O6SRKHGV\nJjNjVoFKBn0c2ayrlTJNUZTa/cFQMQ8CW/MNbHHULLO+1nnlgMAzLM5KoeNqlc1LVgFXSlEat3Ng\nYBJUnBUAJy+CrlyHgaSdiKIop3Qfhn7Uy2uRHj1xgp/+jN0oVpevs75v/RFLQYkp8UGsVhs8+fgx\nAP7sF16kKj5zF775CoEn1RlabR47clh+Cw2Zvykx7737BgDPPHGcnqQQOHT0BN0shXjcwpHnXl6+\nR1AT+eKWqIi/T9xq01obXdEoL049UL2gJApVkgyIZJ46KsDNCvCmKUYOocqkpCLvvM0YpyQb5kST\nhigXwUQDJ1Neqw0iUawToxkIVWu0xjhW5h1eLPO5z9gD0h/94AqTM7aNR46c4LEnrN/kD25eYiv5\nAHtGqocUkQGdJ4k2edoXqzxlMjXNM5pjDLfEZ/g//dZv4YuStdfey+nRqckJTixZpeDs2bP4gf1+\ndnaa8Sl7eHv88dPsCq0WDkLKMjcmmg1mJbJ5YmKc9XUbTfm7f/BlLt+2EZq/+kuffWgbHeWwKQk/\nv/GNb/DGG3Yuvfbd7w4rVQD/6B//EwB+/0tfQovRYGX5DjckJUYQePzar/1PAJTKAYMD1RpOn7YR\n/uVqiatXrT/wmz+4kBeRBrj4nq1I0el0c7r+D//gi0xM2bX7t//23+H48WMA/MW/+Cs89eRZeVb9\n4W186BUFChQoUKBAgQIFfiw+VMuUDkMcsUz1ugNW71iH8s31FUpysq/6inJV6IdaFV+SXNSnShxb\nsFabaqVEWfJvVEoV6mLSq9WG5VusNSnLB5ISZCZbvPxkHw8i3Cx6x0nJK6O4B0oYmHRYA2oEpCZm\nICnxK8bklOK1C+/zype+AsDa5n26knsmVn5O212+cZMgqy/ULLMvVpYwDCHNnLjJ22Ubau+/u3Uf\nRyKFTJowI8n8lLEV1m2/VfNcUEtH5pmbs9dEgw7JiDRfqXePrKNc12WsKqeKKihlrSdJv00iCUo9\nx6Emp/dSv4vq27Ea0ylaajMq36M8bS0UR6drTCD0ptbEPWtZ0H2HcbGInT06ST21p6hSJ6EpdcLq\nRpGUpCaTijJDI1udNp2ND2CZctw8v5JyPRBKyygNyr5/GEZ85/viRHmux7NP2oi81v1tPvXM8/a3\nvJvPu0atzNghe8L7zIvnePIx6zicRG5u9Th64jHeuf4PAbj+g2vcciQKS2uMyiaqyuviGRQEWZ04\nF5OO7pz9zEefzh140zTNT3iu6xIE2VqRWmHY0i/lil1bpSAgzb434GZ5xwaw+qa1yOgw4ehpS4+f\nfPoMTUmCmuhhSZj799dpSSCJow3VvtD+ux1iibzzYvIoyFjFRCMmtAQouYqeWN82N+5TKVsqc6w+\nxsy8pSh8V7EnJ+ZqyfD8U7bu1527W2zLu41Xy/m6McZQlVNqv9OlIda3x04c5ow45O5eW6Z1257g\n55YOY8bs+3upJpD7pAqMJBt2HCfvkzRN8/nwMERJSF8sw836GC9JcsJvfvvbpHfsPSabJZ4/b2mR\nJ594jLLQQPvdXb74jR8AsLcR8vHzts6kTsOcJdjZ6bFubFBDtXqfmze19OUyT5+19xybnOWwWATW\nrr9GdUzkmq+YmrAWrssX32F711oK3njlXcqSOPivjNDG+61tfG84H8Mks2JUSEUmhtEOqdgFPGXw\nhM3wTUQkLiP3O3tshVY+bQ1c1vr2nlpHVKp2PPeMxw0Zc+WkOQOgU40jMrQ2NsYL89aqdbu1iS5J\nMl2VsjRu73l3skxfj+5W4DkuZJamVA+rb2EYyvoDMv8AU2IMeVmdvX53mK8qTTFCKe9197m/YQNq\nbt5Zzq3Nnufm29zhw0dyeeC5LnXJZbe4OMvk5LD80+07NsDr+29doG9GVx+6vS5f/NIfAPDKq69y\n46bd+xcWF/PgDgxsSOLTuZl5toTWPHz4cE6DG5PmtUm7YUwi++h40+HePbvmnCDACAPy9DPP5P0z\nNtakJNa6Rr3BpFD3buDlLirTE5M0GpbhWV1dZX7OWiGbkoPrJ+FDVaai/T5by1bYRr0dAtcKgnMn\ny0wKJdesVijLBC3XA4KKbXxJefhuJtCSYUZr4+W18KoVn0plaCLPikFiVL4wwigiFlO7TmLKmU+T\n4+R17hxn6DOlFAcSUD4ccWJwIonGWNng7g07aS597/u0JNtzolKaQgUuVspsd60Zso8iFL+LSqnC\nmFARQdBFy+ai0zSf9FprHDHrDqJ+ntgxcB0SUQDDJM0zycZhj6UlK+A++dILjEkW4PZmHzNicdXA\n83BkHFzXyyNGFEOWyXGGiQeVcyBu0CgqGZXa8AkkUVpqPDwthVkD1yoJWJ1NYjVQyqV5QkKq9bxN\nAIpVmksSQZQag05lU/IqJFkkJfDUsdH5fRwnN6+jTd7fjmNyKhgHXPE5W99c59aK0CFelQuX7Zg/\nffoJZmftYhwbG2Nxwb5/vexzZ81uUls7nbyI8ZUvfpU3L12W/vTyQqJp1sHyX0foIdfx0LKEHeWh\nRwsCAyBMQgIRIMpRlIX6NhiU+FpUyuUH5lo+R1xNWdZrPIjQmZneuKQSjjhIEw4dttTC2Oy49VMB\ngtjJqYjy4jzTQoH5rocjhWLvXLnN3nWr/CYKxk9a34mu6RFkiSZHwNraOnEsaUQqVeoS+dPv7dOT\nbN7olLYoUzNjdcZKRwEoBVVW16Vm4uIhPFEwUQotiWH9QDE3Y+95bHaCUHw63711l4kxKdB+aJqB\nxL0HSuEdqCenD9D1mTJlzDCa62EYRG3urlqq+cjCcWrjtm8+85kX+WTX+rbMztZpjNmxfe+9G3zv\nHZsypTE3zntXbaTSbHWOVOb7oZkpEnl+Z5DgiPL1/de/hy+pbJ48d4ryuN2Qg+YE04esErnf9Ymw\nc3m2vsDOutSoPLFF0rPzZWvhMLMLZ0ZqH0DY7dGROb7X7dOX88LU9BI49h26JiAWv6ews07Vse8w\nXvbpx5n7QJ+uJJTtpQnbQvE0dYKSuothErInstjogRyqsTVFRXHwMOiOfdZ8A+pS0zAYrHF0XNKL\nPHGEiv8BSJ+DY24MP5qvHxoHTL47STqYPFpa55/NAYHsGIeuKCDXb9/Jf+so8EWOXr58Kd8jjdYg\n9U7Hp6Y5JOPrun4eCRhGaZ58dxS4rssLz9o6j4+fPk0qSlCq03x/SJOU6Wmr4CwuLuZuLtFgkPsm\nuq6iJn6WjheQSNWScikgEHo8KJXy9eSoYZqeUqlEILLHdV2Uk7nOBEB2EB2uPa1TupLmaBQUNF+B\nAgUKFChQoMAj4EO1TO3cW8HsWzPe2ePjzEzZ01uzrqgE2Wm4lDt8O76DL87Zvgry5IwpTp5kK9Uu\npFkZGAeVFfzD4GXOoUFAX6LkwrBDZrDyUHnuHM9ziCSaCGXyU7iNiBi9Nt/d1Q3ur1uNev3uOtur\n1knPCbtMiqPxQqPJE4etBj7ZrLAmdb+ub7XZFivY/iAiEiol8IIHKJmMejFGo+VEmaRRns/Jd10S\nOUlpx8nLWSxNNfj5z9o8HicXZ0klACCoj7EvjqMPhatys6lS5EkUHVROkyr5n73GwcgfFOTRNWPl\nYfr/EJeArESO5sCNcjhK4TuZ6cXkSeuMJs/9pLSBnA5zUFniTUcx3ayM1j6k/AzDNmaWGqNMXk/N\n5s+SfFi7Pd560574a5WqpWWB68sbeSK8LPoGoK9jQqGC+/0ekZyuiFJLMUob1QErRn4SdVTuoGoj\n2ySvVjywobAjwnPdYZmfVA9rLGLQYtEL+32GuSUNqbyzSWNcOR0apVFyCu90Q0KZa3vtFuPaWuJ2\n2jv5+g4ij0iiLEulEtWqUKja4Ap1P760yJ3L9gSchlFe5b7WqJH0PkCOol6fOLIWiHK5xJY4TSeJ\nIQ6tBaJRrlCStpcDnz2huGr1Es2GnZP1skelYS1QkU6JxQn6semTICVcdm/epStmEz1IqT1h17c3\n2UC7w77N5rzrOnlpGRjOD89zhyWaHgK3rekau4bXzW2q4irxqY8+xe3bttTHhpuwUbXuEctjU2yK\n3Ny+uU5nS0oILc1Rllx002aXowuWtlvd7nD4nK1F+exz53Al+acizKNje+0tbl235T12+tt0Y0sD\nxev3qVTsu7m1mJX3LU3y4md+nrPnPzFaAwFd8hloWRONMSaq1lpfHZvGOBJgZBxiiSqOeh5OItSx\nMoTbkgxaw/SkXYszcw0a45JMOYB+ywaMhPtr1GoyDm4pr1WnU41jMkuHl+dB/EhthkqtIr+9RqVs\n1+LhYxN5frZRkBidlzhTSmEyd42DbIE6sAeZgwWHTB4QgaNyeayUkycMxhiyrKCe6w6JQzO0cQ0O\nuHko5eQ0e39ji60D0ZfZLZXjYT6AvKmUK5yXOoNpklgrf/bOatjPmcwzwNz8bPZGPGg5Mge+z6yH\nOt8jUQ5kNWu1zq/XWucWzMHA5HnePM/LZbxSKg94UEpRqYy+b3yoytTiXIljE9ZkuDBVouRZ4ayI\n0bI4VbmSFy90HB9f+HXXxAyycFbSfEJ7roefRfZ5fh7d5nkeWpQvRzlUZdLXmk36UqNJaWiK6V+n\nManUAkrTOP+t5zgfRJfi//v6d4mlCKXf7VCRZHJLk2M8c8RSTcdmxmk2JCWD0kyLoH5s8RBdWTR3\nt3d5D9s/N+6ts9m25sZeGIHQIcYotJvVhhrWpXOdAF8S1NXLJY7M2cSXn/2pT3AiS+C5vUVPosuS\nQUx3b3+k9qWpGSZONMOJbWz6cUAmZD7Jh9SYUk6u+DhKoWT6qSTGZIlAUQcSMw5t1fIre43WuaAw\nJvMjsxuySYcLJ0vKplD46gMMovJQ4ieFcYdPd4dRh1oneYSlUh6pvGe7F+a/DXsDWl0Rqo6bL3A8\nPzcxKxwcJf3gDQ3FxugDigw42XMHEQuH7HieOnksTy+Cq/I+HAUlN8iVPkXuEoTWmoH4J5TLQ1+h\nQRjiyfulStPrSBblOCYRoT/YT/JIPTstbHu3dzdxJXO1Sl0cUZZrtVq+Xl0UjvCUSVCiJH4sndb9\nvBZlHCi0pPkYBTNz88SSWsWkKWsSZdloNpmdEpoKjSt+OIM4YhCJH58rij3Q2duhLGm1jWMz3gPc\nvbdJW6oIzDoek1J3cvrwIuVZS2HvpxGVLCJ1EOGIAPd9D3NAWc7rz2kn9wl5GCq9OqFvaczeIMVJ\nJSIvjdly7bvfHcR0JPFxTI+pQ/Yd713bo6vtWK1uX+POPcnyPzuDEb/W1uY27qpVjn7qk8/S2ba0\n4DuXbzC3aNO5tHfWuHrL+g42pptMz9i0MJvtP6bTt1Tt9vWTjFetj1UpmOOt118D4HO/tPTwNk5P\nUROfKa9Uw/Ht+7uulysbaRyhxbe2PHuEJLZ9H0cdgqqV6S/XJ/FkPMdqkLG2rtmjv2PXQa0Ss3jE\n+jW6zgG/WYz8G0qeSypfj8VuTtXu7q3kxXLHp0pUBqOvReWooSuJQ643GIYKDubA2fIBUWYOyAmV\n61yKXH+y6kdeT/BBOZjPQecB9SyPUlXOULm3/82UHWcYVT4CDJpEEsBqnR5QDg1GDxXA7J5KqQc+\nZ/JS6/jAIdMdKj6GXDl64L3UsM0Klae7SJKEoa5pci3RcZz8nnYfGr2NBc1XoECBAgUKFCjwCFAf\nRLssUKBAgQIFChQo8CAKy1SBAgUKFChQoMAjoFCmChQoUKBAgQIFHgGFMlWgQIECBQoUKPAIKJSp\nAgUKFChQoECBR0ChTBUoUKBAgQIFCjwCCmWqQIECBQoUKFDgEVAoUwUKFChQoECBAo+AQpkqUKBA\ngQIFChR4BBTKVIECBQoUKFCgwCOgUKYKFChQoECBAgUeAYUyVaBAgQIFChQo8AgolKkCBQoUKFCg\nQIFHQKFMFShQoECBAgUKPAIKZapAgQIFChQoUOARUChTBQoUKFCgQIECjwDvw3zY3/ynb5puLwLA\nSRMwWv6icJV81CmpNgCkykFh/+C6Lq5jPyujMXK9VopU7qOMg6usfqgcg+fJb5WLclwA4jQhxd5f\na0MS289hlDKIU/u9AU/UTM9RzIzZf/yLv/Wp7C1/LH77t37T6DRrlkezbtv7yRd8ut0EgNffcdjd\n7QGwv72Cq+w7vPTip9nu2uuv31oGEwNg0gRH2ug6DvudNgCbW+uY1D5sMIgJU3ufRCcMBgMAuuGA\nKLaf4ygmGtjn9vpdtHyv+jGO9Mmr717/iW18j9gE8pyq8ijJ1QaDg/QxkHVBrGAP26aW6XF3/xoA\nF7a+yve+9iYAO++t8bGffRaA9y+8Q2t5G4B+pJgPGgAcnh1nd/UKAD//sec4/9hjAPzf//JrvLW8\nB8D5l55nIt2yz9re4N2tAICjn/0Epz9t7///nP+rDx3Dt6/dMtln13VRMjk918GT+eXhgGsvM8og\n3Ycx+U/RWg//bQyu+eFHp9oQa5Nfr7Ud5yRNSVI7X9I0JUmS/PtU+v/g91E0II3t57/w8z/z0Da+\n+u//ljHGjtf61i537tl+O3Z0kVrF/twkCUbeuVrxcZT9rFUZjB3T7V4fhX3udKOGTGX6cUJQqgLg\nmBRH1m4ca/bafXvNIMWXN63XXPp9O9+7vX2CcgmA3a09fN9+rlR9WnstAP7mP/jSQ9v4F//HXzTP\nvvAcAPe3N+mF9rmloEa/Yz9/5tOfYHKsBsC1K5co+3a+3b67watvvAJAomIWZhdtG8cncLRtu8JQ\nr9vfTkxOYGSN9uOU5ZX7APQGmjCy/YMHfsnOyfZOi8G+XYvolFiEhuM5eK6dY9/6/W/9xDb+w3/1\n942SZxpD3vdpktDv23t3ux0c7DWeMhiZX57r4Hm+tMPN5axKdT6nUCm+su/lOQbfkXk36KFlLrh+\nE61smyKTopSdU67rk4gMHbjQce1zuxrSxP72X/+f//ihY7i0OG+OLRyxfaMTZmcmAPjLv/ZrnF46\nDcCF777Ol7/6FQDOP3mO/eV7ALz+vddQQdk+1yiax5YA+N6VK6hgEoD6/LNUx+YAONlM0JuX5aXb\nrC6vANDXbt5XC80SaWvN9nnFZ+3+jm2vCkhECIzNjXN3cx2AO9t7D23j3//diyZb9w9CobWsRTOU\nJcYYRGQQKUOaixiN0UP5Y8RWoo0a7nnGPPAZub8iF2FghnIsUSkpOr+/PnD/7Bf/719/+L4IPWNk\nV/jhi1X+X5O/hSJMhu3d3N8H4NULl7l16zYApZJPpWRlg+M51BrjAJx//DRPLczY743+UQ/8b0Dj\noXcpLFMFChQoUKBAgQKPgA/VMhXUXCI5uXgaHPmslIuDPZWSxsRibYlSlavLyjGIUQAHg5GTkeOA\nIzqh0sPmuK7CkZOUch1cz/7NaAXG3t8kCkdOgZ6XkMqJTOtUbCyg3IBQRSO30SUkjm1bUu0Q+fa5\na5sOvX05ebdTPDmJTjVqePKweq3CWqsLwP2tDQY9q41399v0ux0APvL0MxxeOAzA1evXuH7zKgD9\nXshe3562Dy1MUQvsTX9w4Rr9QSz9Y2jUK9IP4Pj2tDVIYhqV6kjtm8In6xwFxDJAUZwSGvvuAzU8\nZbUHW9xdvmvbtL7Cjfa7AKx03qe3b091Z18+w9lnPwKANzPL97/6x7ZN93apzzcBWDhSxt23p5Av\n/uHbzE3NAvC//rXP8+VvvQ7AW+9e5NqGtWr9D7/8DLf/q1jBfuerlDx5p/N/9aFt1DrJTzPKWIsn\n2Llj5PhvHGPNATxojfrxePBgM/yNGZ7LlEIp9UNXK6VwHPsOriG3gBhj8utdx8G4o5+NemFEuVoH\nYKxeYrxi+3aiHjAxbvtcpxGlwH7v+j6pWMr6g5ReaN9haqyBTuz8KgUusVh3wyimE9r5W/U9dvbs\nNVHik4pFLIk1cxPWclAqRyhH1qhq4JWttWNCK5LEPstxHFxVHrmNR5YOMTFhLU3KSQnknjNT81RL\n1qJ09PAit2/YeeIZxaHZeQDK5XHevmgtp7vdHSYnrEVkanwS37HvE4YhiVgDd7ba7Las1SxKNf3Q\nfj82Ns3JJXtKvr1yi/22XcckKWWRSf0wRsn4VipVtMnsuj8ZKk2H5gSjcLK5qdPc0uw6DjqV+eK6\neGLl813XWlexssBo+75xqknketf1wLP97QcBJdeOW+TskWg7no7r4oj10sHDkWuM9jCJbUc5VZRE\nDta1wpjRt53WwOWtW9Zq6iR9TnasFbrs+xyat2P1nV4Px7fP/dhLH2P601aW1WenuHrtOgB7nS6z\n89MAXLz6Hluxvb4f16jGdi4kt29wrmnfbXKqzvJta7lPYodELP1jc5M42lpAeiYhjuzesDfo4dfs\nc/04oit7wKNAA9rJrEgcsH6LVQlwDLmw0IYDlp2Dn80D8iaTW8qYA9LngMxRw996mNyyaTCQsUMK\n9ChiL3+qzq2i9h6ybxgnt6a5inzeamO4u23lx+p2izt3raX36qXLdHatZbBUKVOpW1k1MTnJc2es\nhfH4ZANkfz3IGqB+tHHJwLBPDv5B/Yi++Qn4UJWpJE7zEXAdF9+Vhe2X8F3beFclRLIIw5jcrGjM\ncBI4GDxZnFpBJAJNqRKu68vTUtLUTmjNUBFzXR+tRfkCMJlZ2sUTLSFNo7xjYlMiDEdv43/58peY\nmZqRewY4Iry+/b0uSWjbtd+JmRm3C+9TL5wjEE4x8F0uXZUNlUwAACAASURBVHoPgN/+z79JmghV\n1+vmCtqRpSWeeNJSF+1uwhvvXcn7JKOLvJKDM243yv1ej0jswC4OJxesQDl2fJrNu1b4L80f4enH\nnhmpfd+69C2293cBaHV2CffshO+sbzN3zCpqz730LKWS3cSubl7jX/3bfwPAjTdvUh2z96nOVXnq\nC+cAePaFl5ibsm3aLdV47ues8Nx95z2216zCde3WNv/7L4tZ/817XLrxAwD+yq9+lL82dxSAv3vr\nNmFkN8zHTpV46UUr9KJ3NLe/8YZ98P/28DamsrGAnXeOzBHlGIYavYvKaD5+tFQx2uR/UwyFj0IN\nTfZ6aLI3xjxgyjcjKGuZkqWUg+u6P/a6P41arYkjSkFlYpJqzW4ok+NjVKtWQLU7bdodO75BkKBF\nmYpSTRhZGsnFoVqpyTUuUSrUMS6OrL8wgYFwPvfut6iW7RpN04iyKP2pdmk0RGF0Qvr7VjGv1+tE\norgFnkcUDkZu48ljC4xV7fob7Lvonn2fySMVBnLwuPLeRe6urALQarWZmzsFwN2VFbrS9kNzcxxZ\nsDRfvVLFiCKxsXGde6tWyOtUMxjYjbVUqzEzbTf6c0+cy2n5fmuP3fv2+sANckVVaYMRKrkbhdl+\n9VAoFBnNh7EkCYiSLfPCCwKMHDI9x8vlpuc4IEqq0XH+W9e1cwlkc8sOFWq4keKVcHW2JhzAz+/v\nB77c0wWRWa7jkojLgqPSH7NafkwbS7PUJw/Ze3a30dhxO7J4nFbL9uu7777LCaH95xYX2bm1DECp\n6lGp2LaMNaeI+lZuTfmarmf73ow38sPh8RMLNEOrrF27dAGnZPsq7IdEohyXqlWmxy3teG3lNk89\nbeXmG+9epi0bxd56j040+jw9uNYf+F4NjQagcwXKoA/IFSfzNrBjmI3RAcUqNTJ+2L0wGwGlzJAW\nNA+qYRmsgq6yf/wpqnH0kTSoH6mcxDgM5D6BMdREJg1Sh5t3NwB4+91LbLTsL8LtED+1/dxLYhbk\n8PP5Fz/CY0tCB7uKVmjvWfIUFf8nv+fB46tdO/9tvGBB8xUoUKBAgQIFCjwCPlTLlJMafDHle8rD\nk8++61HyrTm5HKSkYuaupg6JWKm01jiZU7gylOXEmWpDe8+eVqLIz51V0zQmFue6SjnAL8lJreKz\n2+7J9RqVUSNJip9RkK6PK+ZVJ3XhRzgO/zjUSnVqTTEnX7rMQCiQMI5xpS2zOIwHCwBMNBv4Yu5X\nWtMTOm+3tZs7wSdJ5gIIuCXqTUs5VGqN3LEeUipyn7urW+y0bBu1USBOpBiXcbGIzR8aw0ns5+Mn\nz7BnfpQD5A/j13/zn7K+vmnbWnGYbdhxc9sR85MnAfCZoVa2nxenpqg17JgknYSBDOLk6QYLJ61l\nKg1mWN20p5DL1y+gQ+tA+rPnF2iP2Xf8ymvvcXfLtu/5Z+bY64kF0jhMj9v2/cwXjvDvfsdSit98\n9Sq/9hfsafXxx1L+xW9cH6l9YK0MuVH8gGOvcSFV2YnQoHI60z1gIk9QYvnEmPzEb08+Ms4KVO7U\nmeYny9SAlnHQWmPSjHY2JJmTuhmeFK0FITutuqSjDSEAg0FCrWznTrVawxU6J8WlJc6eg8Egt3YN\nopS+WIX22h26Pbvmzp09jRZa3vdcSoF9icnxcUKhQLpdUMrO64qfosSS3CjF6EQov7RG5qedOA6e\nb8c97HeJsfMnintUJ2ojtzEZ9Ojt2T53Es1+y75Da22TzU07h++srHH9lp0z65t7HDpkLVPN+hhP\nPWbnp1/x2N6wFtKV/RVKQUZrufS7th/iyBCUhEKPFZ/42CcBCPwSF995x/Zhp0c5FUtJpYbOnPId\nTS8Wp3ZjGGvUR2rfD7EWJrPsBQRigXK9EsMzs4srQsVzwUTijqAMJBkzYMgErYID1GFMkmZyBBwn\nkHdQuMIwOH4JJRYftKKsYumDgE5vV+4ffTDLlGpQKllLadgP2d6z1qh/+2//I0cXLK3T6vZZbFqT\n973NbX7vt34bgIHay2mjOIoZH7P3Of/YSbZXtPz2PoFjZcnEoRoDCXAwnpOviagVUpL797SiK+us\nNYh56Zy1TL1zZ42kbeeIcjWN5mhuE7aN6sBYDgfVUSaXE5qhLDEctHgPLUoO5qBRabhnKIMyw+uz\nixyGY22d3YfuA8PXOMgvDulFyxSNLnAOvufBdipAvF+IY8OiyKSNvS5XL18C4P6VSxzy7bqP04gd\nZcdrfHKKl563jMbRxQUG8v7dfsq3Ltr5dv7UGKem7VzV5kczfQryPyilchmsfgwt+OPwoSpTntIY\nEc6ucvNoO6VSUvHc156mWhNfgv4AT8x+QRAcoDQ0vpjuBmFMtZz5jWi0sSZArROmp8Xf5tAsUWKV\ni539/dwnAMfJfaZKvpPrHCiFlgilINXEZNThw/ELf/bP8daNOwCE6v18o6kFARNl266/dOYpnjxu\nTZK7lRKpUJNxMvSVKJdLODLhkiRE3D0Yb1SZbFqB1ag4jNftgq/WasRitu/193GFPlE4jAuXb2Lo\n7dtrXv36+xw6bJUNpuYJqqMJcC8oIUPCfGOc2abdBKYbdepdS82sXrvA7BMyIYOA8Wk7VuVaiutU\npT8arLxtKcr3uUFv225Ku3sbNMesQHv+hc9z+JTd3OZmNK+9Yc33242Av/6rn7f3T/bQslHHusT9\nTXufP1hrc+yEHf9Dh2eZrFVGap+FymWJMio3hRtlrK8UVrjlpJpxDqzSdChkDjg6GFT+W4BEaACd\nxhiZ1waVufOhdUIWFppqkytK2pBLSa2H9IBC45rR/TSWl+9xaN7S0fe2uygRUIsL0/kGGoYhnijr\nvl8hlCZOT/o0ZU6RxuzuWGqkWimx37FzIEk9HFEuyvU6nihfvhMyPmU3pqiXUJKlNTc9jLgtOy5J\nbNdKpx8T9eyarlU8yt7oAm5zvcV7y1Ygu45LpWnnQxomdNtZVGvM5qZ9//X729y8YRWr/+Nv/A0+\n9fGfAuA3/sO/55VXXwVgfKLBk0+eAKA5Ns4Lz1maYWpinq0tu5n6gcfhObu+v/zl/0p7195/vDFJ\nJ7Xv348iEhm7SGscGffUJLiV0cTywT3PUWp4sHL9XGJ5SoGTyYIDvneuRovccXHyTVIT4si8U2ro\nUWO0IZXtwnGcfLor5eKJ0uH55dwHJyVBZYJCGUq+nQtJpIn06BSYUg5x38qDSllRDuycvXHnHkb2\njMr4NBev3wYg7GlqE9lh9hKf/vgnAHjmsXNUZD6++tprTLSsLDl37gjJvlXQ5ssJzrxV0I6ePslG\n2867+Z0e1ap1GWi6Dsm+dUM4cvZJVMPO5dPnn2Ve5F/gGTBDV4GHwY7JwUNXBpP79+oDbJtBkTNs\nanhcM39KZVH5RXp4IjygHGkOUFMmD+z7U0qPyX00tdH5wc8Yg+EDnN5+CEOlrCz3CRRs9Wx7v/PG\nRdp37D665GiOObZvQz1gUcZx5shx1pbtWKystvDFBzgOI9r3re9s1HgaPWV9jFF6aBg50M0Ghq5F\nqaIWyBp5ILbw4ShovgIFChQoUKBAgUfAh2qZcl0XxKTqGjc3ozmuyiPaKpUSEphBSEwg/6iUHbJg\ngCSFSCiEOE7y3CZBWeVRezpVjE9aDdYraSJRMcNIk6bSbOPiuFkuKoX8FM/3CQf2JK1IbVTLiLi6\nvMqeOGh/9jMv8b1vvwbAfLnBlDzgXqdDb806vS6dGMcX02Y06JNG9rnT402UnMKdvZSxhj1VD3r7\nXLxoaYNud5/paRvV1hgbZ1/omaVDU2y2xXn2yTnGarbPq+Uq3Z7txBvXb9PuWmd3zzP4FXvy4n/5\nn39i+xw/oFa1VglXx3mbZgKHuGepEy/uQseeJnUv5bNCw33+Fz/Oes+eEjZ2IgbftLlY9H6b7die\nPKL6NmNnrRlub/kO55+yZtyfPf8if/gNm/flyvVlnjr7PgCPL1W4dNE+9+1LEalECpXdKv/6Ny1d\nODa5ycz0+Z/YroM4aN5VD/pNHoi2UyhxTOcBq7iXOyg/4FiqLKUHkGhNFNtTr9EpsVDBsTYYmcuO\n6x9wUtfoLLeUsdYyeDCPlVIQ6qFl82GYnJvFrQiNMegSdnfk/bs0hWYq+T792M6XNAkZDOz9S4Fm\nbs7m6ent7w+jxVCUxWm3NxgGiRgHpqenAAhMyIRQzbtuTHdg3z9JA7KznRPUSCM7Hxwcpibt9Y1a\nOY8WGwWbd+9TFuuL53oMZE2stfr0etZycO/+Ji2xHPmez5s/sBF8d24tMz1rrSC3rt+htWOtn0o5\nyHBRDmo8IVTgsWOnGEjUbKfT5qtfs3mPXvn2d3I62HGh7EsblZNbpvqDKGPZSJKEXjBaxKJJ+riu\nXSvOgYAeXJ+2OO2naGpBRi+bPGLS1TGukTxXpVqeFy6JDCrOTBQpRkwRnkkOMAOQWRaUk+af0zgk\nFmo67HcJMwd0fKYmj8otB0Ti5D0Kzj1ziu6uXfcT401On3zCvrJxQPp7v9dmV6xdtVKbx48cB+AX\nnj1BlqNqbmyGSAKA2voCaWj3jz/38ou8/S0bPdy6dYms6e2NHkbYj06kMDIk07OTrGxa2X3v/hoX\n16xlZHO3Radj+zPtd1Dp6NY3R6lhYMsBKDOk7Q6ETFnbUjZEKo/LQmsecArPKE6jGF7E0G/B/kei\n3szQCukciLZ7gNo7kAtLPeDC8HCoAxGFJv8/64biikzthiHLdySH1/oqTwpVWqm40LX96buaprA9\n+tpVVEmiTf0SSC4wT2vmRdbuXbnOmuSsm1yYIihlFP3QAucohy25/2s3NzgsEcDnFsfIjcQjmKY+\nXJrP91BKBGwMqQhh5aTUJDTb8116PSu4bEi0nUZhOKQwkjQdCijHIZAIkvpYg0AiheIozs3Mg7iX\nC6tBbNMdgJ1MGYWj0Sg/m6wpvggR13HAH92A96X/8iX6XatI/Nmf/imef/ZpAK68foGrK5ZCmF86\nxqTQkfH1MXx5bnNilkQ2xNn5BaLEXtOYqOfpH5bv3uXdSzax3JWbt9huSTTdIEaJIIu7hlQm6OKp\nIwTiL9Zv79JuW0HW70d0I6uEzO62qCajmWx3N7fpt+w9EhPg1aQv/R5TC6IU7HR443vWjN6+GnFi\nYDfSz000aH7U+pK88dwSpY1bAKy88nX+8LJVjrZr0/yFjz4FgNNXDEK7WG6vrOK6dnGt9Pr8s2/Z\ncPZnnpnh3a9bYfvO97ZxUsutO77HoGMXSEt7hJ3VkdoHVmEaKkFqmNDwoGZlJCwZ8Fwz9HU6EK2e\n/yb/hyTkTAZ5EkttNE7GL+uETteOueP6BOWaXDOM6NMHnmuTfNrftnoR33zzBgC/+oWHt7EfJuzv\nWaW/1+2wMGcVKK/kE2VK30ATygbU7ffYl81i6eghooFE9iXk/lyDSDM9Zcfa78XcXbd+cLtdL/dl\nnG3UKJXtmDbG4Oolu1Zm53xc7P1r1SrNqj0Itff36MtJaODUSdLRab4TT5whzfyCoiSP0tnearO6\nZufn+v1t0tiuD993ae1aeuCP/uiPKImyee3atdy1pN8PqVYstfOxFz/J5KRVuIxWVCr2nTc3N/nO\nq/YQtbu7S7WaKUcar2mvWViYoSv+VmPj4xw6ZH0ot7d32BB/roeh3dulFthDVq1ayschiiN29u3n\ndjrgqGOfP1mvDaOourukbfuc2B/HyTYiz8GI4u6okFCF0n8GJZGysSZPlJykCWF4IGWG9Hc4GNCR\nJKwLE5NMjC/Z9u3cZ2d3tPYBbO9ucunt7wCg0oh33rWpVbzUx4gy5dUqINTM3McarC7bdf/iYy/y\n+OnHbf+UmyQS1bjZ+c/cumnXysUffJdUaLsbly+RSMqMI08/S+radtVcj+a49VOtTkxh5GB76sgR\nXnn9LdtXtUkCI6lmUo0ejE65+87Qv0kdUI6M1hhn6Mf0QHqDgxF5uWJrhsF8BxQx15jc19MBUpFD\nqTY46VBBS0Sx0sqgM3/Q9ICrgjL5y5mDvlQjwBhDX27pKUstA+zux2ztWpp1e/kug7tWTjf22yhZ\nH532Prptr9HhID9M4m7jyt6vPB+ySH7fJxYlaydKCPdlnS0e5tgzVtGenGnmr7/fT3j7ut2bL16/\nzZ36pDT9OOePWCNDdQRNqaD5ChQoUKBAgQIFHgEfOs2XJeBLE5OXp0idYaRIvx8Riuk/Sks2cSdg\nwmH0QOAl1OpiyfICXGVPe5VKOVcPE5XkCfW0UaQmkHf4/9l7z2BL7/u+7/P008+5vezerdjFojcC\nJApJUSySKFEsVrEoSnKc2E5cxqnjJGO/iJzxaJJ4PBMnsSd2ElkSbcsaWRZFUKLEJpqAABBtASyw\n2L57ezn39HOe/uTF73eeu9TQs4fDDCYv7v8FebFz7zlP+dfftxXwSlp1SgzUygkjC3H1dBOnIbYt\nZeCCbZOak8Mnb5x/mYWq7Gx3371Oop/5p2+9xvaunIBOpyGPVaT6sj0YUZ+S3e/87ALPfEyI1Wcf\nfZLtLfGkuXr1XbY2Zed89dZNVtcFvhoOfUJVASVZlJPdB4Mw37HX9nt4eurcvHk9L9XPzU3R6au6\naa9FqTwZtBB2I/pNVRz6Dv2CPMtnnqhx45Z8/7f+MMAL5IR3onSaRkVOpeHQxr8op9LvDIZYmcB8\nR9KEOb3Grct9Vnwh+H7oRz7CblugyH/5zZd4Z1VOJ0FssK/KpZu9IYW6PIO6F+EP1Y+kH1DUKmW9\n0aC5253o/uDP+TrdRvzke3/MK0q3Vq9QLEgfnJlezsvi31PhgtvMNsXtBSAIhrRb0i/cQolYI378\nQZ+Cclgt1yMdd+zs9pNrRqjeRvv7Pa7dak18j0cWKrx94QYAxbLL2GzHopAbEWaWmcelFFwbUyG/\n2B/RVy+uLLOINR5kY2MHS0/SjlukqqR/3x9wbVMqHFZWJIykmtru2vlptdnusDSvIojUEVdfRA1H\npvEzfpedzuQGuoMsxtDxNwojtNBAY26a5LJUM4MwZeyT5FgOH/3Rj+i/h1y9dg2A6alptve0ihPE\nHD8mfmdHj5xioNU6wzQJw7H/1C5dhdyzzMzjfwoFj4JCF5GVEemzatRKVOoCLQyGg7wP3Kmt7XSY\nrsoU3vVN2j35u51ml1JJSNhB2cOI5BrtRgtHyejBsJPHW9n2LoYqAcw0xtMKYb08zL3umj2Tbk/e\n8zCAWO/JDxL6XTVZDhNQ4UtvGBJolfXMygKhml7ubG3maupJml0oUq3KvbhWjKPvM/IjMvWQKk9X\ncJXwHXQ2WW/JOPijm2/wzl1nAfjEZz5HoDBoSkBP0YMvfvH/4S9+6scAWLn37lxVvnJskeq8UCga\ns0fZ3BfYuVArU1MBxc29PU7cp+/Qq9Ldlfna7+1hpv2J79EiyVV73+NBZ2QHcN73oCi3k78PKlNS\nLtef0oPKlPzzgYJvHE1mZyJQAhE+jEnzYRJh2uOKlUGubb6tCpaRHXDaJ2iZYdDSdd3KDAY6x9zY\n7dHVarB//TrhmozLQafNUJWbhCMcRV36pMQKVRvYWOkYNrdzLy0jS3OPO3s4pLAt66XV69D1pH8+\nM/ugiDOAm7v7vPSmCFUGoxFFV8boN195m2ZfVOmfeqB2x3t8TzdTGRbxGPaw0zxXLolThsriH2Uh\nqSq+MquUq+0Mw8hdemOjm8MbaZJh2Mo9GIUH2WZxnMMqWQyB8qScQhUjk4Hd6zQp6uCx3ELOdXEt\ni3r5YBEZRpNvprqDPlO6sD5YKPLy67IZ2G3us3hE+EI/8uEPcXxFsPz2aMSe5jtlxS0eelQy5N64\n+IdcfFtecBgFOYTg1WuYava3s7PP9qZgzEkU5TDG3JFlzt0nXI5aY4716+oCPBjxwP1S9m5Ui7z0\n0huAcK/6/epE9+dmbu5c3w9GLJySzvbd832e/armDfZKeDoY39lZ5888WVhWyg2WtmTgXKLGy+8K\nFOIle1RtuT/ThF//J1/Xaz9Gx5FJ7/WbCa1UJvxiwyNRPe2tCwP+y4/LZnTvXIH/47fkuzrrCUEi\nG+h2p8PIn3zkR2GQK9owrZzHlGYpifZZ27bYWBWo4Eu/96+o1eQafvozv0CpLJsC03bJZchGBmMz\n0CQiG0vh04xQlX3N/RaOK8/BsFz6KrV2S1UsVUNlxgHXMM4SfP2cLE2wzMmH895Wm9npsTu4TaUq\n/b1YLOe7tST1iQJ5nsMgzK1GQj8iUT6MYxfyDWah4OXQmJHBUc3Hmp2usdWW8v0ostjZVI5SqcDK\nUlX/1iRSb4RRr0NY0oWyWMiNC4tGBMopnKQlQ5++5vH5vQFFfY+dpENbYYMMG9SA8oF77uezn/4M\nAM9/53kW1GH76N4Of/Dss4Bsst6+IKkDS4vHmJuTe6zXqzja5/v9QW7gSWbkkGixXOLMfcL56Ud9\nfF281ve2ubWhE75hCA4yQXvjlUscO3svAIOww0ATHPY3tlmuq3pycY4A2awXrSE4amQ7CAhC6cvT\nZDkJJzNiSq462kdhzvGqNGz6yldrbYb0e7qZTm10T8Z0vcj8om40VncJNf+wVq3S6co1BL0eFpPz\n3p5+5B4ePKJzn5UwNSNwG1aJPU2LCLOUutJE3vrOt2joOLNLBb787JcB+NOXX+WX/rO/AcAoGOXG\npN1uj/VtgaO3t5tYeqi7sLrOlm6OPv5jn+anP/dzABi2RaoG08d7Czx6Sg5+jfI0I3W3T8IBly6+\nPfE9GtzOubwNwuM2s83bPFrMP2czkH3P/4/Vardxmr7nMw9sErKMfB21bvtAE4NUM2sj83bN3u3Q\nXgqTEIm0DYOUnm6mWklGVyHgURIQKN9tvdVmU5XwSb9FP3f9iZjW9XhQrxNqXzUsB0/X2lK1Rjbm\nR5oOrlIJvFKZkvI1y7U6qzoWz1/epKLc329993V2tmUdTeMMS6Hzfmyx+l2hn3zqgTN3vMdDmO+w\nHbbDdtgO22E7bIfth2jvrWlnu02qMQ5ZpYxVlFOpmZbysnGCSTyO77AyrHEhyzIx1c8kjhOGI/X0\nMMEuabWAlFRN8ZI0xQ/lVH3xrZc5ekqI4HZ1iSySasfbL/0u05rxdt/jnyKMXP3MjHpRqxGGSRZP\nfpI6unCUkvpJ7XsJ0/eKT9JnHn+Yj3xMysmvvXmer734IgCbq6v01edkenqaxx5/EoATJ44z0Gy+\n/f0mriPXNj1VZ/moRFuUq1O521FzdyvPy3JdOyffe55Jc19Vdq5HfUp26Z6d4qhS0qlUKVfqE92f\nZxnUq1rRiGxefVOe/XPfujYuBJJlXXrqDeQHCbZ6GNmZxWNH5PsfvvcugkBOfiMTRr6Sj22Ti5cF\n0vy1/+Ufk5xVeNasMr2kp5NRm+ZNKeWPmn0uTstpdeVEhaU5+f1iFLG1KxfU7QWQTN7Ve50mmcIb\nWRJLDBIifBhDqRiwvy8wZbXg0d6VittLL7zA0eOiXFo8dpKSVhTNeESsCrXYD7DHfjyBn0e57Le7\noBmVaRbja2m7iIGrshLDIj8QJnGSm9pmWUryfZPnv39bWFomGSuO0pRAoaVbG1sEA3kX041CDsvv\n7LbxozEUUWZmVqDsglfgxLwq+0Z9CgqtpnGKqxJdq1jgE08K8fOP/vQCqSounSzhweNSKdnc2aJU\nkL5Rn5vK8yRtO8VO1SPM9FhZmtwvrOCnzNSlcrQ7SqkpoX91e4dgqFBTknF8RSrGn/joR/OK9IP3\n30dzXyqDFy68gaEneNsy2VOD2ZdeelEq4MBPfPKTVFQFubR8hFMnpGL77jvv5EfWWr1KXyNH2sMB\nyTgbzzJx9P3amYFXmsyY9Pq7qxSnpK9FZjEnDae9PpttqUYXhj3e94gS0JdsbrSkD6bsYms5op14\nB6adVkKoc8qgFzPTkPFUqtYpq8qwNBixtqMk8tQiVL+nlVqRI8vyDAwnIRpJpebq9ctEvpKMd5vE\n2eS+fX/1F/8CWSB/65gZjjcWvJQItFKdmCYorPN33zrPzg2pGJcKFsWKila2Nvg3//Z3AXj+5ddy\nUUmWwYWLUmmcnZnBUXPO1bffpqn3eOPGVe49q4bEjk2scSYWR2Bs0Jt6BCN5hl/+gy/zJ1/+tvz7\nP5rkLtMc5pPBPa4cJQcKuuzPp+gdqIS/tyZ1oJjLfaOM26pXt0npMsMY+7ySpikDNYx2XfvARyw7\n8BTjtki375HkTdDOb/tsapxTkkUMOlKdbm9vUVYT3I1+lx0VxUxnEeGizAf712/huPLeE7NIMJ6H\nMhNT55LUdMn0ZuxCibK+x1K1QllRA6tYzBGHP/jG87ny+NbaFTZUXT9Vq7Omewi3vkDm/wCQ9MS/\n+f9BK776LMkVgb027n4/sz/yswCkePlNOpA7fyfmgStrkqaY1jhXqkKW498WQw0+bPV2cpjENFNu\nqGHflTe/RX//dQDc2gJpJINz4/q32VgTPH7l5EPMzoqixkj36Hbke8O0SGhNT3yPjz30CKNANmuz\nH3g/H3zsQwDMHzmGpTDcTmufsc9D0fPyn3/u5/8iV66Kyuidi5f42I//OADf/OY385ywQrVKbUau\nZ/nYKT78ox8HYL+5x63roo7ba+3n4bxJ4OdF9cXlldzYLIkGlEoa/Lq0wLzKwO/USlGam/ftNCNe\nXpXvXJlt8NRDkqF14rHTJJZsuN5+Z51XXr0AwOZai6UFDbztrqusWvD3SKeCUepiGPJu373s4yr6\nOH9PhUzVHYtz82ztqcnayOf3XpIF7ZFOyuc+LIsLkck//hei/Nluu7ju5AN/9cpFBrrBNUkw1Awz\njsJcgRrFcW5QWCtX8uDcC6+/zEvflY3y3JFjfOhD8v6PzNUZDZr551R1wewNu+yrZD9LEwIdvAM/\nIHXHcHeI4ajMPIM0ui0VQPtOwTKp/wD3+M6l6ywtyCbUNjMsnVhKroejfK6trX2aLVk4Wr0eVd1E\n90YZuy3d6Hk2+2obUJsqsFKRw4nlZLlqr9MbYIxNjgM/IgAAIABJREFUcM0kD7XO/CGzU+PU7FmG\netDq9iJCtWEIrZRUeT792KXiTL5h/NGnP4yvXJ3vbO9jj4PVExNP+/BDD5zmc5/9GQA+8L5H87mn\ncuoE65qysLK4QPUjHwbg4qVLnDguh5mf+ImP87v/9vcAePvi29x1VkxwGzPT/MiHhXvl90ZsNeVw\nEGUx6zdl0g6iCF8PhFlG7jTvZgb1qjvR/RmmR29f+unMkTqp2s5kR1bobMj3+NtbuKZwFs0gxu7K\nM75rcZE3XpNNoVG2Mdwx5cKipNwc3zBIFO4ptntk+jyOTNUYLshz3WsPMXWG2d3psjAj114p2hRr\n8vO7164QqOo4GiUHqRMTtCSOcBTidl0n5yNahkNZDyrYLpFC5U6hxE5TNsEzlQKeqkItP+SNt2Tt\n8colBr0xDJtx85bwdLxKmURDj8PMwNa50jRSUGW1Y7lYyVjtGhOG0h+brRb/5t/8AQC//Tu/T3cw\nObfPJM0D1CHLc1gxwNJnlaa3K+m4zcAz/b7mmRkZqTXmJBsHGbdpdrAfuj3/08gYheOxPswPS2Dn\nyrvMuI0/xYGic5L2yoU3MXR3V51q0FGD2zdeeZ2zp4TyEkYhsSqJnSgGta8Y+j6+rbA1BkWlJKRp\nRlmNeA3TZqSKf6cEY9FvcpviOUsSnIps9mv1AjcuCc3FH3QoGuP4hT7pUHnIRojr3ZkrNW6HMN9h\nO2yH7bAdtsN22A7bD9He08rUw/EWjaFUKb503cZ/VOIazOkVIj3xO0aCMyadW/aBsadp5ifLghWT\nqP/J3tp1ti+JD0l7fwNbT2dh0KfTlYrVQinh1htyKpk/usJAc6IK2V7ulba3ep7hnpTGW3sX8Ipy\naq/P3EvjSGPie7SdjEy9eUr1Rc7dcx8AfhpDLDve//iXvsBAoZTd/RZ9rbiYtktijknT+9Rqcjr4\nm3/zb7O2KhWr6akpZuakmlap1LHH3hrZAaG/0+qwvSeEz+Z+k/m6fM761gYFS64hNWwWl6SK4Lom\nFpPFH7zv2Gm2h3KqiEYjOvreKpUSpWXZxVeOlzilBPt7HzjCsbvlWf7e73+ToCDf/9z5q3nmmmk5\npHrUigyTUSoVGcOco9BTKLjm4ZhS2Xn8qafZWBRi4MvtFwktOX12KHP3PfLzybkaX/pjqYxs7A5J\n3cnhoZ3V6wzUj8skI9LTUpTEB4qaJMHKo1wMLIW0+s0tru9KZfLVN95iV4mNv/AXPoWFQodZxmgc\nY1Qs4CpR10+GB0quNMvNMJM4ZE1FBNeuXmN/V57/wvw873//+wGYKjncf2LyCurV1RYjPTzfc3aR\nV167AUCjauSmrDOLx/CKUlFwOxWGagQZRRGZijjCKKTZlvslM1lfkt+fmSnhqLLLH2UUK1opjVK+\n+kcSzfLYQ0sc0SproVTEUwjHNCwSlTImccjmnozXjd09lmYnPymW3ALDnlR/zpw8lYs4otRiry3P\n/Be+8Es8+KAYurqmgTXOTExTjh+TKucvfeELORzyx1/7Oh0lGp84fowPfVB8077z/Av558/OzXDy\nlMCaTz79AZ57QSCfdmuXuCmnZ9O0MLXiFkVhDge7hQJxONlYnF05RqbPrOAWoCLzVHWhzvGFsZ/f\nNoYlc83eToCn1f1qaYpoINWrQr1BoaZw6P42maPZiVUPFURj2xZle0xGL+fVkKkZgzCQn7dWfa5c\nlXlneqZAolWM1jAgVIgn9IPczHWSZnk1LIUXM9shUVjV8ewc9jItl519qbL1ByOmFmRea7XbuZFj\nHMe4SiuJ0gxb1c5ZGJGmMhBuXb9CqSbXbwGBVrv2mrsM+jIf1AoLZMgzf/aPv835tyQS6/xb7/Lq\neZmT4swjMSafbwxhggNaSVF43zLN3FQa4/boKDiAAr+30jRuWZYdmHYmKWk8rrwkBya7aZbHVxkG\nFFTp7ZbLuGPza8PI49cMsrz6knFAwZmkBfv7+XscOS6+CkPiOCRWEU0cxGRavfJ7PXZUhToMI0KF\n5SuWiauVqTBIcNQzMk0gS8aGnFYeg5XGCYbO2WYK0VDeaXVqhkzHmR2E1MZRNGFIQYUZFrtkweQG\ns+/pZsp1HOYUMjnXXuetNTGftOaWiLmNo/R9NJdZlmGMB6E9pLMqE3Ld6uEtywNamS1hxPK633zt\nHbL9Nf3jKgt1NQq0exQrqlQYptimXM/Vd75G0ZYX09x+F0Pzf46d7uJVx5up5Tve4/rWBmUtLQdJ\nyvMvynWeO3uWgi5S/VE/V94tLC5Q08lor9Xl6DEpyT/+vscwFY+vlks8cK9YKZCmuUVElmZEKseO\nIp+xjXxlaY7lJcmYCsKER+6XxWJja43XvisT+9vvvEFVO6XneZQLk3WFJ+8+Q/WkTLzTL32L774j\n8vGF0/fTPCL3d/Xty5y6KXyiOc/KXSYLjZhHHhEs++F76/yfv6lKxMzIFVup6ZIV5fPN8hEIdDPV\nrHPuEeGfJfUKJx6XTerlly9x6zWVrdfrLC+IuqZS2GJxSgeXEZD9ADyNjWtXCJTvYZLlG/oojvMS\nvGWasoABozhjfl4330UzH/iW4XL1svAx1lfXqJfGBqQ3eVBVm41GlZnpsZ45AdSiwnG5tiYT+6uv\nv8olNWrd2d7JlWLn7jnH+x4RdZhlZRybDKmVjzfF8Rug2Qrpa2n7oQfP5I7/oyDlQYVuceo8+5Vv\nAeA6UK/JdXY7Aw3TFa7F+pZc8/VbCSj3ca/dYqBcoTMnF3jqQ6JAs0KfGzcFYrELdapagk+SkJJy\niOIoIlHL8UG7SceaXFnrj0IKnvTJI0srlJUP5Scm+wrDlMvlPE3BsMy8Vu8HQQ5pFEslXFUpnjp1\nkl3lx5lkVNU64uqVS6yrrPuhhx/k1Enh2EzPTPHEY/KuV9eu0mnLRjgIQxLlKUWmSUnnm2qlSsGb\nDOZrHFvOzWK3t3aYWpaLf/KcxUN3SX/0fYurl5SvNCzRzKRf3+ytg+69owaU9H2W3TKxckZK9RJO\nf7zapsTKUcocg2Qsdk1NEj1cVctVrt2Qxaflj/LNSGo5WEXlgWUWubPkBG1zr0tiyvuZmp4hVovy\nYpxhKhzt2ga9nvSvSn2Kz//cpwH42m9/kY4eVKwkY0OhxvZ+h0z7pmUmuMo1myla1Cu6ibA8Wnvy\nXW++eZ4v/ssvAvA3/srf4t/+jsB5f/iN1zh5t/Tly2t7nLxPeLmjUUL2A+w0jPx/xA19zJNKjSxP\n9zCysVHmn28Z3G6TcNuGK+jIQeKt195k0FOrhiQh1R1yEsTEurnwigUoyftdPr3CvEL6/Tj+3hDg\nMWSWZf+B6/n+LS7UCHRTFrS7eUC4ZZp5Bm0SZQS5FX/GSAsOqZEd0FZGMa3mUK8BElVs27ZNSdfX\nYqGYp6VEcUZfzZutMMnX4Awbc5w1maR52ohhmZjK8U2ygDAeTHyPhzDfYTtsh+2wHbbDdtgO2w/R\n3tPKVLt2lKojx6HjgwGXL0sOVnbfY5iunKRM08TUSoZpGlgK2xkYpFq96o0iXF+qGnPlETuu+tOY\nBpfekJiRW7c2CUa6AzdD5ubHp/8O09MCFQz6Zba35FQ1pMWcmmem3S0sJYH63ats3XpR7+CpO95j\npdLIvS9efesN3vzX/wqAz/zkp/ipT30KgDCM81JuJ+4zGOou3XKolmXn7I/8nHD41ttv5tlsJ44u\nM12XE3wchTharnY9G19PGXGa5IRD07SZqks1aKo+xXRdnnOhWGc4kipCwbXzVPc7tcTqENYFZpx5\n6iwPPShwXnFqib2+VIhSw2Y7FGjm5s0mpaqceueOesw15Hk/eG6J33tW3snqVpSXzr3yUezCGK4y\nSQI5MWy+NCLZVzLmMwHOcXl+M2eXufaCQKB7W13W1+R3Vh69m7/9tzQPbPYWr759aaL7A2huXM89\noTzbzOENI45JtSqUYdJMtLIzCCmomWClZFGvyrMcZE7uE/Otb3wtJ4ufOXcvtqXK1CQlUu+kQa8F\n6rlSqZTxVMhQyQbcf1Kgi3C5kZutzs/XCDsC1SRpwCiY3IOp323TLcr17+5s8eEPii/ZyuI8a5vy\njsquSV+/q1Ap4w810iFNqVWKep0FDIWaDcPIq6aGGTHS/kgWMBho1l5mUbBl/BU9k70tLaknXXwl\nnGZOiUCzGs14SF9htTCEnb3JzRD9OM7NgB3boe/rKbxQ4uSJEwBsbW9RKcv1TNerGPbYBNCAPIvO\nYKSwRLlcztWstgmtpvT5zfU1mvvS57Ms4p57xM9tenYKUvnb+aki+00Zc0PfJ1ByvMCmKni5Lfbm\nTq3kVPLIE8f2eeZe+Z4PP1ijpmN0fa1Mva7ZZ6UWRYWX+46PeUrGWeCZBMZAr3Ge0Uh+3yWlNiUV\npb3WDqnmSUaWQ6s3VgU6dAbSx3e2d4l0jo6CjFRhYcNyscqeXrNL7E+eW2ekSW5SvLnbo6Cq5oE/\nzOe+quvgKF71X/+d/5Z5NTLdfP0V3npXxr3f97GV05FFMbE1ruaE2BrtdXr+GEdUmXp9czf3NUzS\nhK/80R8D8DOf/WW+8e2XAbh8s82DT0rl9tEn3sfPf168qLZ2mhS8yRXgt8XlYWLgaGXYNMHQOcNI\nU8zbolyM74H5xuRy8nnfMCDryztqXrpCW0n5WZRKRBrgGDbBvlR5ao067VSpM7dusaL+aVbJJdCL\nC4KAUCvz5XI5j8SapCWJQaDeUgZJ7lU4N7eApXFHdppBpETzOCGNFQq0DVRoTxZE+btzvWIuOHNt\nh6KKegwsukq1MAyboCLv0chS0DkyTWJKCgUmhpXX9kzzgPQfZT5pNnkl/D3dTF03SpzvyoT5lGWy\nsilKsFs7O2THZLEw0yAvbaapSaAltyzLyBT3jQcdCr48rP24T4JMhuvre+zekMnqgZkGnbpCPqcf\n5vLLvwPAijnEKEsnW1mYpqvcojQIMFVJNVUr4jQUqutts3H5m3oH/8Ud79G2rdzobmt9g+MnROFz\n8eoN7r0ukNiRlSO5pN0gxdXfTxOfkS46aZrm3ImtjXX2NK/LMxP++A9lE/r888/lZouf/ORP8sEP\nfVSezyjjhZfEELPd3uXEceFvrKzcRb0hRoT33fcwWxsy0Thmlis27tSe37nA+nmBnHrtjM6ads5i\nkZk5zR2bLpK58p57lR5BUQbj+5+q87H75N160YC5We3CxgKWbqDa3TLjsnUcdnPTSGdocVPQFbZv\nbrP4UVnQ6icXWXlc7u/aS9f5u3//KwB86JlTfOITwmd5+kPnMKYmHxQls5+rSy3ATMbcluwgU8+0\naSnvZrfVp7E/NoEs4Wne7CiIcxj2xo1LNFR54nmPMlLCUhhGxAoLmnHC7pqY1q11mni6WJyY8kjG\nMvA0JQjLej0RrVvyLqIkIht7U0zQVrd26KuB3bnTK7g6saxv7BKoKqZcMmmrmq+YWrhqjrvX7LKr\nHLvlo0ugeZtBkIAqMUn8XKpcdB2OK++w2Wzx8p+JKevHPnwfK8dl0u51hjjaB5IkY3tDODCjYcBw\nnIgQ29jm5MX02eUlbHsc8mvmgdKNBahMyfyxtdthOJLnX/IcTG+cUWdjOuO/NbD0+SwtLubBrFka\n09rXzdFwkG+Iet0u02rXsb29yeuvyXh9+NwpagoLFsvFfDM1HA7zBdE0LAqFyQ42UadFY1ae9xOP\n1XjfA3KNWZIyWJd7DXZ9FvTw2NnfoqPvtj2KidQuJAtsfN3wjVKDMb2myQBTLVPCJKSo4zKNbYbJ\n2C3bp6CB8sXQYrgn/cUIEwmSROLdxrBLMgwYhZNDJ8cWZ6k2hLJwc73JnHLsImcepaZScywKyPWf\nPNrAb8kBo7XXZKA5omlqMlBH7VKhQKh5qEYcM60LcsNNqER6UCla+fgb+glrG3J4v3jlFsZYYmwM\n8nfoOBk7W2LJMNWoY5uTq/kyK8FW1aSdQaafmSYxtk4mQYyQfoA4bEMizzAZRextSx8Mh+T2DEeP\nNZivSX94+rEjGKls+q5cuY6hB+dhaLClGXajxMWM5Ltq5RKzdTnUb0Q+sdJNWt2Dg/+iW8b5ATJr\nsyw7CHPOslwVPTM7n//z3CigpikhdhozzjT3ioXc5oFuB09NkQtZhjVQJbRpYer4TvbbuDqnelgk\n+kHlUhVT6RtumjA0dA52XXxrbM0U5RtVwzRyeHGSdgjzHbbDdtgO22E7bIftsP0Q7T2tTL2w+g6v\nr4r64VqxwTE9cfo338JbEnKxk1qYmeyWAyCKZYdZbG9Tb0tpYqow4PlX5ET+ut9hMJQ94frNLWaU\nSPbE/cfp3/soAMZjHyfZl1ODv/0SvT3Z+Q+CHqam2RftEi3N0yq6KZWSksKbtyiUJ99z3nVqKYcB\nuqFBdU4I5YNBj4vvyjUvLC3k5VIxQktu+3mcLwSOnqrvv/ccSSJ29udffZnf/C2BDuv1Btuq7Prf\n/vd/iluQHftjj7yf5WWpQN28foUvnxfC5PGTJ3lYPX6+8pXf5+67BKI7cXRp4oiHDbfDcUtIl9OF\nCheG4uX1woVLPPXpnwDgVz72STZ7Ar3dWLnO9p5CsqVLnDyqz74T8/TjAoU8/cG/ztf+vZTO//lv\nfS339rAsj0zN+PxBiF3UXLMbNqMvyee/7y89zAc+JxW5r7d/n0tvSx+59ruv8LXvyO/YTgOn2Jzo\n/kCEEuP8KiOLczNSDINIFSMxBjPLAiPWjljYtvpeJXFOIK5ZJr7+adHxyDQGwXNLGJoHNxj4+H3p\nX72uxeaOnPivXLyBr35oYZLlalfb8YijsbFnxvw4P6xapF6cfDhv7ezx8GNPAHBsZSavsFiWS0Gr\nM34Q4uoz7/Z7hImqbhKfVlveY7lSIdPKVBgleVncs236Q6n+mKZBSWObvIrLmVPqRUVGHGmGZLlO\nrArB7c1dMoU6/DQdF744caIB4fiJ3rmdv/AWrr6LFANXTTtLbgFD+/uJ4yfwCnKPWAbZGOaznJxe\na1k2zrhKhUmkBN4wTFheEsPPRx96mLcuiFL5xMoKs9NSQbn07iWuaMbfA+dO5waCrW6X3aaMC98f\nUW/U9FmZpOlkar4CPU4tyN8tTqVsbMr7qRU8zL70kSvXNnGqWiG0yszo+Xm7N6ClcUVxZuBrxTW2\nLRw1QrQ9l8hVQnacoN6cJG5KqpBQEvaoFOVvp2dK9NV/LI4STGc8p6SMOjKPj4ZD7B+golEtlUHJ\n/xcu3cQfewnVpogUwaDgMlLlVzBTpa3qz2u3rtNSI8qR6RJpNc02LY4ppcNzijhq0Bv6ET31k/Ij\nqGjfT9OEXl8+8/kX/j2JztFhknD0mMyhjSmXhWmpoPnDHnOLP4AaJIvzd/7GK+e59bZQVTwzpjEt\nfXa31SNVL6SphsnirEbsOC6BQnjR0OaGGh7boxnOvF/EKV51hKnln5XHTtIN5ecLN3ZJXFkn2vsh\nxTxSKGBLY8qM6Tq29hkjSkkULUmjhKE/efUtjqP8Hk04MB5Os1wVnUQB5aF6r1XKnNFfchKTek3W\nNm+vTerL5xQMm6JWjtJymaIq8qqJlUO6RqWQZ/llSfo9nqMj9W6M6hGBwohBGlBy5btGsU9i/P8U\n5ju7vIytnbi1t0+3JyXYoxe+wd2nTwDQcKqYyqD34h5FLcul3U0y5WxYQczXXnwFgA3LpaNKjmHP\n54Ej8iBmuk3mdSBd37jIvLpn39hx2NuTgXf11hrFOSnHzx1ZoKkKg/Z+D1oCq5mZw8LinVV847a4\nfJRIpZVmllKtyGTX7Xe5ekXk7U8//UEJBUXkpmO5b5IeON6mSfp9f37uuec4ckQGcK3eyCWme3u7\n/Osv/iYAU9UiRVWaPfXEIzR105Qa8Cd/8iUAXvzuixRUwRcnGTONqYnur1BP+ZUnPif3So0vZ/8O\ngNcvXcqd0gruNF4qHfWuKQuvI5Pe1//kBY7pxnR+usovfF4+58zp9/PGRTFQi6I2WSaD1HHKmOPi\naZoQ6fv0SUh68vw2X17knv9ILDZOPHqKRGW2YTdho6U8l9YO9x2d7P7kq4zcAsEyTSJVNw2DGAry\nPuePnGThlExW9dlZzr8qqs1hZyuXbM9UiqQqefeDiCAPwt1j4Iuh6I1bN1hdH8MS2xAo5GeljMZK\nzTjBUMVcFI9IdFFIkoS1tmwYK57DkUZl4nt8+KFHSOMxv8nAUdVbEidkmV6DYeEqJ8ctGcwqjzDy\nSxg6QVmWRWfMn0mNg9K/aWPqYSCJ41yO3e00qVdlE1qfahBqSLJlkJfXbctkHIfpWO08S2xuyiOI\nJ1+Id3d2CHzpM4blUCgKZBX4AaniBo888iSNKeEX2Z6BpZsHMutg/CE8G/nbMN/YppnJsWMnAPiV\nX/4VvvSl3wfg7jN35ZSEW7dW6em80g9CilW5Bj+Ic3i0VKnmnA0/GBH6k3Hfnnx4MefnZb7H9Y0b\nAJyZt/E1i3K/F9PfkfmxVMioL8pG9omjx2i1RH0YxX0CvYIoHdFVjloQlxn2FWYKMxwNl89ME0sX\n9kYBpqpqF2JBfVZtTdIQRZAII5eWcuO2eylpNjnXptUdkZZlkaw06ti2fH6QZHi6wU2zCEfVkI7p\nkKqR5iAJGCk01glG4whGHDPjTF3Wg4SATYWyh4FJ1Jf72g5CqsqlO3byKBeVe/VnL/wpjYbQR/pB\nhys3hKqSBgPae3Jgu3H5IkvLsrH6yZ9+4o73aMXhOGecYa/Fmm7KK0nG+rjfJSb1aek7J+9fYeOm\nbNAT18LUMWdnZRqe/E5ztcnzfeH6lu1CboQcU8KqyHrWb1cIDU3NcEZUCrqjsGw6HemDpUKVVkuU\n2Waa4eqc0VrfotudPDxeOF/yc5KmOVROZuSZnAFmzueyhwPu0jHkdvpEalXkZiZTGnZuGRGm8qQy\nt0ymikWn1iBUBX7v+DlShc3dd1/DVhqN4RUp6uZ3ZjHFSGVDWsygrPy+3vZO7rw+STuE+Q7bYTts\nh+2wHbbDdth+iPaeVqZOTp/hw/dIvMb5yy/ykhqhLdVCnpqSMmp5uE7UvQFAaRhT0EPaG2Gbd23Z\nka4Me5xYkB3p1NJpbq5KSbK27/Ojs+qPYac4FTlhzxVajKZl679agOYtgR+Goz4LalZnmAMa05rN\nN72IZ6tizjeo/AAmc8PIwtFokbJjkqgCpt9p8e4b3wWg0WhQb0ju0OzMNBX1v7E9J/c0SpMkj9LJ\nUvA1aqM3GLK4LCcL23aZaqgCMYlYXZWT5rWrFzmpflVJlDClZPpRENHal9NToz5NplDT2sYuW1u7\nE92f46W88O2vAWB1DK7tyslsarbOTiCf/U+e/W08T8vKJZvXn3sNgJcv9LmqpoXHZ6r8d39tXC26\nwvy8vCvbGBCruWmaBpgaG2SZ7oGyIo5zsvXqGze49rIKGa5u4inZ1o96FF352wXb5tzcZHln8vEJ\nmVZ/Cq6bp5279SXue1xI7YvHz+SnYdu12NPq5cXdVQL1LaoXC7m3Sr/bzQnNf/hHX6GnSreUGJSs\n6llmrpIzLRtLT5MRMfGYwGtYB5ELXjHvI+1+cKCem6A9eN+53KOo1YN2X34uFx1cV342SUDL3I4F\np09KRenm2utEqrQhjYjH+ViZQRqPSeo+naFCAkmM2ZCKgusWmZuXE2EYZ/haiUvTGFd93oqlEpkS\n9D2vQODLadJyHJJoMggMoDB9HEsz4aw0pl6WuSEsBrR78r3Xr1+lptXyRqFxQJRWMitIBXDsL2YY\nZu5LFYYRkVZCCwWPxx4TWsHpkyfoaPZYt9PJ/ZZ2dnaoqZdWvVqlUZPrSdKITN9pMBrlIpQ7tTNH\nHRjHG40C5sfmllFMpBBMwc7Y1Gik0dDi+qZUMou1EU8+JFWqJx8+y/aeVEfXdjo0i/L73cQmVPVT\nu93HsKTq4bg2ialq2lKRhYZChI5LEsr773UjSmXpFxXbZVZJ6ksLdVavTg65v/TKq1TmBIoqVhpU\nxx5+KWxpJWhmaZaSVqC6gw4LR4RsffzUXdx8QegD5al5Yl3uCo7NUN/zxvYeXRUeuSULSxGDIM2I\nFfr82Mc/SlGFAxffWaPbk3/vdzq8/KKIk2YbNWJ9Vp5jcePW1Ynv8daNK4z0/VfrZY6oeGF0fYeK\nqWITHKId6YNrr91itiE3cNfRXZbm9TkXZrEyeT5hGBLa0gdD0yGK5Xf6vsdAvcbef3oOQ2FNgn1c\npSqEiU2vKcjCeu8IrehA/JJq/SWKe4TjSWmClrVaWEqpSVwvj/VLsywnl5dtF08rj3EyzL8LA2Kd\nh8Iooj6uihsWqRL3je4AVLkbtNvERYXNncJBFaw+g69QoG+aBHrvw90emZoKl2+r7mfG9wvq+Q+3\n93QzdbUxT//+DwJQPneW2b5IXocNk7ciefHLszNYM2f0L0qUtP757ptv82cXBUtOz5zh0cfFxHIr\nMjHeFvisEWUsP6g48fGjVO8WTs7UbINzTfnMxfoMwydkshj2R9TVUdmrOhRU5eBZBYpaJrx6aY3p\nxuSGj9XGNJ4qMCzLZlclms2dbXoqM3/2y3+Aq7BK0StQVx7F1EyDmRnZZE1PT1Oty7UVCoV8EbFs\nG0vNFiuVWl7qXt9YE+gAWFvfZOWI5IcFgU8yUtl1krKioa5TU7M5t2c0HBCnk2HDF765yQuvfxmA\nWtmioth94phcviLv5/zNy5w9I9+z1fb5s5cF0oqKBte35VouX9nl8Yf+FIAzf+Fx7rlX/n1u3mV9\nQ6WsVpQ74iZpSKY4uGma2Dqg+ht9vvHrXwVgmO4ye0omXrdcIuzKPe3Xyzy325vo/gBCP8zVfP1o\nRKEum4hnPv5pqouySR0lZr7pc2yDOYWKVr0itsq3h90eI8X3MQxGuikY+V0GAxnI1VqJgm7KjCwl\nVQ6AY7tixAqUPQud47Fsm+FAJ95aOVcT+aZJMKFzNkDJChnowtfsBRSUb2eaNqSqenLAVvNB28qw\nSzrRZBl1tefoddts7w/0emp5gPMoSuioSeKyQW0UAAAgAElEQVRco0Cs0M7iTJ1tzeUyDZeCKj3j\nICFSp+5isYofadiunzDSPWLv5h5t5QJ9aoJ7/PqlARW1f7DjmLmSfNCx6SL1mjoeJ0n+nOM4yQ0E\nozDEV6NRx3VzLqNl23S6MqbbrTYF5fO0220aU2pBMtVgR20SkjTJOW6bW5tM6Qbq6MoKrkIIcRRR\nVH6OYWQMB5PZP7hJSDrW1LsWli/XvrffzYPjB37MYKjwqQn7amDY2WuxtiZB4+XaB3jk/ocAqE9t\nsDfOOu0MUNSLQrnMQO9jp7VJoyRz04mVYySBzOOleIDn6uJfcKgpLDxTmckPGJWySR64OUHzwwh/\nV69zOKKbyrUtHTuOo4bLm+s3cdTF3F2eYqRcw6s3VnMo1TSc3LqiVipyU99tVijx0Y9pvumla2xd\nvwFASIyvliW1WpUf/3EJqb92/ddxPJmrPvdTH6Kg+ZOFQgHTFJ6cYYBpTW6N8MLLr5GW9SDfj/JD\nxel7j1EqyLu7cnOTRBVq00sLnD4lRYC5qoXryXVmJrg69xSdWdqpwrWGjalq4M1re1zflucwt2hw\nelb67HR9BkMVgqPEZWtT5pjrW1t4S6KWrpRL7LVknU4yg2xCni3A7sY6ZT3MWIvLOWfKykzSMffN\n8XBWxOw27TRJOjLOUtvA2ZFrJjWIpzRM2yti64HZcAo4s7KOJpUqwViluLNGMnY3LxZpawrFbmsb\nR2lGw+Y63jEZf6VqjY7O0/3hCNudnDN1CPMdtsN22A7bYTtsh+2w/RDtPa1MbZYs2g8+DsBUOiTb\nF0+dHgPetYUkvV1YouoorOKYeHq6GXQ6eOtSou7Pz/PQ++UktWQ47Kk6wc9GXJiR3e+p0hzBhpyA\nu60uZ89KleqxX34y91SyMHMYAyPDNMa+MjaxkqB/e+f/4r57Tk98j8VSMc8Fsl2XI8ekQjQ7O4vx\n0R8BwLQtQiUXd9sdNjfkZLe+dos3zwsRO/D9PMOqWq9ydFk+p9vtUKvICWhkDLHUZ6pYLOOoeeLe\nXiv/fD8Mc1VSEB3EobieQ1sz1Uwjw3EmO2VceSUgacn3tMOYosIhhpthafTL/AP3sL8jz/7y+StE\nmjdolA1MNYcxIpMvf0dI20892WB6Xu7j/gfmuHVL3rPhZDmZO0sTMvUcw3IwlBSeZRGdVSVClmCk\n0FJ5tkwWKFzhR/TVJHOSFkQxlj61YZRx6m4hnM4snyCMlLQd+TnU2OuPQK9taeUkYSgnyP3tDj2N\n2jDtLIdkCsWSeDIBrunmahbLsvJStWWZedyLZdmUlJgZJQnJOPogjTFShaPSWKpKE7Yw7GIZqpBx\nY6JQrnNklUhChW0snyCWflH0THwtEbm2xaOPjuONRnzxX38DgBcvX+XkivTNeq2cG5kOBiHDQE6W\nH3n6IaxxZMvIz6MbsjShMCbrJxm7TakcjPwoj4OQjLHJIyx6qU23r8nzzT020AiZs0eZViFEaqSs\nbwg8HsYZM1NSGR72u+wrJF6r1fIoGsM08FTtaNnQVNPOa9eusrgo8NLi/FxenZ5qTHFVsUPbsrjv\nXpmHjhw9gq25Yp1OjzBQj5w0pqRVqjs1O45I0L+LktxnJ0gs9pVA3OlHB5low5D9liqYjIRN9dj7\nX//JV/nFvyjVmWceX+DooooC0jX6Xa2Y1Kaxh1LpuPLuFjNqjFm822WgIoIsCvF0XFIs5vFJJxaP\nsrMv37uxdwWcyd/hI48+hFvUSn8KnkJvpucxvyD9N8PAU5gv6bf4Z//8/wbgzJm7+dlfFKPlf/rP\nf4NnnnwagI9/5EPcuCbUgE/+7Kc5c5eM76/8xm/xO7/5GwB87qc+w3Ovngfgz577Dv/JX/1rADxw\n3z10lQD9N/7q53F1jk4yQOf9IIwwfgA/tCP3PkisJPJCkGLWZV6uGRElT76r6LgUVeHaODpN15J3\nvdUxMVQznMUmBUueSaVi0+lq1p5bxjY087VdZH9HKjK3trpcKEnVb7EB9ZJ8fmSVGHkCxdtzU3S0\nLD5IAyz1HXNsNze1naTt9XvEanjcmJ/PBSxpehBKk3pFvHmhS1hxRn9sglso5cpKp1CmVBMUwDly\nnJFW9TumQ1Ornz4psbLdg2xIvy39ttfdJ4ykH/rBgOMnBMVaOnWa3pb4MgbDLi2tAO5ttyhPTzYW\n4b3O5sti0lQG2CB1sMvywlLbYC+US9nd7GLrBGGmEZYOnt7NXW6sCg49CrrUy/IQP/KjH6emLzjq\nRgT7MomsDW/w8EPysM6dPUtFuQrDQZei4u6JQa4UylKTbJw7ZMT5z9MViySYHCJK05RU4agkSXJJ\nda1eFVdlBCowtSMuzC9y6rQM5iAc0VOFxO72Dlu6ydrcWOfN8zKwm80ms6pCWFpaZlMlrFEUsd+S\nztfu9GhpLlO73WJDf2dra5tORzpWuVKlMJaEZymTVqWzgkOg8FbSyeiqCatXgVpZFtKae5q1K7IQ\n9cKU4qJAAqE5RKkWOJ7H1TX5j1//V9/l8z8tk94XPv8Ut1blGs+/tY2r6irLdDHGhdQszcvEWZZg\nK2cnGka5GieoxTg1mYSHfg+SyUvSgzjLFUc7+z5VVQX6QZq/TzOKiHTjs7GxSTBWmnolZlXGW/Gm\nMBXOXdtdz81oXcehqAqTOIrzTZNt27n7fxhGuZuxZZFz6SzDzB32g8AnuS142TAmn9ziJKTdlY1A\nf+RTrerClMSgcIXj2bR68jz9YUjZkUl7plHB0hdpGCk//7MC3d/aGOTS9Z3NTRZVRXp9dYcPPyP5\nkMeWa0S6ISp40FblWLXu4eu9tLt9RmqBIPvPg8XX+AHgk+DGC4y0r2Z+H7eiC8pWSlfhy2HQx7ku\nC+sDDz6BqTCrbWX5GB0MBvnmqFqtUqrIO2006rz9tliD7O7u5Nl8pUKBc/eJo/zHPvZRblwT+LtS\nreKqEWSv3cId0wpsF0eTHtIsPQi3vUMrFiuMNHtu2O9StuS6biUFLq/L+A8GfYJkzPHK6LaVPxV2\nsF2FBXd7fOMlOdi+e63Do+fk2XulmIEp7zAOTGyVtg+3DULNYLy1cI3GvHxObaqI56hqrxuQRnI9\nzW4LPxhzzsJ87E7SjGhInI4TIgwchWxSf5ivDVgOsXIcv/2NP+LMaYGlPv0TP06gGXxf/9a/55e/\n8AUAnnnyCbpj5Ve9ktuvPPWBD/DVr4iNzGNPvI8PfFD4vf/Dr/4qF14X3udP/thH+bVf+0cAvPjc\n1zl+TOgMaXYQAzwY+QxU4v/hjz5+x3ssLh/PnfpHrS57pryj1V5KcSSb+GH13pxDFIQWtgbWx5UF\nsOV9mVhkwZhjmpCqxL+QmIyJKqNSGee4rB9eZhGoEe9WGtHUa0icItWjQosxDagkY3NlM7fHyH6A\ngxtAkAzoj+Q6p9I0z2LNAEupHNeb27zx+ksAPFNfwlGout/ZJxjIBrBSqpEcExulnXaTzoZsBrOH\n7qWl77G5c5N4pHAkUb7nC+LwwDc0tYj0HdlOiX3NAUz2Rrk7wKg9xJ48r/oQ5jtsh+2wHbbDdtgO\n22H7Ydp7WpkyLYNIowQiI0ELCoRphJFIKd8wgExOGXXXpq4n5tnjx1guiTnj8uI8H3haSrZHj63w\nyZ/6JCBZeLu7qgr0yhQqQkjz4yGvPf88AGkWsLCoJ2/Hxla1mOMWKGmyuetWsU3Zkh4/dYrhcPI8\nsCiMSDU7yMmy3I8zMaO8tOl47m3wVco4PsU0DGoVjUkpVzitHja+P6LZlErP1avX2NCK1f7+DmVV\nf91cvcrWnvz7t7/zfO6LMhwM6GtGU6lU4MQJgSxnZgt5lSVLMpJkMgO2H/nPP8elZy8CcOWbr+Rw\nWJpYeFqqDge7uJrBeP8zz7A/FAJ6apIbrHa3U4JN+duvPnsFR3Pu/vKvfJD/6e9/BoBf/R+f5aXX\n5OSRuhb2geVUfio1McjG0S+ZQbwv/SgpWwSqSisVSwSDyXPrejF5Or1RnM1NGrc3N5hSPy7TMkEh\n02GnR19N/Rw3ws7PgSmbqp5q9/tYSpYMwzg3kxwOfHpj9ZZVpaiE6dvzFeM4zitTURIT6vUMg/DA\n5NWwsOzJh7NrGXi2xplkPmYq11N2SiTmUL/XxtbIBcvM2NuWd7EwNwWZ3HuWQWNq7MdzF6u3pGIR\ndNs8+pBUXB/9wAdxkdN2p9PEVMihWC5THEfv9LqMlBA/GAQU9EgYWRklVVJtbzdx3Mnv8ZkzC7lS\nyLFMimNDTqzctytlinicZ0aa+7ZZpklN439arX0GenKdm1/K1ZSjIMLWqmK/28vHUxwFrN+Satc9\nZ89w9sxZADyvlPtb7e7ssqaZc8ViiWMrInIYjfy8CnanlrlVUh0Hl9d3cWpyf820zlDnoL1OC18V\nhwZZDqXONBxa43mhPkVhWqCTtt8iisaQWcyeioR2dnrEmpPZ2hkxW5N32NuPKFTlegslFzTWpRTE\n9LXK7g96eRV3rjHL9u7kcTJzFYtEVae2mVGyxnl/EI+Vz6bJYJy55g/5+c9+Wq7B9eiqwvXk0WUe\nOCfVFiMaUfPkXY3CIY7OxkeXlphWAdAbb77JX/lLfxmAn//cZ/nTbwiU/d/8nf+eMycEzl29eY0P\nPC4V1ySOc9+lxZlZ4rQx8T22Q0DXCR+HdEEqR9ZsQppqJTx1MbV66ePjqD+Uk1kkiaxPGQaoOa7l\nmFCSPtsb9LHHhruGSaKk6jTKyLTUZCQuiarzksSmqJ5iqWWPpznS22KBwMgjkCZpjj0iHOh6k6ZY\nSivJIBfRbGzf4lZfUJTlUo0TarKbDCMyvfdekrG+KoKzxCzjLYjgaK25RnckVIU0DUkMFeaMBvk1\nFwo1akVZl6p2gdKOokDdEV1VEfa2NwhVHGS5FlEy+T2+p5upOOgeuDeTMI4XtLKUTF1ojSxhaUFg\nu7uPTXF0STruQuMuyq7I0rEcxr5v3X6TqVl56CvHl9jckpfRbPV56WXZgNjGkMFAHZ7thK1dNfFy\nnXxidxwPR6WbpVIDx1K3ZDOhWJgcNw39IM8Py6IE01bI0rSwdAIXwaVOChxUvQ3IVXtpnOSOsWma\nUlcV0AP338/KUeFPra6tsrkpkubRcMBDDzwIQH8wzCGf+flF7r5bNgCNRiPP/TIN3bgClmPlz+FO\n7cc/+XM8cr8sqv9i+A/ZfUM6tuuZZL7AoZ2ddZ744F8BYPZIyMWLAs82jjv4pqre3vK53JLP2buR\n8MfqVj63/CZ/+TNSGv+H/+AX+Tt/TzIVn3t5A1PxcQzhz4AoWMYW5SYZqRrwJQ0XSpqpR0Yyufca\nM7NLFGx5//fc9z7KagzX2VonVjsP13FIx/BJZ5/RQAOzTR+/r9yJ4YBWWzLmEtMjVHuLQsHF0b5g\nOwU2t2XBYjAAa6yYS0AXNdclh5z8ICQc19oNiyDSbDDbIg0ndyQORn7OXVpamqEy7hdmhmGNeYQG\njj0+DUR4uhksliyc3CncpehJ/7p2Y5tBX57/9FQ133TUCxahwq+9bgA60ZmWSakkk2S3HWKo6Wup\nUAJ12A5GCQPd2I6CFNuY3P7h9ImT+WYzTxxANuKWwoWZYTJQ+ME0shxW7rS6ROqqHUY+5lBDUZN0\n7E1Lmhk5dLuycozZGXkOlVKRlgYah0HI3Kz0+f39NtMzahQ4NU29If9eLBZzFe9wMMq5j3dqe70k\nd2s23Bq3AuWz1KZJLemnQWLgKS0Af0CqQdqzcw2MTT1sVGs8oK70djzEUMXT+lbA1RsyRve7Ce2O\nwiitPpYrG81m1yDdUwdrG6KhulanKUVXnk271WdFrVrmFs7wzut/MtH9Adhh52CTGkSMdMF3bTOX\nrRtehUtvCg3iyNw0hTFMGgcUdNH2zAxUnVcyvVyJa2Hm9iLFQoGPf+ITAPzLf/e7/MJPy6bsZ37q\np1m/IfOT32nxiz/zWQB+64u/zfysLM6njq8wo2rOkhkTZwf97U6tbltktlynlSSEaqWRGBmGPkMz\njvP5xnEtbF26nRQ8pc6YidhsABRtF0MVuu0oxojUEdxMMRSit6yYLBuvxxmM8wrLFon2kxhIxvym\nOCXVTFnTNHOKzCTNLth0NaT82oXXWDkjMHip2mCoB5VRMKS8KLDyjmWxYB3AuM6S2gFNzxJnevA7\ndZaj75PN7PZzXyfsSV81ohjPkvmsNjVLUTdKnuGA8gp932dLN+B+5uJMy+Y33IZgKM/ZrJcwwsnN\nEQ5hvsN22A7bYTtsh+2wHbYfor2nlalsuI+pO2fbMcnGyiUyLN0hFyzwlATa3Ong9yRraM11GSph\nzLFNPMUH3KLNfkcglp2dXdr7UrpLwpTivEbFLE1RKKj6YWuDSE/zlmXmFRzbdrTMAa63g6HQkWNk\nFNSE832P/+Qd7zEJo4N07CTNVWem7eYwXxwf5PEZmcFBYFCWn5LIsjzOIkmTvBJjZDBVl110rVrh\n1AkhW4ZBSKwEvCiK8hJsmmaMy3i3G4HGcUymSkbDyPKy651ahXkKx+QU/dRnP86XrwsB13bd8cEG\nwyyxdFJK6p39VzC06jU1PU2kipdurYtliWoFx6Q8L74pv/v7FzAGcu3/6S//Av/zr/51AP6rv/fP\neOFVgU4cp5BXo9LUwNTPTDio5qQ9H0NPJxFhTjKdpB1fPkGqxF5/a5OOVggd1yHsaXUxTRmqT4lh\nWXiqFPOjEUONPAlH/TyHLIxSAlWzWCU7j+yI4xRbVTrd3iBXcFqmJMgDJPFBvE0cRUSa4p5i5bBR\nHCUM/clz6yzLzongFiaGPs/AD7C0nyaWRVlhxyyz8EpamSoW6KhCxi7W2G9LNXh9aw9TqyrlgsuN\naxJDUW+n2GpM2u/1KSjE4tkWjsKdUQyjSP59EKY4phLi7YQsVLKwbfOD2Oi5rpurV7vd7gGJ3zRy\n400sK/fnSjE4fkygyeGwz9q6VBUd12ZpUYjG42ouyDgbf87C/AKxzivNZjP3GYriiHvuEQXf5cvX\nCBTKjPyYSKHtdJgy9MdVdBPbmswv7LuXO8xoJynWZkl9qV6vXb/F3o5UrKPEx1UIF8fOcyZnFmaY\nq2s1xDIppPL74bDLxesyh16+sc9eT+5vFEGifa2+PEOmisbru33UAxnPhdkZqZJULYNEFatxbFJ0\nZHy/9PxbXHzr0kT3BxD398nUj8txPaJw3I+GeBp/MhoMefu8EMQ/+NST7O9KVdDMUvpKfK8UXJpb\nUgEO21tkWqGILTP3fKuYRUoqGNnf7/Dqd4UMPTM1x/KsVO6+/tWv8tjjUjlfWFzkW9/6NgDNe89w\ndF7mRTONCFRA8eRnP3/He3SzjFjna8eysLWTGaY5XpKAiHGhJkvIR0FiH/xspinxOB7GMPPqa2oa\nmLrUp6abQ8OpCak1zuPLiBVONU2TcJx5l4mQSr43PZhHUxNj8sIUjldmGMt7ufndb7K3JmjFyfvf\nT6k4Nm82KerN9O2Utio0Swa4ioMWj09hDtWYu7NPsiVzTHmQslwUxMaumJg6X2ZhTDySa+7HA0b6\nOcPYx1Bvr8wKGWjfGOx383v0vDTPYZykvaebKSPqY2VjlU5GNF7YSalrud80kzxwuDeEUnGcSRbT\nVVfhipMyq5l6jmeysS0TwaDbxzNlMJfLRVxHM8yyiHj8Xanx/7L3ZrGSJeeZ2BcRZ8mT+13rVt3a\ne6vqZje7uWmjthEFyhIljTyaRRrIhh9sD8aPxujBhmwDhg0MbMAGPOOBNR4InhE9GGgwWiFK4iaS\norrFbvbCZm9V1bVX3TXz5p5niwg//P+Jk9ULK8sF9NP5CFZnZWWePBEnlj++71+QzAuq0rgoECk8\nR9l7XgJIliJgXELDZZBlmYvms9ZA8sbnCQWtCz8T6SaGgHB1y7TO3QCVotxAF+ofQ+uyfp/W2tWu\nk1IAbLgp5cMWEwPGXd8C7rUxxn0GFlByuU1KoIaE/SKeePok6v8p0azzYYq7N+lZrZ59CnFGRvC1\nG3+D3V16niNN4bsAcPDuFLMepwrohPDq9P7tdxL8379HlP3m9hn8gy9QyPZv/eZ/jn/8X1MUzY1b\n+/ADMpQMBDT7bUljodnfLp7MEDTZEEhSZ4wuA20sumyw6lyjeFjGs9C80SV5jJssU86SOTyOwptP\nxzh5jjZkP2whqnNCvcxiOmepazqF79E4TeOZkzFGc+18S7xcQnECPp1ZzDndQqw1LMtto/EYqijo\nKURpiC+BNDMuuWiWGcyY1k/SeRkxBcAvKgFoA58X5zgxmHMi2HieoBBcNo+dcnKalxxC8IFhPOzj\nBNcqG44nGM+LmoApJG+41kjYvJApa5hx1vnxtI8JR155Qrl7XgbThUzi9Xod9TptlEoKpGzYxnkG\nIYrDlYdGg5Pp1msY3WArQRi0OYmvEDwmAMRJ7NYPY41L8mlMXibkHA5xin0fz5x9BDu3aK0SluY+\n/QVurmdpCm/JiMWXr4/RZSl7tV1Db0DjUWcZ1rgGn9BzTLlAvKiFCFgunuUJzj+yzfeS4btvUTTf\nzXfu4IhTysxSIOR5YIxFe4OMhfbJLYCfW5Ik0JxtPVwXACecFJ6PHifKPbaxheefp5Qv337+Rays\nLF8E+Lf+6f/uDNPA95ByH2c6hc8JU6ezBHe5vuWLr768MCekq/s2GI7wV39DFSiszpAXmfcB5yOm\nhI8BS/H7Rz3803/+L+i34tQZFGvrm/jjv/gLAMAozTEcURtfev0VBHyfnlIuM/5v/h+/c9825tY6\nv70st9Dsp6NtmbnHWumKFWttSZYDAClg+fPCAJrHlElzV6A4teTWAQDW88oTgRSQRTJoIZ2BCaHK\nAFptXXFjWAtR+BdKS5bWkljvrmN+gqPkJj30ejTe5t85QmeFxmGezXCca9kGXh2HQzJwVhFDcjSf\nvrMPyad2OdXYe5OuE+UeUr7P+WyIlPskNhkm7Ked2ByxpufbOn4cuebk3UcHyIqIfatdJHc+TeB5\ny6fUqWS+ChUqVKhQoUKFh8BHykyFnkYyp1OmFhqK5Q1fADWWQwKhIfm0p6xwtZ5gMwhbnEoMxmyp\n1nSAnKlfneWAR9+1MkfMycZ6wxmmHM2VWgNThE4YCWNKFqm4nzwTECxXGJPCPIDJmWUJNMtOxkh3\nTUvHT2qXUi7PhpAlXaqEhFJlyRTnmi4kfL5O4AeYMHM3HA2cs2KWZdAuH4hw8qUV1p16jbEwnD+L\nWAy+B6EcJXw/GCuR8vdObDbx2b/3KQDAnev7+MN/R8/25MbjmPWvAwDm2W0MOffQrdduYc4V7HVf\nIePIu9XHOogLRmY7wsYGOeZ+/bXL2DhGp9if/KHP4b//rX8EAPif/5ffxrXrJO0KSGTsmBmYUsbI\nxwaiwZFZWiFLH0ACExIhJ4lL0gQdZkMazQZyruc0H48Rc2LUOwf72NwgR9RmdwV39kgemsUxNLM2\nsyRF4fE9HA7RahdUu8E8oWsKXyDj51Ovhe4EWVMhtjjaKtcGCTNl41oDDS7r0mg2XR6zZZAYiUAW\nTFMOwYxeFNXcqW4+j+FzDpveYIRNjtobTycIOV/SQW/gpJcTJxsuh1s+F65sSKcTukNs6PuIWQ6b\njEZod+kzvuejy1Lvnd4cY5ZQkZc53/zIgyqc45dAo15HzpXn61GEdocchDvtlnv/aDTC3Z097ofY\nyePtdhNZXrB1MWIuMWFsyQz7nu+Sed6azdHrE6MTeGUuMCskmlwu6ulnnsUBj400TlGrEcMoZckq\nCiVc394P0krMWXq7vb+PNpf7CdsNGB53oz3fRUMKz4fPzyf12rhDt4tRP4VQ5OAbrDfgzyhfljjs\n4fg2saxRo4E9LuuSp4DiUiJ5asBLE0QYQrHM1Ounbi3rHQzx6hvfBwBsnz2L1Y1jS7UPAL7y7e9A\nMk0irEbI7gjGk+W6bCwsO6Yf9PouabK10q2JaZK4XIMQgupOghSALC+Ye4EpM5bWGuz2uINg4fF6\nevHEMexzotbxdAhTLJtGYO62KgNrl8+HlkE4mU8oDwGz7vM0drmrlBdCFkSQsG6uW2mRl2kvYV3w\ngkDO67RWykWVC0/A8lovtILgnI5WG1f7VMKDLsgoYV1QlLC2dDcR0u0ry6DeqGFrm53IAx+DPkl+\ng727ONi7SveZpkg4OrYufYyLXHYmheBSbPbSbcQtWhvyehfZFWKv5lYjZif+3JMQLXYnOeyjd0Cs\nZWvzOAKfa//Nd+CBnm8yncNyIuRwJXJBclJ5UMHym/9HK/OlMRRvfEbkgCyMCw+W/VKkJx1fZox2\nlGeaxU4mM1JiznSshXYLoxVwNeaU0UiLwofTicsIbgEXamuNceGmRpcRYkrKcmMSytW5WgZ5lkFy\n+K5VCqZICorST8p6HgwvNJ5U5eSXstRobZk0UCnlFufVlVX4LPNoWIhCL5RAkhQyYnm/1loI/i1h\njcvM6wnhMmZLKVyh1fshESly9nubDga4zMn73nz9Fo5i1tnjF9C/dR0AcJjcQr7C2b49D15EC9rU\nJkhGtFG3VzYx5dQYj378JD5xnLJrXzzzCfz5V/4MADAf5rh44SwA4B//V38f/+e/+A8AgBuX77pC\nloG0aPAimVnrfI6GnoetE8uHKudxiqOUpJFMa3S5mLRY0FvbjSaeOkNpJs6dOQ3BCRD7h4cYc8Hn\nereFlFel4Wzq6oTVfAVThKt7QIdDgM8f28QaR34Fng/BchJmKbocyRgIDzOe7PmGgKoXtam8ByoC\nbCFc8eQ0z9FgOT03Cvs9krdaUeCyznc7XVeHbOfoCKeK39UpTErG/f7dKzixTVFbUWsDG+xnNB3d\nQb3V4etLnOKoJ4sIESfAlCJ0WkRv/CbSORkvaSbgszFbC32qk7ckalHksvxP53OM+BBy2xo3L+Mk\nxYClmtX1TdS4H9K92K0rRmvkLIFIAcznJBHt7+1iyAbUbD5zY2M6nWLCEUrNdhcRy1GtVhPdLrX9\n+vXrKHbHer2OgNMhSEXJKZfB0fXLqJacBY4AACAASURBVIUc7dWqYWODDNPMzHB0lzZ8FfjYOEUR\n0aPDHvzCgMsljjg0XPk1tFnOa62t4cxpCje/e/UK1lnaO3tmG7dv0P325yk66/Rs+94ekpSu0677\nEFzh4Kg/wEqD5vrdgwFWN2lcn9g+jiBaPhOilNKlQfGVD79IuqikK9QNYSGL5L4QblOTCphx2L3N\nE1iu9+j5PkTh3iEFVOFCYYGMn229UUNQVBoQEhnvH8ls4g7+tUABLnllGdlpNFwy3WUwjlMo/m6a\n5pjz4VNDOCMoS5KysoaQ5V4iLJy3hgEKC9NXCiYvarJaqCL8XVu3L6Y6d4dPXyhIzsivVIAsLdZR\nDVG4iWjjDA1tqa+XRZbFCDh1y8nt01jtkgw92zyNI87EPzrsIeP5NJr03D6dKiAtascqgYTb0jcx\nFEe5i0hCc23PHJmzIUTcxOnVT9LvPvG489N+44U/gknot6wN4fH48VulH6dS4oEspErmq1ChQoUK\nFSpUeAh8tEk7TeJKxeQ6gWVmSvoCHtO30lPO4U0I6SIMDADFjrEaOTSf7BOdYMYyidbGMUoCGcDy\ng/CVYwgyY5AVTqPGwme6OqxFFGUHIDcWwhSsmYR+AJsz1xqiKEtjFayT+azz+zPGOgrcKgPLFIoE\nXOQdcef02pPGnc50nmHOkkOel6UZAj90ZzJrS+dyTykYpk610Y6h03nuTk+ep3BsbblcWikSDCZ0\n6h29eRXZHWII/+a7feQN+v3bu19BzEyTFT7CGv2+aAtwLk90GiH8Gp84I4kVzgUixgZfeoEiZPTP\nbuD7lwpJ82U89jZF840nAWpcOkPIkm4+G/r4Ap/8D+IY+eN0Gn7z8Q2sPXJmqfYBVO4nyYqagz4S\nrll1pHJ43JawE0Ht071F0iKoc2TIZIaVM3TK3zx/GjNmUA/u7mI8ZqfXaYJmhyQzEfrQLC3Uwhrq\nLKWJwEM2o3Gd+3NkXAZonkzhFadhCYyZeUHgQS0pDwHAaDxBp0OnOm3KGoiesi660A8Cl0Ay8IEa\ns0Lr3Q46nKjxsXMhojpFq02nc7SbHJGXGVy+TIEEnUYLZznP0OrxCPMp3fPx048jj6lPbt94GQMu\nddKINI6v0/N99/oufO7zKAgx5bpZy2Ayi2ELuRsCc3ZepjlQSt+PPkrlKZ64cBEhBwPcvnkbwhRJ\nPn20GvRcWvUIb7xOSWhfe+klN89833MJXT0/cA7LEBJ1ZpWPDg8x4sjjeD6BZYbXmszJhRAW2ZIR\nRFrHeOwCRZbVN7pImLk/uHLZ1TXbPPuIY/cFgBYznPFwiHlM/V1rNmFymjewAaI23cujH7+AtM91\n4oIcT18ghuvd3R7qXDMVaR17u7QepIMUgwnnBIuBPKYxK5TCOs9LzxjYePkEupACokjQqySUV+RL\nklCyZGGKHGiekI719X2BTpNYQWPKqNkwrLnE0JQBuKivJ9FgGbRRj1wOpjTLoJmtODrcg2X2u92M\nYG3BXnnOtSLPTVFicyn0xxOXtNNqlOF5SrrxK5TvooG1kFCFmmGMkzKtLeexsXBO5MYIJ4Pa3DgH\nayG9MrrbWKdUhEHNRbbDaMf8G8CxeDDWRccug0bUgBBlNHvBxNWCGuocLV+PmhhyEjc92EfMc6um\nfPRY0WooQD1OysVjp7dd/si9vXehebzFowNMeb1cWz+Pc1wPczY+wi5Hn0/6fccqBk1Z7s3WuHFl\nPeFKLi2DjzZpp5kj5uKzWlmAZQwlA5dAMDfaSV2ehKtZpK1xPidZrp3kJ6VBVlCeFu4zGtZJfp70\nHGVoJFDjiJ00yZDxPegkppB7UILNIgQ7yZMHSsBmF2aRthbluiiQ80OS1rqQdm1KySEwFoV1ZFBG\nYAgROIlFKQXN8kOeZ8iz4rV2kWxCiDKE2wiXBVrbUhf3Aw/HeOM+e2IdW2vLRSwaGOxfo1pjdmeO\nx88/BwB49cYu9kccqTST8ArjQkpHVQe1AGwzIQ9ynGiSsVMbC+y+QyGul64NoHza5L/0Z1+C5SKq\nOzen8D9J93h4+w4mfdoYPa8GyxPwY5/4IfziGvsTvfka7vCiIS+ex2hjeZlPhj4MU/y1Tgsh+yUp\n33PhNZP5HCovNkMNxY1sGIWco/b6N+/CY2p7O+pgwqHweTKG4kSU2hPIWRrJhkcYD8lAC1fbzpcu\nFAKCQ9GTNINh6aIWhm5PSE0KL1xeApvMEtR5A89yC1P4rPlAyNEySZa7rMhRqwmf5Y2tLR9pnPDr\ns0BRr9DbQ5cNBzPTaEb0HL1aE3FOB4B284RLNVIL2hhOqb2ejNBUtMkKTIAVGigZzkBJzjg+m2Gx\nTt/94AcBgpDmTb1h0OK5nmapi8gTQmB7mxIFJnGCd7hyQBwniFiS9jwPJ0/SZ7IsQ5oUiVI9RDwv\nfd93Ul1Qi1xEZJ7nONgnY6Pf6yFhg67D2dUB3hB5TgslXMHc++Hic5/B489+AgBwe+8uDvbJH2s4\nHDuJJxlNMOUC1evrqzixTZnWR7MZ9vZ43M1jHO2T70mzs445J6y1SDE4ICmkEdVgc9qgZsMh6qwP\nRTYGeJOfjHwgpGde8yXSpHDFsMg4E3lihZMal4HyPbeZWxhkeRF9LaCKQ6K2yAsDwfNg+dkaaFcD\nMwgCd+iSiiJkASosXchzUgHdFvu62TKljPAk5nwAn8wmKMagEnAHc8AuVCwwSB/AmKq3O7B8P1mS\nIeFUDVmcwfD7JtcICuc0qdxvCS3gFwmXF/ZLAeXS+1josgYtPCePWmucr5YxFh63N0k06lFpTBVb\nCUmFRaRkmbpnGaSZBU8JeJ6CZMPK96yLSLfWYjpieX8+xkRwhvJk5AzkrSjCRszyXC/HoEdpWRTu\nIEzJl+rG5V2k7JeppynmEzK4JoMeMl34pyoX7e3VPeem4Yc+FEvn1iPiZllUMl+FChUqVKhQocJD\n4CNlprTM4bNkAqudJOcr4axlvUAfaqvdOVR5HnRe0LeBi/ARQqDG1HUucpcwU0hZUjsQLleJMMJZ\n71meAxx1sZgnRgrPOboGQQ0PYnNqbRzdCyHK2kcojypygaKWC07NwpQRhVoLR+Uq5bkaYNPZHDGX\nv8gz7ZiDXGvoIhGokEARxZJlrsRAzfewuUI629bGBjZWO/y+hVoyA9tYH+HG65QzZvDWG9jtcz6p\nOzeRcemRMAgh+b5UGMBv0737oUJ7lSPjOgrJTTrpjntTjDlXjVePoPj5HB3u4cw5Skp64+oenv8O\n/e7Fcyew2qVn3hv4qDepL//+f/F3sMW5xV76H97ArR6dTlKtMc8GS7UPAKbjCUxBbXtemRRPlDUB\nk8kUgh3olZRAxokF4bncLfNZBslyiAoChCH3SZRjypJWZBuIiuidrDxht4PIMR1aa+TstDsVCtkR\n9ZsSwjl1xrMZYrG8BGYNYIoSKwKOdUrTFIFfRCBmMIZ+V+cGEd9DVGtjyv2cmBr4gIduuw5bMAd+\niJPbJHtF0TFE3JbpwRswRR6dtIf17ScAABunn8T4gKJ6dq++hCbXN3zi4+chOEjkaDDAbLa8RJRn\nBg12cBdCIGF3gFqtDo8jf2DhEqgC1jFKjz7+BGaFpGitk0Yuv3vNBYBcfOpjLgpW63I9K4I8AGK1\nFhPlFn04nc7cOkcn9SK5r+eS+94PfhBif4fm38HeXfS5Zmct9J28PBmMsH2eZMzNjU1kxbpgNBoc\n3TjZ24XmKNUsmUKCmCljhCv1cfv2bZdPLGqvIuYo63Y9QJ3rp+ogdMpAnmcQfpGc1Yfl/GxSKQTR\n8rl7sjwr2ZM8c/U5/QWG3hOyZAulgleoE2nq3l+MVpaAi2oWsLCcN0/bMk+TUh6KkLZU50iKKGhr\nnMuIhnV134yGk9u0ttB2+T1jHqcQvE/ozCB3NfIMwGPJaOOUFg1dlnXJTJlrUEkXfJRLXSobmSli\nvagkTMFSLUR9Syldvqo8yzEukgrb3K15wpTRfJI/tyzyhRxVYajgF1KUsAhqBbPWQneLgh+GvQMk\nPD9inSHNqL23hnuIb5DMLm5ZTIa0rp87r+BzHVGrjVME5rMh0oST/obKOZp7oYLHrgp+XUHVmJ0M\nhWOphC8cg70MPlJjKp3NIQUPxCxHxpLJ2E6QcQSDEtJJctrkjkpUQkJzqLISWUnj6dxFvUVB4CS/\nWZYi73Oyv1oIywMizxNYpu7yTMOT9CBpnBZ0o4TgpJ2erx5EWYC2sZOdtPFK3yj4MBwZJW2ZkkEt\n+kdYwLPlIDMoMl0LFyKbpJkLyc+yDGk253ZlzijzlHKbbLfZQKdNG0q31USNpaBASnhM1We5hVbL\nDYVrb7+EK99/CQAw2N/BW7c4UaEA6q1i45LOl8AIi6hD1z73+CmsrdPCG2Q5vvWVFwAA7z6/h2zE\n/TfP4fmR67+jKUkkQdti94BoXLmzDqU5o69OEFuaRDv970Ot02T8V0ONA66t9sxsCn99eUoacQ6f\no7rqXuAWIk9IhBx67EtNUSMAZG5R5+i2TAon9fpaIWRDCYHvQpsn47GTl6N5BrVSSAsUVg0A+SxB\nyAkQk3mMORs+4+EIZkTtmnnKSbjT2RzZA/gTRaHnQvCFsm4TCYMQEUu0a36INZbbfAWXPkEiAQw9\ni8loDzVFKQ3IB4PbLuD8Go8m7+Bonw1tL3CZtGu1lqsxJrLcUf9bp59xG0RmBAKWC5srWxDe8nUy\nyRgoUmJYt4koBXcIgRBu4fU9H4oLn3uBj05Qc59JnV8KEHEx8giCkuXy+2X1gjJ9QlHEFSCpqTAk\nW00fxcKSZZmTbTzpuWLE98NgeIgBh30nWYaU/eeMrxAUEWetuouknMUJJhOSVY/6B/B4HcyyFDWO\nvPND360XeVZKRbu37+DkWapqsHbmInxBcszwzi0khaZlU+dGEAS+M9zyLHMVcgPlu8TByyDXxqVG\nkEqW0pUU7rCsAZdGxErhMnxrI0qfJpTpJ5SnXP1UYa07OEFIFEFjerFyBKU+pn42Frk7LEu3NVj+\nXwH7ABHg88OZq2NpYWBdZWHA53VOQrn13RrrEr76yodm4y5PEpQ1Xy1EQQLkGob3Tmt0ua8YAVGM\nQWEhTJGSSLrxKwUgeb4u1uIT1iJYMuoUoESptogqh6FC8QCgNbywMHB8bPE+dHSwgf4hHQ6CegNh\nsyAWBGbss0tJqOme79yWkHw/tW69TIirfCgmRqQHqMITIhQQEa89dQkVshEdUH1SgNbFYMk6mUAl\n81WoUKFChQoVKjwUhF0ycqRChQoVKlSoUKHC+1ExUxUqVKhQoUKFCg+BypiqUKFChQoVKlR4CFTG\nVIUKFSpUqFChwkOgMqYqVKhQoUKFChUeApUxVaFChQoVKlSo8BCojKkKFSpUqFChQoWHQGVMVahQ\noUKFChUqPAQqY6pChQoVKlSoUOEhUBlTFSpUqFChQoUKD4HKmKpQoUKFChUqVHgIVMZUhQoVKlSo\nUKHCQ6AypipUqFChQoUKFR4ClTFVoUKFChUqVKjwEKiMqQoVKlSoUKFChYdAZUxVqFChQoUKFSo8\nBCpjqkKFChUqVKhQ4SHgfZQ/9sXf/V0b1msAgDCK4IcBAMBXPkIvBAAoT0FJBQCQUkJKWb5W/FpI\nCCEAAOPxGIdHPQBAnMY4ffo0AKDVasEYs/Dr4j3/Bay1sNa611prAIAxxr3OsgxJkgAA/tZnP1t+\n+UMwnk5snuf0S0K4+yzawf/g7kIKiQ+8qBD4wH+wH/w2/xP/137IJxY+a8vPCFv+vdFo/MA2/vQ/\n+vcWgp6PgIKUNIQ8L4Dv0fuBtFD8rDzPg+/7AIBaLUQtpOdf8yVsPgEADPvvYHDzrwEAj59cxY9+\n7tcAAN+97mM8p+tHUQ25oWcSZylS7mMDC6vo+omWmCcZACDTBpmmNiWZhuax8Of/3VP3fYanHvu0\nTXN65goZTq2vAAA+/ugTePvVNwEAN27fRnNtDQCQ+zXc3N0HAHTbIRo1up8sSzGaUhtba11YRWN8\n4/hJPHL+LADgsL+P8Zw+I7Ic6W26Ti3NULd0z6FSmMbUrlhoDHRMfbu5gouf+iQAoF6ru/v/3X/2\nz+/bxl/+279iD/Z3AQBRo4UnLzxJ99/pQPFzVEq656ikhOX+h8lhDfU/rIDv0zwWUsHwOPKVxfE2\nP/fQR8pTMddAkhffBSL+LpSC5rHUbdagJDUhySwSvqYAYPMUAPB3f+O/vG8b1849Ytv8qUaaYDib\nAwAGucGFC08BAFbabVy88AQA4Oy58/jGN74FAJhO57h0+RIAYGfvDrKU+v/nf+EXMR7R8/rrv/pL\nBD7ds9barTcGmiYV7p1ngHv7/fiA1mhjfmAbf/I3Pm0vPn0RAHDxM6fRDKhf+4cjvPD16wCA2djH\nY59oAACG4yPMpvRMrEhx4lgbALC1tYLRhPp1+9QZ9HfGAIDv/9UtZHNqd/tYF+sbitsXoxbQ2O9s\nNTHO7wIArr9zGW986wAA4GerOHb2BACgeSbD2VOn6LuzEJevvA4A+IN/9uX7r6fDmS36UEoBLLG2\nlRB473q/+F+A1uj3PiMAMNbC8vMUQkDweMy0wavfo/v/6te/ikuX3gYAjPr7OL7ZBQBcvPgUPvWp\nTwAAfvbzv3zfNj7yi79gjwa03mjjQxsaU6ubK4Cg/t/otlzTpdfC2hqto0rMYVP6vBUGjQ4966s3\nb6LeXOPPRxC2DwBoqgg714YAgHPnV3F4RL972J/g4lMnAQDjeQ9xRmvMcDLD0xcfpeunKQZHvFYJ\niySlMfMX/9tv37eN/+MX/8paXs+kkHCNEQKWv+1Li9PHWgCAR7dXcGyD+rPVaiBU/BloSNA4V/Aw\nmtLrf/fHf4rvvPwyAOBTzz6F9RW6ThZnGPBnXvr+FXTWqI3NlU3Ai/juhJuYxgJ8mzC2tD/+p//s\nx+/bxoqZqlChQoUKFSpUeAh8pMyU70l4bOELGKA46UoFY+m1tHAsgrUSlu29xdeQClnOJ/VkBmfx\nSokgoJNuwSyBf829EveeUD7otLL4d2stxH1t0hKeV3bpIjMlPuQiAoAoTPOFj1jBN0s38YH39l7Y\nD/iJH3gKsz/4eh+EZsOHFEUbJRSzQr4XwPeK1x6Uos8opRyj6HueYyO1kkC4BQDYbK5gPrgDAMjU\nDP3JjF6bbYS1giXRkNy3fs1HcWbPjUHO4yXINHw+SWQayLlZ2iho/QBtDOuYchu7nQYyS6cxGdTw\nyCPEaBzs95DP6D63HzuLUcLjFxmanQ4AQEggvkunN88YaMtjdjyCp6gBBoaYDAAnTm9BbW/Q/Q9n\n0DM6NW4e38IspdezNEaY0KlRBxITZoj8UEE9wEC9eeMagpCeV1SvIWZGbzpLEBaMse+j5Hale6Ze\nWHf3L0TJuiolIfmE53keRJ2YOHgKId9a05PwmPmCBQwKBspgntGvzeBB8ZisRRIbdbp+PZDI+DS8\nDOLBACaiE/w0N0gzuman3YHkwX/p8mUcHREb2KgDzz5Dp/DB0Qgbq3S6/ea3c9zdIfblcH8fvV6P\ne0QA2h1jS9bpPY9hcX596Ch8EMKFYTJg6/g63Xurjts3rwEAbt68g+GM2Ic0aaLXo3EaxzOsth8D\nADz68fNIsiMAQKZnWDm+CQDYH+6hd0jv7x7exkqTrj8b96E2qS8bnQAnT9Pnr9x+C/0hsR7TvkTT\nJzZkcDRFQTpunVgHPGYjgynydPgArbQoOoe68UE76v2ff+8e4N6HRc7rhFjYS/I8w7vXrgMA/vDL\nX8XXn38RAPD9119GMhoAAEJhsdak/nntldfwrW9+FQDws5//5fve4WgvRhbb8t4U9dV0MkTUoDlk\nrEExGeN4imBGg6wb+Qg8mh/aWqQxrQ21oA5f0P2kcYJaja7f7LQQtphBlSkaHZ6jQQTNjLE0NYyZ\nqYyiDkZDWhsOen006sSA9w4P0azV7tu2AlKW25iAcU9FCAtf0v08enIdn3zyDABgsx1AOTVHQphi\nfS3nmZXA1es05r/3+uuYc9tnSQwhaO729nfApD7ScQ/7zE6nswm6m8SchvUGrKDfyi2gUahJH75v\nfxA+UmMq8JQzpjwh3MIrpUWpgi0uPMY9AIPS6Mh1joQ3FCGA8XgEAFhZW3MLu7UWSqmFXy9lvqKD\nFo2peyVB3GMECfHwBN57jZp7f2zxdxc+U/5l4UK417hy/3avuFf83uJvkWG4YNzZcpGyZrlFqi49\nZ0BJKSEKyU8YSDaIlZAIPPqdIPRLqUgpJwUa5UHwZ/L5EQ7HtIBvHt9EL6brTOIhApavjLZQvnLX\nKRaQQErA8HM2ATTLyBYWwkmQ/lLSZ4FGlsNYWkinwwzakCHz4pvv4vQmyciqHmGwTxts7WAf7ToZ\nUIe9A4wndP9h3UcQ0P3PBiNELZJVTJYiTWhS1+shwib9llcPMDo6pP4MFO7uktySdbvonlgFAIz7\nRxix1GW1RjYhQ6+zsQrvnvH+gyGlQHeF7jmq150hrk2OXPMYkQKWV3BhLayz1hWMKZ6pgIdiDABW\nFPMbTqrzPeXGaaLhDM88024o+4GPbpMW9tVm4OSzONXOGBeeRKCWX7LmkyFyPnR51kOe0WsZx25+\nPPXUk7h27TIA4Pf+w++j0aBn9Mj5x3H6zFkAwMeeeQq9IzIY9g8OMBrTBgoB5HyQWxxf719+Rfnn\nwvnIfUNIiKJd1iwtF0z7c7d51ms1CElj7WB/7sZCcyVA74Dk3Pl0hvUmfTedDHA0ovHbbPkYT8ng\n8kwDdkzXxHiGTpPuqy0b2ASPF7+Jm2/cAgDs9XYxntL8uHtljiAnmanbaWBthfpytdvFu+9eoXse\n7ALxvWvtD0ZpTC3ivevaB73/oVdcOCALIdzBWxvhDhjSWtzapTZ+6evfwB996SsAgLevXsPKBhnc\njcY6wnwKANjotHCM53GogPlwtHQLZV6Dz3uMhg+r6VnAaOic+8r6SPlANYrHiDM2fFZaOLlJa8Ne\nrwet6POdzjp6fbqHk8cUwC4G/eEYOY+NeW4xZheWTHvYO6DfbUVNaFA/1CMPB/z+0UxgOKOx76kA\nnW576TYqJbC4xTo3F6NxmuW8T148g2MdWr89mwO6nAkSC4YVCjeKHO9cobk7HI8AXm9m8Rx54bKj\njWMZfAGkhXx5uONer24eQ7NDfeiroJyjQkA+gDFVyXwVKlSoUKFChQoPgY+UmYI1pRMrDIQtbDkL\nIQom5V5atzg1CCFhLVnj4/F4QU4TmM/Jcm7rLgrnb98v2QgBsUDmLDBfHyLzvf/95VmN9zrNfxDE\n+xzQP0Dm+zAuRSzIgguw+HDnzA90sFw4Jlhtlpb6al4NivuemKnSwd5jNkF6Cp5fSHtwrKNSQKnw\nKEQsFR1N9zBmqaDZ+SQ8dm4NfO0kJ/p+wapZ2EJe0QbuTGBV2YUWTipS1rDz6nJo5RnqbZIx3t0/\ngOB7uN0fYnWbGrB5+hT6vR0AwGg4QGeL7lkgcsyUDOtoNsl5fTCcwmfpMEsS7O7SdzubK2i0Iu5D\ni7U6nex7d4dImCFo1TvwFN1Du9mB5pP9dNCDx93Q0CjlsyXQ7rbRatFprFHvIPBDvgdVMrECC/1W\njkdjjJuvOjOApXYJIVGQY7nWGM2IQRvPM8cShoGHdp1OlkHTR8zS3kozQrcVFD9VOrL7EsMZ9Wfq\nC2y2lpcWoA3yGTEHRkpoZtM2Ns/hF37+5wAAn/2RH8JBj2S+wXSC8ZgYw09/6ocwGhEzCB948eVX\nAAB7h/vQJuZrLqxhQrg5JUDuCq4TFwjm4u0cEl5AbfGjOjTLkdJomPl0qeaJROGQAx+Gh13U+F7a\nYg01PuHnmMFGxKZGJ0KA18c3/+oNNCJislrnumhu0vPp+Gtocx+f/NhJNEOSSzzRwLqk8XLnWh+D\nfZLqxmNgzNJrepS7vum2G7h7gxix4xfaeOJxYnO++ecHyHqLLhj3aeN7mIFFZv2D2PcPY6zee41F\nRaIIkDFGY/+A+vOPv/aX+Pd//KcAgCtXLyGe0rgIQx/z/nW6UDIHeyGgUfOhNfVDlsXoNhpLt9EI\ngZRHRi4s/ILVVwrgMbtz99Atc831FUynxLL2BzOstIkharTWMEuJOeodHaFWozl95kwT/SHd29vv\n3oHySLo9HBoktmBwLDo+Pes4NtCgzytfIEnofuYzQAvqh7WVtgs8WQZSLjwLAaeKNJTExVPk7rHd\nbTrncqECCG4w7zAAgCzTbp077B3gyrWrAAArJTT34SyJXZDLLNUArz0QwrHlQI54RMES+9kcM7Yh\nVjaOw68RfautWIrpLPCRGlOz6RR+SA84NwZewIuqsU5m8jwPkqP5tM6RMTVPf6cHPxwO0eDBWq/X\n3cR4++23scYRVkEQ3BM5U/hVweIeX6QP9T9aMKbMkhLYB13DPQyL0liypX+TXdCPsch+f8hDfK/K\nd8+/mVJycIsF7v3Ch7b3B7RjEUIZKJ7sSgn3rHzPczIcpAS/DSHNPZS6ZBpaiRz1gP7hRu8uxod7\nAIAQFhF/uRvV4IcccSFwjxRs2c/IWo3i8WghUXSyNXbBOM3xICRs02ToHKeF5WDeQ8ILWpzNcTCi\n+3xkax2tFRpr03kOj6WoIOq4yDuLABHLKpMohGUfhuk8wc07dJ2njq0hqlEbPWhYNkBGhweo12l6\nbmx0kBWLdlCHGtBG1sYM2ZBkvtluHatnzi/fxtYK2kxtB37oFnDPk/ALQ9j33MK1qDpLJSHYsJ3v\n76FZ42ii9hqmGb3fjBqQfM1O08cqb9DdVoSQr5+kBgcD6qtxkjv/uE49hBA0TtpSQlnaoHvjGLsZ\nffexZRq54LOotcHHniJ/t//kH/46nnuGXnciH49+miKvgmYDWaq57RG0LRbnMZ7/a4oUevmVl92w\nUkoBiwF3xUtj3jNJWc6GdR8P6zUEbMzADyFZOkcONFrLySc1r44oorFz+8ZdzA9pAzkXPgE/o+uN\n81sQbCifXNuCYkN8lp5EFJBsHfGrjAAAIABJREFUF+9MkE3o/d3RHKcj8tu7eGoF7SZd/+Bggtu3\n6MDTO5qg7dN3c3EcfR6DXttCxOzTZuuI2Iey2QyxdYbW65OPraC9VUaePgg+zLC6Z539kM/f6yta\nupVobXDp6rsAgO+8+iq+9i2K5vz2C89jmlG/CSMgWBJK4zGSIzISV9od1Lj/02SGVuF+JDVkEe26\nBCbTIcIGHd6MFVB8mJkfzSAjuu+gEcHw2mmMgsfuFUezKa7tk9HfCBQaEd3nejtEGFGfX9+dYMjz\nzGgPgU/XmecZLG+SjVrNSVrDyRwJGzVXb2VIR9Qw3zNoRPS6GUW4c+to6TZClH0upYRhUmVrtYPz\nJ6jtvhAwLO1RECm78tgECUfT7h0cOhvi4PAQM/ZbjWoh5mwr5HnuXBnjTMNjYxlC0v9B/nGqOBCm\nM/T36XCbaYtV9qWqNToPdAivZL4KFSpUqFChQoWHwEfKTOUmK53KtILhQ0yaacg5WaFKKec4Trmf\nyMRcjM4LghCNBjEH3W4HJ1kqiK9eQ8pRSaIpHNOjpIBYcBS1usgpYUr2ygCy+IwxKLzljNXQdnla\nejHfzD3RfHbhpLSgyFlpS9f4BfnPvidHCtxnFqL2Fq8PC6lL5/uC8tS490R2b5Ri6RhrlpT5IAwE\nR19AwOVfEcq6XB0Q78nvVTRbSmfp13xAGTpV7N1+F/MhO17nKTx+5gEkAqndNQuZT8ryN4Qo/ihY\nu6J9996DtRmWRT6fQ/Dn1zfWcPuAqPN2M4BmB8ztJ89DXyB+5LVX34DHuZ/qzQgDPv3nWqPDcova\nXEfgk+SH6RghS3u+8pGMSdaxRmO0S/0wm01RxK1dvvQWAo6i0ZlAPqCT8ZqYYspM2d7dEHO1PO3e\naLag+MSmPAFZSKjSwKl8snymUgjHTCkBhPzdIADWBZ2MD3oT9DgKqHXqBDY4p8v6WtPJf3EcI05Y\nBvcUVtp8wh7NwT75QF24XC/DmcaIcx0lmXGOt8vACkCz9LW2voFf/4e/DgB45pknsb9LztevXHsX\nn/v856hPkg6ymK7fXFlDfZWe15kzp/Ezn/sJauPBPm7evEH9IwCoQi6ybhwKiHKNQdlvQRBipU7P\nfbMVwYvoee2nBn0e5tpYZNlyDtqBlGh1iEWKp1PM7lDfn213kXPuoVboYTwgBqEpPZzvksSTHfMw\nmFBb40Thyls0pq7vHKBxnp7t9qMrECzbnT3bgmSW9aTchuHEYbd2mlDMFExaQ4iA3vfGPlYEta9/\n6RaGM/qtzBsht8uf4d8v4f1gZ/T3MVRuXRNu7bGwuLNDTMSXv/lNfPkbfwkA+N5blzAY0iBMjnah\nQmLfgnoXNuNxXZMIA+qIIPBQ8+makZJoMUPb8D3nyL4MPBVASeormecoSK0szrHWpfGipIcZs2Pz\nwRweO2GnOnHRzNYKrK/QmG1HdYzGdKGD/TkmY5pDNSOwzY7j++OxY3xsojGcE+OtjULKQSjW85Fw\nF0ahguD77PdGSKfLP8cQeanBaOv22jQ+xN+88m0AwPBoiCkHM4wmMaYTWldmsxEmM2I/kyxFjaOE\nN7qruHGJovlu7e7iiYuUc63h1TAd0ZqaZTmCgpgCrV0A+6pLduJXAj5HUObTAwz22DH92Gm02itL\nt/EjNaYMDCRHYcVpgumMbrrZbKHZoAFqTOk/5fs+ooh6wvN8tFr0mTRN3aTJc40BLxY3b17H1jGi\nDFfardIgWjQ6ZOmhT0bEgvy3mBzQFsaULVM4LIFFA0qp0odHitKXanG+L7KI99LSYiF89N7FYtH/\ny9HXVrhNENai+LaA/XBd0F3lAaBn0EynaljkxXNIvTLqSkmIIsGqEo7eDTwFq+l5hkYhTum5HR5c\nxcYmGceNSMBmFHquUukiyITQsHwhI4wLzfc85dqX5Tk0R29hwXgVQiDLCtNk4/5NnIwxvsNU/uZJ\n3ODomrWVBtaaNNm311Zw+tMfBwAMb91ExAam7YQ4mnBSTaWwypLNSgbwegBdj5zcc/fKNRyxxLnR\nbSHkyDgzTzAY0uI26A0RsC+V9Go4sUqvYw+IeVMb3t3B7f5yvjYAEIYRPJZTPVWmK1BK3TPepBvL\n0vkpBr6PgCXdqbRYY3+xMJ4indOz6914B9eukj/DIxcu4PyZbQBAqxmhEdJzjEIFn68Z+hK3d6mD\npvH8nrnS5ii/0Pcw5L59UHzyU5/BqXNnqS1RgLffpSigwd4OIvYtObh1G1/+0pcBAI89+RR+6df+\nAQDg2LFN/PiPfxYAkOcG//K3/xUAYDgalBu0WAjPEwqCZejtbgdnNzl9gfIRuvbmTsrspsDL3K5Y\n5pjFy7Wxu95B4QXR25ugwb5lm9sCPU3jdD6xaAsyxLeaHdQ4CeQsneH2Ac2/k2td/OjTJHs+9kjs\n/K1k6KHXI+M+aq+hxobSweEQGe+w7WgVJ+v0W0e5wsYFGu+nN07gja+8BgC4/MoedI/aNIiHuH19\n+dQI70+qWc7pAu9LjMr/RntJOX6TlAylb7/4Iv7f3yd/qBe++xr6u9fpi1mKsEvJRTMZIe5TuhYz\n7eHsFic4XW3D8rYpAdRUkdLHIqzRbzXCENIub/S32iuYzgsfxLz0PYWPkH8rnyVoc6Ryq7mGsHCX\nUU2sH6O59eTjj+PTz9ABJkCOlCXrTGeI2X1gPp2j0SADbTzPMGNZNo5TpBl9fjxKcDCk9e/1y1fd\nWjUaTyE97mvpIfKbS7dxsHfH3bPv+9Ca+udbr7yG2YTGg6d8zNgmGI+nyPn+hfsDqDdCWEHv7/l7\neOfNdwAAd3buoM6pGmphgAYnh4Yt3UwkyvEgFWC94tRoYVwiUIU8oXUoTaYQorN0GyuZr0KFChUq\nVKhQ4SHw0eaZCmsuR9E7l99BvUnW/vlHHkW7WVCngbNglVL3vC7ksyRJ0O+TM2QcxxiNyLLd2b0N\nY5/jz0xdEjIlFOyCZFZIhtZal5hNKW8hp5V1vzUZjZCly5+GybmulPmKk/0iM0VSI8uXC3KbtaaU\nxFTpLGeMcQ57RlsUBWgWIwfpWkU5C+Mi7rBQFuH/nxv9vbh19avO6XyRULeAuy9fyaLiDIzMIZlO\nbYY+OswCZI0aJlN6bjeuv4JWh8bCZLYDndCJube7h6DG+Yw8USZxMwZBwZJ4HnLmxedp7J6tUrIM\nZDAa4yIyCz9x3zZG0kL06WS2sbmJVk4nWjvWjlnt7d3FhVN0ItxqNzDn09XxzS3s9bh/tEY85nIy\nRuOgT6xNqixmI5Y9bAbFDMW4N8AUJTva5flhIF1kS5bnGI8of4xQCSYc1XM4nUKL5Zkpzyudyz2l\nHOvkeaXM7smytJOSwo01Yy2mU5oT0/4BglX63W5QQ53lyHGcoMaRdGL3LUw96kP/9GMuAd90LpDz\nsXeeaUxyer8uBFab9H4r8l1ussRIHE2Wz1Ek4TkH4R/5zKdd7qVaWMMvfuHnAQBf/urX8H/9P/8W\nAPDTP/ZZvHntJgBgZ5riF37tNwAAG2sb8C5wNGWjg29/83kAwLef/3Y5F6xwLLfMc5xlueWzH7uI\ntVrh0K8wmBbsm3asUsNabDADu6sNcrncTD1+8hispH7VcoCVDWII15oNdLi0zO07h3j3GjEsx1ba\nOHmOnGvzfAJoYkSFAposOQa1Ot7Zp8/vxynWAmKMv/fqHScLT6YJRnP6XS+sITCcH0ys4mPhWQDA\nemMFrwsqvTSYSQzeps93j3fQbC4fkbnI9AMfnD/vvZF9xfqrlAfDcv0LL7+Gv/jaXwIA/vSbX8PN\nm9RGkQE5R3Jl8xnSmJzRdZrBMsu9uR7i1BblQgqkcvPG5DkM5zsMfImAo3VtbpDnyyeXnU1naLXo\nuWytb6MgVVrNJmpcR8XzgGaX7iFjx3gAyP0MZx55BgDw+CNP4tQ2sdbbxzxIdpGQIijzNFkDy/41\nEqDMl6AyKkWAtxDAzTu3AQD/5L/9XxGz9DYYj1Dr0vxutBuOVV4Gf/qHv4d2i8bSSreLOgeQzeIU\nG5vHAQBnz57GZEpr22uvvYpM05hpN1suX5xSAmkRPapjZJx7q9Fs4J23iaXSMHjssUf5ly0Kfx8h\nyz1EKUnJ8PhfXaUsWwbDWUGuKcviIzWmLAQO+7RRnjh5CidPnwUAHNvaQqdZyHxlmL5SyqU6SNPU\nRfYZY9yiLYTA6hpFJV28eBGNBkeKLEQfJWniwpz39vaxt0eLSJ7nuMg66/ET285vyBiDHhtrb73z\nDsYDev0f/+Kv3LeNQpSbjpQCkq0KuUhXC1FGGNgyTUGuc8Q8UGbTKVJOqEah6BwuG4QI2TdGiFIK\n9H0fAS+Inu8tGHQLtPfCfb43/cOyqRH2bn3HhdWRssE+NbKUbCLPh/AKSU5DFj5WtRCK5ap80sb+\nEW22k/HEpUBIZjMcMb2+e+MG6h1euKR20VXaWhThgtLz3O+qhb4Pw8AZlPE8xuFhb6n2AcAkXEXA\nz6EOjTNrdM/v7u4iCWlBe/utSzjepjG73ung8g2q0bWytY0aSyyTeYxDjrRZ6bYhQeO3d3iA/oyN\nO086uU2niTNClVLwg4KqVs6wVmENEev4k8kMvREtONN5ipx/dxn4nufChD3PcwaUUsqFiktRyn/e\nQuJNKQX6A+rP4f4+Xk/YiGivoL1FMsmxziYaLEsEQYTM0nWGscSU5YR6IJ0xtT+Yo8Fp0tfqAQTL\nJIOJxmTOEY7zHJNk+SOBr3ysr7KBsboCjzeOmpVosCPF5beuuOzWv/KFn8Nv/jf/BAAg/BA19oFR\nngfbJrrfbAFP8Zrx/AsvOAdG8kGkNp7ZPoafevoCAGA7CjEdkH9O1Opgnte5XTGm7Bt1OJshZp9R\nk2mIJaOHU50i4nQSYTzF8IDu92BviPPHaGy2Hz+OMfuZHY1TvHuTnpuZDXH2OB0GopqH6YQ2sflE\nw7LkmGYGOUeQDUb7OH2KJKR2p4twTs/2sD+C5JWl4TVweJXG42wk8MOf+DG6fnsL//ZLfwIAaHV8\nt14vj0LaYz8+gOWbou8F13sDYC083iTH0xH+7OtfAwD8yz/4Bi59n4y7ee+KS5uSmRAZR4hm8RTZ\nnOZlEIZYX6F5f+70CdQ5qlgY44zm0fAIPETQ7XRh0nLem3z5uTibT7C6TmPn1NY6RuwHudquO0ku\nSWJIXtPjyQg+W1xPXHwST3/yh+lCRiLmhMfTWEL5ReR06SukhIQQZIxRYmOe07ZMoq2kxYnNY3Q/\nG1vo9yh5aSuI0GnQ+uf5Hjy1vPvL3WuXcJstlnarg+PbZDx2Nk5jnrIh7AWoc5qHoB4iYf/nIIqQ\ns39fGISuPqew1h1mut1V7B9SqoM0zZDxZ7ROnRTv+8odqJTnQTGRkuY5koyelzRUk4Kub5BnD0Ck\nLP3JChUqVKhQoUKFCu/DR8pM7R/0MJoQG3H67HkMmS1qNltosPOYtdaxUcYYl0ciXigBQbmfjHt/\nxqUQTp485eSQo6MhUj7t7e7s4N2r5PV/eHjoaMK1tTUnb1gBF9kwGAzw7mUqf/Dd77wIieUtcLlQ\nhEgIeW8lGH6/d3iImzdv8m+NMIs5gsTk8FkGW+t0sck5s5RSzhm5d9jDcMDRUwcHGAwouiwIAzTa\ndJJ67tln8ewz5BztK+Wc6cnHvoj8WCjVY8z7yul8GCYT63JIwS5EMAkLwRkkjzwN7bEsKegEAQCH\nM4P6iKM2synGfO95bpEl9MzbtRqeeZbu/UYUQXG0lFAKe5xf6cbuHvqcRM8oDcknpMDzXB9rPXd9\nn6YpxtMiVOz+uFR/AqsJJe9rxRJrp84CAK72R4jqdHKaJyPnDH3y5Bnc/j45W4vhAGe79NwuHe5D\n+QWj5OHYcXp/LxshHZNjb5pbqMLJ3hqoojw6DMDVzq0WkJx4TsznrkzH1omTOBpyaZN55nJdLQOl\npGP05D30t3KnfDrR8enfWEh2jM3zFHc4Wd563EN7nVibnUTg3MknABALM2XGSvgBWix1Rb6Fx0yl\n0QaHQ+pDazUUyyRH4wwTdj5NTZk4tB4odB5gLmqtcfwESQieJ+EX5EWW4K13yAG9Gfj40c9Qnqlu\nt47jnPPGCK8ce1IgDJl1rdeweYyCGDzfd2Urut0OnnuWXAw+8cxFnOySpDG6dQ2RovVmODiCYIYu\n1Ro3ePwPZ4lrbw6BD0v2+15M4gwbm5Tw8NbeFVy7QWPqXLeHC+eIWRgmCl5ITNDO3T34fGL3wxyW\nS5748xrqnOOr7QOtY/T53A+w16PTvsUYwwFJP63VLrodDgaaW8zZDSL0W9g5JBZ/ePcWfvnzPwMA\nePaswR8GdP2Dg33o4YMEEZQBSVrnmHFC01azfY+0V8x1Y3Jcu0Ps2x9+7ev4vT/4fWr7/hDpiOa0\nns0Qx7RnKL8BscDiN5q0hjYaIbpFxG0YIeeEnM2whiN+bmk8xwqP/VajhimvrUeTATKWDpeB8hSa\nvO63myF80OtO3UeHx9FkomBdiSUJv0b3GTW6mBSJabMUoz4xLDeuTyFksY/miJhZi8IQqnC8VnC+\nH8pKiKIuIeCCI5557oewcZ5Y1iydw/BnUhkjy5Zv47NPP+XKiuVaI2DWvV4PUePIx6N+z7HroR9g\nXOSIswaSGfInL1zAzeskxR7u7kEz23Xu9CnUW9QnQeBjzjK0hXaBB5PJyK2jSimEHBWoLRAXcq0o\n1z9P5tBp4R5yf3ykxlR/MHTG1MErr7q6a88+k8Iyzaa1dsaUtdZJe1rre2S+MtpHIOf6RdNxgv4h\nLRDT0Rg5G0dH/T6ShB68lGVUUq1Wc4vhPIkx5nu7fv06Xn31Vb7mGD/yw59Zuo1a63KSG+MkMU8J\nzLiA7xe/+EU8//wL9BnPR3edjaZagNVNWqj7u7v4/N+ixejs2bP48lcoyujatZsuIZnne3jrbZKX\nPv7xZ5BzaPQL33kBf/sLvwQA+KVf+ILLaE2bknJ9uJgFeFmZb2ZzyEJTNtoZU0oqICs2/wwm5Ykg\nBFShy8PgkFMgpNOxM1K1Nkim1Pd3b97AT3z8aQDAiUaI/s51ur4vcX6b+unsqU1867uURHFnOELO\nG1RulKPgtdYICrkqVGg/QLbe2YmLMEdksGT9GCcbdB1RbyHnTaFe7+LGAS3anzh9FhsbFLGVJjme\n+9g5aq8EcsOJ7bIEn3mOfBvOP3MRf/QVkj0mRz0UWRtaaxu48HH6zHdfeR23bpLfluf5KOo0e9Ji\nGtMEn6eB83OQ8JwxsgyEQBnxKRbSc6CUx6WS7n0rNAY7JD9ceedt9K+TMVJra+wecfb002sYcXZR\nXwtstGnBbNaEq7WXZgZTNpzHswwHbFwnOXDA/lBZnrmFN6rVXETvWidCKJYz+qld0v3uZDqCMVyA\n2mZot2nt+bEf/QxSXgN2bl5Hypn4W6sbaDSL0HjhDmmwGse3WAI5fcbd50999kfwUz9OstbW1oar\nAJBMnsK1V2gteePF5xGxhDC/G+MgpfXAGImUg7+sB2BJmS+eJDjYYRk5OI5jW3S/a41N7PTIN2tv\nP0OLk8V6Kx3ME2rfO/v7MCO6l5889zh8jhBVYY6Yw06P0hyXeeNab65gxEbQ4fgAQUS/2w4V/DpH\n9OoYzZDufTBL8OJL3wUA+EGO5z52FgDQE0PsPkA032IdvcHoCC+8QP5qP/1TP4MOS6+9/qEbtC+/\n/iZ+78//EgDw6qVr2LlJKTDyLEE6pvmazaduj4EZOZ+8eisqfXRhXFFfK70y3YvRSLl/AmEQBewP\nJwUEy/hpEiNZSDZ9PwjpYzqidWIwbrvDql8LEIZ8D/CR8Dp36vEteA1q+zhXmLFPnC8EDBs4+egA\nNUFtTLIMIUtanhTwOVmy5wMiLwwWwC+8UKSPWUYGyN+8/CaGc5bYVIopD9TOcR8mXT5i8dnnPuHc\nB6bTCXZ2OVp6pYH1DTLMKQE3GX3Dwx72DY3VwWSMGu+jGxsbuH75EgAgnceYceFiAZTuCVLhkCW/\nIACM4eeSziEKvzYLzHn+QSrkRb6hJEXOhhiSscsEvwwqma9ChQoVKlSoUOEh8JEyUyurq46NqjVa\niBplnorJhK39IHAWpud5SIqq1lnm2KjpdOpeJ0lKDroA2s0VXL5MJ+aDnT3U+JQhhQc/oNfG5AsW\n8hTffeklAMD2ubOIE7JCn3/heezfJafRz/7oj+Hpjz2zdBuVlK78jFxwEAckLt+4DgD4gz/5Eyim\nGz//d34VdY9ODXmWIuVTyb/+nd/B6dPkzLt2fBMTZs1eefllhOzE/at/7+9ic5tkjNPnzrg8T5fe\nfBP/+t/8GwBApAI8+xzJD2sba07aEUK5UgLUL8ud+JN8Dq9Iya8tNteIkXnqwgXcvEXJDAfjQVGu\njbgnpmKT0Rgxn/w1NCKWCjCGS7g1nU0dDR216ogPC/4+x6hHJ8vjG5v4ic9Qm77+0osYxYWEp50j\ntZSeYw1qtdCxVMtg9cRx5HW6t97eHRxdpXvO0hRrXArjiXNnsdcj2SM4topz7HB85+rbOLZC4+hZ\nr4MrV8h500/niEAOvL/6hf8Ij1+g6+xeuQSdUP88+txn4DeI9bj0vTfQ4CNqmmcAS2MSnmOLpuOp\ni0LJUwNXqG8pWBhORqtzg7xgoyRgi9xJRsCww29y5ypufe/7AID5ZIJtjuqRNQ89Ll2y5tXRqtFY\n3l6vI2cKtT9OMOLT/HiWI2Onc601hODTpK+QMzvtB6F7doa/AwCzeOLkwmXgeR729knauXHjBk5w\ntNsoVNjepmfRWctwcEhsaTzpYciMhRABLDPbmZ0h5hJBw4O+Syp7bnvTRQ39/M99DptrFBjQajSo\nKCUAbG1ihctTDDOD733jmwCAqVGYTGjcZvMchhNcQgZI58tJ0lFocZXl5Uc2N/HoCtXgO9wZY/cu\njTtlJY6v0hyttz3sjHj+ywbOnaB15MSxOlg1Qm4t7u6RjHVrMEWD1+hmvYaCh9jZGyDep8888f+x\n92bBkmXXddg6d745Z755fjXP1TOAbkwNEiJNmLRM0ZJI2YqwwnJIYTvoP/46FPaXFWFF6MNDhL9E\nR3iQTFEUB4gmBJAN9IQGeqquoWt49eYx58w733v8sfc9mdVssLIMR+vn7R9kP2TdvOfeM+6111qr\ns5iuU+ar2fGRMFzi6pp6risLDVxepmzt9x+8Cz94huwiJDSd7nn78UP84M9IH2p9dRWLSzQ//vf/\n+B8jNekeNk86uM2Zi8QPkfos9jgcIOWicCkTBdvatgGLq7NtS4fkMVEuupjlbLOmm7A4y+P1W0hi\ntm8xNcVM9Yc9+AOeJ4Igt0CcKK5dv4r1RWrL/OISNLaXKhbLgEHrlguBmLMwVmkKdYZ3daFypqyJ\nyELIXhNxQmPXcQpwGUozRQZkDKVlGiyG/1LbhsarlWsKmB59/vT+I2yx/tvaYgkit4CrVXCy35q4\njYdHR5ibp7XKKZSg85rX7x5DCLqfsFhT4qV+b6DKQ3zfR4E1JnVNQ8ClP1EUKV/e4XCIVk5uW1lC\nu0331qiXoPFcrmnaGAIjYbLNEoSOHO7JZIqAYdOD7UdP1Wgcjy90M7W2sqYYVpVaDQ5vrCzTUJ1y\nvF6gWCwg4gmt3++qdtWqNcQMKX167z6OGG6pVGqIVNpPImJ2hW1ZMDjNmaSakkzIhIatXUoDH7fb\nOOKJ99atj/HNr34dAPDyyy+PGIIThKEbyMagiPxVDIMAv/f7/woA8Mnt27jOGzTdsvHdP/kuACAY\nDjC7TIPEGIZYr3FtRirwwguvAADefvNdbD5+DAA42N9FmSdwL/BUqvv8hYsYtiiV/j/8k3+C3/md\n36G2vPIyakyvJZhnJGkt5WTpzCSJ1EBAmqLCz+bGlSvIuHYikSHS3LjasNBt0r10Wy1Vs5VmKXvp\nAdWFVcW0+mTzEH/25rsAgBcvriPmvyd+AN2kgf/xx3cxtb4OAFheXsePP/yQb2ckdWEYUBPjoB8r\n1sokUXOr0EyWajBtNI+ovi1sh9jdoonlSzcKcOvUlw+CDlav0WYqs7ZRnaeFRqtGqHAtoO714Pdo\nMyJwEzeu0sJ+fvo8JE965aUqfvjWJwAAv3eEF29epHZJgZM29c3ITzFfon6RQMIw6JkUCtmI6TRB\n2JajVJqV0Cly0U6un9I0TMeUjn+4dQcyoYlrvmxhpkhtn664arJKgmMc3ydIK+gvw09pMzgIod6j\nkHJkyCyg6mE0XVcSHmGYKOjFMAxouXy6bqDrT/4e4zjCkDcsw0GgpEMs10WPDY3LU3XoRZ4bhhXl\nC+mUikgylnOQQBDQe+92TtDrMSMuHmJ5kd7F3Ow0ppilZju26m8SQJnhole/8Q3s79DzfOfhY3gs\nsik0U9VnpYEPpJNBRIVZDYZO739On0fzkKCNXqcPP6H7LVbrGJp0PdPR4Kb0/TOGDY2Za4W6xMIc\nvZ+N3RiPWRohEDZWmPEnkgwFrutZTCVaHSqn8Lwh9pjx1O4PlMHv0sICkhwZi0LsnnCd50aIqjM1\nUfvoh0cs6NlGBfu7tHn8b/+7f4TXvv4tuubJIe5tc22X7QJ8uEr8IUJmKUa9JhyG5EpFG3l5oakJ\npc4vsxTgjdv0zBSMnOkmJATLrwx7begsGmloAgHXcCVhFwErdidxgjSdfNPfOjlCxPfcWLmMYpWe\nuS8lRCFfeySm6rkPYIytRzQnlYsu7tyiOSNJI7z21ZcAAO9/eAsthroG/SHOr9CG/hdefQnf/QMq\nMei227jxZYKmncVldRB99dJZ1HJ9BsNUc7kEILhdemaD96kTxR//8f+Fmzfo3urVGVSr1AeC2EOv\nzX2pHyDluVBDhrkStT2OIpSYGXy8v6vkaTJNIOZN0P7xCQxmhLvFMjI+sMkYyA1MNDkm0g05Yi8a\nQpX+aLoGwf6itmaomuRJ4hTmO43TOI3TOI3TOI3T+DniC81MOZaFpWVKrxuGoQrKC66jdoZxHCu2\nnaEbMNz876E6MQ8HPh4rlT7rAAAgAElEQVQ+oBPKm2++gwGLGBZdF2UWBkvjWOk0eWJkCVipVlV6\nz7ZtVcC7vfUYn3z8MQDy4srtI6q16jMJsAHjPncSBsN5H//kA/zwB38OAJiamcGQYc0/+ef/Ant8\nEkzDIXbufwQACIM+ehG1y7BMLK9QCv+3/6vfRo+hMqvgQufdeKlSVrvuLE4x9YtUvL69uYXdfcq+\nPZ+kGPDpyXFclSEQAhMziDRNQuNTtA4NuW6bbgikXOg3GAwQc3G5yWlkgMkFbF+QIUPEFgfVqSrm\nFqlftNsn+NM33qR2ywBVvn4WJQiZ8dQLUtxcI188Z24Jb/6UMj6dwQCaRtcct0VJswxZOjkLrO4W\nYHIWzLIsxJxpTKGhd0Ss0I2tI0yt0snp9uYDzF6hzOG5589hboa1YYYBui57RDWHiBjSCoZtVIsE\nIdRmFpFxpnSQZXjMnmGxZsDiAmi7UIXOBadakKJgUyaoNfRRqREsWCp7KOiTZ21MQ1MMPsMyYXKB\nvmkagCpkFyinuV9XqrJFNSNFgbOaQRBgsUanxko5QZjR94t9CcmCosfdCKFFGVS9WFXZaU0TI29H\njFh7SRwh5L5sGrr6u9A0BflMEkLQvAEAe3v7ihkcRSPrjMpUA6vrBEHFUQhHo3eUpAk0eySOmIvm\nDoYD5PnmtbU1ZXHluA4azL4Vgv498CTzeG55CWs3SKNK/PCHaj4b15rLssnxIWemhLPMLCzvp3jM\nzM7zZ5fx6Jgg6NA2cL/HpI9ujOsNynqE/T5iLob/ZHcfRWagmuUCYh6yhpRw83eiGwCPoQur8+g1\n6Eu9YaK0q4pVFyVmFJdKReRY/7DfxZC9AqfcJZjP0E8BqLG7sHIGL1+heeJ/+Wd/gJCzD5cvnFM6\ngrsdH0MWx/V7bVUsbusZ7DwLmibIObO6bkBnfbAgTpTnpGPo0FnrzDJ0+JyJk0kAK58rpYTgtEcW\nB4j5nSfZk5ZhT4vm0TH2donc8aVvWfCZoKHJDOvrNL5llsJm+O/Dn/wU775FhfiXLl7Cd//o33Ab\ngZevE5s26AdodSjb9XjvUOky1uoNPPiUYNDNzU0IzjxmQQjHpbXz1as34bC+WJxJCCv3R00QeZwV\nioDgGeBaXcuQMKtufm4G3/kVIkjde3AfxyeUdV9dXVWiyxuPN1Bixt+lc+cVkStBhiKz9v7wD/9I\nlRLohoV1HsflahUpoyRZKuFY+fxUHpHbBCBz+zNImPzZMA3ApXG/MDOLojtav54WX+hmStd1VbtS\nKpVwfExpyCAIVIoxyzJV05Rl2ROK1idMu/2jP/wT/PSn7wMAhDBg8wQbDT24DPM41qjmwSm4aPZo\nonn84CEKXHNk2xbqrFTcqNZw9iy9jF/91V/FysoK37VU9zZp5ONI0zS0GYJsHR7h13+NOhBMHWU2\narZtGwkzBjY/+gDv/Aui8qaFAt7+l78HAAiPm3j+q98EAKysLEIsE/ZsWhaSMdkDxcLSdKXc+tVv\nfB0Op97bnY5KmdeqVRRLI8NOlf58So8wDE2lxTUpkfLkr2kSI4HyVNVjRUEEkxelmfk5nDC7xu91\n4TPDsl9owOWNQ+gNscNedW/8RRNnWJbg3JmL8HggvPil13DjOUoZf3DvUzj8LFOvh4jhyjRMIXL1\nbiHG0rtPDxk1Ydq02amUbAQJXT8Maoh9mtwePDiCyfccpTF6AS1YC3NV2Fw3ZMOCPU3fDzQNgzj3\ngirAcYiCX3EcIM03mCn6LEqpFSrwWVm6eeKjwGJ51YaJYS4LYZexUKdFUPonqE9OWCTRPSOfTDRl\ndJymKQxztMneOKF7my5b0HN4PEox4PrCOUtCZ9XifT/FxTW6fs000M/F9cIQ0mOvuDBCZrPPoCZg\nWnl9pKZgPl0XMPLOJAQMhpUzmam6jklCIkWrzeOvfQKfIZnHW5uYqhEkNxUEkMxKqpRrcBiWHfT7\nih2ZJZlSipYyQ42NYr/5+jewukqHnEKxoDzV0ixCxl6QcSyVcK9uWVhYy2tj5vHg/kO+0VSNI3ou\nk8039ek6JNPfh50TnD1DG4352RnsD6ndP3j7PXS4Bmt6bgqXazR3LC6tISlSO+7f+xCaSZuOr79+\nE9+yqF+f7B7D4NsahInywyxYwNwZWoQfHw5hca0WEGB9jv7tg4199Af0zsvlIuaXuZ6r1USWTK7U\nLwA1jo+Oj9Fn5X1NM7CzRQcb2zIxOKEDaScqI8pro7wWrFw0OcuUgbBharC571uGVEb2QmbKjUCG\nA+gsIuv3h4ptpyFTEiSaJkfOFHGMNM2lewQMa3LQR0sAI2OGuW0gYDjd0gz0Wb7i9q3b+MpXSZzT\nNCQkzxmarkPnemBDpuqAVKo1EBzQeqmV6jB4o+Q4rto4WDId+QCWKugxszZOIhR4zjYMB6k6XJnQ\n+EDoDzxVGzxJWIaNYxZOjuMIV67Spq8+VcPhEUHfS4uL6lDh2iaqXK/39a99DWkuhRTH+PgOwZqa\nEGqvMDM9rUpYdMOA4Ofp+77aQFmWpRI4lm0rGaI0TeHzQUvXdFX+0u20MTs3N3EbT2G+0ziN0ziN\n0ziN0ziNnyO+0MyUaZojfQ9AnQLHNY4MY2SFEkWRgmoGgwH+nz/9UwDAO+++i36XTlJusYQo18dI\nUuj8/bW1NeWLh0wqeKlz0kJPoyxVqVTCAReg66aGr7xKO/8bN26oewuC4Jl24OPtkVLgh2+8AQDw\nhj6u3yD9pON2E/UqZcRM20LELtVbgwDzoN9dqtSxd4dOXu8ed7B6ho78Z17/Fg53KQuysbGh0mBR\nFCPhXXelVlMiZ+vr60ovZW9/X8GgtuPgmB3hZ2amUKvWJmqboWXQ84JEmSBih/s0TQG2uYkyA5KL\noeMkUsX/c0tLKJao3WGnT0xMAHqpgNYhwRLRoAcwK2ZtdhZXbtI7WVlaQcwZhJW1dVQ5o3h4dIBm\nKz/xJOp4ICEguZBXaiNNpUmiUgghE+ojrlnAAjPXIt9Fs09ZlahTxO49OmFfuF5GMNzj35qFzpCZ\nLjK4JmVAWjKCmzFMNtuA5O90OiGQ66DYwFkWTDw7VcPyNH3W9DLaDGX3owAnnNr2Yg0Nhmem6jbA\nQqCTBAnT5TBogpTfBWQGhzNiURKjxEXY5xcqaHHm67Cd4rCXW7zE6DNkdmbegM3w7p3dFrY6fJpM\nBQwrLwjtYZjrxdllZQsUx6HyxHJdG+YYnCcZjqoXTJSfIfuWZSksznwVCg6296iPuefPQOPsYQIJ\n06Dv6EJg2O+r55CrbPlBrMgvlmWhUmGPsZkprK5RxqVeq6oshZSpghfjGND5NJ+lEhW2y6hWKipb\nagoTGT83AR2OVZyofdsbm/DY0ujL06s4P5VnfwIsL6wDANZmT2A1Katiw0W7RyfwglZHoUoQxtqF\n62gyM3Vj7wQRf8eGQML3NT1TUzYwsd9DgQuCV87M4qDHEGjrSHlm6oaOfsj+fa4DTaM+FcCH703O\nApOAYiB//MEHePs2ZaBCs4aoTWM0yxK0WFx0GA4hGJHIUkCw3pfrutCZEWuIGCZnpmSSImBYLUwA\nAbrnTquJJGCLnTiFnpMXZAbHzMUt9VH5gKT5ntquKXHLScLQbaQZZ7sEUOO5zRAWeixIffvefTz/\nMjGYNUhFUpCQYLQTscyQ5dCVbaEbsEWKbqg5WGiGsgAz0hRODjVnGnQex47pw+c1ybAd6Abdj5QG\nqsyCDP0Q8hk035ZX1uCzLZSUGVK+/yuXL+Di+bMASJQ1R6LmZmYUFGsYGgQ3UssSpAynxkmElP08\nLcscs3EbWWJ1O01lHzeuVWlaFiT/W5mmyIntQkqEnKXafvgA5dIzkM8m/ub/D2GaJgJefFutltoo\njde3PGlsKRT8UCwW8eprrwEAVlbWsblJbIbDg2M0j2ggZXFENHIA9+5/+oT4Z8AdS2hCvQDP8xSE\nF8YB7rIAZqlUwsWLxKSqVCr/n2G+IAhwxAt9EEWITngAZxmO+AXrtoU0N2ucmsX1X/olAMDQ76DM\nRsCzlTpK7Md2sHeANm8kpRBot9vqmkqEU0rVsQzTQMhK8GEQQue07k+/92d4802qTfrP/t5/iq98\n5csTtS3xfWgmb4hTqYwmkzhRtIkk6iuPOUOTiEN+h3PLOH/2KgAg9n3YPNEVqhV8ynTmYOjjqy//\nHQDAqy+9At+n9j3cP8BLzz8PADh/9SJ2jmnz8t6HbyNgEUs909WiZ+o6DEV9lZDPUIty81oNPlOD\nkyRFmZ/9pfN13PmIFpHHP/bR6nKdi6dBsJ9WMnQgp2mx1WwDhsOTwNCGzcw7vWjD4EU+cUgBHgBM\nG7hxiWCgj979CJLpMnEawmAKcMPUsX5hHQCwE0q0+rShW2wUIYeT+w+mSazUgCGzEQU4TTDo0jVl\n5GGNvREtU8OVdYJwKkUT4Q4tNIeDADrrKiwlGe7u0IbucU+iy5Blqtmo1eg6tpuiZNHfu0mALkML\ntqEp36zAl6qOrFx0UCsKbruEeBa4VujIGJ7bPzoaQUSmDYNhDKvgKKh8MPDUGDJNE/lPpVmqJnnT\nNBU8XqlWIXN/OE1Tn5NEImQqm+8FUDt8XSiKerVaVfeZiVQpoxdLFVSq0xO17/77myi+ug4AiOsd\nHJ6QHMLBQYrVNfr71557GR1mDZ70WsqsWDdsgGUMZhsu9kN6HkLT0T+mzc6g28f0MrHAzpxZhcPM\n3XDoQDCFvVhfwp23SZxTT6FKMcI4hJf7nfkBdo5p4xMgQosZdpOElJkau7fvfAKTr9moFpErSHzt\nlZt4j5WqT378EQI+OJuOq2o6LUtTfnyRF2OYOwroJsDjslJ0kIbU94d9D4ZO7c0MSx02TE0qhew0\ny5SHpJASGW+IRCYVy2yiEDZ0O5escLC6SvWgaZyoet1f+/VfU33m2CqgMUWs70qphIVF+mwbQkkd\nnF8/o4y0DUPD+TWCq2KpIeZNUyikEosNOgNoDE2bIoGfy9nE/dwPGCtLi1hiJuOjfh+6NbmS/dLi\nslqDG1M1yFxoI0th8Q9olgtDz6HyRB2uBFHP6evaSNIlyzLYnPSwbRtBLqPkDVEpjbx7czX08XU8\njiIkXJutaRo03ghHQYjDfYId79+9g+np+sRtPIX5TuM0TuM0TuM0TuM0fo74wjNTedYpyzLF4BNi\n5Ef1ZGYK6hRQLJZw9SplNc6fu4Bej04Q/d4Qx8fEBtjf3cHODqWBm82mSgf2BwNELToxRXGMhE86\nSSRVyl5PM2xt08mu1WoRhAbg7NmzWGG39IlDnVATTLE9TM/3IBh601JNZXRm61MqJTk9N492hzIx\nh80jZKwVVXfL2GOdlt/9vX+Nbp9Oef/hX/91hHyayNJUsaT8MITJ8EkaJxB56tfUsbVDbfzBn/8A\nt1if5Pmb1yfOTBlaBsm/mUYpIva4SuMQU1U6JZxdLsFkj7ksFchSuq+SITFdpO/ErlAn6QoMrM6x\n/lVWxwvPUXHi5s4DfPffkgZXrVpCga9fmSngf/s/SJT0o9s/Rk64CIah8viThoCh02nbNHQlejlJ\nXFg1YLIIYBJLmGbeHx1cmqF7+77w8NZP7wAAfF/i3CU6+WlxgJhT2IbrIstFRJ0ALhfKx1EGLab+\na1sFOMwIC2SIwgw9hwsvvYhej/4ehzpcvgfrYAdxk7Jg5XMX8SPOOiZCV0XPk8Rw2EPW53R5GCro\nNg4DBAFnppIIJqNe7pyLs8vUl4/iPswOnQ4btokqnyzvHXrYPOFCTtdUgoMSITLOGNfqVZQbXNjt\nB6ooX7qmGgcCFoxcVFFn/R8APT+BlovGTBKajpSPtFGcwTDonbpOSUEygETIJ9RM6rCZHQvdRMQn\nY8O2ofM9WEUXpZSguvr0NCw+GWdSKsZRKjWkDEuESaKEh23bVHBzHGUjawuRqnmuXm+gPj0zUfOG\nrQges9V+kj3ACtu9XG6sw/Yoc3t+bh5rz1FG/8O7t/EB27EkZQ+zDTp1p+EAizwuK8kQ1hL1wXh5\nCYGk5xFnJvzjE340Nky2crFtBwXWJNpvtZCyPFGURCprU603YHVpju4N+hD25FitblgImJnV6w1Q\nrfNYyXzsMPS98WgD+essWBp0JjjolgHBKAQygTJndlZvrGDtzDkAwJXrN7C+SiUUjelp/Okf/HMA\nwL/63f8ZYZrDdiYkw92ua0Izc/HoEHpuiSVMJfps2cAzoHwol0zYTDCxLV1pKCZJotbI6ZlpZXs0\nv7yKv8bEFqfoYolhMsvQUWPNtEa9gpdYrFnTJFyGJh9+9BGKDA2XG1OolNlr1PdR4PUpES4qZbax\n6Q/x4gVioH77W6+jd5s0/VpRiIozEt1+Wui6BU3L9dMktlng+dH9+4p4Uq1WUa8xIaxRV9Y+URSp\njCqQIWZds6WlBVRKBD0XiyX0mSF/0DzB5fNEJtMNXaFh4/uKLB1l4wPfR4sFofcPDnB4SIxq19KV\nVtck8YWz+fJUm67ragM1/ll8hlOa/7emCVVl77oFuC4NmNlZDSvMkPGvX1UpvcGgj25eZ9LvY58p\n561mE0P2get0ugpD9b0+dH+UqLt37x4A4JNPPsHSEqW6f+u3/pPJGsp04iAMkeR1IHZR0aWFBhQb\nJdWWnB4epQn5QAFwdBc691VNE3j3fRKy7HRP4PH9v/3Wj/DCS8RqC8NECWBbljaqERKAzveQRTG2\n9mizKaXEc9evAwDa7baSozDdv7pLXDp/DgZv1GQClFg6uVJ0MHuFoNF6JYVu5P59GSRTpDW4MFlA\n0M8MnHCtysN7t1Et0I6oVi3h3XeJ6rt3fAiw1MHs3DQaddqM3L/zEWRAG82vPH9JbSh73YF6NpZl\nosALRLHownmGCdxFhgJPmFGWYtinDW4Y+mjwfb72pUUcdCkd3A0OENucdne6CHzqd26tggj0u1pp\nDrMzvAAZESKuhYAdQTB7KgoDlJgp9twrL+L9j6mNP7m1gyKzz16//jwOP34HAKD7AYoMJx312oi8\nyT3PPK+PAdPJ4zgag88kWLceSRzi00GkvuPxdOEFEVJOx88UTVyeov6waWZ4xNDncT+GZfEk2ahi\nmmGnxdk6Wsc0Fh3ThM/XjNMERZ7wFyoOyiU2Vc5iDD2eA3RNyW9MFiMmruu4iuEqx8yEoyhWlHaz\nYCu6dKJBuRSYtgWbx6gxGEDjzRE0TUlKQGhqEZSQY/Ub2hOeok32Dk0SwOWx44cD5V5gW9bEZQX1\nRgVtNrZt6hFOjmiBWiotoFakhajXO0R3mw5NqzULj9jrrTPwsMRtmqkWkHA5giYFqtO0sHuyCNug\nvnk46GHICtP1mXlovIlfqElUGPZ8GO5jjmGRwG8jZir8+tlVeNyn3vjAh/YMHpKp30HrmA4PAoB0\naRwM/YfodOiedw92yRsU5EM35APe2vkL+Du/SSUDN28+h7k5GqNzc3NK2d0wbcXOswwbGveFd7/3\nB9jv0PiOQgGb6/aiTEPALMXYT5Gv8YM4VeKQrqbBMicHfVw9gUyH/Ft9tflOkgxRzOxeTUDn95VB\nolCn9yIl0ODnr+sSMQuxRsMBcgUK19Jh83+sLM7it37rbwMAdjY3UJmntfP58hRKDEEvz89B8u/e\nWD2LlZtkPG+aNubYZL03cNCPnsF/EFAwvqFrCLhs4e0330LE8N/U1DRanPTQhIbz7C5QKBZw7jx9\nXlxdVrWG5UoZjsVM6yRWG8+i66LTprlwulpU0OHx8ZFKdPieh6MD6lfbW1sYssOIUyigwvXM3/7W\n1+C4I3mUp8UpzHcap3Eap3Eap3Eap/FzxBeamRqH8D5baJ4L2H0W5lNF6pqm9FeE0JFXpMlMKpsR\nyzFR4x17ENSwMHZS9IO8CDvAkKv1e70euiwX3241lZCm73s44ZR2r9dD9AwO4OP37Ac+Ys6a6Ial\nnLt1XVcpTClTmMyCK7kuMv6teDhEzGyYdq+NjcckUmpbOhbmSKPo6OgQLjP1GlMzyjPPNE1VBC80\nTXkcBWGAAWduNAjUK6Mi2GRCM6lrF86j3aXnFwQpQp/u98MPP8HcPBXOZsJFykWORddCuUTvxzYN\nCM7Hn/Rj5O4nmuagzKerlaUKnBJDHnPr2N6m5zfVmEbC+iuHOxuYn6LTs2aWEedsuOV5pJyRGwRD\nDFlXyHEdOM7kmama7cDh4nUvDhFyW0wDKOp0ilqqF3GO9b7e+6CFf/MmwRgvz2eYmc+LSVNYJXqu\nhaILl+/BzELoXISdyiHS1OTno0NIuv5qVYN2geAeq1DFW/eIcHGURig1qO394RAFzij24UMWJ29j\nEsfqfgqOpYQxTcNAxkW+UewhZi2wnWGG3gaNibIOpQM1UzRR4mym4+hKX6dqlTFzlix21tfXceM6\nQfQy8nCw9xgAsOjG6IeUPRS6gbOzlKmpugIZPwfXMOCW6PQZZQLt/rMwa0dirf2+B48L0OMoUUX/\naTLOvo2hsWinZVrQ9fx5CuQOOKbhAJLmiTTTIDnLEmdC2VcZGlTBehTFqvDW933lZn/l6jkcHBC7\n9+2330WSWx8FPqw88/WUuHx9DfceUjbKi4dKo+xfvvFj/AJ7V968eBHdQyJ3uIUiqmwD1I0Al7MV\nS3MVHAQsxFtwUGcWqewk0Fkg0SgX4DATN5IJDg4IRnRcB2FM85RECo9LEAKvj7l5mqcOT/axvU3k\nnmzMKmiS6B18iNYOMQ27Rw9xdNTi6wywUKbrFJwCiqy3lor3FWPyv/iH/yV+82//TQCAaZgQOmOQ\nkIosk2YSce7BGCU4d/kaAOA/+M2/i//zd/8nAEC7N0SRYa8wlWi1uaBZABq/qjhOlXZVb5gqiHiS\nqBQdhLwUp1IijPPibKHmbiGE0rHSNB1+viZlUhEf0ixExBp0yTBE2WVoQ2ZgnWXMz82heUDvNwkG\nuHKd0ATNdOBwNq1RshH59HxmpxsKshz0+zB8er+2lkAMJie8nFusI+NSgoWZBpKA14diBbZDbZlf\nWoHt0rt7++138HiLykC++rVX8RIL4kZZhogh9wSZYq3buomHj8iX9/bt2yi69K5fef4mSry2bD7a\nQJuzq/1+FwNm7haKFZgMDS+tXVC+nbpdQnc4uWfOF7qZ0jTtZ2ymRqFUgfn7udeaaVpqM+V5nqIh\nA7RJAEg5ORchExAoFkbqpQX+nKUpYt44pEmi4K1x5XXP89Dh2qVms6UkByaJDFCU6p2dHXz/+/+W\nG6aP+cYZcFgwrF6rYGGBFmXf95UXULXWUBNyv99XyuX15UU0Gpzq9vbV9zXdQMB1KQSJjp5h7qUX\npaP6DUvTMcsTkGZZSJLJalGCThePHtJEev/xAcKIUq4izVBr0EAwCg4ChluLtoOlWZqEr19Zx/QU\nM2QQw3Xpfe4mBhJWqbULgGUz7KKV4bNnlR8P8Oku4fWHu9swwaJyeqa82076IR7u0b0N0hAe1y7p\nuq7Um//Rf/30NhoCigpdtE3E/K76gwg7zPQYdlPEfU79x0Xc36Pn6rQSzLcYKipINJb4+ZgpPDYE\n1jILQtImRYoMXFqCRGbQeQNdjWPsH7JRrDkDf52lILY24Hbo7xpsLMxSX5ibnsXDe5NPbmEYqA1s\nuVRW40MXEiGn4LO0DF3QMwz8SLGqUpFAMhyyN4xhH/P40C2kMS12Kxcv4Mvffh0AsP3wEd5943v0\nDDtHqNkM/5UruMoL39zyMhxeYwNvqIyONU1HmrPCANTtZzFzHm2UoihW4ynLpOrvUjITFYCMBGyG\nwSDHPQvHF3+BcZWN/BASJ4n6LCwdNtcRuW6kajaiKMbUNCuNm7ZS7d7a3sbWNm2Wg8Af0YGfEjev\nrOH9t6huLzMyLF6m2p8Hbz3A7h+T/9rXW1/CN65RfVA03IPBz89ONBisbt/pedAZRi5VS9ASHrtC\nKtmW3YM2fI/+7dL6EvJp+vadW2i2CLpsto8QdvgwsDiL669Qrdbvf/d7+OB9GruWyHDuzGQyLACg\nGSkqBbpmyYmwt0O1rEU9wmyVN7uJj5ChvTCMMMXGzpeW6zi5R64TmqbDKlGdkV2ehlWa5eubI+9H\nIVFk6Zhf/4//Abb3aZz97//sf8UsuxpkcYaQfQ/TJMUiG81fuXgdpWo+/xXQbPcnbiMyiYTHfZoK\nRLx7EVmmDi1+GKpe6DqWknMwhAYnN9WWQJ9dJfxeBFvn2scSUGDI2nYKEDzX9lMBnaFm13XQ7tL8\nMYwlAi4fCDFEa5Ng4qvfeB1GgZiGux8OcPnqxYmbeOnCitqU+ZHEJx/fBgBUGlVVg/ZoYwODAY2V\nmbl5lBmqrtVqakxomlAHP02MHBRazZZSdm8fHGDAa+0PWk24XFTb7Y7Keuq1OhbmSHjWdl0csqDo\nvbu3scMSKpsbRVzg2qtJ4hTmO43TOI3TOI3TOI3T+DniC89MfV7ROWWsxj+Pslf5qa7XG6gdZhD4\nsFhC33GckXdXwVUpPdKWyk+EI5aTGPtdaZpjcJtUJ9c4jlX2Z2lpGXE0OUtq/FB5dHiIj9nvz3EL\n6pSsaZryxSuXXJTY7mUwGKji+G++/m0l3uZ5nmqDrutKeFPXD9Hn062mG0i54DNJYvVbhmFAZ8hK\nM0aiqa49yh7Zps56OACeIqtxsL+P5Tk6XQ/7QzzepoJ2oRtoHrFwZRwjP813dRv7W1RwfNIZYpVt\nKNJkgMYs7fq91MSDbcr4FB0Tlkv3uHnoI/PoOo1qEXt7BBU82tyCN8h1tEzMMPup1wuxywX2TrWC\nCrNWim4BvfbkxdlxEirh2OHQR6tJ2b+jZg+dIypaLBk6dG5jueoCbDkzKJkYztFDPHam0fepLb2O\niU5W5TbqKHLlatFKkETUa/aP2qg4NCRX7QKciCCcrU/uwVklSEgXKXqcObAdDeuX6Rked44h+5Pr\nvriuOzpJmxagxBY1FPik7g2HCEI6yQndRqFCY0LXMmTMqBn4AW4NqK9VbIHlczRG55ZmEPYJ+qwU\nNVgp+11NLWN2Kor5lW4AACAASURBVBcjtbDg0nNINR0RF/Y6toGQM0dhGMBlexvHcXDSf8bMlPo0\nMkxLZYaEM9uxTBHxbxVEETIbQfR5JtzQRzYUURSNSCvDocpCp+lIiyoJpRILNQ0HxUKNP7vI5Ejb\n5sxZEtl85UsvoNWlTHgcjwppnxalgqasQeaXpqBllCFaWC3B69Lf3/z4Q4Qx9d9i5sMLuRQgc+GY\n9P1qo4aFCwRvGYMUsaA5KA1SdBi63Ht8hI9vU4aiPtdAuUr9fWFuBhH3R6doYplP+8gSbGw9BgDc\nvX8PA55rXn7lAv7Wb/7iRO0DgFJ1GYZNv1Wuv4OV0o8BAGEKJXTabp1grkj9bmFhTgmvxv4JooDm\ngCj0IY8JNhKaDqNAY7RYXYDgona7UIFbojFRrlbwd//+bwMAPvrgQ/SalPUYeBFS7jtRkuKv/0d/\nCwDwN3/r7yNNeA2zLEScUZ8kzJkzcBjqb4YW+oeUJdGzWK15uiHgqH6hIeasqTBNRAxT+mGIgJOp\ndqEGj1GD7n4Lm9tMihEahqzzNUiLePNDKh8xbQsp6B9/vNFBynY1hXoNTkjt3dzeQsakocCdhYNn\nQGyyCDl6ORxIPN6g+f7kg2PYhZypp4MT3hBCh75A8/rm1hZCRhkaM9N4cJfexe7mFjotyhLu7e6h\nfcKixVKOmHpBMLJQq9XgMPznWC68IfXt3d09RCnr3TkmFudpPX7hykWcWc+tkp4eX/hm6vPZfAZ0\n3VDfUTdnGCjyRiPLoGAyKSuKBhkEAYosJlcqFhRj54kNlCbUpCelHIlbZtkTUGN+b7TZYSaPaT7T\nZkoig+CEX61eh+vm1OlMMQ2FgBIkG/Z6agMWRiH6PBE0pm7hO//+dwBAGbQCQKlUVvqKEiNDVZKa\nYE84y1Zmy2mSgokoaDdbSuSzaFjY4lqE6y++gH2Gr5Y5bf2zwjZNnFmiTj7bKINfD+4+2oZmsqHr\nzAxilqU/OukpduPG1ia2DgjO0GSAYoUmN7dyFkWLOvaOnYIREtx9eILXnqPaj6mSiySkSbV2+Sp+\n/A5trOIgwFBSm7JYYLVO6fv95hFSnkxWryzDrsz+le0aj+2DfYBFFE+OW1yjBxh2AUuL9HwKiY+l\nFfp88XIBA55XkoKGHtdwfRom6Oyz8a9uYqrEcgIlA9UCDd752QLmuR6g0Ggg5EEd2jqkTc8nlbvQ\nM+qDbtGFznIbU3NzsFkSPN4bwpHPYgIsRmw1Y6QeLDQdhkvXrFg2Bn3etApNSW8IISFzQVSrBIPr\njKQmwPqmSJAh6NLkNl0uwmRYxTQ0JLwQDLwBooT+rWs6iJkCP4hTWCwFYRvAkGuOtlohus/kOS6R\nb6c0TR9tptIUEdcyttpt1S6nWFaMPJobcjVpXV0nTVM1twwHQ8UwFkKog0qShLBz368ECAP2r9Sh\npBfK5RJmZ+i9v/raV9Dq0Lh/770PkE0Iue8c7+HMtXUAwIXzdQieJ/YQYo83hf04xZAZXg8PT9Dj\n2ihX2IiZQfbLZ76OBkNjD+5u4fw8M41tie2NPb53HVMLNNgf7zxAdUAbkMWFGQxYXNj3Q3zwCUPN\naQTBm+CB18XaWeqzv/SdV3Dx8vxE7QNobYBG4743iBVLWaYZEn72rcMuakskD3D20lU0d2mOWV5b\nRb1C76F98kDR3GWWAh4d8A73byHV6JAjpI0qy0XYpg6jQH325Vdewu//32RA7/mJgsAa9Qq+/vrr\nAID5xQsY9ug5ZFkI+QwGuf3KKmSJnslOK8Fw5zEA6i/5emYYOgw+gBVsGxbXH1m2CcPI2eMR/JhV\n3jUBg8fZ3ft3ccxsdjsNITyue7JtpLlrRZKqspipShEFZuJWinYuto47b3wEj8eHoRkwJf8f/83f\ne2obLVsHa5oijPoYsqTH8fER/Ig+t5pdBLwbdJ0ClleIRV+rVbC6SqzDJElwl5n2t299ioMDeqdx\nFI+t5ZoS/Z1dXsLCwqi/NZtUhrC3v49B3+PnnKHCZu0XL63ha18lmaCVuYV86ZooTmG+0ziN0ziN\n0ziN0ziNnyO+0MyUYRgq4/Ok5tQoM0WF6VDfKTBbzbIcdZ04ikeaLpZUkFkYhkjSvLBUqoyPoRtK\n1C0bs13RNE3BOVmWjRWoZurvY7aBE8XJSfOJtGKeTbt9967yDcwkVPHvpfOXVSq33+thH7m2SYRu\nl046Ozs7KqvV7/eRsAfAoD/Ap7xLn5qZg80pWFM31IlG0wQchkQ/ufUxfvQOifa98uJLWF0k1kKt\nWsfuLp1cXmH/p58VtUoVYFd2XQZYmWfILwxhFahNjUoNuzvUjiAJVdajXHNRLjN7CyFMk06ECXSc\nWaTi2evn62ix5s1c0UXRZMhsr4cqC7TV61XMvkpZIVs3EDIUcdIZojpDJ+zuoKdgzNnGFIrm5Hoh\nG9v7qDCkJawSSiXWh9JMhFwUrvk2dC4EX9RNzJyj+9dXlrDNHlQPT7poMNQ4UyzC5kxH7Mc46NHn\nD497qLh0/5em6mBCJO63+/j0mE5Ovl2EyYJ33dBDsUKnfKPUQMZ2E8NhF56YvLOmSYwkt48wDaVp\nmiZSiWQmcQSL04SaGMHvlqUrQVyrYCqtJZklCJkMkgmpimcHgz4sPRfrTSF52rFsC4J/66jZhuCb\nqBVtNRaPuhGO+gz5pfRvJg0BHTncHEUJup0efx55fiZxjB6TONIsQ40LsQvFEgyLGVZCKA9B3RhZ\nXyVjgpyapqnPaZaAyYIIgwgRizlquoa6STCS7RZRYj2bVbuAv/bL3+ab1tFsTma3EmQp1s9RUfXZ\nxSoaTOjoHh/D1OiZVcsm5pcowyI1Bxoz0TrdIT56TFmnS3uHWFqg7G6v6+OE9YbmZ8o4Zmuhnzx8\nCFlgDMY2Eea6UT/6AaQR8jOrIOGC9enpKkqsC3f26ktoD6lNaxdWsduh312dAEEJ/DZkRvNjySkA\nLMSbZLHK4FnFAt55g3T4Ll89j3/wD/9zAEBtZhqSyQv1qVVYDo1jUzcheKz0hz76PZpvkrAJr0fP\nYb/dQYfnDy1tImEIrxckiJLcQ9JB54AK4h/f+QtUZtcBAIbhIp4wuwgAehbBFPRsp0uaYvf2gxgp\nZ3+CgYdU+egBK5ydRuBhe/sxXccwkfF49fwhkOQehRZKi0RCCI8P0Dmi/i6DAEbRUP828qi9U1Mu\nFllE+dLqCkzQ8//ow4/Q86g/6KYF25o8F6PrJtxcS832cNykcgw/6GN6jia9hYVFNLmkot3u4qRF\n8+vRySGWlwg+NnUDOs9Vg24XUe4pBKGY7VkmEYZ51kmDz5poh4cH6Hbp+lEUKyuaWrWES5eoM776\n6otYXaZMli61J5Cyp8UXLo0wXic1DvmNxDk1fJ7gXZpmyHdEmczUJkUIoZh9WZao6n5kUEJ4QgIZ\nY11C6E/AfJ8XUo7E/miTNXmu7+HDDZXuNwwT164x/fmdd9WGKMsyfO2rXwMA/PK/9ysKKgijUIlO\nZkIqAbP9/QPF2mu3e9AaNNiOT5o4YAmHtTUfrkWdybatMTaRC1mgds5Mz+AG309jahqzC5RGdYsl\neOFk9TZZEOL4IF8wAYshnqmCC7ZBQ+INsMQClWcXp2DmbBmZIMccM2QosQdZllqYZ1p8mmjotGlC\nPrs8hcUVmpA3N+6hwItbrxgjZUkGkWZqY933fTR7PFhkrMxYg9hEEk6+0WhMzaHAtGKZaTBYyTtJ\nEnQZitKEjgJTof2oj83HtKktd7qYXqCUdH1mCiWuLZkq2pBprrRtYJtZTz/eP8DmFsGtsruH5gG9\n/6qhoce068b8KloM/5VrNThM47WKBWi8KBw1j3D3wacTt9G0bLVpCgMPEcMnpm7A4s29EEJJewiM\nzKKjIFOfbbegvO1834Oeb+gtCwFPYkUzQyS4bk8YymQWmoGEIVTXlWDRc/TDFCfsjRgkNsAlFbWC\nRMl8Fs8zDYI7ZZpkSuk8jmMFs8dxjBYbfhPEzqUHpgODhYGlLhT7TwihxAezNFVj2jAMNe79METK\nC1MURWpjCEC5EdChMvfjK+PipYv8dxc/ee+jydqXpJhlmPfG2hn0farnO3N+HdeuvAgA+PDDO1hc\np4PHy8+9DM+nh3nQ7OL99z8AANRnl1FjaHdxpohdlj3QnEU83CfI7OONT9DjGlSZCDSmaHy8cGkR\nv/I3Xqfn1+2gatBmcWFpHke8cJWmHdz5lK75aHsfXf8BAODVm09vom4W0Bnw5l4KBAN6xroADIal\nBlGMw33aEP3Gb/wKfu07v8jfScjwEoDMSnCrNN8hk0CW1wRpaPhcT5l0EbCcSq9RQcRw3nS9gr94\nm57hw3fvKZkMxzbw6b23AQCbj3+KtXU6iNanV2G6NP8try09tY37W1tIMjrM6jeuolymebFo6BB8\n/ykkNE44FCwbc1O0EX949zaSJtUmFubXYPPBr1wqKRgu6RyitUf1l+HhLqyUYF8pdIiQ2uhKC0vs\nvrBSsTHjskhtOsT7n1A/8f0OCixiKRyBZ9hnwPcSZLzBr9RcXL1GtZ6bOw6WeVe9tLSK4yN6j3fv\nfopNZrjapqXMimfqDVh5zXOSqBIMQCrhVpK9oPvf3d3FTkblEuP1iMWSi+VVeqcvvXgD1y6TKGi9\n4iq3hlTTVLnMJHEK853GaZzGaZzGaZzGafwc8e8sMzUO832WzTduLTOC28Z0qcZ2i3Lss6ZpyJEO\nKSQkn0oJ8ht9Hof58lPjE36Amqa+IzRN+WZNEodHzSdOomvrVBh56eIVfPAB7fAty1aS9Zvb24gY\nHgiCQDEQPd9T+llZJpByajkMUnJ8B3DmzDk4Dtuw1Goo8Em6UCgolqJlWbC4cHFpZRVXrlNmSoCE\nCQEqrQ3DyZgZoe/B4XTqoNdXomlRr0dwCABYRZRZaNF1CkpALfQ9lQ1p9VrwQjqt2lZJCXv6voEg\noXY3qjVssU/SxuEJygVqX9eXiDnrkUYJPC5QDqSEzIteQ0+x+XaHMZJnYNfoMBFx0bA39BRbZm5x\nHpUFgjVFFCtLI0NGOGJvp8PtLTSqdMK7dv0cCmV6D7Hfx8Z90gSqFKu4Nkcns7SwDJ/JFFYQI+G2\nS8NCfYZOtWESoyLoedq1MtqcpbRdG/0OZS+73RaC3uSMRcswETL8hBDKqiISkXK81w0dgjOJOjKV\npZJSqDEYhTGKrBVVrtRUcXnoe/CVpZBAhRVaMwAthkEdW6LOlj/CsnDCOkbHA6k0aWzHRY1TVjMV\nE8mEGVQKCcn3H8eR0q4qFAsweXyYukCXn2HgDVFTUF1KGQwQmy8VnBHTDIBPw2EUIuW+N+47OvQ8\n9JhI4nme8hw0DENp3Dmuo+YYx7CV7tzKyhKyCTPhC7U6GuwtWqkWEUj6nedeuAx/SO9h77CEo2Mm\nffgRHIeyAF955RV88zXKjiedNiI+yU/NltELKTvzo48/xF5IWdMvf/MK9h9Rse/mdgttZhGvrM5h\neZWg0aOjGLMNgp/qs3VsfcJQv+dBOnRvj7Y2MTs7+bJjGCZkSs9YOmXMnKd0lhl10OKC+82HBzh7\nmfSPvv3tXwATYuH7kRIIFULANDj7ncYKzTCQQmdfPE1W4TAxpFxfIfIOgNXV67jwA8rs/NkP7yF3\nGLlwfg5Xr9Dv9vpDdJokGnlyeBctTiu/9NovPLWNslCCsLi4f/sQckDkGlMkELxGplmGPKHrmho2\nGGY/3tlGj39L9jpoMEEmjIbwPIIsu7ufos/zqB5HSixZCgNSp/cS6hp6LbqHVn8OFjOSg34Dt7ap\nXZkjYOfVEpZEkefjScL3IkQZ69dpEmfP0ty2vLqKw2Maf++8/bby3G012xjwvGiaJj75hHSpdAk0\nmSwVhzEcZs3GSazmpDRN1ec4DBWjt1wuKrjwyrXLuHaT1ua5mSk4eT9JE+QiaqlmQOTZrgni34EC\nOm+adF1RjzVdH/1dCMW6EUJA7Y7G55fPzDX5Zkdi9HUJqAeaSTligXyGzTcekuEK2kxl6n7EM5T0\nB8GIVj8YDOCxIu3N557HzMysalfuDXV4ePjEhjDfYNbrDTXBnlk/q75TKBZIxAxAsViEyWlLwzDU\nMxz39hqvBUuSRN0bQav8nciHhslqiqrzq8iZTTPFuqppq1XnkPH73D46wZA3hYVEg5kynFGZUm0y\nSiV0mKJrW2WYbJpZKlUUTV8KC50uDSih1xDzYjGITXT6NOhc24XFBsJalKHCbBxhmdjd3eNnPED6\nDD5Sb3z/Tayt0aJTLBWVerprW3C4DsQERsbCMVA3WYHZDrHTpDqKyr6Na9NXuF1F9Dv0b/cebGAh\np2PHEnWH35tmwM3yTaiNwz2aNAbeACtnWUYiC2Ez3JkEPu588D4AoL23h0WWzJgk/ChUfoWmrj9x\nwMhFajvttlp0TF1TG2Hbtp9gxuX1QUk6JjkQRhC8gMI00WcT3jARMHhjUkpSxS5LNFuZEmcQSqFa\nxgFChlsOIwPJM0xZUqaj+qY0xHBIGwDLdrC4TO/XcRzUmY32+PFDnPDGamZhiUoLAMRRiphZUkGU\noufT4jUcDpAwdCjGDoGdTgdbW7SB6fW6qLDTgGHqyi+yUqkoeRdNAyQzQD0vxObmo4nad+3KRfRY\nobnl99Fs05joDobotln8t+Giw4KEiYzh8qHl6OgQF8+SHMIHG3dwwqVoQ3+Au3zvH2/ew6vfpu9c\nXD+D2/ZPAQA3rq7hvbuP+ZoBfBb/NEvA0YAgJ9+J0Y3p73Ec4dNt+hxGMZYKcxO1DwCCYRMJ17od\n3nofIffNc9dvAo9pgT2v2fgbv/EbAIAXbl5WnoACGbJMFcuizcbqSeLB4Dndtixo7KAhAWTc73TD\nUEzpSrWGRfZnlQAy3kzfeO46blymzV1/0FT1gs3mISxjf+I2njt3Hn7Ia55TwGBA787rNBEH1L8i\nP1B+nmHoQbI0CTyJhA/Cza1b6B7QM0mHbWQ9gq+z2IfF4rs6OUcCAEwI1ZYMOg479FvH+4+xssyb\njhduoMwHfy/TILhWTli6qlGaJDKkXMMIIEmRcK1npxvhz7/3IwDAT977iTKLNnQDOouROm4Bc7NU\nx5TGGQ5b1M+TJAF4LpFZhigaCZ/mh8NSwcYyv7tLly/iwgXa/M7OTqNUZhFljdihFNpIFBTaCDqc\nIE5hvtM4jdM4jdM4jdM4jZ8jvtDMFDQNqmpNaEp/iE51eTbq8y1n6H9GGZzPyxWJsb2hwFimKRvt\nxqWUKjvzBJw3SohB00jXikI+kTl6WiRJojJBhmEo8c+pqWmY5uhxj/zA5F+CKgFKbY5nzsZZBXIs\nnTnKsgGaNsq4jf/b/Bmapjn2bzP1ECX0iZ3cb+20VJrYMUykEZ04q6UydM5Dp7AR8inh3oNNZc1S\nr1VQYk2wk14HPc4upamFq1coZVyrAc0mpactW8fDR5TlsW0HOqdih4Oh0voRmgaXMzWWJpFt0D0E\nSYZFZiuur1/GMWd5Jomj/SbOrFImqFwowWS7g36zhX6T2uK4FsoVumfT1EcwrB4iCOgk/ejhbUxP\nUbZofnYFTo1O5JF+iF0WOz0JIsyX6IQkwgxc345BMMBhm4suZ2eVlowcRihyanvz3j3c+QllpqxY\novIMTDcpScSVQiDNGZq6DodZLrphoNsZZRRyJl2cSSTMkqLuNDop5j1ZMwyEGbcrSGFzpykYGTIm\nLTT9FIJZipapweUMY5okMHK9LS9Ah0+rlm3DtCZnZdL9/eWxUi6XUatTdrdWrSGK6fPR8T6Ggzyr\nMZoPfK+nCs2HXhe7XMx7ctRSEF4QBIoU43k+7t4lqKbX68F1mZFsaCixuGShUIDkMRqEAQ5OqH/2\n+x62NimD8j/+03/6V7at0+4ABeqb2yeHONylDNTG5kPFFl5eWUalSp/jlouP7pCty6NHu7h05nkA\ngJEBIfusHZ0coRnS+PO1BI1puvfF+Wm4L1GRLhwNXS5ujhHjhDMgmmHh3n3q14vBEnZY2yiWAbY2\nKOOXQmJ9feQJ+rSQaYR7D25Re1uPEXEB+q2Pu5iu07199cvXcZ1tP4qWDcPISQQSUV4qkQ6hCfps\naIkaT8iANMwZ4BlygkwiI8XIi70MhZFeJnSei+fn5xTUL7MENRb8bFTqOLN8duI2tpoHGEZ0zXMX\nrqHITGJvahEmow2JHyjWcqYBGs+p3cNDtFg7UFomBBfWh+1DWFxYn7b3kA34+aeRmveFTJDlqI5h\nwbHpd2vT05hZZG0mYaGYzxNZHzrPhZZjQ6aTMxb7Aw9Zlme/hcoSnzT7sPh9XTi/jjaLK7daLdXe\nXhDC6zNCIQz1XmSWqUwZtY36pGGYqJapz9+8fh7PPUfZQ8d2YPFaYYhM+R5myWitTMeQHJkJVS4z\nSXyxm6nPbIGU+KSUVIcBSs3K8U3R5/j3PfPvCe1zNQ6e3MjIJzY4o1qt7AkfwKfF+EZG1zXobK75\nBMQ5BhtmWTr2W6N7TJJU3TKZXOZGxGKspmzEiJQyw+c9qnFF+c9u3GSODUNDlk5mrnrrg1vqfl3b\nUQtFo15XQmnlahkyZVp8L4Dk1LkXJKhVebJKBVyHBm+WSnicwi66RdW5B2GIHhtTGqaBOm9MK6Ui\nBAv5GYahNnF+FKLFKrgDz8eQF+E4kzCeIQk7U5/GPEOyjmPBY9FDRBI2190M/AFaRyyEZ5kKNth9\nvImQ6eHW6gpu/5gWL28twuw5mmCz4hQODyiV78cB6kVKo3fbJ+j26DnEEqgzu8YpWkhSWswtARyw\njMV7b72FlCeZotBReQZpBKQpAq45EVJCy6ULggz5ocW2beXZJ6UzJpqbQjBdOk5SZSacJLHa7Nim\npeD3RtFE2aZrtntDJbwZJxJxQBsxXzMA3kCtNlykrJh+3EvUZlZkCYxscuNRAGrDUq5UcenKJQBA\nfaqqYEQdGfw+bX51oaHMxr5JGsA0mVEYRsr7zfc87G4TfPzej99HnV0KgiBQDNpSuYhej+5z/+BI\nLehpFCE/T2lCU4tFkiQK8lZ1bBNEZ/8EgUNjrtnqwAH9foIUOi8adslWEOubb32EAffNVGT44x/8\nawDA1TNncXaNYOpzyzM441K/u3NnHy1mV+1WDmAzLDKIhuhyDaKuZ2iy7IHj1rG7y2zaxMCQFabj\nqI8Kw1iZpeN4c2/iNgoZw+P5oJk6kC71hbuf7uPaeYKivv36Aqos2xAND5HouaG8CcGbDtMswnG5\nBECmSLmvJVGgvgMh1DwYR0DKUBRkCpkv2pmAy0VZJSvEoEWHPS+KYebyPhBKJX2S8HotJILGkyEy\nODyf2ZqDNF/wBVBixqVuGmpOtw0DOs/BCQQE9+u4WIFg6DjpLSM+ok1uOjhBxqxixzRhMHM3NQx1\n//Nz05idoWc13ZhCyvVxVnuAXMFTJIDpTL59ePRwS61b01PTiJN8jZRYX6ND5sJ8TdUMn5w01VzY\n6Q3QZVHbXneoNmViTP7IdS2ssLDn+voSKmxMfXZ9TTmGJEmCKtezOq4NYExGaSyBo6l1MfuZjP/P\ni1OY7zRO4zRO4zRO4zRO4+eILzQzNZ4V+azm1CjbgpGNw2e+8zOu+jP+Lj4XShvfhY7fkxwT6Prs\nd54tOyZUtkgIqIxb/r8AkKZyVOT2GeHQ0Q55XG9LIH9VQjyZ0RNPMA3/Miw4fuvjvyWEGMsGpnDN\n1kStqxQKqujcdRw4fCpqj6VldU0oqOjcufNKByoMA8ScxYiiGDZnUirlEgKfTsyeZ6HIbuFxoqu0\nchT56LOgXrlcVuSF9kkPvQGdWoSuYW6O0tPrq8tK9HR/++HEFh0AcPXsORTZzuR4cIwCt9HVdIQB\n3edwMMCQ2SYagFqF/desIh7uUebIqg6RCX6ug48wxYKQplvGwKHTfK1Sh2QH+PZgiC5nixbml9Hj\nwluRSoQetXHQ6+In75K2TfvoGA3OFjWSGDP25JmpIPCQeSx6aFkocVrc0HWkMf19GA3gcwbCNE0E\nPt2bbVuwOP1tGAbyGt8oSgHOTupGqk78rU6AFn9nEAI5opxlqWLtGQgxY+WfTcRmbhEFRNz2kmtA\nl3mG9tliemoaKyzGF3gdtI4YPhl08XiLsgsnJ4coMjzWPt4DJwIgDAtxmrNBEwWnb21vYWPjMbUl\nTZUOkGlp6HQoo9NqtZDyM5FZqqAFYDT3aLqG8d456XxTTCX6PbqvsDeEW6Ubnp2fQhbRFXe3H6PJ\nQp3CkChxauzstRX0znMmcHYNr716FQDQjw/hJ9SvdasCm8fBh7duI1d21WwTn3AB+tqsg8IctePK\nzVnUGcquOlXMzxKzrN88xAWDMiCJYyMyJ2edAgKXOQM1t7SIT+9RcXy1aOOVlwmmfO2VF6HzvaWJ\nh4SLszXNQOBx1tHUYdklvqKm9NB03UaW5kXMETQWBTVtC0Lwd0xbkREACYf7frVcVYiBN+zC4mtm\naaTGzSRgX+x5SBg21dIELs+dcRIrfUTNMlXmn9pG76VWLim2diY0ZAy/BwMTMX/2RIaZAluNJXOI\nWNAy8H0Y3JZM01UbdaGrZ5JCwuA5xjJMVZQv4wRSn5zU0+8N1VokoKPCLNS5mQamWbPMD0ZMXdu+\njJwzNBiG6PBcuLtzgJMTmlNDL1QWOGvrS7h8hYRJZ2Zqao00dUvpOEJgTBxcQiIv8RmVE+m6Bsnf\n0VP5BJnrafGFbqbiOH5C9mB8g/Ok6fGokeP1TXmM/9u/Kj4fthttrMbNSbMsGfPWevJzLhw6SWia\neAKey6FG8l7M2zWSgsiyWH1H+wxzIE9nZtloc0ftkOqa42oRQuQbpfGrjERN2+22ordrQijpCE16\nuLLmYZIoFIsw+D4lhBI/tBxbUSmDKETM6eA4ihUNvVQsweIFVh9jjSVpiqVFYlxYlqXMnt2Ciwvn\nqU7DD3wlAllv1BXN3S24sJghlSGGZCXhKBqiUqUFWTf+X/beLNaWLM3v+q0V4x7PPN177pg3p6qs\nyswau5s2STclJgAAIABJREFUbaDldsuWG7Axo8SThYwFliwEBgkJyQLzBA9+MwgDEg8Iy20kmjZt\ng1ztbrndVV2VWZVz3nk68zl73jEvHtYXsfe5dYd9+1r5FP98yH33iR0RK2IN3/r+3/f/Xi7uLfR8\neqLCPmBSZV2d9gdEYkwpQ2VkFVleqew6YZvOum1LLzF44qoejE5prdg4mnh9BSUFfn0v4O6XNkbm\npD+sig9HUcJQMhmLxCVJZDK5d4tEss+W2z4dkSJY0QXrncWHcxA2KhkDx3GreMP5OELf9cosYfI8\nr2LW8qJgMLD3U+RZlSlbTlRg35fU1OWsn1RUoOM5lXCe77usC21zYcknLez5e1GG79g+4GYRTREQ\nDF2Ik8Xd7mquvt7B/kN+6zf/PgBHj95lRTKU0iSppC9W11fZ2JCMJpMzEXmDQmlOJJbj+LhHrycx\nKnnBo0eWPpnPmoWUvCgpImbRBszthGZf23FebiDzHKMX66uXN5YJjDXQBydD9h9LbTh/ghHW/uL2\nKq9dt/THbkcx6tk+9cbXLlWFbX21i+7adxIfTSshxEY3ZGvF9scv//E9ymBJf6lBLFlmd26N2b5o\nx8f42lkllHthfZm2CEue4DKObX9prm8QdtcWah+A9ppcumAzL/+j/+Df4/f/4T8B4NHpkH/zL/4F\nAFaXmiSpfVee75KJsVBkGXlZhDlcxS1lAKaDqri4dnwKmavybIyrxbggr4oJ503v3J49khirYerj\nt2xbwjS3mehAkhiMWixsAsAxWfXbIo7Iy9ioIsFxy0Xex3OlCoiZFe0OXZdAJG4mSUomNB9BUEkp\nmNDHc0SSA00iGxIXxfLqTPG/pJh3lkI2VizdPU0zUlk7tza3ceSZTKM+Ri8+FldWlqsO73keI8lC\nzQvNxYvWAL+wsw1zBk6pNF8YRSa04NfeeqMyrLIkpdu2c3C32yKQ7OG8SM5JLc2jlHpBzWKsrYNi\ntqaWsdaFMbD4Hrym+WrUqFGjRo0aNV4F6mV27DVq1KhRo0aNGjXOo/ZM1ahRo0aNGjVqvAJqY6pG\njRo1atSoUeMVUBtTNWrUqFGjRo0ar4DamKpRo0aNGjVq1HgF1MZUjRo1atSoUaPGK6A2pmrUqFGj\nRo0aNV4BtTFVo0aNGjVq1KjxCqiNqRo1atSoUaNGjVdAbUzVqFGjRo0aNWq8AmpjqkaNGjVq1KhR\n4xVQG1M1atSoUaNGjRqvgNqYqlGjRo0aNWrUeAXUxlSNGjVq1KhRo8YroDamatSoUaNGjRo1XgG1\nMVWjRo0aNWrUqPEKcL/Ki/3Xf/9nxhjzz//Ecs5Fz1zdw7l7ccConztm/oj/6i9+U/ECrF34H0yR\n5ACoHByxV02egorsZxVjHHtMu+Pzztu7AOxuN8mSHgBpMaHTaAGgjUMyjQHw3IJGIwBgMo0Yjkby\nvUORpfa6RU6RJAD4fhPfbwDgMuH47BCARncZz7XnT+KELLf387/81n/+3Db+d3/zvzCZcwpAwCnu\ndA+Afn+P3Dj23I1ljo/tMZ31ywyHXQAe3uuR2EeAj4Ny7TULL+Fr738fgAsXr/JHn/1dAL71+iX+\n9J/4SwBEps3RyYcAHB58xt7gpj3n4aeMRxN73Slk8RIAY7NOP7NN6Q1SnKANwG/+r7/9wnf4V//q\nXzVaP32fUfULYyiKAoA8z5nv14v0caV+/jae/K78t1Lqqcc/+Zvyun/rb/2tF7bxf/sbf9n0R1MA\n0sKQ57bvaK1oBLZ/uUqTSRsLNK5jT+soQ5LJ9fMCR56VdhyMscdnBRTF7DmUz8rzHLS25xmMp2Ry\nTJKmIG0xCk4HAwBGo4g4tZ1mOk0wcg9/9//54QvbuPXakgnDEIAgCPB9396/4+AH9rPrujiOI23X\neK6dEgPPq9rVbHa4eOESAG+++Rbtdse2McuIYzvOHO2htStttee13yu03HNepIxGtl1JEpHn9iEW\n8swAjCmqd/qf/JX/8rlt/Gt//T8043Ek92JYXrN9fzgdVn0hihKuXb8GQMN3SUcyBxmHh0d2LoiL\nnG7HtunKxV0u7uzYe5wM+cmPf2zPOYlY29wC4O2vvU+zbdvXHz6mGWzbz4M+61sbAHz5xcf8we//\nEwDu3dqjsbYCwDfff4etZXuf/81f/5svfIefZBh5TKAAZdvlFoaJzH294wFOYd9hkU0pZJIJwy7R\nxPbxxsoy7a01OY3CcaWvFVTvMElSsly+1w7F1M4ro5Meqmnnj5YqOL3/OQD50gV0aMeKMgGhtvd2\nPXzE5sYyAKvr11/Yxt/64tCYcqzMHa3NuX+ilf65Ywr17HVvfv54xhFzJ3vhbT4Tf/q15Rf++P/4\nb/9j0/DsO3r0uE/YseNyY2uZo0PbD2+8/jqPHxwAEI8T1lbtuuGqHLDzUwF4xpU71kxlInK0Zpra\nJzGOErpNe/7X3t5h960rAAzGMZOzMQCj8YSga/v8uNdncmz70uB4ynBo3/vmeoONTXsP7/07/9kL\n2/iVGlOO0hh59X/8V/fzMKpc4Bb+xbnfyT+qyfzcucw5G2sBaJScV6nZOYtCURQeAI7jorAdazSC\nn/70CICj/TbKnNizZJ/T8eyE7xc+cbnwqSlBaF+bKQomE/vitXIwsmCZPKUwtpN1gjYt155HFRMG\no749Z6uLDpoAZFlOHEULtS7wl/Bk0YjjCWKD4Xs+cWYHuzIuprDtnozO2Fq113FSl88+tfebuQ28\noDxng3hYvkMXB3v8RmuFzz/7RwB8eOtTlGcHnYkLxrltaxS5jE6tsejpZVZWfxGAhn+dK8ubAKys\n7LC1vbtQ+wCSJKE0ppRS5wyoeUNp3pgqPxdFUX2eP3Z+QiuK2YKptX7mpDd/Dy+eGBcz4kosNxp4\nzswo9wO7wDmOpuXZftp0vdl41QqxgUiLgnFkF6AsSiojRWtdLUwZUFT3o9HaPpOw6RNJX1tuNTHG\ntjEvcqLEbhiSJOXy6qptEwWT2Pb9OMloNbyF21i+h/LeymfnOjMDyvM8XPn85G/L79M05eHDB/Ye\n4oQ333zL3v/y8uy9zL9HDI4uz2kqo1IphyCQjY3rkKZ2gciyFE+euVLqnHH1PKRZjCOGmut65/pp\naRSmOiaJxnJfHtHUPsvxKCJO7fMuKJiMrZG3vraC59h3MokmrLbFGHUdblyxY2i51WA4FWN3MGbl\ngj0mSw5IYju+e6enOMo+g7W1JVbEyOo0G0zHo4XaZ58HaJ2X/7IWBlDkGZDLvSlGx3YT2mh6ZJnt\nX3Ekv8FuEsoNZpamNJoy+fguStu5MotHxBN7jPablD3NcUAhhm8S4YshNkomhC3b9z1HkY+H9jxu\nVhnKi8B1HIwqZg0uW2uq5tp/67J/zc0l+lWMKcC8Ajn1EutiGhfozLZRmxklFo0n5GIQHTzeI5G5\nwXd9Eumrylf4Yqlok+OU40m7eI6c0wFfxuu4cJnIWLh/cMyDge0bSeZz5wtrrO0fn5J69l2TRGx2\nrKG91FilJQ/ddxTuSzyemuarUaNGjRo1atR4BXylnik9v7NXisWJueejdDAtujMvj1LmyW9n1J46\n9/llYKrNhVJgTC7fGpCdWp6r2Y7AVcgmnwePh6jCWuNultDUdpfXcgpI7feFB24kry3PyDOh89wG\njiO7W63xXPvZDx0C2b36ToAXWPdz4fgEjXZ119NpsFDr4ijFsZsxWmEHJ7Cu//7hGZNIdmZJQSS7\nkKQ/ZHtT2uSm5JF9rkvLQeUdyFRCZ9Ve/8Kl69w8tO7XO6OfMNq3x0+HXQLxRjV0jHHtZ+V2WN34\nBgDt8BtMC7vzL7QG2Vs6niJoLN7X0jR9Kc/UvDdq/vM8jDE0m9bjFgQB/b71EGZZVl1r3ntijHkq\nzfesXeaT9/Yi9KZTctnhFSYmjsWNXuRMxWvaDFoEgb23LIlwHeuBMEoTCaVslCJJ7GfH9RiLZ8qQ\nQSa7+dzQ8O27WOoGTGL7vclTEA+K9nw8aVucZRSyC28FIa1l62o/PT2jG8767IvgOM45D2Dl/XFm\nz9OZe+b63Gd1jv5zHHufvV6PTz75BIDLly+zs3MBgCAILQcB6MBFCSVju0LZNzJ8P5TPLq5rn0Oe\n57hueS2Hoig9Mc/HZDIkmtpzbG9f5O79ewBs7myxI56g6WjA1oal2E56Z1DY40+OD9AN2x8n0YSN\nK5YKWV7qcHp0DEC32WBPPCz7D++z1JH3cNzHadpJYG//Ma9f+bY9vt2Ewr7/NElwxTv37jtfpys0\n38r6Gl98+tFC7QPwNeSm9MiU4xpwXQrxaKgsJ8/EezlNMHJ8kSW4Mg+GDZdiar0e+eSU2z/5AICN\nr7/P+kXbdhfD6cS2nXhUURLN0KGxYp9V2osZypzb8gtCeVdRNKTRtNfyQk2WxQu3kTyzfGPVytmn\n+dGuiqdQcs8b8vML0TPxfH+Kes7q91KMTaGqfu37Ll7pRRpN8IWiSOOsWrcCx0UJu0Lh4OhyzcvR\n1XjKccRllWmXYWwfxqPBhEjms+agTelSH8cRd+9Yz9TDx3tgrId0e8njO7/6ttyDxknsuut5miJP\nFm7iV2pMWfqrNKb+OcZOqXP/A0qa7unXqI6bZ/mMqai9c33kj3Gf5yhCGSQGoOS80RjpEKZIK7vK\naAel7YSVmzcxvh38q9su5GcAuGGTTscuKCaNGfVtbFKjvUrYsjFQjkoxhR3MGysd1rt2IvB1xmnP\nujydsIPvWWonTVJ68v2LcHD/Ac0ta7DsbChashjGYYPizN5LyoSO8NH90RgyO4g83ajcpkUESWaN\nL6er8CR+qhO2aPrrAAyjA3qRndziYsyGb12xk8EIOjZOY737K0RTS+cNJhPyzNIPvtdA2EJWOj7x\naE9acOOFbZw3poBnGlPzf39W/FS5ILdaLTY27AK3urrKwYEd1Ht7exXdUxRFdfy80aSUOmfcPQ0v\na0zl2mWS2smkSBMCmcTSNGUoMUr9JCWMxbhL84puSfOUJJbFwlEoubc8hyQtY4hylCw68WTKckti\nThqw9/ARYA1Jyva6fhXHEqUZmQyKhutXNEwcxxyfDRduo6N1NRi11nhi0GmtZzFNcwaX/VwatvMG\nrKUh7TFuRa3fvn2bKLLP4cZrbxCGtsMpdLWgW0N4ZiyX9LspDLMupqpFX2uNKRabltudFu22fX69\n3gn37t8H4L1vv8/Wqh3bLLXY2BDKNMtIcnv80dwz0M2QjTV7zN3bt/DkfnevXKbZsvNRHGfcu/cQ\nAL/RJsqt8XJ21oNfspdqhB7T1FKKaZwQiOHY7TT4xttv2mu5Lsd7DxZqH0CgINclTQqZzKeOBndZ\n5pgsIyqN/nhaGQ+NVgvtSRvTmKnEneZHd7n7D/8eAA/vPeTX/tJfkXM6hBIveHZ8hJJ5q8gMWt5P\nq90maFhDMggA2YMub6zQlLUi7d9nPE4XbqNWRTV2lTLVsqRROOdXtSf+z3N3+ovETFXXfe6Jnv7V\nyxhTjlIUqe37nptXRkoyTWg07HrSCJvV+qCKHCQOznOc2UYFXcUy5kYxkvH38OyYOwd2g3rz/n41\nH68tX6yo7dQMQfrkm19/netrdk5adke8+/pFAH7y4U0Cz54/DBzybLHwF3tvNWrUqFGjRo0aNf7Y\n+GppPkzlkfnnG4L+8zCLUIjz3tK5AHQj/4F1TL2Mb0opNds/GFMF4RbM7z7yikbUJiNNyt2qxhUO\nzZg1hrLLOxznNAJ7bzsr63SW7G6xiMcMh0LzLW/QWrGudJ+EqG89Oqsrq1zbtR4d12SVR6G1vIYO\n7G50GkUMpou5pU/2bzHObCDq6vJFVjv23peXOhwe2J1Ekme8uWV3xt/69jusimfs3mHO7rJQP1lK\nQ3Z721fXuPyaPSZsjXl913qdvjy7S5rZdqRjQ7ZsPTte62tEqb33yaFPjt2RBIHPVHaTSTLG921f\nc90TPH+6UPvg5z1TJYqieKZnqvx+/hhjTEUtLS0tsbxsKdZWq8Xbb1u38pUrVzg6sgkIBwcH1W9L\n7wdAo9Egz0s64ek7pZf1TE3TCY9P7XWTfszrly8D4DiGhlBaSZoQz22wk6QM5Ewx4k1ruz6ZZK/G\nWTpzvjouE+Gvw0aILwG/w2RCJBStF4Ro2UFmWUzg2l1jiOZ0bNsfKoMWOtJxNHG2+Hv0/HBG7Wmn\nej426LwM+J7tdB3Hreg2Rzu48hxcx6toBvudPT6JE44Pbf/c2bpYeWIKU+C5QXXPJZQyFWXluLPM\nxzzLqwxHpRTFgjPO2toq7badC7747BbLK7Z/pWlGEot38fAxKpfsNqO4fuUqAGaS8sHnNitt5/Wr\ntBr23o/2DliX4H+UQ3vJeomVG3L3ofXu+n5If2j7jsKldyLB313F40fWO3Z2ckIe236hMazKnHXW\n63P18uLJIJJqI9dSGPFuZElKmamZNnwm8t7cVFf0tUoztIRWxIMRRjyrG1tLbMmcdPPeQyYSEO8o\njzJv4NM/+hG9wwN5nvC9f+lfsW2/dglXstIK7RO27DNvNEMiGU++Ad95iaU1z56akW5QFM+l6OxT\nedb3TwtYBzX7iTFzf3sGi/Os6xteJuML11FoCR/orLQ4PLEMQitsVXNaLz5jZcV6GxuBxkhmJcaG\nCgAY5WBkkjGuVyW8UBRckmzNdhjiiJ3RbTXY2bI07ubmGn/4s1sAHPULAqEXv/XOVaKxXUPSZEKn\nLck4CrJ8cQ/jV2tMaaosL7VwzNTLGl2zTvkyKgxGnf+Bmf/+JaCURpUpGNpUrkobM1VmbBhUST8Y\nVR2TJ4ZCKA3fm8X8HJxkuDIph82ClU6ZzafIJEPFaIWWrKoAUw3C9TDg6pKdOFyT0xM/qu9qUr9c\nOEL8BdMW4rhHMLWp09Ohz5EshuudZVY71pjLo5g31+zkeU1PKcZ2sn2z0+Kt79qO2vACkhNL2fid\nM5ITSxHmoyHfvWQX9tC8yYlv07rv4pGk9pyTzCcRCilLHhLFkndjfILQtml5aYU0tQMkyU9YXV4s\nJgyebUzN03lPfj//+WnyCWmaVnFSQJUBt7S0xKosXm+99RaJvM+zszNiMXzzPGd/fx+A8Xi8WJbO\nCzAc9jk9tdRxHmsSmQqG0ymthqT4uwWZ0FumKKrYA1PkFJKdl3tZRaU0jcMsUxbyQmIhjOE4thuD\nIoZIDJMsSViRbKju6hqra5auDV2f/NYdwBovSyIFMkimtF9iPnD9Bq70a+W4UC5w2qmMKcdxcGQh\n9lynWihdN6hixDRUNIOrXdpCWW5ubrO9ZQ3/drs9R5kAhZ2EXc9FyQpdGDOj+rVb0QLKzN5lURSW\n/lwACsWJpJUr19Bdsvd16/ZN0h3JZG00KENPdtbXubhpY7we3H2MK5Pb6OSMh7JYXbywy862Pebo\nuMfd+48BeLR3zKn03253mYZv55TRaMyHH/wIgPXtgAeP7fGHh8e42j7j0TTmi5tfAtBoNjAvQYi4\nQC7xl+PxhIZv+8LobEDsW4N7qdUma9u295OoomRzRTVvKlOwtmrnp88+OeYLa/fQ2l2iI9nOaWFw\nZe5u+Tk//vD3AQg7G/itXwMgmowYnlkDeu3KJp6856SXUuVv5jZ0YlFo5lbCeWkEFPppY9yYauOv\n9BNZ6HPHmHNxWHNGUyXDoOYCiJ8Rh6We+Nu5r19iLHou8phZWesSZ2XGc0AmcXmTKCaX+dJ1XDLZ\nGGNy1FxmbWWoasX6mhhQjbCKGebCBlpoxJ2dFleu2DG6fzRku2tvor9/RHxmz99tv8HNW1ZqJzea\nILTnKUxRZcgvgprmq1GjRo0aNWrUeAV8tQHomFlA98KB3Qsc99RDzNMM6hdg3uX5xwuQLxRUkaXO\nLINPFQ6OaJXooiAXjZRcF2i5bk5BJp6pIjW0JRhSuy6T3Hopbt+NiKfWi7O77VIooeeyqMocxFN4\n4kVY9VwuN+z9uOTcb4g3yjdMRDhUoXAXfFadlXU2RTeqYXKOD+w5Gk7AxVW7o32722FbdiHDvfsY\noRm07+L27L2cTQ3Hffvbk8jhgcQV9/SUuGupnO7KBvvHtn1Hw5TM2INMnoGxO780VSTybJTSoGwQ\nfmEy4ti6krMiYjxefN+QZdlTM+kWodKe1JYqPVytVotHj2zg9Q9+8APee+89AK5du1Z5phqNRkVL\n7e7uMhJRwuFwyMnJyc/dw6t4pnwvYGvN7ti0qxmn9llpHwrHnj+OUySBkpbfJBEdKMdx0LIP026T\nRsO65qPptNKiiqZjVKkBo8ExtkOcHfcpt/DtZgNXxDMnacqqiMsOspTOkvVgJnnKWMaH4zfRavGd\nYuA7hIH1LjmeV2WXYXQVNO/7/rlg9PL5a+1RiOcmDEKWxPNx8cJFdrZsBmuj0ayCy7MsO++ZUrPP\npXekMIpcvs9MQSYP16s0qV6Orj04OOFMPFOpB6lQwekgYyoB5b/4/nfxs5Iam/C5eIjGUcT2hm1H\nWmTs3bV9czqMiab2vg4PDuj1rDeq3W5TiKcpnqbEo1iek8PNm58B8NEnI/qRHbvD4ZRVuYfHh33w\nbdD5d773Pr1Hhwu1DyCPMnoHosN3sM/rb74BQCcIOJSsQy8ztMR7OXIMrjxXtzBkkfVebWxtcXhk\nx9P/9D/+X+zfs/PH11D8WRFp7K50GIunqX90QCbejdPBKQ/vWM/F199+m2g0lLanKC20e+ZWq0de\n5DOvygJ4cOuzyoOtlKLRtONAO35FdYWBT17qgiUp7Y6d50zDrQJnPNevEh8cx8GXTDelNEqELjEa\nXXqPTTELhzEKLf1Q6VniFKbAUbO5s/LMG87rNL4AwyjBdeyzXc0N25Jtev/+fsUyGK0xpRac0uSV\nBlaB0aXH25+Nj1yhchm7RuHI89FKo+WYpvaIT2yfPNjr0xJq+IKf4yf2PY56Pc761nPuahftluO1\nqGjiRfAVZ/MVzLL5Fv4V8HzTZt61WX2cO7/6uROYJw8vb/DJM758ZJfS5OJXV+gq/sHGipUcsMbI\nSyoUKDGsjMoopP9kGUwjyYJreJXA5iRJufXIdr7jXkpXWwNms1iq7rUwBVoMqwBDR2IFHDLaMul4\n7ZBEBrw27nl1uOdgbWkLR9yyN6512evbCWo8yPi20HNr0T7TU7s4TweTShB0OO7jiJJwP3K5eWgH\n5g8fpuzldkF2lqDRtZ283crIU0mnDVwiEW/MsgxH23Y0WqtMR9a4TKKM9iVLBWZJisKex3WmjIcv\nJ/b4ZDYdPHuhm0+pn1+Qy78BhGHIG2/YhaDRaFSTktaa42O7KHz88cdcu2Zpzffee48ViYGL47iK\nmdJaV5+fRjkuCkd5bKzad5GYDCMT2lI75PjYGm7TSUSz2ZWH4qNM6RZvV1RU4DQJHNs3E7dgImKO\nhclJZHJTuJz1xfiNwEjmptvSiGoHrhty8MDG25xOBjiOXVBMYfDk/FrlGBZfpDzPxoDZzwrPmcvg\nK+NwlMbzStFRB1eETJutNiurlkK4euky6yv2c+gH1W8tDWuqc5ZZmShViXYaY6pnpV1ntmDlcxRw\nPnuPWZZVVO+LcHR8xsmR7fvX336TFYm33Nvb4+olq9h+bWeblvTNf/bjH/GDH/ye3KJLt2PjfTrN\nDuVScHzc5/DgJwCMR31abfvs280GvgiOnhQ9Hh9aAydLs7msfsWxZBdHSYSS8IWl9iqZ0Ij94ZAD\n2RgsgsNH++zfs5Tv4GgPYZRZ7izRkHadHO5XFJ6rmIVTkKJK8qVIuW+Zcob6KkNlDagPvjzlo49s\n7Nif+dVf4kvJSP74Jz8lLysoTIdokXzQeUSjbQ2ZPMloilRHPE1Jhna+iZPJwvIWAH/n7/z31dzt\nOg6BqKrnuSaXZ9huhOSi7O5rRbdrr5s6LiL8Teg3UbKurK9v8sbbNnPZ8zzaDWvYdlrLGFmfiiKt\nGL+z0z6JxKOtra1W/oA0jsikX3uuSyShB6PRiPHEGiC/dOPffmEbp9MMR9vzTCcZTaGkPa1Zkczv\nwTjCE9PQVQWpvN9cORTleuk7JOX9o0Ce8zxVnmMohBZsdlZAhtN4kBM69lobW5eJ5VpH45w0ERkM\nx6+yWR0Fjru4iVTTfDVq1KhRo0aNGq+Ar9QzZV3f4s5c2OdTerJebPc9GTfHs/5dBd096WV4infG\nmJcKQtfKr1yVtpXWkjcqp6DMApm5J4PEwRHr2iOvXKG5O6UoSn2dcSUaqPxKtonTScFIMqnax1Na\na61ZO/JSEDAjlmBIl4yirD2V64q2SYtsRhG+ALuv7XL6UIK/84yLly0dM32g2Antbm98csqje3Yb\nmGcpjmff+cPTnI9v22s+iA37UlXidg8y8Z6t6THL4nVK4gmh0EAGf67Wm6o0g8aTAZl4r7rdNr4v\nWkVRn60L9pn5QUQ6XdyL87w6e/NZe/PeK11pLeXV52azWVFIcRyzJsGSOzs7PJZA3Xa7XYl5jsdj\ntrct9RYEQaW/cnp6WlF+88HJz8ouXARp4pKJJpTxchxpS5JMK5etKhTJVMQ587gqwaFwCcVLkRVT\nxpJ5Z0yGKuzu2XUzPK/UimryxU3b3gcHfd67br0mo9Eso+aTLx4zlfvptBXajOU5LLPUsfcTxTHS\nHRaCp72qXbrIcP2yhIxGSRC81lSZemtrW1y+bD2DW1tbVXac77roMncEKEqPrs4qOkRrTSC0/JNU\n7CwhYUafaEdjyuSUbNZnMCwcgB6EAVoyCF0n5JJ4hk+PjtmVfpRNx0zkfrPMVJTyrVu3q5Izo8EQ\nP7Bzx1p3uQrUj9qN2bzgeowj8S62Q9JN6wm6f2+PwwPrjex2Vgk9e54syfiF71oBqkajQVcSDW7d\nvMOHP1tctHPSO+HgwV37j2hMPLTt+uTOLbY3bZD90soKvWPrKXMLGIuHyG3lrEh7uy2P9VXbF1qr\n12gP7DGD03v8wT/9GIBf+N43+cHv/AN73X6PZREa7U33K2/R6uYmd29b0dY1ckqSLc6mFIlo3KFY\nEpr3HrAzAAAgAElEQVR6EfR69wgksL7RaJCOxIvXH1M6n/uBj1fVxoTR1I6/JHOJU+lTyiEuBXEL\nxe//nn2PXhiw1La02sryBqloJ3meqoK/B4NBlbnWarar/lhkSZXkhJr1Tdd1aQv1zb//Ys8UOJWn\nbzzO8JBsXT9ko2u938n9+7RFL8zThqkMidxoAvH7eMXIalABhXJwZM3OdGHrewI4WsoNwXGeILHu\nHDkKr2XfS3v9OpvLkv1uprh7NklqJQxolmK9eUrYXHzC+YqlEWy6Jzw1QeC5eF4UU1kL73nLinrK\nP8wzraSZNAK8XEafrTVW8tOglXxWTpW1V5CjXTGanEl1LWOyis+2hTtLFeUCEUbH8TyCwJ4zL/oU\n2g7gL28fMkmti/rGhQ5NESq7v3fEp57tuIHOORlYY8bNB5yMRcxMh+TRYhO4bhQ0JB348PABl1dt\nx95tNon37wFwtL/Ho0Pryj+NPVLHTrAP+w3+75v2Oj2Tkwm1lBaqykRK04zJxMZpeJ0uRrj+KJpW\nbmjf90hlUCdJPotvcgJ8z7pxr171Wd2wcRp5OsZ1Fjc6noyTeupzeELUszze87zqc5IkFWVzdHRU\nfd9qtSoqMEkSLlywVO17771XGV/z5wnDsMr+e17m4MtgNB7QFOmIZtNlKuJ3UZRUMT4rSx6jif1+\nmo4wU7twx1OHwLcTYKvtgRKjLJmwIirQmXGqeAPHC9m9KAvTKOWzhzblPIniqv7dOIItUZneXVvD\nSLzV2mqLQhb08XRaGZiLwDVBtQDt7KyysWEn0sJAktn7XFneZGfbGnc725foSEaq4zqzxDtmxYpN\nnlcUjqN1RZMYY6o+4ThORcUqNRM1NYo5gdN8Rv+ZOcpWzYReX4Sl1TY9KQh96+Yt1mQB/9Z7X2dz\n00oaXNrd5ad/YLPtTk56XL5s08SPjo7YuWCNERPnHByIOG5maHdFwsP3KiPLb7QYyHzROz0Bif/s\ntNsM+/bzeDxl84LtF91ukwti0N28eZOLu5binpz2cJ9RRPxp2Lt3m5HMB1cuXaEvNNzpwSMubUvs\nmufjyTn3Ht5j0rNZqi2TEmzae2i6PistkZFxFI22/X54us/Nm7btP/qDf8ZHf/gHAKRxSm9gr6VR\nKNmwLbfbbKxbw6TVaIDEZMW9A4zQ2jlFFb+2CFRhSGWe8By32uQXWQq5xOQR44lYaBRPJWQGAq+B\n65Vzj8tAKhOMpmNmFTc8xn3bTx48ukMo5/F8XcXK5kWC1iV9fUQu1/UdjSPfT6bTaj5bXlrC819C\n5d3Y+rQAk1FMHpWF1Q1hQ9ruGhpBKYZhyGUtzPOikhjynQZKNtJe0CSSGL0WhrC8Vl7Ql3Hx+Mvb\nbF65bq87HvP+963ExdXX3mU4kRqOR484+uxTADa6IdqT8e0ZltaWF25iTfPVqFGjRo0aNWq8Ar5a\nz9Qczfeyod2Fmgvg/jk8f1c+r7Jh5aRKT9azf1f9Tb3o7D9/rVKAD0eR5+ImLFSlLeWqmFxJMLVb\nVBlQ2uQEstUNk5RMdlupdittlmKaU0jEoe82cJW1nDPT4/5dK6o32HvIlVW7g295Plqol6abMfXt\nzjvrT+kNS8+UIc0W6wqulyLxghTpAW5h3eXRmcv+sS03cXQ64Sy1u4cfH7vc6tmda4TLkTwPrTLK\nIn/NQFVUp0vCmtRiM6Ygk52W67qznbxWIPTpZJKQZvZ5BK0m06mlw9Z2DM22bXcy9kmTxcuQPM/L\n87Taea7rVlTd8vJy5f52HKfSihoMBpUQZ6PROHfMUGiJRqNR7fw8z6u8VM8LNJ/POnwZ75RWYzod\nSy1M4yG9fpmh5FVif5526JfeSzSR1FU8PUvxA/teuuMmzZa9z+k4oxOVgfiaZanl1nADLqzZ53Dx\nl64xlD5w98sDfvQzm13W6TZ457rty6srDfJKxHJEZsqs05jB6eL6Pa/fuMFoYDPHvvPOW+xs2Y5b\nFIZCiWets4Yf2s/abVReAYOqgnm11pRcgSkKHPE2e75DVpQ0T1plNxmVV1XunTzFiPiuIqvKWShC\npmVJHhxciaw2WX4uu+95CFuKrV3rgXp0ew9XPIS7uztM5JrB2hpO11JdDx/ssbZux//Va1d4+23r\nLcrHYwLX3vvRWR8vKKlsTS7jr0gTCumbWZxU8+PySpc4kgSQdMC1q7ZsjOtqfvrTHwNw7949Qglf\n6A+P2b24tVD7AHqnRxihf08Oj2lK8Pf2+hrxRDxlJ0dckcSNaDLkTDTZlB5WFEg0zTgbS9jE8AGm\nrF261OHgsQ1w/8HvnDKS7MXBaMJq+a7MLHlhcnZYlScZ9o4YHtl72394wI54/TqdNmHzJXTt4pkX\nepKZyhObTt2qnEw0zQkkmzJLMtJSpFTFGAkHcTUVneqqAl/04tI8Z1hmumm3YlpyoyjSMoswIZX6\nr6ZQGNGIc8IAxEvse6bSXZpOzsjzmbDwi2DMLNs1SVJKRs71FN7Ezj0XdzdZ6dh59PSkT0pZmy8H\nedcNr8AJ7TjO4ynZiaV3G66LFvHrIkkJh3YdUIfHhAN73ZXTEdm+ZUyKi1nFGil0FU4Shg5uIBm9\nvkN7bXG69iuWRpilYqqXMlFshz5nTD3FrjpHHZqZQaTM05PVnncPlQrxS9InShdldVNLTapZTTXX\nCE8c9Lh20Ro7uxtrhJJh5+bgS0097fWIZIIdZD6TqW1cmmVMhcIe9FNGh0IbTB0cKRQ1moy5l9lr\nOWFGo2sn0LUQpq69ruN7eA0bw5MbDzNZzGW7tr7G8ZmkkTbGuGVM2HjMnUeWvhmMU35g7Sp+eKzo\ni7q65zXwQ4mpiONqAcE4pMKntxs5Fy/ZyWR/3yGNyok9rmJ8gqAJMhCyfEoY2oGQTCJMx96DH/TJ\n09LN7TOeLlZ7sMSL6LN5Wsf3/erzeDyuKLmVlRW2JI2+1WpVhtX8OV3XrWJtWq1WZUAZY85TRU8R\n6tRa/7FpvpUll1QyrCZRQSkQm8Q5WihI49isP4BomNOT+3fcsJoM9096tGLb3niacO+xfc6dpuLS\nlmQWmYJkKv1RGf78n/lVAI6/NuQ3fv1PAPDp/ftMDqzhowuPoqrBptHYi0XTqDJkFsE7X3sbUltz\n6/XL23SCMl7TYByJ93B0JZRbqARdUmxaUYqXK1PM3Y9Cy6JGUVR1NZXrVDUEXQ2eyIGYwSGBSHq4\nOkVC33AaOzSF/s6KWd0yO08tttH0fNjYtmNbJwXLHXtfeTJk/9Ceox8lXHrdGjjdpWV6QoF973vv\n8c133gLg8d1bREKlra4t0ZN4oiQuWF21VOAkSqsUeWXyufpoCWsb9lnu7x1W9Rt/4fvf5Xd+53cA\nODna40f/1J6/1Qz55nvfWKh9YOPbjBgOnYbHdGzvrRlo+se2v4TeZjXn7l68yqNbdwHo9c8qWnU0\nHHL3U/u9Hn9GvG/76ZVWTsuxm9CbH92u4l2HyZQ1IY5clbEkCu4H9z7m7gdWzBPtVrGpD+/e5o13\nvwvAv/hrv4rnL25MaeNXUiNZlNvzAk6hqmLhWV6Ql2l7yqtiXwsKUjGmVB4TiLyIF3pVQeDQcZgq\niZuDiqbOk4JiKtI2DXs2EEF2sWNik+KKhI4xRUVHFgaKfPE4VFSOJzGLKENWifs6DGQDfP3GdiVB\ncng8mK3nWYIvxYfPvrzJyaiM9dU4IotzphSFUId+ZmiWGyEFdz63quejtS0+/vhDAMbBEleuvgZA\n7/gYR2jTJJ2Qy/PvLjdxX8Iormm+GjVq1KhRo0aNV8BX65my6Sz284Is3yx/az7/z7yQezPm6Z6n\n85d9hteBl/eclXA9hWz4hZ4p3agZrdDuqn7huxt85127Y+60Q1rium45AdMDu0v6+MefMRxKqQK1\nghdYd35rtc2OZCGEjRYmsTu+H//+T3nwpej6uE364sX52cM+I7mhd9/cZuuCvW7YbYAnGkK5i1mw\n/EGmBqRadoediBS7E0rHY45FW+pBL+CP7trdzKM4oxVKOZugUT3VIOzQatnv+2d9PAkO/dq7K2xu\n2Xs5OtZMC5H2TzOC0F4rLwwjceNO4wgqD2TI0prdebc7BYXQf4PRIdPx4rTy+QysZwegl16i+Xp5\ny8vLladp/hilVEXtaa2rIOPpdFrRfGWtMbD037yQX3nOJ+m8Py7N108mTIaSRRqGeEFJP+UsNW1/\n1LkhdsRj6cbVMw+0Qknmj4ljMtnJBY5ChZLB1ww5lBJBcToBY9/vWrdNS9zxu9+4zkR0x/7Z377F\n/X0bCHxpvUUk732p20SL9tPG5mqVeLAIWu023aZ104dhgONK1Xo1o2iNysnFu5qmOcrMkhxc8YIV\nRiFsCIVyULqs9+faclCAm6sqqcBTkIwt/RDkfZYD+5x7Z8ccHViPiLscs7z7dQAyp3lOR2xR/TDX\nCTmREi+ub2uPAbTbDbzQUqYf/OEPeect6wn6s//qn+HBbaupdOXCKiay99LqNtjcsUHV8WBCcma/\nb3qKNaFwu6HHmvD7jx89YCw1+IwpWGqJh211qdJs+uXvfY9f+f73Afjik5uMJMssJ+W+eI4WwcO7\nt9m9YLMUDw+PePTYJrm0WiFNSUYoHAOe7b9JlLB3YDNHo8mQqBS+PTok79mElKtXtzl9bO+zPR3y\n3tes9/jLkymnZ5ZO8h2HRObQ73//u1x/zVJ4h5//UyaH1u2e5Ibusn3mW0tNuqFk7qYJQb740uqq\nnEQy7IqsIBDRzrDlobLSA+iihMZ1HIjleMe4qDIcABhXJagMMhRpeAGeWya85JQLlOO5FCWTlhkC\nydDVBaRp6eXMcQKpbxjPssGDIKR4iSB7z/XIhR7K4j5uOVXpkKysjTjq4zj2hprRKZ5Qe/HZiNGZ\n9Uz97hcH3EnL2nw+15bsPb93oUtDvJAqnqMFiylN0ZF7YHIKygSfkGMJbfjxx1+yOrDj9er1NRLJ\n9gqDFvolEpe+egX0iubjhQYRzMWoPLEWvnjhOP939cT/nzzGnDvGnLtu8TKxKE5WFTM12lSSDn7R\n53u/aCejP/Erb7ArBUfvHpwSK5ECaHXR4srdu3XADz+3g/Zk6XU2LlrDJ/AKli9ZY+rN71xn94b9\nfuXqBr/5t/8PAM72E4y4macF3H5sJ1zltfj+Jduxtq7tEGs7AeWRIjGLFZBNinvEuaX51joh09QO\n6sF4wDiybb3dd9lPyuykDFeVnLuH0vb6ndZS5drumTM6Lfv5xltJFcvzR3+UlGMC19FVzECOFQUE\n2NrYrOKVFAXDE3vM4ztjml37/E5PTnHM6kLtK1G+/6fV6Cv/Pv+3Mp7r7OysMq42NjbO1VxbX1+v\nflsaTkqpKk5qMpmci8OaP/+8gfYqYp0lihz8sMyciUklNiYMW9woY1pSh1t37KKZpJMqZb7hQymN\n3tAeidxPFOcEpQpnXFSFjtNco2TWvrGzxumhnTwf7t/msXDWD+/vVXIXiSoohJaIsghfKMjAa9Pu\nLK5I7PhBNW8kKXhCWbpuUaVUKzIolcPjCUXprA8Cu2oBKKeST3AcD61sH3bcFr6c08kKfFksHJOT\nRhKDlg2IZVFOhgMyETocxo9JHGvwrF1+C3+u9tiiCPwmF3bsnOIXitdEHfz+vTs8vHMbgE8/vc3+\nI2tc/Mav/zrLUtczHZ7Qk8K8J/0RSyLg6XVW6AgVn2YJU7mfeJJxIsax5zm0xZBJnbwSxlzuLnMg\n9R7/0f/7//HmG1Y0UjdDfEkbczCMR4vH2hzu73N6ZM/Z7w+qeI0g8HGkr919tIfWNj7LxAmxUMoN\nP+b3f+t/B2xcmGpYg9FRbSSxjNX1BhsSS/fR4371/D3XrQRWO82Qex/9EIDBwT38UjHfRDgyFxZK\no/JScVktLG8BVhgzL1Xbta76QjOcCeU6nmYS23blZOTSp/LYVKKzSZqRywZSK5eiNF6KCMrviwKV\n2z7bbjXoKzsWo3GMlnGWFTCVzVKR5zQpC5/rKp4rdDXaWZzY8hyPQqi6bhqxG9k1qRgbyVwHfvQh\ne2JlHR+eMZUC8KOzKY97cj/Ll/jOO98GYDLs0TUiDt29SOf979jPGB785AMABp/8mM11yU59/S0K\niclqeIZb+5Ym/uHHn/Evb9t2rS61ULL5D0ONyRfPWKxpvho1atSoUaNGjVfAV+qZMqpAVdl85py4\n5bPsOjXvyar0oZ5xjJl5sIw6n6331Gop85l6SqGkZICTTPDFLZp7DaaLezNptlxGk1I4LYbE7lze\nf6fFr/2aDXjrXt7AF7d08CBlou0u7yDOaIqRvr27TXjTelZ0s0UkO4t8cISRXeH+UR9nw+4i33jj\nTf7Ub/xJAP7e//yPkfhzPA1Gdi6DtMXPPrGehr2TRzREDHHUjxn3y2y3t57bvo21DHdkH0izmWCm\npV6WT1+C5B/0J4wloPb9t7/LtatWx+eLuzdJM8lC8XwakvLkBXDjNfv+dy/kfPa57SOTSUhbKNAs\nS4nlnIPJhIZ4dhzHqTL+PA+ODu2O5+DghAu+uM5j96UyT+B8oPez/l5SM2maVrRdp9OhJbSHUqqi\n8JIkodOxO+But1tRQs1ms9rFGmPOaQyV3tcsyypvlOM4T/XKvizNlyVF5ZnKclXVEkuIcSTYut1q\nE0gA5untIcc9Oz7e/M4beBJofDaMOBXtsiyLCWS3qgtTZcAl+ZjVsnyEo7m1b9/Rb//ep/hCI+1s\nLjMaWpqvcBSBJCcoPWUqWjLKaBphKUz7YhjlkMszyQuHLC9FDzVK6AStZoktyhTkElCcoaraYIUp\nMGomtlm+u8xtYkRg1lGaUOgQv4gZTG0bh9GIvBRAVCHtZXv/SeLw2Ze23tvrwUol1voynqneWY+t\nHfu7N197HWGEuPngHg+ldsrSyho/+9ju0teWWvzJf+EXAYh8zZlkroVei454plCGpfU1eTaGO3ft\nfPHw+B5fSlmXtICm0MK9aMRkYr0bGo8d0WC6c/8hn4h3bOvaVb7z/W8C8PjOLaLD04XbeHB0Rlp6\nfDC0RIcodL3KOzYaTyiUHev9s0EVQP/d9y8TZjZ7K3NgNBFPR29CnNg+tbm1Qf9UBHGHUyLxmkVx\nRFHW9opOefzRPwHA0znbEvQfTyf4jj1P4bg4rv1tu7XMysbiWWCTaCbamhcKMxavU5ZTmFKPCTLx\nkjQaPoGsH3maVZ7PIleVh8txDGWehOd51rMMGOMg5QcxWY44WZkOUhjLDWlNXpbkcWGal5p+aSUk\nbSYDfP8lSnRlBYEEiK/EBb54MKdFxOnAziV3hmMGcv/5BIJyCjYuTdd6i/aPeoSu7VffubjEkug1\nDscDxkIB65UWbalHm25e5LZ4vlbDLbY3dgGIMXz9bZuY8eUHO1xYtY0PQ03mSda97y6iFV7hK1ZA\nL6xbXVDO/Qanioj6+SWs/P48RViURpmZmWFKKuCBjck6R+KpmcFVntOcu5rBEwukOH1gV2Yg2LhK\npBaP6Pe9gmZQukgHrG3Zgfpv/Pq7fP0ty7t7Vy9ydmjdk5O0x4kspukkJz+1BUfDAHzhyP18TNqz\nrvq436+Kzw5WV1hv2XadFB2++cu/DMCD+yM++O0/sr9NXFLJaoseP+LRsb3WUaNAe/beimmKiWdx\nP89HQntDhDTjAcm4TK93iGPJhMkUoRgUK2trDE8kw05DJkaK73tksmhfu9LiN/41e85r11r89MNZ\n2rURf/xomFXZZ3Gc0GpKcd0kJZXFNolGXL4i/UufcLJfzg4t4uFiNOaLMG/glFIHWutKeHNjY6Oi\nHcMwrLLzut1uZWQFQVAtmu12u1JLjqLoHC1YHjOdTqtrKaWeKZnwMsZUrkylnIzxaEhqcDyaciYF\nZPNWUmW0jSYR08Se/7Xdy4zGdkHcOx0yFlolzzO0ZMktd1sVDXNv/7Si2Mgd7kp68ucP7vPaDVF8\njzWmZNVUSixtD52cqKSMHYd8vLjbvaAKDyEzirQqfJlXRYy1nsVx5sZUGUqpAU+kOzxdUEiMCmlE\nHtlxk+sRqdx0lhcoycp1XIOvJA3f9TmSQrrjfkJzZce20XFZWpu9r3lJjEXfo1aKDakfqLTiH/+e\nrbt3cHzE+pb9fnt9m58d/wyAu/du0vumjdPaXN9mq8wKPjqlVapZe4ZC6h+qIuf6jdfkebgMp7ZN\nj/ePODiS+o3jMWlUyPOOWZPNj+N5HBzbcb927RKdJTsmWt0QL+ks1D6A5eUOR6e2r11YW2G1rCcZ\nDdkQ5n654xBL3xwPNUbGxx9+eJN3r1tq/eLODkstue5JiiNSKdNJi+OhnSfSLKlU+9NhyvqKHZd+\nCI2ujLk0JxbK9yxzCIQyW1rqkIlkQjo+QZuXkEZwHTLZmOVZihaKzYsVbqlA7wCUCt8OnozXaZRV\nyt+t5hJpXmaFKpxSANMPSLXEUhlNIpvPbDxCO6VKekghsYyu55JLHdROx6dcLx0dVtmRWueMhv2F\n25jFCZ5Q90mgeaztu7izN8YVweg8NjgiQNpxDYGIizqeR1vW4NPDMZ8/tAr0g1GDb27ZfnVpZUD3\ns7sAFK5TyZQ0Ow1+Z8+e/6OPH6I3vgVAVIzof/jb9vPgiOWrdjOhPEPYlox3Vz1XPulJ1DRfjRo1\natSoUaPGK+Ar9UwVSYTJ53ZgogWhlEI/czdWeqZm3itjTCWACcx9NucCzUumRsG581fngarem19k\nNKQ0QB5HmLS0lpOq/tUiUOMDCvGUvPlGi//0r/0FAJL9+xTH1hulu0s4A5sxExYJN6Qi/fHtz7n1\nf/4mAK0mbIZ2xzeOjsmllpEJFI6xO4Leo8/Zd+x5nCik6dhd76/9qctsnnwGwP6tMUcSaN5sTWm0\nZfvvdJjm9rrxeEoyWKyS+3F/Sqdld4dZ1GIimRVTVZBKd0oBXzSvDh98QbsUmAs7VU23MPAYSU23\n9lLKW29begCjWV0Xb86S4u5t8Z6ZjEg8X6EXYkQr5fDgAcrYXdf2lubyjVltqjiW/qUjyBfP5psv\n0/IkSm/QeDxmICULYEbPTCYTrlyxHsjl5eVzlN98/b6nBZ2HYXjumPIe8jyvKMV5mu9JnamX8Uw5\nKqioZoCmlA05nZySyviYjPvVczPax/HtPWxsLBOLwN9gFDGWHbmjdVWiKQwCItnppgXceWT71/e/\nCXvHts8GvkunXd7QmELmhtTM6dBkiiC0u//RcMhk/DL7v1lmbWI0jvAeBRoj7dJFWunxGFMQy3sx\nhcGTTJ5mI6Ahwp6egkySH0bTIeiyjzUwknXYi04ZS3bs3kGPW3ctXb+8eoGvv2Uz0zwd0inKGo6d\nc+/uWUkPT6IZhmwLrdYbjypKs9Pp0JSEhTtffs5kaD07O7vf44OPfgrAd779i2zs2jIbrfYqSrwe\neTYlF6274ckpiSQI7O5coBFaT82PP/yI3pnt+2mUMRAKPYlTzk6tV1M32mjxRg6OTlkJ7YtuXn+N\nlXe6C7UPAFdXYqvdjsvyim3XZBQRizCp6+hKB6wwBiOencO9Mz4Ur/+9x1O6qzaTOUkdMgnm/uHP\nHrCxKiKQvkcklKXJiyohYnO9S8Oz5wnaAUMRpu3sNFkVbS9TKDTW23Xwxd/n7J5t7/f+3N94YROV\nmomjmsJUc0yqNLG0S6VFFfCtpxluGfaRahKZg11PkRelBprGiLcuVB5Oo/ToxcSSGBJnIxxZ25y0\nIJTasS2/gRJ+K88mJPI8HVpsb9o15vDokCR+mfmmQHXttdJWg40LVmQ1X7qDfmB1oFqTHEIZT2FY\nZSlO4wmeJDq9v+Lyu30733w5nnIiGezfeHuN9zv2/DvHY1Jf1oHmkOOePf7Mf4uheNN+8I9+i/uf\nWfr7m6/v0vnlX7HXbfiVaGdBYkv6sJjX6Ss1pu589jFaeN9LV67SWLITQWEKnGcW2pVJD68KiDIY\nTGGePAQDlJmM56KwzMyYOkfsmQJHOm4jiRg8lFpu4z7dHTvwMkPlMlwE2f5n5LLQf/tbv8w3v247\n8cO+4fiTL+z57++jhVbbOYnoBvZznozwJ5K5cnDIazJ5vbazyeW3vwbA7ncuQde6NkdZXmVhueMh\nxamNacimY645NlOhuwnfeNdm1Vy6dBklwoUffPQl/YHtZG6Rs9pZzGA8O8vxpXaRdtqVyKG/tU7c\nsIMip18mj+C0Qjpr9j0fHo9Y6trn4TttfFFm31yeEIQSJ5Avsb4lnPWnI7SR2IzRCZksUCsrq5yd\n2PZl8ZSVVXv8+iakZSaPY5B5iHiaE5bBAQtgXt38SZmE0miKoohU7qcwOa7QwpPJhMPDw+q316/b\nBavRaFS/dRynouryPK/iqrIsm8XjzNGI8zFZzzOgXormS8MqJqjbDYkkDm4Sw5HEwX3r4jq+iKYu\ndwMublqDa6Pd4MsybTnKiCPJ8AlcwrAsIKzIy7GrNfunduH73Z9+xvGpndAu7rRpN+1LGo5jznr2\nmFbLpyEyGCZVeBKLFLoevrt4bb5SJhggyQocWWeU9shk/tDkKKG1MFT0X5YXuF4Z6+SQyULjun5V\nsFW7KX5DqNvWGlqqIR+Pz+hLYe39wzGjiT3+zXdfx2taOsEYh1Z5Q2ZWj8913RfG65VYXlrm1mdW\nQX6YxZXBvdzugtRavLqzTSlIcuHCNh98YGuQPd7/B/z6n/5zAHRaLYwYx5oMR87TcF16PWsE9waH\nnMoilkymbGxY+swUmuNDO68FflDFba1tbnFwYueyzbDF3hc29mppo0Nrc/G4tyIxuFIRoac0a9hx\nvNpd4kTGGV5A6Np5wpgTyqAgjSIv6b9JRiAVEXQ8Rkvf7E0TumWcjjHEsdBtqbJFv4F3r6/glTRZ\nmrNvm8U0nbJW1qIsFMopx3QK8eIUmJcosrSsHOBhZAdQaCgK297CZFXcyjTKUUKtZuksmy/PPZoS\nU1gUipaooTsoRiKhMR2PCMXQTtIcXVWecGg17LoSDackpap6yyUqwxlUTrNh16RuO+P4+GzhNg45\natAAACAASURBVDYbLoXEMU0x6A07jr924Q3MR/Y5T74c0ZOxdThJGYlkwnQ44MaabdeNpQ693K4h\nPzxJ2BMJikd3Rpys2DXkV9dCNmQsDnOHLyTLXK2skZ/ZNWqNPW58710AfvmX3mP3qs1gVk5aiaBq\nCqpFZAHUNF+NGjVq1KhRo8Yr4Cv1TD388jO6gbXfru5sgXhV0jSjI56RRmNGdRTFvDinU1FyWZZV\nu/w8z6uAbDO3o1Nz3gWbtlfuROcEOYuUQtzATj6lyK2F3I8j/LI+lqtJy8C/BRCyjy/u2AvBmOTR\nXQBuNDyutkUPZNjjTITxOB7iyE79RjbltbesB+rTW1mVwbC1scZS1+6A1hqa9es2aLexvsZQgltP\nHxwRSzbiJB4SudZ6H/SHGHGNrzSgsSI1yd5cZ3hmd535aIApFttJRSNF1BTBOBVRxHbH0Lz8PqNV\nS2fkjz9kY9l6o8ZjzecDGzzfXV6uAseLPOa16/bZ/Pl/3eDKM7556wxT2GO2tn0OD+y1HhycsCzV\n7BUpLRH5bK5ptrfFw9JOaQtdZbKeFagD0sit+tqieJZnqqTnkjSt+qkxVB4lrXXlaXIch81NW46j\n251RG/Peh/mswMFgMNf3Cx4/ts9tf3//maKO816Ml/FMjYc5kdRLUxh8ocCaoQ9mFpTakoSRbivg\nxrZty7TfZzgQ+jUz5JIkMB1HNETfzGiHycSefxzljCWT54Of3eHqVUsvb6yFxBLMPR1npEKfxCi2\nJAjUxSEodXc6s7I3i0A7CiVUWpoWaGmL9r2q7p5CS6kqUMalEC90rhRIW5QfVhl5mXJIy9+GLcKW\n0H9+QCzeZuW2SbFj1wnWuPGm9U5ubF3BkTHtFFTUlJl7n8aYqhzRi9DqLPMHv2uzzNzQx5fMy/aF\nDV67YrOWLm9s0Lt+FYDD0zN6sts/O3zM2bHN+GsuXWZwJvX1zk5Zl7ADJ2jSEGHdo8MepyeWwusP\nBsSxHQeD4RAtdFhreYn+0NJ/zWZIWNY4cxw+kZIe5pbh7kObZPPv/lt/+YVtvL7mEsrcpxoNdlfs\nOrG9vMx00z6nRuAzEe/ozVt3Kqo5MzAVj+tKtyAQTaWzyWmlezUcJUwkqcH1dZUZp3KH7WXbB5u+\nwYjHBO1gSu0n16chQd5JbtCeJPpEivwltODGSVwlPhg1k4tWxsGRJTovFL54oNbXVkjlPrPU0JE+\n6Dg+nfb/z96bxdqWnPd9v6o17enM853v7e7bE9nd7Oas0aHlQRETGbJk2bIBIwEUJLAfkgAJEMBI\ngOQhSIwgAQIbCJTYMGwYkB1BtARZpmJZHMShSXaTzZ77zvOZz9nzmqryUN+qvQ/V5N3XF+in9SfY\nWGfftdeuqlX11Vf/b3LMUavV5tln3bw7Pt5msCuJMVVJIkETq82Of74qITbisN5IfJCF1glx6H43\njjosLToz3xOXnmY8nj0YpNNpcNyvIptLzLwbw82Lp+jvub3n6reucktyim0Pcoy0sxkEHIt7Sm9F\ncUn2h/s2pbfiohDGap2v7Lgov9sPtvm1s26PXCljn7txqbmGlhJEn3nySRpSKmnUP2a/5+b55sYi\nZd/tzSowqEfIpfWRKlO9nbtEQoumR/voxE2CojDEkqhxuTN3Ijy8ModE4XThV0tfMtsORyOMKD4l\nU5vLVN0gayyVVVBZQyC0fqyhlAKQw6Mxy6fc4I7DiFw2R6WKE/5ZD8Mov0NbCrkOfvgqe203UZI8\nRu27lxSVlqYs/s5xj8Wgyk6bk8sG9FxngVw2IHv1fe7cdnT+ra9bGqtuAm09/wxrZ5wPhuqljKWo\na2epydqCUzyGcy2OR24SD64fsv+uE2Rv3/g+33jLRfkcdI/IrdsI/s4//Ec/sX+NjiaVwcwHI9bW\nfxaA1vpP09hym/8n4i1SCQ0/PuxhtfjJNY6JJJT1ySd6/NJ/7K4vPhHTHUoNuDQjlXQSzdaIjQ33\nzgeDiL4I6mZS8NQzLjw5y48B93wdGkq5psjQYvcPVY59hJBzY8yJgsaVkpKmqTe9YS2BzEdtjFdw\nxuOxV6ystYzEn2g4HPooP5jM0+mDAUzme57n3ier3+9/aJ2+6jf+fTAcdWm1JWt0rigC168kDlns\niBl5OKAYVfeXvHfbhR7n5YgDmb9ZkTMcV9mbK2MYjAY5V286Zf32zq4PMV5cjDh/1s3fODZkEg11\nenOezSX37SzNacrGRGlJ5LrZSBg+ggC3FiZBv4pMogJtUZCL5FN2UqUgVBol/oUqDhjJPDdZQUMU\nHFNa8ioSMEy8n1ScNDGiVM4tbmFDSemhl+jLnNk77jMnWdVb83M+kaIxE1+8NE1nNvPdvrtDID6I\nc80GY0lvMewNufQZp0x1kpAPbrr39p33bpJIOoH2XMLBrnNrWDozT0PSZb/51lv0z7nkn5eeuYTu\nVsUEQ0xVi7LdouHHIGDrjItkzUvLSA5oG2vLnNpypsAigOUzzm3CKs2771+dqX8Af/UL51ESFWqN\npdly7yfWoDbkcKUtvYEU3k4i3jty62ac5mR9p0A3OpCL3O/3Br6/w7Fi/8DJx6QZ+fp3AfDME+5A\nGMWQijI1zjKfiiUvDeNcTGl6UqEjDCPUIyhT4eqKdw0p8sL7RrV1g6VQlPUoIBQFcG6+7RXwooC5\njhuHPCsIJQJ1rrVAIibCtkl4+amPuf52j/jgXRcNl5QFWkyK+Tgnk3W28cR5Ni44v08TNRkMqkoM\nIc3EKWubm6d56cWXZ+5jFCtKiR4epZZjSaeiG4b4tFN8Fhe3mA/dPadtgZaUQUEjIRVT/xWrMFJ4\nuX/6NO/sOOXr8OADGvICdvM244Hbaz996TRPveBqJg5juP6Dt9znX3yZ1x+4w/83vvkq5079LQBO\nrc+jq3zTkcbMWqqF2sxXo0aNGjVq1KjxWPhImSmdjllZdeanwcEuB+IYFjfnuCr0W35+7E/hZVHy\nxBOOqozbEAaVc2iJkci7GANV3SFrvROdshYrJzWFIpYTWRwGaHFQjJVhNHCnmFvdbe5L+vr9bspC\nQ56v8TmTZkHBGMlnyPvfeZ0nllzbVpfOsvdDpxUfpV10VSMoL+lJPbCxUeRyZNYZNKr8HgsJoxVH\nbd5+633sdXeyuPPGt0Gcu3V7AyUqdXl4j6ThTsz52TWa847F6RRtInFev7D5DN96z7FUO+kuRTTb\nSaokQwUyxvEpFra+AMDv/8GXvVlqZa7FUxtO6//YrxyRdNwppDUH195xY/yJl445f9kxUIXdYnff\nXTumxZ2WxlnqHZo/95k5hhIlubS8zmAkjrGHR4zl80bRIJMaYMrklOI8XY5ywvHsDE6e5ydMaVVS\nzfF47M1wzWZzkrSzKDxDlOe5L/2ysrLimaZ+v+8ZqDAMfZ2+6ecHQeBZ2eFweMKUXbVnmin7cea+\nWaB0xlAitZKwQxLKmossw1xY30GBEMDkRrEsOYSu3nnA9p4b8wf7Q3a77t0tthPmxNR0PEjZPXSn\nRpNbWjIOz15aZ0VMNaPxkHwkZk2NLzkTh4p5qU+WjsY+ym8+aaLV7Bl0syxFCVukbeBPjoWCVJ5T\nmrFLrgu0m01awvQQROQypmVpPUsc6NKzAqEKaFfRfAQEwlJpIrS4M2yc67AquX8G4z6FkvIsRZ8A\n7xHv3RCstaTpbOzbjSvXOHXGneo3T61zsOPMcN29+94M92DnPq+/7eRFmodYiazNxmOOxen86PCQ\nUxJWmcQJX/2aMx2unztH2HYs4vxGypmmY0nMnTvsPHCO7J/85CvcvufMha+//oaPgItCzSeefRaA\nXrfH9oP7Mh7naESzBxFEofFlp9DWlyRJNT5BpbUQSr/OnFnkj1+94e4ZFz5J9KCfICKUBBjJmusk\nhsGgKidkMRKh1k4iMvGm3znK6R479vXe9oFnwQaDnCs3nBxaXUhY33BjGIQB+hGW48azL/q1Xpnv\nABo2ZE4CLpIgJJXFePP+fUpxNwhRdJtCH5eWQIJKDvQu995907XHDlmQ95unI8xQojUPe6i8cjfQ\nxJJXKwwSlhYkcWtjgSTI/DgbYZe27+7QiGfPFxZGAbEkWu7lKX3J29YPS44ln9StJIGhW0NGx4i/\nOjvdQ45brj03egUN2cNup4oH950FpDUaEIhsToN5viFJqK8OrrJ6WZjw4Rs09t28De810cJatjtL\nvPeB268+dXEZlYuMSYJHYps+UmWqEcAZKcZ51D3mliRVbM+t0JBMr2l/dGKTSAduonQ6CUvLjs6M\n45hjiU4oipJcBnG/1ycXQaSNRQlNHwYhC5LcLgoDxn0n5FuRpnfoBND1G1e5edsJhcNeDtoN+vJS\nhyeffmrmPiobEkgk0tblJ/hAIr52Xv8hyVWnbOyN90gCiYAqzFTSUTVljowIxWas5sd8e9fdf/X4\nOh+P3MJYLgO6AzchjttzjDtuIoa7PRYk9PeDa9ssrzjzJfsDnnrC9WVxY5MNKQL7fmgoZ1SmhuOU\njvizzM99gn/xL/4/AH74+quMU+d30W50OXfJtfGlz2lOnReFL9B8+qfFbj7o0zt2wrmfx+SFZKBN\nIrJMimnGluVVMYGZu5xfd8/ZP9rnvgjwMhuTiN+CxpBL2G8rCbDlhDovh7NH8w36A78phGHoFZxO\np3MidUFVgy8sCu/nEkURi4uL/v5KsQqCwJv8+v2+z4YehqH3p5r2n9Jae0XMWjs5YEylTPhRE9+j\nmPyihqGQSCebp8xV9Q3bAUXp+tVpz3NXMsrPtSNOr0ty0bk2e/sucjTLUnSVxsCWU75g1iXEBIJA\n8cxl2fRXFkgHlb8HJJKMb9g1lKJMlcqQ5eJ7kyhCUXwKowiZ/T2Ox2PvExKqKts5bqOrfKNKi1hY\naDQCkNqRlolvWl4WlJXSZA2lbMRt3SKK3VoY5xlGDj8lAaH47hVZn0KUwaSRYMRvK88z74+hVTBd\n0f3PVHj4cRgOh6yfcuM6t7bI4Z6TZVur6ywuuQ3knZvXoSpgmxfs7bvN/8Kli6yKeW5vZ5cLcv+Z\n02f4f3/v3wDw/pUbbG44H5kiarIoKQpyA5kUvS6tIZL1sbS8QFMU7v3tbZakiPVau8OiZAQvwpDw\nEUpL9npjb2qxKOKgymKvUPIOg1BRiMm02QnZ2nD9Pb21zte/6+ap1REvPu/6GwUZ21VB4yjgxm1n\nEvr6Ww9IZM39zOdOs7roNv/rN3cYyJzNc0UsZvzOZpMwdu+wEViMTKTAKuJk9m14fv1JXzTY2kma\nSEtJLvuiyQ0qcWu0EzSxokwpM8bKfDRZjpHDJLYkEAXTmpAHYvosipyiIX6rQY5kfKBUCi1JTUc6\n4q6k8bHh5NBlrCUZiJw7DFB64o7zMJSlIY6rRKapXwfdXPGNG45I+Te3d9m/6ZTujrZcXHb3F3GT\nbuDadnM84vR59x5v3HzAqiyWFxY7LEhzfnA84B35vDfIOJYo/Tl9g08qSWeze4vLl15y/dq8xD/5\n7d8F4HOXVnnirFQDKM2HV075MajNfDVq1KhRo0aNGo+Bj5SZCgpDQ05+e/du8s5NZ/LpLK2yJOaB\nB/fv+oRhxsB1qe9kyNnccrkgnnzyMj/4vnOeHo3GXH7W1ZO7dvMaezvumQtzHcq8qmukmReH7DxP\nGXQlP4bNGEkSr+PuPkNJa793lJNLUr/5uSa5md3pVRGRiIkiWmzz1Tdckjw1tjwlJ9RWYCnFtOdy\nikw4YSOmOhWUCLvK4Z0bvCoOkNnaOolUnn+6zAmkxlje36UrDrbz+RDbcP0d5AqktlVhMpaO3en1\n7vX3iSTZ5ULUZjebrZzMeGxJ5RS4c+09rr3hqOSlxZLNTZfP6i/9hbNcOOc+p5xnKLWXosYYI/3I\nswQdSaLIeyOSUE7p8xHiZ04zwJsiev0hGMdGBeEqK0vupLK/OyL0szj3ucjKvETZqrQCBHb2RIGD\n4YC2mpR+qRzHkyTxzFQxxUZ1u13PCrVaLRpCZ09/V2vtWZswDP1zwjA8Eb1VsVetVoulJWeevXfv\nnjcDmB+J/Pr3xeJ8zPGx5M4JMkZyrhrtGT7xrHMWfur8Ga7cGUhfSvaFDY5Dzcefc4zI+XNrDCVq\nMgxS4pbkC+sbhkNJ8rm+wIXzbj7e3dln99CxplEcsS6s6eFhl32JKBuXmkJMY2e2Osw33XjqaEgr\nmT2ar8zBytHS6nIyT4LIJ+7VqoGW8iDjcUlD8rA1mwmFmI9tUXrn6yAIpwIPQjKRGaN0wGAoTGU8\nz8KiBEiUQ2+201p52RYGEapKImqN/1wxe43FX/21X8PK1OmNezx44NbHsy+/RCoJU7f3Drl205kw\nYhWzIVF+rWaLmzduALAQxgTiiDzq9+mJOenu7fucOevKyfSz+/T3nWxd7rT4qc99BoA//srXyIUF\nP7O1SdRwDbp/7x6lyKlYh7z8c+7+vV4XZSemrIfhsD9x+2gkCYWwIRpDJE7klJpS6kAeHg7ZXHEs\n2Opam0xMNke9McfCLv3cpzZ5MazWYoOvfdftMX/y+h0unnLz9Bf/3CXWVhyzNh6X9AfybnXo55EK\nFLoKVLKWsjIPKYgeYWeNkpanI0+Y67VFic+IKgyhlPtbXNvw+Y8ylWOrXEhZAWIJCa3y9RMpjS9X\nY4zxEcllnoGY9POy9NGr2eIiWiIHMyxFZyJzxlVCX2N8cMcs6Ha7GFvlAjNE8h6P91LevuH2pMPO\nEs0XnFy5eHoTfezmbRg2GYhlYZTu0q0ip5XlSSG7Pp5kXF6sgkcUNw6EPWwvMZTSQVEYk0o04vU0\npiXm5rm1s1w9cuPwh995m7/7lHNdKYqBN/nNYrX9SJWpU+urhCK4Iq1oiWmpGB9yXxJIKvSEDrSa\nQBKh6Rj2D12tp1u3bnH1motQGQ9Sbt264e7BEMimPDjcYSz1hcIg4OwZF52wsDCHFT+c9Y11drbd\nS32we9eHcisVE1S1j1BcuXV35j624iWCwL3U7/3gTfqS+G/rEx/n9ne/DcDpfkou4bXGBpTVwrCG\nXLLNKl0QyevZGStYc+a59ec/jnrg+nvr3R+SZE7zGIQ9jsUfozCGnsz0leVzzKVO8UgXNDsHjlId\n3b/BvETbLDW2yGdcGFYnPvR/bnHAr/66UzrKuMPr35QImeEymxJleLC7S2/P9TVNj7wgas7FiKyl\nSKEh451EyicFtbakFP+2heUFIvEfuHtzl5HY/cNQoayE8aqGr6eWDbsE8t1iCC31CMpUf+AVnDAM\nvakuSZIT2cqrqL0sy/yYjMfjE9nNV1dX/Xcrs930c4qi8Ndaa29SbDab/rtra2sMBm6wRqPRCf+p\nR/WVqmCy6XQICeOhFPItGiwL3X80TOlJZCXKctiTQquRphFX5rySNSliPNduE4lpIc2GfPwVN2fP\nnFlhRyLKrNVk4qeRlpb+Hbemy9LQq9ZfEHrl8e79AccdqSd5OOLc1vLMfVRqkoLCgjdLKK0JqsoK\nKqDKF1ykYx8lnOc5xlZmyklaliBQKKr6ZDE9iUo66vfZ2XXKoLGHLCxJEeEmPg1DGEwikou88KYp\nV29xUg3iR2su/jg888LH2JP6d9e/d5XFRbfbHo8GvPmOc1M4OOhyJBvFx597jueecQfP3sERgSRn\n3Tx/iqFEjt6+dcuP/Te/9qc+lcm9g/t0Jbv55196iQf3nWIVasXWhlOI+8Mxe+I2kY6H5NopIEmS\n0JC6hfnOgM3Vib/gw5AWuU81A8VE6VSlNxVpHRGI3+xwVDCWiLxvfPsmrzzvDgaEJV/6t85ntd8f\n8As/63xxV6KCeWlbI0k4teXkxNrqnDfbWVswL64NeVkwkhQYJrc0RM4GYcS4ysJeGLqPEHUaBsGJ\nVCkVlLJUU8EGGiTazgClGAOLsOVLfQTWosqJvTiTItyW4IRPXrXphxgwQxmeAi3yINARyJyNlCFQ\nU/KmSgdjDMzuvujknJ7M6yqFyr3re9wTUmXt1CnWN5yyv7q6zPZN2U96A29WbrfgWPyrg9GA0y3X\nzq2FiBdWXfuPWpZviO/b+qlNrouusDeEr6eu99/dvcvCPUmVMf4y7dh9/t7uMUbWIrnxvmmzmPBq\nM1+NGjVq1KhRo8Zj4CNlppZX22Sl0waXVltcbjrKzQQBmdAUxuCZqbJ0CT0BdDQxa6TjA1YXXNOH\nUcm47zTbZrNBJM6WKoS2mNusteRpVUsKHx2UjgZsiEN8v3eB+/ed+a9tYkxFwWvlq6jPgnaywbxU\nSB8eHJNIev+55S32JMLOHitCNdFjja6cKgOSqp6gMZhKQQ4sqiWlPBbPUsVQ3L3yNlaiIoqii/ir\n07eWQuplnT6zTr4kDujlEeO33Uk2tIb7D5wzamfpZRZWTs/UvyRpkxbuBF6Ou7QrdjGPaUpekNe/\nkbK25JKPPvPJu2QjV0pCjyCSsg/d45TRSJytlSFN3XOiSBNLTcK5+YjByHVqd6fP4a6UVxmPMcax\njlFimJ8T01sGmdDWrRBsIbWdeiVbq0sz9Q+g2+v6quzTEXnGGH89bbZrNBqTvGfDIQsLUm0+jv31\n/Py8Z6yq71f3VCyYMeaEo3n1+ebmpo/4297e9vmnpp/3qAxVM26wuugYAo2dqkVp0dLH2wdjxmLu\nTpKQo0PHtrQXFzmU0iJ5UTAv89rkIYGY4RaaDbaeuwDAxqktfuvrrwFw4fSKdyEfpDk9icpdXV3m\nqXXnWJoEcCC5f3YOR8RTEZE3bs5u2jSldc7dQBjF3pwX6KloK2v8aduZccUMPZXvZzq3l7sWNwSr\naM25ebW8fpogdGaJew92GApzGseNKZYz8deKDG8nUf4/lOXE5PcwfO+H32dN2ChVGF/aaZRnIJFK\n860Ol845lvjpy095Ru6zL73C02cdOxMFiuP7jn1/6823UHIyv3/vNv/4//6/XF8TeP5JV08touTq\nB66EzOrKGvclirCZRMQyfmWRMxRmp726SHNO5NfqMpefuDBT/8DVGaxqIeZFPnkPFNjRhDkMxBwW\n6oBOR97zQcDPfsr1/dyZBf7Z7znXkD99/TZCYPNXfv4Z2mKp6LRadDpSB7I/wIh7hMVSSIBMWmQg\n86LVbPmIwnE2JK3KwFjjWa1Z8OPWrkL5epJW4UsjWa18gmqtAl8aRwFVkiQL5FUZtClGyBjjAxyU\nAh1J4EmJC6kFjNWoqnalNvKP8h0zVR/3ERJaJklCaaZKJok5eG9/TCpO8+ubMf0j54C+f3CXUtjG\nzbUVDiT5dUMrssLtM6Nejll0smcvDijEpL8+lxDL+7ry3nUiWXNHx8cciqVrc2uTOWEwn877FDJn\n/vzP/5S3SpEFj2TK/EiVqZIex5KKIIgDVmQSlxZoixKEnvKZUr42kaXwk8CYCGubco3PwIwOq7qj\nKGV9okAsPgzZJT6TwTIppaRP2FxfZV4EY5pbSkmuVxhD/ggJ2LDQ7bsX2c9KnnzqAgBnF7fYlgYd\nqcAXlUQVlZsPBkUpCzIkohTBVASwsOBMPqvJAoPU0ZaHKHJJ+NkIm1gxa+bkvhDt+Mq7lE13P0kO\nPSf4EgrihjOZrCytkkjo6UO7V0Y0JEqn3+8ShFL76mjkkwCWZYPf+5L7/PZ+iz/3hTPSrjcwaZU1\nPCSu6vqFuVeUkzig2ZDolHLkhX9IxJxkwbWtEem4eieahjgoaFt681OiI7qHzlzR0HMkyexhvKPR\niH2JjJrrdE6Y5yrlSGvtzX9lWfpUB6PR6ERKg8pst7y87K8Hg4FXplqtln9+lmU+QnA6cWin0+Gc\nbIjLy8tsbzuFeHt725sX8zx/JIXq9MoCpZiZQh2QSOj0aJgTVjX7Ari06ebIcX9IuCYFs5OYhhRJ\n3j/u0mhWxVUtSubs2soc48Ipe7EtmetIQdUwotGW2m9WsSwRqGsrHdYlZcJiK6E85dbi3tj4pJ1F\nWfJgZzBzH5UKsLYySygUk6zn1T5grSWo1lDU9P4nZVFMAuyUIgwrE0jgr7VWvjCyCpsEEtk3v7To\nQ/KVUgTiJxrqGCUnnjhuEUhkmjG592kpi4xixo34nffeIXrmaQD6/R4H2+5wdGnzNEeyKT315Cka\nErJlel0Ojlzk2txzL7Eg8g7T4+qOkxEfXLuBlfqZl55cZnwgtS7n5vncJ13002K7wbr48y2vrHB0\n5Obg/sE+L7/gTLubG2v84G2XnDMOIo4kgjoPDY3l2c18LkXIJCq3UoKMLYlkDWmGlDLXorDglWfd\n4XFrbYFtiUb9xPOr/MYXXS2277xxm5t3nKnoW6/fgFjMZ0XpU4QEUURhq3QFOWPxe2s0m15eZ3nu\n3Q1gcihG4d/t48BaUFPeOtX6NqUlkAkcGOUjzhQuChVcsKrVkibGTlwJjLI+khW0n48wOSRoAnTV\nfqWpFP2TrnzWR6/OAsOkQHsSKqz87s7xkIGsoU6rSW/sDuq2sBhx6wgbbV8vzxBRigkvL5WPWCzK\ngp6Yfe3CCkXoDrfd/jFxVMmAEUg299WNRZ5Q7nf/w1Oabdkvm0WKEZmR5pa4PXv0cG3mq1GjRo0a\nNWrUeAx8pMxU1HDOeeDMOZXmbC2ovHJyM1Q6nlYhlVasdehPve7UKM6bKErltMfCBj73SGlyV71b\nnlDV37Jmiiq2ijKrtOuSRuK+G8VglZg9DDyKzplnO4zkJFXqjPZFZ7rI8pJ9SchmNhYJxNn2oHuA\nFapYozxLEegGKCl1EyU8ddqVeGgvzHFPomFupymBOEGfP/sEO3dcTpWDfp8cp5k3735AU0icYVBS\nislyqT3H+c1V+bwH7M3Uv8PDAZsSJEIQOZMCcNQ79KUVWp1zGGEBvvm1lGzgTopnT3+KKJI6fZ0B\nee5OvcYGlb8j4+GIyr6ZRAnWVHXuMhaE0h31AwphuKIooCPlTyKlyFPHXAz7GRJkRMs0PfswC4wx\nPqruzp07/lS6trrq50673fZMUxzHPmpvNBpxJKf/brfry89Ya2lL8tcgCDx7NV1rb9rMWq4CXgAA\nIABJREFUl2XZiSSfFSO2sLDg6/2dO3fOJ0q9e/eu/91ZsJA0nT0NCKyww8AotOzsujFvBiEdoeNN\noWnGFQOsaLWrqLfI56jKioJc5vLCfBMriS5Vf49nL5zy95zddCzoQiMhF2feKNEsz7uJ1aDw0Uqr\nG3NEYp476hWcXp/dAT2OJ9GXWmt/PW22CwJFFFQm19An/gt04CMKmTK3OFNh5dSec3js2KB8/4hS\nPo+bIZEEwoSERHIaDoLQr29X87GSfyVR9TnBicSNPwl3bt7m9Koby5deeolXj92an2u3UcoxRwcH\nB6xIMsa1pQ2I3RgfH+yw26gSHA94/4pzWD/u91i54JjkFz/xPLfekTxNKiYRBjgMtH8/169eJZK1\nNRr2aTXc9S/+pV/g3gPHMhyNuvQkRHdtc91Hbc6CoigpqoS4wEgCMYIgQHJqopT1Ds3tduJzUX3m\nhQ3+1ZedOfL2vT4r826+/9wrW+xcco7mZW44EEf8ICrZ2HDzKwwV4ypnE9YzzzrQvnxSWUyS6RZF\ngfIhfJYomp3RUHqStLWao/KYyT5noUpCGKvAJ4ZW03aoKaLIOprKfWy0z7E2qfwn98kcdDa/iZmy\n9AyX8d9x64bJ9SNEEw9TgxBERNoQ5e6PhUbTv9M3v/smqbj7HBQ5uTC67yrL8NhFql7c3KIja+WB\nzZgX68Bn5wNWYjf/3xqVPlehynP6/arcWEBTrGFtY1kVd5KNOYsu3HP6+z0GQzcmR/2MNSnVM8vu\n8dGmRogCmpKJ3GAIJPpMT8WSugTYleKjCKOq9hFeOTJhQDXnjDGeXs3KyQwKo4SBKCxFnqNFOXJC\nbIo6lU2/kYCpaN0iBR81EvrNfRYM0gdeYcnUiAdHbrMLGNOXybp85hTH2472vtbdoxShHVhY7Dhz\nVLOzihK7bz/PGUiRyGHe5SCVawWBhCLd3N6ehLwGAUYWWRqmpD4aQ2Gk70dlBnvOT6LMbs+cDDFs\ntDiSEPlIld48MR5aUqlZ9dLHPs358075u3X1CoNdN5av3oCFRTeWl5/qEyVO0FlVoitFVutJHTpd\nEASTsPuxKCbjIXTmha5dXSUUs8iof0Aoc+p4HHG4LxtpErA/GM7UP3DKUWXCazQaFKLU7O3teyWr\n3W77aL4kSbxPU1EUDKSdg8HA318Uhd9Ip1MjNJvNE9F/VdTewcGB942a9tUKguCEUrC8vOzveZRU\nCaUJGVVh1Fr59dEf5hz3XZvnm/M+uhTwPkQFxhd7XWy3aclGlkTWmwestTSq8nqDAWe3XMLV4/6A\nJfGf2Vhe5Kjy/yozosp8pmIqB8B2FPrw9kazAY+QKDBIQgJVKUfaKyxhoAmqFCQa75MVhoFPyBgG\n4Ymoycq0V5bGR/aVhRcT6MBOJVyNffqEQIVoUaxKW05SMqD9Gi3tVCJWDcGMcfXLC8tcu+KUnbl2\nmzNnxe9RlZw966KXv/rVP+HFF58H4OKT532DH9y6z/dfc7IpjhSxRLQtry7TlN9/6tIlvvIH/849\nf2Flynxd0JR0FVeuX+fsRZc+YWlp0Y9BUWZU55fVzipWDtFJELKzP7syNRyPSBpVod3AR506D6Iq\nvUHsFVkdhGzvujV0+nSDtXWnNH3r9Xt88T9wpnJjMhbmq2SbDfShpIjpNNg5ct99/Z27BHLCK6x1\nCiTOvzCV+WjK0isURVHSmnO/FUYB6YypZoAT2dKnlR3LxCKnmCSdDZiQA0Ybr0TZaWVq+gMVeB8r\nl/q0OgwYLJWsxStTFuvnJmYqqbSayiir3L/NisFgRLPyYVYRmciVpcWEkdTRu3r1FqcWnZwYHBxx\n1HXz5OKpFf7Ob/xHAIRtzR9/w2X0H8SGm3IYa8QhhVQgeP3d+4hbNK1mkzPn3PxstZs0xL8zKic+\np32tKCVJc4Di+LAnY5KQpuKSMEMfazNfjRo1atSoUaPGY+AjZaay3ExOe5RoSTiJ1hg5iVqrCMXj\nniAgkcRjpsh9osswCEBNzIKVr1ykoSGlXIoy9ZXnC2UIqtIDOvQOjXaqWnscJz53Rxhknsa2ZhLt\nMwvCRgMkyWdkEg5uuIRwxfwOB/uO0Rn2MgrfhpggqirSG3oS4ZaZEUHo+jvMRty+9YYMyZjdu47y\nxFpfV2xwfM87IgZKo83kBFGxUZqJ9lymY7rpjtyj/EnnYbh49hT7+3Kizo/IR+5kMO4l9I7caWP3\nsMcrn3EnY11o7ly7AkCrs8zinMtzs3vvmHjOnTw2T+36XDwUIb19OTEcjzCF658ylkho33ghpCm2\nS13uU+ZyOokU1jjTBXEDveTm0a29lFe/7cbv783Qx+WVlUkiPBSjkWOaDg8PTyTPXFxyFPBzzz7n\nWarxeOzZqDAMfQLPMJzkPKqeASdp/dFo5Msk7ezs+CSMo9HIM1/TTuZlWfrP8zw/8dyHIS0L+lnl\n9DxmdV4iECNNd+To8tF4TBXOYgKFkd9K4tiviZTShVECWIjEHIbVhFLdnULTkaS8SikW5yRnT5Z6\nc0gQhj4Cqtlpe0Z6bAxK3kUrjhkMZj/xG2W8o24UhcRRleNOo6VtWitioVCqsijgGKhppq+SE1qD\nFnbMlviSOZSFdzFQVvncVcSGwkxFXVbLMpiYFK2OvGmvmKrz+DAsthe4cuVdAK51btCUtvQP9olu\nS4Rae4FQImhv3L7Ji886luqAgrfec9FtcTPh8mW3Xi8/d5lbwhztbW/z4gsvAJCXmuUVZ1IMwoDR\nyDE4p05t0W67NXd0dIAxznXg1q1rnD4jZaTiNqO+OLJHMfdu3p6pf+DmeGUGsuVETmV5SlLJjFL5\nCESL4daeRDLvz3P5CbdG/+ir17i97Z7TTGAopr0kyumNhfHRMdvy3TCKfH3Dosx9VJcOAjJh37AK\n8YvG2BIVy/MbDUJ50X9thj5qa6a8uydJW5XF55BSTNa+ZarkjJ0wTVpNIoxLM8WCqgmD6iw/k/lV\nWWYwTN2vUGYi/7xp70R7ph46C6xhmIrsVBHsO8vMqUvnuXT2LADd/g1f5zOIGlTL8eWXnuU3/upf\nBuBo/w7XrztG9fVru7yx5+7//UhD5Pr1R7sZg5ZjCfP8kF/9m38RgAtnzlBKG/71v/kDunediX6Z\nTe+uQstycOiYss3NNYZ9J28WZ+jiR6pMjUa5Dz2OY4WRyWpMia1qYhl82LtSIXEkwrMsvWlBa+vr\nXSlliZNqkoVkMonTbEQpZidrCyLx9wgDjfbUf+zrcpU2nEQbBE2sT9imQc3ub/Ox5z9PKQpOOh5R\niqbX7/Y4s+Iib+JwUpC3VLkPbS2KAiM+J2VZMpL6ZKqMOZQ0BlnvHYbHbsG3g0WUFr8UayWb+snM\n2NPRINPJALXSnh5WSnl/tIdhPBrxxEUXsbO7l5KLyXE8tAwkHPvu7XtsP3DpKvp7h3Qk8V+8tM6c\nFKLe3TbcfNNltCdLOfOUmPDSMXl+JB+PQCI1Q20pJMFcEGk/ZjafpNIIg4DBSCKzljrMi0l5Pxty\nfDj7wn/m6af9WJVl6eng0XhMWimP6SQz8527d/3n9+7f8wItyzL/3QcPHviw+GnFR2vt78nznNu3\n3UZzeHjo2xAEk0iY6aLHRVH4a6WUV+hmQRzFhFVtvlLjdUdb0Iyq+oMpqdyjw2RC9+vJgccow0ja\nH4ehp/6tMb5m3zDPPK0/HKe0xG+hGWifIiQ3ljnxKWsmDVdMDxc9GokporDWR9/OCu8DNWUe1VMy\nQCvlbGvIxiJLx0o/wb2jST3EqfWllJdnYRj6OanD0L+LIFAUXg5ZpusqGr9MJ8lXp3/rYRh1BzSk\nXtva+ibvff/7AOT9nk+QuL6+TCgmjL2DPZJQTLIqYCSuA+cvnaM/dpvS2tYakbgaDHs975/3x3/y\np1w841LZXDpz2rlC4Hz4Qjm0rm+s05Pkip2lOTodN9/TMmBzza31wLiM6LNinI4nh+Ug9n5sWZkS\n6arupSaUm86utPw7PDzq+XqSn3/xjLPLAgeHpTd7hVFAWSVnDQMO992YXD6zyJMXnfJogX1JKr13\nNGYkWe+NNT7DvgpCMgm1H6YjinT2eVoWpVfEtQ5OKjtVUfPpz34karf6M5hO4WEnJkOlTrhTYexE\nZvhDrLUTs6C1UzXprB9Ppv2w1NQPz4DNjXWO5SDUHYzoSuT5060FPvG0K4j92vfe56Dn7knLlIsb\n7t1dvHyO96+4A/lWAJ+67Paf7/5wj3u33HN++90uoyo7ezxPc+zm4ebSIj/z+c8D8OxTl9Gyv16/\nc4c/fseZC7+5VyI1UXhp/TQ6cJ0cjwYkceUg/HDUZr4aNWrUqFGjRo3HwEfKTOkg8FR+mk2qtSsd\n+tT0xlofJRUGUydC8A6HRWF8040pQcwVOlD0pOSFMaU31YRBgBYzYpFasup0q/DOpNaMvVN7HE/l\n31AKgtmdXs+eedqf2vJikj8py0ZYoftVGVBIG6wyvp1FUXoC15iMEnmOyX1OIIvFrjla1JSld/gt\ny9JHSlprPcMVhBNWo/qsGs9SuGut9Mkokp+AK/f2SYTxmV9Yxkg5m9vzPQphyXoHu9x515kQthZX\n0Elb+hQwPHb3D3sDFlsfA6C7vcmV7HsArGwdU0g7k0SBlRxM4yFzVaooawmD6uTfYJS756tsC1O6\n6/nWKd59x+XOufr+HutV4tIZMD8//6HlHdxPV+9nYrJO09Tnh1paXvK1zXZ3d7kiJ6o0TU8wg1V+\nqOkSMtM5qrTWnt0Iw5PO0NOJPT8sEnAWaBUwL7ndsjikP5K5VlpSX1soIJV3ESvjT6LjIiewVQK+\nACXvKM0sld2jmUQTJ+wgohxIfcYo9qfs0pQ+HW6BYiAO8bmxnk0xRjOSvG0q0I+yFInj2JvklFJT\nc1ydiPKr8utYC9ZM1lkkp1KllCufIdemcjSfaovWIUWVIzEIPKtljDkRMDD9Hqso3qKcmPZOtvMn\nY3Fuka3Tji3q9QYMBm780uOUcxccExTFAUbcI86eewJVukb3DrrE4lS/sLTA3V2XWDeIEzbXnXnu\n3Ol1vvktx3YNBgNKSez67ltvOdMXMBwN2BTz31NPPUk6FjZdGY4k0nFx7RJz7Y60eZ6/8IU/P1P/\noGL8HNqdJk35q9ubsILokMNDt+YUimcuOKNMYZVv88WzTbJMXAaCCcsTBpq5OTcOF07PoYxE7ZkM\nK1HTFlhou7nciBvYdXGkNiW9niTzNAHdnrs/jCKixdkZDaXVCUZ0mr2cZn+0D4rCfz7tFK619iSS\nDiYMl5lyVVFw8to/X/l9yFrrE8BOt0f+UX5gEiE4CwJlacXud+eaC7RPXQSgcXqRj0WupuvzV56A\nt11AxXIyzy9/4bMAvPLkGR5IHcng3Cpbkkfs1PkW96WOa3/cotFw7+5nn3sCe+RM1Z/6qc+zdtYF\nHvTNJDPWJz/1eb7/qnP9+J3dGzz3jJS+WjlNmDn3lzC0tDqzv8ePNpovDLBFZarTaKlh5yIV3EBn\nWUagJyHnlWApy3IS5WW0j4DTKvA1t6Y3pjAIvNDW4H0YlFI+bDkrDUPxb4nDSVRFOrZTYe+R/61Z\nYFThEqPhonKqKJZW0iSUaAOT4SMK7YRPxVo7UbKYtnOXGNmkFHYikI3ym0VRTDLbnqCJtfYbgXE2\nimogqPjz8hEiwcqyYHfPKQJLi0O0mFgbcwYlSdMWkyZxWVHhBaXQ+nlWkIsSUeYll865EOzrV/vc\nuOsiLja6fT8r+709JJiPiA5GUmCoqM3RthvL7lHC1vmfAWB3Z588l1QKTQ2Fu3+hueBNxLOg2Wye\n2NBOCDfBdHj9j2JaEauUo+3tbfb390/8+49eT5uBoig6ufFOCcbpjOzTytSsNd3AFfyOKoUl1JRC\n95cYP/HKcuJzVBYZgdxfGOPNLZqGF+D5lCk+VNYXtY6CwJv85totrHx3VJSUMmcKaykkanaxE5GL\nC0BZ4EPjKQ2DR6h59qPj7ItLByFRUEUPWy9gi8L46L8oib1cMdaiqs3FWm8N0dpFQrrPFaX4lJmp\numVa4+vuWWtPFMpW6uTar747a/LV809fpJDi5l/60r/CiN9HR0csdVxqhOa8pjd0Mu7CxXWC0JkF\nx+mQQsZ42B2yvuLW4gcH99g84zaru/fucnzg5uyFrVMMB27su/tHtBclijTS3Nx1CUJ73bH3vQqC\nMUZM9KZ0NVEBTm1tPpKpNkkSf2AclxlFXpm+QxpN9w7jMESrSvHFz1mFdv61uCitOHYHrSzr+7US\nhQlaNvlPPLtMKvOr0XDpOlz7DUlS+fY1iFtuHQyOhyzPSfHeSPvDahzFlMXs89SacqJMGTPlEeWi\nPquOqSmNy8t0JvM8zzJvzwv01CF6at5NK1DT0kLBifsnlR4mytoJ+WftCdPjw5BnGfMtN1brq0ss\nSEUKNeozF7vn/Bd/6ae59ZJzhZlvap4Wn7sYy6CQYvNFQVOqqPz655/j5591xEKWl7Ql1cez509j\nC/eO5pZXsNdfB2Bgrc8ify6A//SXnLJ2/+Asp1elUsXoLlbaubja4RG2/trMV6NGjRo1atSo8ThQ\nj5KbpkaNGjVq1KhRo8ZJ1MxUjRo1atSoUaPGY6BWpmrUqFGjRo0aNR4DtTJVo0aNGjVq1KjxGKiV\nqRo1atSoUaNGjcdArUzVqFGjRo0aNWo8BmplqkaNGjVq1KhR4zFQK1M1atSoUaNGjRqPgVqZqlGj\nRo0aNWrUeAzUylSNGjVq1KhRo8ZjoFamatSoUaNGjRo1HgO1MlWjRo0aNWrUqPEYqJWpGjVq1KhR\no0aNx0CtTNWoUaNGjRo1ajwGamWqRo0aNWrUqFHjMVArUzVq1KhRo0aNGo+B8KP8sX/9+1+3rXYT\ngHarxfxcA4Brd+7wD/75PwfgoDeiEQQAnF9fZGtxGYDPf+ZzfO4zLwPQakdYY/1ztVIAGAvdo0MA\nwijGWndPEIQUcr23v89br70GwHA05t+9+nUArl5/j263C0Cv3+XTL30egP/y7/7XvPvu+wD8rb/9\n6+phffzS3/8/LRj5yzLORgAURUGcxADkRUlRlK7tWpFmmbS/IGm48UkaTdI0B0ChMNJfaw1lNnb9\n0oo0TQEoyxJk3DqLS0RhLPdDUbrfGvV7KFsAkGZjitI9s7mwzPLGKQB+7T//T35iH9/4/f/DVjq4\n1ho1dbdSH/7V6nOltX9XSin/udb//jq9tRYj79Yai7XGf15Kv4uyREmbX/ilv/PQd/j3/5f/1VZz\n50f7FMgYH3e7dOR9fuubX+fshXMAdOZXabUXAFhYnCNJEgDiOCbQoX9mGLv2XHv/XX7w3e8CcPrC\neV7+1GcAaLbnqKZ4pODB3TsA/PD7rzFO3ft/5XM/w9r6BgDGVHMO/uqv/JWH9vHqP/gVezAYAlDG\nHW7d7wMQNhoszLUAsGnJ1pqbj2vNgCCIAGgkEVq53zNhiTKy/owF+TywoEy1/gIwbt4ZNGnu5nVp\nS4y8o6woMfKOrFXkeSot1Zgy8u2upsrF3/ynD+3jf/ff/mf21/7aLwLwrR/8Lv/yS27d37+X0zt2\na67IxuSynk6d2aR3PHBfbixz+ZM/B8D1N79DNeeXVreIG20Augf3ONq9C8DWM59kcd7JqsXlZb7w\n8z8DwHNnVzgcu76szDVZm5sD4NU//QbvvfllAKK58/zWP/odAI72HzAv99y8+t5P7OPP/u1ftYeH\nhzJm1s/N6blvKdnYOO3atbRCIe/KqtDLuzjUdFpunqbjAYP+MQB5PsKW7r0Nuilp6sas0Wmxeco9\nsyQmjNx4NJpt8tzJu9FwQJa6sYwDGMv14f4eReHe/5Uvf/uh7/DL7x/ZQNbB//Y//j36h7sA/MW/\n/Je5du06AF/546/wG3/zbwLwxV/9a4yl74EO/B5grcWIvEMb939w89XKmBgYjVz7tdZEkVvfRk2e\nUz3L/YPFyjOn158Bcu2e+cXnNx7ax7/+q79m74zc3NkLNgmX3TWBIpXxV0EIfn24fcM11AKFdKv0\n8j1QGo30vRigrOwxymKl7425BpHIMFs2ScdtuadFqdx3x3mKDibyPopCf21l3H7w9//GQ/v4yk9/\n1n7xi78MwMc+9nEasoZQmukvq+ovayllTKfH1lrjZfL0PI+imEDaGYYhcSztBP98a6zfd4fjASXu\n+tSps1gvwwxGZFWeF2Spu/4LP/e5h/axZqZq1KhRo0aNGjUeAx8pMxUGmgVhpoJQceXGNQD+3avf\nJghdUxrtNuc3nWZ+McyI0x0A3n3taxwfu1PJT3/2M6xvrQNOUzWiIff7Xb70D/8nAH79v/of+Pq3\nvwfAa6+9yre/8y0Arly9RUPYgs999qf5+DMfA0AVXUx5FoDRuORb33oVgF/+k19mb9/97t/627/+\n8E62m4wG7pRPnmNFE1ZaU1Qn9SgmiKfYndCdGsbpiG63577b7aGFyYjCmLKQE0cYQOk09bIo/SnJ\nae/u8/7hAc12R343IMuECShzEC0/jmKSphsHUxruXP3g4X1zTwQq1ubHs1E/7psn/p5iqT70fjv5\njrHGn1qUUpN+T92Dcqc2QE42buzHRQZ69nZaa0+cRH+0veDGTIWOCXjqmcvcvHkTgE5rieBD+vOj\nz6yYVTvOGffdqf3WrRuMczcXnn72efLCvSudZ7zz5g8BSEdDxuOxf6Zvz9TpbaY+qjbNpmOGdRjw\n9Cn3/fn5DvMNN3fKdEDibkErSymMwniY0s/d/eOyQMvcVAZaLccitRoxFW0ZRvPowM21Qe8Bg5Ew\nFiokFKrJGk0up8w8LzxbgLIoOUknSQNsOXMfVRmyuuRkyZmtRfo9N267D3o0G9L3QBHKe+x1u4xd\nF1nZWOHwwV15UMTc0qp7zvknOXfZyYx7d25w/d3Xpf05+zvu/qcunWZ5axMAow2tlpN5i8srdObn\nARiVkOeuPdnRDsOhG5PReEQjmTBxPwkLc3P+ZH58fOzngFKaUFjEstAc7DsZGoaWztwiAGmW0+86\nBioOFSZzbczSMVpYCWyGMY69nO/MMZRXMhz22N9zz1xZO+3fSV7khLEb18QaCuMGMyszooZjOxvt\nOfpH3Zn6B47RjeX5F05v8PXvfRWAr/2T61x/sO2ebxX3b77lrkc9wqQl7S8mTDgaIR8oUZQiwwyW\nigJWBmzFhlgL8hq01hgzmXeVHMpVSCYyNy9y/y7cnP2z8uPH4e3+ErS3XNuCNggbVRYlJnC/FaCn\nBJ31rLVCuT0BKLKcUO4pTElQybwwoWpaaVKUcmvO5CVJKDIGRSGscp4NiGV9NBsNClnfpjRkpWNZ\nlbJEcTxzH29evc7v/PZvA5ANB7z4yqcBSJqtP7MvgJOPlZwbjUcEIieUhqOjIwDW19e8vC/KnFCY\nWZTB9l2bszylLKp3F6CV21PLsqDRjH1flJ6wfpM9BG/1mAUfqTLVmWvz5gdu0/m9r3yFt65edY2I\nQhqJW8xFPkSlsoA3FnliwwmxhUbIu++4BbO3e8y5LScUfv4v/gJJ5AT1zvYd7rzrlKAPPniX73zv\nmwB8/7WvEkXV5Eh47XvfB+D+zi4XLlwAwPT2iGRz6Y8G9AdOgVKxZul0a+Y+Lp06RXh4AEDa7aFz\neWFRRCkLL4yTyYQuDVomZWkto6GbQFGoiUO3mi2aYGrilmXur6OoErwWeSQaha3MKrYkqPalIKTi\nzIMopNlxY5jnJf3j2QTcRJXiQxSOStk5+ek01f5hn59UBCZf1kz92Ml/mjwD+6HPtyhyoeDHxcgv\nllkwrfhYa71QcuMqyrE1ZJkTLKtr69y75wR7tz9gTkzTxpgTfVRUirXyykKYJAwq0wIle4dujl+5\nes2b1UyW0xTaOs9GaBGeWuuf8C5+MpJI0RGFO0o0pnTPLAvIxq4949GAUe4+z4xmlIrpKIi5v+eU\nfl0WrC+69dcIQ/pDNzfvH/UZinA+/fxF5lefBeDgyhv0dt8GoKNGdJqO7rcoL7iKoqQsqkmr0LJD\nRPFks5sFL7zyNGsiP/TbEVo291BZTOHWWafdIGq7dd/rj8hEm5prhDz1/HMA3Lh2mzNPXAbg/MVL\nfsMqh4dsbTlz19zaFnv3bgHQPz5kmLn1d2xS0oFTlBIdcPX+PgBffe015kWBanaalGIewxrCOJip\nfyoJmVuclz+gLwcxUxYo7eaODkLK0inoe/v7aNlwGo0OG2tu/atySrnPx15xaISKsXdHsLTF/Jgd\nF/SORRGLOywuOtlUpGPCuJpTTRL57mhYYkQRn2vNUY5nf4dFYQlEDn788jNsn3Lv88WnzvHi8UUA\nrt+5y8H1dwD406/8Ic9++gsAjEtNLPIxVgothpjclKSVUhAFxNV4W8swF9eAoqTou3vGVpPJ+8yz\nEmvccwYmYCAHnnQ89oIv0JBod/+vfOLMQ/s4CLYwmbgn6C65aHFhHKGUa1teZGjtrqcPkxaFEcEf\nhIE3O2KLiRKhLKWt+pU5eyZgdEgua8JQoK0cwAkZDtycCYImUSTyxlqyrDrIGXKRW7Og3Wiyffce\nAL/7L3+Hceba88LLr3hyo+obOHm5t7cHQKfT8QfjfNjnaN/J2rlW7BXbEkMUTciBStl05lA3Pkmc\nEIaJtL8ALS4GWYZi2kQuyqwpH+mQWpv5atSoUaNGjRo1HgMfKTP1v//Wb/H7f+CcLof9HpGYE/JA\nw7w7HZ5b3yIMnDa4N2ozvO8Yk5X5JvNtdzK6v7fDB287p93b9+7y1/+Gcz58/et/xAPtTlv/zX//\nP3P+jDsVvPH2Dt2eO0kV+cizOWm/z/ffehOAcf+YCxcdNb/QanHxonPsXVheBjX7MPWOexRyurFW\nkQu3HFgoROvOxqnXqKc14TTNMLYy4Rl/f1Faf3J0jtvuOgwCTy2XpiSqHPCYsAu5Mf5EVhrrHdmj\ndhsrTEM2HlPkxUz9s+CdvI2xJ5zHJ2awD9fRp9kTxYezKYopZ0OmKFfwbJ6V/8meT+iCAAAgAElE\nQVRDJzdZe4K8yuXz1OSE9sPI5B+PE23z9E/p2TFbFowH7lS3/aDHe+87lvXJyzGnz5//M8+ZPuFo\nwFh5V+0WmTBN5Sij3XYsaO+460+ioU7ozLu5Py4zglic2pPYMzWPykx1miEWd/qMVEguv2WDklFl\nfrKW4ZE7nadFRNB2vzvfbnLWVo6xinbi+lLkJQdiSts/6pPLNDDvv8viPWcWakSaTBzQj4qC/sit\n70YjJpBlVqIhnJjBjayho94QW8x+Gp5fWCaSU++gWzDqj6X9Ee1YzJHNBmNxMk2jgEiYhkao2L3u\nAk9GRwOKkXunl85t8slnLgBw/ZmLHA8di26CmB++7VjFO+/+kHfffAOAwKTs3LoBwOryMiMJHrj1\n9g84u+jGNmkugYyJMSVxczbzSaZKgsQN2uLyonc47h4eYW3FIgYoEfNpmrOz697D1iYo69753k7P\ns6+tliYS6q0sFAgLMypSmi03N1vteY6OnDw9PjikJaa9RmeeQoJpkmbLO+qboiAbuPtDrWi3J0zE\nw2BQiJjCEpHKXNi4cJ7gWJzdjw45EGvGH/6zf8LurmP8Np7/FEqCQZSOsGUlixVUjBuKQldyIqMQ\nxjLPx+TChhjV8IyGKadcDBhhqUzcxgdTlGgyOxu7CJCqgqKsgo2sN5sTGmzhxj8rSy//wjAiDCfB\nLF5AKe1ZKmu1d+mwKqdyUo8CTSHyu8gKtKyPHIsVdjQgQlmxlhS5d9xPwialrL8sSwns7PtioBWd\njps/x0eH/NG//kMAFheXOSfyMowj3xVjjDftNRtNZGvjYHDEnOgBSZR41lWphHZrQfquKMvK/Jph\nZC2U1lJWwV5lSiDvfdgf+z3eMtlP8rygLGeXqx+pMvXb/+z/IagUk6hFY8UpUy9dfpJf/OTzAPzC\nZ19m0HcL46Db462rNwC4du8+/fI+ABudRZ5+4gIAb77+LV695EwIv/vlb7DwtKN4D775Vf7t//Nb\n7reasLrmfmtteZGh2GLXT22RC4W892CbzVUX0fbpl19gbc3R988+/QJnTk02x4fhePuBV46Wllcw\nYr4sy4yGvLzxoO+VF6U0uQjYgJIkcrNmPBqRyaYWRzEI3Rs0WyRijoyUZih+D+SZn0BhoCZUZVk6\nvwAgCOJJ5JvVjEThUhbC5mymTGsMpZgQ3VyvqGeYTKeTE3Da12iy6Ssf7WWVNAKxX1dRKNZOyQk1\nFak3+Q1rwTtDTCtrxvj7C2u9qXMWFEVxQkmcUOpT0SaTTlMUhRd0SqkTJsVKiXLRL1X7lVeC5+bm\nWBK/nr3dHRripKSU4vDQ+QbMLc/56J0wjFhdWQOcD5GP2npEZaosCoworlmaMpCIMx1NBHWn3UaH\nTsi3bUAiJqJEFwRLrp0lmnI8lDZr5iUatb0Wen+PUZaijh646zKlLKp3nVAZrG0J1puvlRfgZZmR\niCSN4oTWjPMUxHQlgvTalT2uveMi31ZX5lmsfJdySzoSZWo4dr4pwMHdO7zwCScDLpy9yPlnnwHg\n8tlz5Llr28L8AoW8393dO9hd5wN6fPsm7/Scm0ASJuxIxJ3a7NARn9EwG5Jnsi5DRTLnFI8gHWKy\n2fzC0nFKIhFnYaBYWHYHSaPg+NDJBWUm5v8wcKZbgO3t+2yuOXm3tDTvfTIVJUOJ8rQGyszJxwLr\n5VGSxLSlH73egP0D19eNJCEUeVrmmY/8Mo0mpXw3z0Y+qnkWbN+/SRXvtXt0xN1D1/5vf/8HPDHf\nljaP0SLT28OMvR/8KQCddsJ4wfWxrzUEblwXGy1aIrcaKkSlsnbGQ7KRM8O2OgGnFt3m3IhDel15\nh1oz13F7SW94RG7cujnuHnvfImssIzHhwqce2sesnJjubaDBr8sRSkxs7pgovlFFSaVvKaW9rAoC\nTSgnEoXy8kkpPSUaFZH4LxJqKlewqHQmVfkxwrBai0PsUJTHsiCUd1qi0WZ2oWrBKzVJs0Ff/ERv\n37jJpUuXpP3BhDSovgSYsvRzIAhCrHEKkTXa+xVbq3zUIVMERRQp36/j40MOJdq/zMesrawA0Ejm\nsZUypaz3swP1SHK1NvPVqFGjRo0aNWo8Bj5SZuofP3OWD8QZ8+r8MotPOo1048wpn/Phn/7R17m7\n7RzMPvbkRS6cdqa3bDziquTa+d6NW1C6vD6L8xHXr18B4Ppen+dfdNrmp//cL/HOD1wOqXanwc9+\n9qcA6O4f8/5b7jlXr1zjN3/zN939H3+BU6ecWfCFV16iJSbIdJjS784efaJtSSDae5antNruBDwe\nZRO2yJpJNInJyeREHmlFJCcLG00i+JSBhkRX2DACMclkeYGS62TqxJ4kAaOuiyi0Svn8GyhNlExO\nMYW0Jwg0QTibXu2c8qqTs5pinRTVicrak5F6H67d24n1bPpTayamtA+JfpvcN2GmKofQk/ebCVOl\n9NSvzYbpPFP+t/XkkePxmOWVJQDOnTvH8qozC+fldDjISed7n57GWM9YJUnC6opzqt3d2WFXnC6T\nJGF+3s1BrS337zvnzVarzeLiirRNn4g2eZRT1HickgrDOB4pxuJM32gWdDpursWxpiGMqDGWjpjG\nlFZk4lCMhaKschcpGk13/2hQUIp9JgwD8GaJECXmhHGWEQTivJwX6GBiPq7YnyJLacg4LHVa/P/s\nvdeTpNl1J/a79342TVWWN91d7Xu6x3QPZjAYAATIJUUsAC4oEhJJMaTQKijKRGhDL/uokP4Cxb7p\nQS5CJpZYYbWkAksKZAggCDsDOxjb3rvqsukzP3ONHs75blaDZrIDEfNU5wU9haysz1xz7vmZU0um\nPw2Px3vIBlQ1SROBkydIMZUNCzzZ4TktFURFfM8Nmkyy/tjFV/Hrv/k5+ruzLUR1qh6W/QH6+bi6\ndSR8/SozmNFU0ZmLHFxG65xROdKIKihh3IRliLZ08BVeXRYwrOKUkCjHlcfWPxxaT9RqCAJ/Mm/O\nzfrx3tvbfwqmlrzOZsMB2gFBfrPNORTs61UW5QGhh0IY0rpibQ5tKlLyBLIx1mA0IuL7/t42FlcY\nsnYOMqzUogFCVtg5oz38NFUMt7yqqxELWK7C3Nl6gosbhGa02gGUoEqZFAbZ5lUAwOM3R8gbNC/d\n3CIWNmieBY2mV8oOhiNE/G+b52jU6X0m4xCD3gMAQNhagmIYUQVALaYKoHQZBgzzSuR+N1VKwSbT\nq07hJoRpq0toRhjCOGQfKQrjKiXdZK0OlITluVJa673GAhmgKjtJ5UhlABbCsDAkcCFcBU1qDSWZ\nnC0DKIb5hKvDciVI5wMYTT+PwxgO00OZxmiEQbV+SC8q2Ng4jjRN+foNpKoI5c7vW0mSeGpLmibQ\n5eSZVFVO42gvBQCtS7++pnGEOzeJgiEgkPP7iiKJTofW2t3dLjTTLhaXF6B4zfvxT36M589f4L/0\nmx96jx9pMvW5//F/wu8bmhi17gj2EUmJb2/exaNHVCK/vvUY2QPaON658R5unidFzajUWF0kO4R/\nZ+Mo8gElC9Zo/C9f+QoA4MHmQ+j3iKvwpd/8PP7g3/sDAMDxtXmcP/0cAOC9qx9A8zXcvnMNVz4g\nafNnPvYK5lk2LCDQ5bKuLbTHZacJYzQiLtkO+12vftCl9uaZwlqP3ZZae3jOHlDw5fnogFFnCWuz\n6g9gzLBBICaK/1pa89LyVEVeHiysnBgjmgKK1XzlaOANP5WUyPLpFnAyNZukQU8bb05+/neZXhKE\nx2oN6Xzp1h0EzwQtxPR/2Ar9o9/xfIADiZIVpMwAy5w9fcr5srKEgXTPpuY78B9+Y7JWeKXitWvX\nMTdPMMCLL77oVUNOWP8UDqr5nJvw1aQUfrIrpdBg2KAocs+T0lpjgeG8ohh7OK8sNNK0Mbm8g2aB\nz7BJDYsCI4YK8jLwC4i18DyBQX8MxTL9OI5R6MJfW3UvKghQ0QqKUmNYcTwKATMkmBIq9gujtA6W\nvwcy8Oo5KYSHo9I0xswsL9rJHEJVJW5jjAbTJ4z37tzHw/uUQA2KEc5cIPXXw7u7ePyAKAP1Woq1\nNTqYvfL6CRw5wv9+7eNYXKKkNet1EEpOdpzATC3iyw8QMiy7PP86FmZoPGx2v46dNiUqw1EGwfLz\nR70M6NM8G+cFZmdZPSWAYszzG8JDFx8W1lqUfODS1nqLB6kCzM1Rop84h3aXISohIPmwZqzBcECq\n46LoImC4sJE0UGQ8n6zzh7VakmDMa5kxGoIPX81m3R8Se51dRPw8arMLMDznVBgi4J87W0JnEzXy\nh8X27Xf9YWZxdhXrzIPd3rwJx88pTWNoTnYaaYyMYeewt4OS18p4tIqNVVrfTy+tYOPMWQBAVGug\nz+P01q3rePiQ9qRBVnpu7VjnXlFamBwFHwacMQBv4I1GDMGHinxY4Fm2VkdySgBsAcOH6yIrEXBS\no6LA2y3QYZZh8MJBMh/UlKVnPIgw8muvLie2ORDw6y7KyfpdWgvByVqkhnCW3pctEmSG7jcXPdQV\nFQdCo9Dn5zxNSKEma/mB82baqPkE0DjnkyatDRz/u93Zw2hMfysvRsjGrBje3fOHycIYb92iswzH\n2JpkOBzg4UNS2Z47fxZnztAaIATQ3qWD1hvf+wFGPOY3TpyD4jny4NoNrHCiN9U9Tv3JwziMwziM\nwziMwziMw/hb8ZFWpr55+SoSLg/bIMSR56nqtPCJV/EcE68/nRX4z7cJ5tt6/2d4jz2hfnj1Ot7i\n5Prx2gk0VqjsfnqhjoUa3cZ7u3tQD8hv5Otf38cLs5S1bqy8hHqNSu25tviv/4t/BgB4592f4F/+\nX/8PAODf/Pmf4Y//6R/R53Fy4vEoha8WTBN5NkbJJXsH50uPSgYIq8qKFBgwVGCtnRAI49hn2oN8\nhEqbFoaRbxNQS2pQmitKQiBhwm/aaCLhbL/ZSFGfod/NCuvbRkgT+CqOMTnshMWIYErzTWssnIfz\nxFPVkL/LfPMptQmMv1fpJGzlS3XgE9oa7/kRBgEcn5b6eYlt5trDhWi0uGIigIRfljGTE55z8OTj\nUDioZ6hMaV14EjaEmIgFMan+tFqzePyA4OL5VguLK6v8IePL63DW+1JZA1+doQrX5JrHTP6GVB6q\nqaexN++LgxAzXL2qN2d9xcRZM6lMCQDPAPMpKVDncv/8jALArY6c8SiMEhEsQ6iDrIAdc0XJlJAM\n+elx7k1hnVAYZHw6L3LM8oCUdkLqjBKB2ZhOt1Gc+PYwWhtfNanVUk/Ez/IMw0GlqhJ/5xj7+6LT\nGaE/puu8dq+H5VVW6DZa6LFP0sryEXz6M58BALz6yiuYm6XqEgKBUY8qN3rYheNqdlSfQTJPFfIg\nCOAMnZiDuIkT5wl2erk3xp9/7f8GALTbPdRnKrg5RpnRM2ykIRbn2CMqimArI147aQv1YWGd8JUR\nOAfn2J/ISThuJ9WYnwMcQ1Q2x4jXnZFVpJoEEFgDJVhNJsZeVZnnBrD0HyutBT++CgNvQCylwMwM\nrem9/S46bOYpohBxkysjRemrJ1IGUMH0ar7zJ9cRMDS6s5+R4guAyx1Yt4OyBPIhQY3NpIW4RmNn\nOBr799O/dxtX2Evv5k9+ikufonZhSxsb6Azo5+++9w42N6liaa3z87gY95Gwz9vCbBNLDO/LpIn6\nKlWPbRyj16X52t/J8OARQUv/1RT3aE1Z+TADwiHm9YwEeUxqL7SvtDviUQAAAjdZn4Q1EyWaKbwY\ngGghFXwGv0YWxiDiv9VSJWYj+lsLtQjNkGDqJK7j6gMaG7tlCsdmvb3Rlh9j04QzDgduEWyDhgf3\n7iCufKyk9ET8fjFGlxWjvV4XI67cChkg4IqhFAIRqxFlEPhqqYwkct4jL9+4jt19EhUY5bC0RFCv\nNQ4L8/Tv5cUW3vwR+VO+8NILWFuhavYL50/C5NNXUT/SZOrKtXcxN0MbgVQCw4d3AJDrcqXSqc02\nkHD5e/6Lv41Xfu8/BgB8ur2L/ApBeDffehvff0KD/t2dIWJOlJYXWzADUg3JOMOJCx8DABw/edz3\nlQrjEIvztKj+zu/+h3i8S4PmzZ/8oBLMQWICVVsHX3qcJozRHoeGACSPGp0Nsc2mZRIOT3jSQggP\nsbXm56F4oAyHQ7gqiRMSitONo3IDNd5o8rz0A9Q458uMRheQvGBJ4VDkVTl2Ar+VpZ7AUXgah/8H\n7++A0/pBF03n3AGzToen3c0nSr2DiraDvzsx/FTIGFa986SN3T1aJPd6GjHDKxtH5tBmhXwoE8RV\nLy5ToFmf9HcL+J4ikQLP8A6FFN6iQh5QwjjAK3aWl5extkqb6pXLHyBkTluU1H0C5aydWBcI4Uvw\nKgh8Unb16lW8/c47AICi0Fhkk8mj62t49JA4GyeOn8A8TRusrB1Ba47gigpeqS7uWThTw/4IKfMN\nrNGej1EeUH/FNYW9Id3LVneINKSFJQkCzASV3YaeQLemRMIy+XoUYLZG/KNAxai+VErreVJBmCBn\n6CiJQ8w0K46Y9JuIdBopy/+jOPby9mnixPEVpOzIbkyIMycIInJa48Fjgn9a9RbOHKefz8RAOeKF\n1xmMO5RMDfe3PTejOT+PWHA/zKgxSVqiBIo3+ksXX8Tld6gP4INbd1D1I7XaYsSmvHmRIeQuCEgC\nNOboWSVOY3Z+AuP+g2ENLHOgpJhwsJwr/JiVrvCKsLqq4eEdGlPp7CJOnTwOANjafeCh19FYQ0lW\nlMpJ8pqNMw/J2iBCyO+5yMcIOSOu1VK0O0S/6OzvYIETkCBKUbApZSSVX5umifF4gGJAa8BgaHHs\nCG10Dz94F1ubdOiesQJSsfmrkx7u6fV6sOyeL2yAcp/W+v0nW/jaNTKOdaGE5TXa2InhsINAwYln\nIAXqyzQB+/0e9DbBQ1GzgXZlIHnkBK4/ps/vdzXG7el5tkU59nwNGSqUnqsg4Krz7gE1s3A40DnA\noloFpJT+MBZYDcdcsCIMEfG8ERITWoSziDgZ/08/G+Hjp/kdqXk0qncXx7h6jz7z1e928aNHE97c\ns/RUtTATF3M439uzs7uNN5/QvmitxdFTJwAAC+vrqLMdTF6WGHAyVavHWF6mNTKK1eQwZhUsJ3qi\nTDHgMTMyOWLuNdrpdjFiNWsoAxR8UFw/egSLN9hCw4yxu0VzxJQGWTadZRBwCPMdxmEcxmEcxmEc\nxmH8UvGRVqa+/s2v4Ch3uT+6esRXiGZrs95SPo4CX56spzEC/nk0M4vWEn1+44//GPPf/msAgHzz\nTXz5GEF+P3wHiGepBCuaM/iLv/4mAKDRmsOpY3QKO3/yOI5t0EnUSoWXX74IAEhrCV58nnpuWaM9\nRARrJj2XpgjnrK9eCKG8auTKu2/j3nVSmcRWeCt+pQJPIh22WlhZI18UGQWQXKWy1iGpjB07XQwT\nJoLKALrK9sNocoITBiH7Ww1HY/T554GKEHHJvNDGVwusc1OTl5/uBzf5uXyq953DASa4Lz07KVBV\noDTsgUqWAKO82O2O8N13iDB4595O5d2ItdU5HJ/nsrLTkCM6IdUXZ2BZORUiILM6AM5q74MiXeBL\n5NPGU/Clr0zJA5W9EsvrBO0d29jAHe5gf+rscxNBwQECevUoAGBvbw+3uJXS1WvX/ClKlxpPtiqF\nVQNHmWyb1lIP+a6vr0/8V/C0SemzhHESA64WmNEQmmGeRr2BqOKn2sxD3HEYoh7QH24kKeqN6l0I\nFBmfhkOHR22q2tQjgTpXbWSs4PwpVmI8os8MxwXGrCJL48j31rJWeB8d5ybGsNbCK4KmiUBqOEMV\nqFpNYHuPqiYz9QRxZfyXxJhlmkDR34Vgwmne7+Hq22QMvP34Mc6donnZDI+j4EqPaiwgaNB6o/MM\nET+rmXqMz/yjXwUA3H9wDT32nOrsjTBm1aQrRigYQmi2Yiwt0ck4NzmSZLpl2bnSj3FC3RhutcZX\nGsNAYTymsV+fmcWpU0StuH/vLkRBFet6IlGYqqWKot6IIEiuqmpv7Q1hebuot5qA5HcbWhhTmY+m\nmLGVeKGLAbf3mF9eRRxV9yQhn2Hbebz5AEOGRk+fvYTnnich0c9/+H0UvID0rUOHq2b1SHh4TpsS\niknqcRzAGXr/aeCgLLdpMRolG3iGUnkUIgwjWO5dKpyDZQJ0LY0RV23B8jHKLVqLH+8P8LhN39Nx\nNQy4qjlNKOl8K0pntVd3Q8D7RjmHAxQJB1tUFZOJTlkq5c2AtVDexNXYEpb3ocBM1l3hxIS8Pqjj\n4inyVQvcEFKR0s2JAkfmqFKqgjnc/DeEqGyNAxj3DFUbKaiNFqgdmmXDzzhNcXydqo07+3u+3+lw\n2EdV68mzwvvOlYX2HlVz0Qw039f21j7KIb2LjfU1vP8+VR5//v47OHmcXANko4GsYEgjCvDkCa0N\noQpx8fwlAMBffuXPkHXp+5u1BNHM3NT3+JEmU1/60h/h3XfeAAB8+yc/RZPL+usLs1hq0eI2kzZQ\n800xU+/erUsLr4hUIR4+ocF6dGUdncp8K61jn91vn5+bxxLDhT/+5l/g7okzAIDZhWWcP0P/PnLi\ntO9l9F/+0X+GeoOuoSz1RCzmrId8pokwrAG8MRlncP32XQDAG5evYsw4brfbxjI3Th2OCnT7NMmP\nlhonn/84fdGJk7h3lWDN1YUW4oQmdgaHMZuaRkmKNKTFXziBgrlaEBY5Ewr6/aHv0+UUEDLHSigF\nzZ9XUnpl34cFSfwr/oPw/yYeUAXe04QHAIeJc6/wLCmCOkXFY1ICjxge+Kvv3cR7N4iLFIcasaBr\nV3A4foT4CdrV4Nhlfq5ZR8aLuVTWu2Vb6zzEZqxBrqfHvp07qFicGHVK4KnEukqaj6wfgaz6Qv2C\num7MSfNoNMITtvy4fee2t0AwxvjDgy4Nxrxof3D5A8y3CM5bXFzE2XO0iURRxFDrLyawzxZRGiDj\nCZXW6pAMh0RJ6FO00jjfv6pWk1hgrlNgnS+pG6nQY2WqcwlqnJistpqQ/MytFNCuskmIUPKqU+Ql\n6iHBM3GovIpNytA3NwYmXDNjtHfYnmaJU2GElLP0ZiLx7vt0mKmlKXIu368dPwqTUzJbSIU6r0l3\nHtzGX377R/QcxhmOcLITBiFUJcEe9+CYWyfjHgJW7QkZ4vTJEwCAC889h7/8GkF+sNYfrmqhRsgb\nBzRQDmmc6LKEttMty8JpCN6UhJO+/5pwJapsVKgYsaL19PHWAC+co41lYWUBnT7BK2kjgGZemi6d\npyYYqwFZ9SkTCHjtgApQVuaKKvAHT2tLb5ngjEXOvLRRmCCdn+ffVXDP4Jw9Hg1QsInpuz//GX7+\nLnFiTQS89uuUsN587128c4sOMydm5xBUyZTWCBmeTRshJCuitQYU2/MrE9PzAqhNBUcUwc9LIQNk\n7NRflhoR20WkKkLCa9tMJNBjztHO1kN0mMM1TQhrYHntJGcYHkeYJIZCCoiKHukcNDvmKyE8fCaF\n9L9bSomYx0AkJm7igdMouO+l04AQ9Jnv/uwuzp+lNew3PtGGtvQ8RV4CQ7q2tegEFhL6ns2OhJ2S\n2wcAxkqfwEohIfig1Zxroc7mqGOrPWdqMOj75swEjbMB8LhAUdDeH4aRTww7nS5EtSYZg9t36frL\nYgLVxUGJwYD7oNZjf9Dd3dtDs3L3D2LkPYL6oyD2fTiniUOY7zAO4zAO4zAO4zAO45eIj7Qy9btf\n+EOkEWWhP/nZLVw6/woAYH6+ic2dGwCA7mgbKeMMYsdNstO8xJBL5ONS4sIGmWmtzsd47wZloa3G\nLF54/lUAwHl7H1+89AkAwCAT6Bb0ne9t7UMqOnHMteZ9J+utzSeYZ5avNQaOS7/GGIL9pozSWGr/\nAmCQDXH5PvlnbZw/h81dOqltZxmax8nPRndHaF8n09FiNMYH20Sg/+J/9J8gPkrlz0cfvI0hn8hn\nawkMq92GOkM+4uNKIGC4PF/muVcRugMVGqEMRnxikgJeIaEC5Qn6HxbO2gMtaSaGnFI6PO0pRf+r\nHbDNZdNe/2BfNekrWd3hAG9dp6rN1euPAUef28lL1CJ6lstLc96srTU3B8ctEbLcoKjUcKKErIzk\nnPHXqbX28Mo0Ye2EqO8O+kxhUnlyByqWQghPCs8KgwF7oD150sf+Pp2idnd3sc+eN8WB1j9CCCiu\nnkRxhKLqE1cU2N2v/IEkTh5oG1Ndj7PPakU6iSSOEIbcjy2IfGWqtDkGDAtpF0KxiV4M4NGwqjAq\nCO51KSXQGdM7crHG88vsSySBAf+tsnS+uiClRaCIvNxopIiYtB0EwuOpRuOAUMFB6wnsAT39Hc+2\n5hDwcT42DrZHY+zh3REQsKHkySMYckumpdUjsDmN1bzfxoDJ4o0wxPKREwCA+sIR7G2SF9FW+z5a\nR8m3Zi2dhXCTKnHMlcpLL7+Ob/6/XwMAdNt7KLhaECQO48pAsGYxHlf+U2MvQvmwaEYhhoOq4qr8\nuzLawRaVilggiKjibkSJn79PlZ1PvvICTrToNH7n0RXfykc4hYQ96kZj499DGEcwvKYUZe4rC0oK\nSFbuGFv4HmqzszNod2itabd3INnMNa7Nwtjpz/Crc6sY8zpVFAU++4mXAAB3Hy3gbfYU3NncRJu9\nnxaKOiKu2kC6yisW9TiEGDIE3QjR4zVjf1z6SqyzFnHCSjFpvJAoEgoR70m1GjDToHerHWAqs9Px\nCAGvT2eOzuKIWpr6Hk2ZMwWCFHyViSyEQIX/SRFMhC0O/jkr5yCrSrXQCFnckQiN184STeDO1hNs\ncc9MrUoUXL1PpMWxOv3uajqHr3+d+tTOwkFUfVsf7CIYkw/X9YEBCkJ1FhoR+r1qhn94JHDeMLaf\nZQhZlPHzt9/BOqvtzlw471tc2ZGEYxhchNIrEMMg8iT7fj/z1fm52TlI3rN7nT4ME+6bjQaePCJC\n+ZYFnj9DdJ+ZkxuImQoTqBE6fao8nr54AVd43pd5DllOTw/5SJOpn73zU5K+CLAAACAASURBVPzp\nn34VADA/18Lt+8QbUfIMZhrHAAD1UCKKGbcOBHLG7HuPtxAJKu6HscD6GiUa1248xEydSvMOEhHz\nGe7db+Odm8ylOXIcM8s0sE4trmNmibguT3b3sbVPcIuKY68CsWYiOSfIZ/pkKplpIOIZ/PDRQ4Dh\nudrMLHYuU9I06o3x4DYtyFGcQHLJfF+P8JOrZAXx8Ru3cOH1T9EzqdVx+advAgA6WYbWLC12WpfI\neMBtt3fR5E0qVqE3UnTC+gTA5mMYXnSkCvxEtYi8Q/GHhTngCC7xdNLx1Oc8zGc91GIPuNfmpcOV\nR8Ql+eDKfez3aMIW5RglK7xkIHHiNDefXpjH0FRJTY40peRl0NuBZJhPSAlXlexhPafLOIthMb3B\n3MGEEZhoFoV0sMwTcLCTpAYT5sJgOMDDB/Ru9/f3/LMy1ky4dFICXgqvkWVVYkUO4QCgoggN7te2\nuLSIMKjMFq3v/Udf/Xc//w+LRpyQtB5AHApY/rs2dwgUK+wihaBy29cW3er5BynGnHyXWYGAuwWs\nzgRIuafXuLDeGT3PS++276xDUCmOwgCmaghrJEo+MOR56aHMOEmgK6hDANEzQAtKOCyv0AFpaX4O\nEc/jhXqEorq2rAfrVvgXHEb7xFmbazbwuV+j+VcLAywtsR2CUHh4j97vD969ifljtBH8zvIaWkw3\nEFHo7/f0uXP4/L9LTup3bvzAK9n6W9u+IfrzLy7ji79DXKYPbj7GYDBdspH1Bn7DiZIatGG+oFCo\npwxLOiDjhtZRQ6LPXMNb793GmRN0oMs7QMhJZ+kKFBnz4Yz01NEgsH7tKHOBUFCCZp2E4I1OyQgF\nvyslBZIGjd/9dhttPiQuLkvIePqxevbMWRTFhI5geOxcLErkTA34yp/8K/TYyHE/NpgLq+a9g4kq\nFxZBBfnWa+hzMlWUBiKoEiiBIq9gNY0aw3lhkaPSzCUiwahD+4pTKVI+DBR5iSEnj+cuXMLF11+e\n+h6dNZ4u4Qy8OSek8H1HnZnwI511UFWvOkhPqRBWQLJb+UYzxq+fo0TfDTvYb2f+Omv89fN6jI8t\n0nxaa8zi3Uf0rL7+1R0Mn9D3fPaEw8VLBA2LU6/iaEJQf/fmFna3nkx9j+uzEURMY2Y+WsMO98i7\ndfMWVo6s87UV6PLBZjQcPdXEPeP1pt/b8X1tAeKTAsD66gqOLtNecffWbU/fEc6ix3+rHJcY9hjS\nLwrPDWw2Gmhwv1sVhH4N3r9/H5mePpk6hPkO4zAO4zAO4zAO4zB+ifhIK1P/3ze+icdbdJJ75dWX\n8ZOf/gwAcPHSRXzru98DAOqkzuXV82dP4dgaEbU7bQGuDOLS+Q1srFI2u7a0gZu33wMAZP1txBl9\n/9JLr0G1KFdcWV5CNENl15/+4Id49/3/HgBlwj99m9rJPN7cxD/9/X8fAPD8hRdQa1IGXpQ5ymch\nLwcRSu6Qfv/adV912traxdaAsm6jImzv07/rMw6CYcdZozDgNjY333gTLVbeHL/0KYQJnfLe+MZf\nIB5Qxp6IEA0R+evsMpF2fqYFwyTSUCo4Lvnn+chLyqx1QFUSTmsIpjRgcweqIb/oM3WwOjLx5rKY\nqdHpp9UIvcJkXGj86Aob6g1GsHzyELb0/kf1RoqQYT6nJAyXdN/46T3UEoJnXz4zD1GdCazDxBoO\n/lRqrUNeTF9dtAfuxVrrDVydk0/dY8lwgnUOO7sE5917uIndnV3+/wvfXzGMIt82oTTaX1ueFR4e\nDaPQl7CVVDB8KkrTFCkTJJ1zExnlAXLkLz7/D4v+KPf97+rNSRWsHiVIahO/J8WVKRUGWOFr7nQd\nbltWzQYBBLclqQuNwYiuOdcTeE4X1sMkSgrvjzXOxwjzygfKQFSVsiRGWimppPDKVBUGCNPpz3/D\n/Q5GrOD7J//4M/jcrxCtQAAYcy+dcmzwZJs+o/OB7zu5evI0TrxKBOcscxDsfSbjGPNHqYruLj/C\ntWtUbe53dtFgIm3UWICsYESh8Pu/92UAQNOtQ3GF4/vfew8fXKVx8vrHz+DTn6Lf3e11cePWdOTl\nUVYgZsJuFAFlzua8ASAEE2prsyi5H2oaKDR5PR3v9pCxt9Ta2jHcf0R/M44iGEPbQpjE0JbhcasR\n8jqV6Ry64Pemja+MNGtNBGwcKpzwlaDZhkSfKwKd/S5m5qdn9UopEfEaoJRCyWO/mYaYDWjMCpFg\nzKqGvcJ6nzQYeB8iBYuYydNJLUbYi/19FTmLL6LAC0xUEEwEyUWOtMlwdBhhc5v2mOUj876CbYVC\nn01t+4MhllpTeoUBMNb5Nl9KwnsKagkP7YnCTnqsWkCxya4JLRKGTUsrcO4sjaOPrS3hu3/9dbrO\n46s4xQaqiZFYmmfPQh3jsylBYFp3EMzQc7j9EAhYJHDhfIrZBa6mLqcYXyY0oXfvMo664dT3eHVr\nH0LS51945VW8wHOoVotxhA2PdX+E8R7ti3mee9J8rVZDzL5mYc1iZob25rm5OW/gGYbKm+D+1eX3\n0Nun62zONf0yGUchelz5+s53/ga1Oo2fY2tHcWKDqnhSRBBcPV48uoj+oHKK/vD4SJMpk3Wwtkbl\n8lu3bsIyjyUqLJbZzPPCS+cxYmVLp9fFVZacb212MGZJ5Bd+7TMYFTxRFwPsjypJdYlE0nc2aily\nLve+ffMuTh5lWXeaIozp8404xJ/dp8GkrMW771NSJozD3DxtFuMsw0xzdvqbDGpos5LA3roKzTLw\nvnBYZYXdwFgMeZLkmUWTN5ovrp/BPk+q2zffxeo9Wqhbcy2c3KBS6/jSx3HjMkGBu8MOSlZ/xYFE\nzAt15ICEHbNlGMIDX0KhrBy5rYFg2MMOh5Byyt58znlMX0jpE4G/vZlXRp0ThZ0QwmPctx8XaHAC\nd/H0Kh5w49nClqjzII/j1PN6jDGo5Cz3H+3g+CI34jQ179KtfmGffboZ8vQL+EHFnpSTZsICE86U\ntRb9Pm0QDx48wOYOLbBZYXzyLdxEEVTk+aQ3oxQImVcHMUnKpBIQ4E0K2v87DELfJ+zp+3JP/exZ\nkikVxQiZH9KYqUPw2BGYSLCLovBKzMg5WIZTe8Mxbt7Y5m+qod2me+8fb+HUfDr5nuqFOAdbmQY6\nSfwoVA739JEwDNDkhC5JE9+XK04TCL7OIAr9pjNNfPDBA5TMO2ukkU/QZtI6WuzabZIAW44g5qzf\nRSOlJTHr7QCsJB3Yuu+xmaYJVrn5+uc//xkUvITONmcw5sapKqr5BRkuR2FoLhp7EkFGz+3C+lls\nrJ+nv7U/gisooWs1JDZmZ6a7QRXhQKYPzfydMAwRRxMYs1IkJUmMEauZTKCR88qwOreC3TZBl+Ni\niBrTJpSKUVhaX4rxCIrfSSDhoXglJWSldnbWb0qdTgedToeffc2bIPcGPahw+ncohfAZkXPOH8YE\nnIepIZSHizuFRslJ4nKkUGND5zSJvb1MLU28w741A09JIIsE/k7jPCyfxA5zbNCbCYU85sbO4zFC\nPryN8wL7/Ez6RTG5tmnCWm8YLZz1CrsAyiv4pFWwlR2FNQCv3bG1mK0SzIUUv/sp6jm4ffnHGHTu\nAgB+9R9fxGdfpv3shXMGoaE5au4MEP2YFK59N8Tc6SppdcgzGgOPdjW+c4t7EZ6LIPv0mZWhw1Ez\nObh+WNTnVpCNaYxvPXyEz/4H1De33Wmj26aEJQgCTytoJLVJ38Cs8F1FlBT4lU++TvfywovIskot\nPcAm9/pdXJxDnef32tqa574lcYiIjXK/9m/f8JyvpcVFvPIKHbROnT6F1hJRSPJRhM5w+oTxEOY7\njMM4jMM4jMM4jMP4JeIjrUz9/pe+4E/nnUHP9ztaqzXxT36D+mMdPb7hpWDd0QhbzPTPSg0Wq+DU\n0TUEXEaPE42FOSKjv3rpeaxx/61IKRzh1hxQCpohk1cunkeT7eWzx5uYYRJmLBzmlsgLpR46NCIu\nuxqHYac6hX94JOkMNncI9lgdt33PuxISOqKsexwodNlLpmetV8wE432ogK5tkHWw/RMinf/o4X30\ntynrboZAPKaT0Xh/G5YNH10YoMG+RA1rIJlgKSG9skiGCYrKe8loX0Y1pUauDyrt/v6wbuIVZQ4Y\nxlGfgsof5Wljz4MqvwpGObIY4tQaKSucsPjxbTrF3nw0wmzjQF887q3VasUwTK5cXwpx5ihVC50u\nAZFUFzHpPWgdCoaTrLXea2uqe/wFA9OJN5b1VSvnnK8WxXHi4bwyLzyZNK0lSLnNjDYGHfbd6fd7\nviITxwfgVUfKSoC8WKo2JK25FmpsJunsgZ4XvyAAmNZ4FQDm52fhKvI3nG9zostiAl9a641dwzBB\nVJnIuhh371PFZ9DbguUqW602wktHaA5FCt6ry0YWMZvvCkhUiLJSEorfS1JLEFdmlUrAcUVSBQqG\nYfNs0IdhgnBrinvc72W4ziRTq+FdzqIoQpqw/1AUIFH0mTRR6LDiNIlj/Pgy+Uz9zVt3sLFOhoaf\n/81P4Ng6VY7OPncaNiRSbW9/F3rEkEDUQD2kk73WJcY5Q/0Pcgye0Ho2HgyQczXq8lub0JauJ9PA\nIKP7ZZTx7w1tHRxXB8q8gDGV35BCh32RTJmjwbBt7ow3iE1qKYZMKO8PxkiZWNwb9hFXSlNpfU/F\nUElo/rl0wrefkVIhYZGNdCXa+2TqqIIA/MqhlEON1XzjAhg+A3QShqE3NZZS+uq0cRop+xGev3Aa\nb3FLplFZoJBs6BuHyPidD3LjFXMCCpXFV1AX0DnDZNIh54pPKiNI3nBmFprY5mL1O7fvo2A4bzZz\nWJ6l+d21At2SlXe6gLLTV98EbKUmgVMOZSXQcAJSV/tQgZSFBMuNGKfWadw9d2QOx3nf2jid4Oxx\nmk9v95fxhK29AitwZIZu+MyJALbkSrLewv2/psrLwkKI2UsM1x6vYfsxVfTevTHATUvVxl85+Y/w\nieO0Tn/jyS6uvP3e1Pd4/tJrKEb0u6+//Co+ydWl4bjv3y8EJpU4TPYNZyetyoSQWGHj76IoULA/\nYj4eYWuXCPHnzp/BLAuqJKiFHADsd9vY3qN7LwuLTpvuvdMeYmeXYMGN4xs4dZaqeyeObniz0Gni\nI02mlmYaaLDCo1E/iYCTqSg6AGOIyQZzLJ7HK+lputAwhmTIxGnte/sIRHj+DBsC/ton/IshaIch\nLee8OgjG+EVBL87g7CVqTlrmOca8iI3HY2T878AJBNPvUehs30OXe/soY1GrStSiRMKlf+cUdGWu\nJgIUvrlxF2gTVLCqQmQ//hsAQD+tIeQEpYwVVniVWpFAWPUtUxKOS6HhsI+cy5NjJ5CzWZqamYWp\nNrVk0ujUZQbT9gEmOIkfiHV+s32qobGbJFkOE0WQEtabMSaRQKCqflESRxlW7eYptObmsciQ1ipu\ng4FlGOPkkSaaDVrESi2ggkoxB5/QFVoj05wgWItnMREwxjwFX1YbioOErdQd1vl+kkEYIOPk1VqH\nhPlN2mjsMH9KhYEf4/V63ScsoQiQMuSgrUFYOR4LIOHNYqY1j4gNEyl5qq7hacjvWWC+XrfnE8ws\nGyPnPmTO6AnMWov9YhJHMVK+hl6ee1nxMBAYMf/o6uX7+JULBIe0VmaR8zNRMp40XRUOtTrdY5om\n/vst4OHRAAqSYUeTW4zYQiDPChTj6ZMpFYQwvJkWkMiZI1aMx8h3KJGJgginVujaIhXAVk3KTYA3\nf0pS8feu3EVnn5KQ888dxfoqJR6j3btQrJrLRwbZiA8k7V2ImH5uDvzdxztt7D6i8QCdwWqao0Iq\nFHyYafeHcGK6ZVlKgZK5gCWAQDF8I0LEPLdGgwzW0r3WajESfvaNRoJ2mw59/fYQKyt0T0mSIMto\n00MWwlUJmorh+DBjXYFATDiFISvaktBgNKSDZ705j4TnbrvX8xzBpFnDsDe9srYoywP2K9IvMdIJ\nb1nz6ddfw09/RG71b9+4AcdcrfZgjP0GHyqN9snmaEbDsOrbBJK6QYAOPLZKZOoJZlideez8KXz3\nA7LuedweohYwh88WWJ1jx/yyRFlRGa0FngECU3AeKnXGgVE+pG6MY/O0Nrx4Yh6fPE884YvnTmJj\nna5/tuHQK2k2LMzlUI7sPzbnE1w6T5957mQfI16Hvva/tfHrX6B51lq7je1WpWocIWM1eBT2sc59\nLO+4c2hkVJQo7ACPrl2ja3jpNEwxff9BGTRwfIOu87VPfhyr3Cw6H4V+TQ2kgqng/XqNeGugtVAy\n39RZ4Q1LsyxDwQet9v42NPMa03oNBfdGjKVAznw6JRRa3CFldWkVaVTtxw61enXYc/jO33ybvvPF\nl3DqxKnp73HqTx7GYRzGYRzGYRzGYRzG34qPtDKV5SNvogabI2TYy8QpLJ9u4ihEWZ16nPEtT8Jg\n7P11RKB8RUQKgyqVt2biwSMBOFn1NTJwfIox+oAJpwWGJZ0Oi1LDsu+L0RqoSMHWQDxDX7fNWx9g\nyCXDMUKMuRpVDxwmoIr0bQIiYTHLlYkVF+IYtyQojINjszRbjBBwKX1OpOCOHTACCKpTjFFw3J8q\nGwzguBJghUPOPi3l/hOACZlIE3T5GSbBhOT7YeFgq4o0tT6QlecUcKAcBcNQ16iwiCoGrLBQ3Gon\njiL0xvxOjMER7rsXN2Zx9SE9qf2dvvd9SaXGhRNE/F2YbSDnCqRxDnHVV0wKOFGpyUoMczqRG+tQ\n6mdQgXV6aLJiRMlJ7dkBHs6zZtKzsd1ue4KkCCJvnlqUOcZVxWdsD6j2YiQHKk2SGxAGGr4iWhQ5\nZppUyk9rtcmjtQfGohNPtb15lspUoS0MV0OKIvNGsyKIUfDYd8KiwdW3SFjojE573UEX166QGe3m\n5tibHm4caeHNd8k77rVLJ7A8R9c/zode5dWoxV59mQ2HKE1lYpkiqPyzNHzbGCGcJy9LBAiD6d+j\nsw72YIWgOv1b45+jcQYFm21q7VCyuWgva8Mx4b4sc2TsdxfGEYbsidbevu5h67Gpw1max7XhPkqu\nihYrz6G9R7+7sz9Ah6sywmkviiiKsYd5ZBAdgF8/PCKu4hs7gaBNUSCq03tbXTuKzSfUnqm7s4vW\n7AI/A43HXCVrpk2cf54QgGG2j4zbdVhj4Pi9aWdgUPn/TcQexjhoQ/ca1SOss8r63oMd5FwJKp2D\n40qZEgKN+vRKN2vtAaNc5wnK0gUe4lxZXMTvffm3AQDtP/kTbO/ROM0y4MEOvavWxjISVoTZJPbK\nuHK3i4Ir22EcYmGWqifPnX8OL7xEfVtXjhzHHJtBj+2f4vEdgpOSUHqS+u7enqeeAJhAV1OEFA62\nIrsLh+ebNB6/8PET+I1P0Zp3fCNFndeMOJAIAqoA3rrxEH/5Q5pncwmwMU/w+ztvbSHtkhDq+Cf3\n8TfXaZ/7zo9iOK6c/8bn5jB/jp7h6EEb2tDeoOQQ+1xtrs1dRO8dEjzdvPwmdh/QnDhztMQ/+4Nz\nU9+j7Wq8/Dr1vl1eXUDG1eb+ThsxJwU2jjzMaoxFyN5PRk2II8opGDaYLYoxekOCjNvjLpIKuYoc\nxrxmjwYZQjZUVpGCYHQjjkI0uT8nhMPqGqn9jS0xHNK1LS0sI02nFIPgI06mynyMktU4oUy81NZp\nCa0YttMaAfNeJBK/AFoYKF5InZGQkgeuzL35pDhQLpW2hK0aRjrr5eTCHJDMl8bDLaYsYdgAzxal\n3xyLwvjNZZrIsrGHfPaMwz1WDLw01/Iu00JIhJKSo0AJRKwySqMABSdEutR+oXZaAwOG+fIc3YwX\nlChAxIaJwWzTq3biWh0FJ4bZ/iYE8xtCG8KxUtLMNjHmUncnHKGG5lT3V2qDMUMLYSCRykrhozy3\nyFntzTnfvrKHlSPEaTu1Vscuc+CGoz4avOB/760neOEUDdrnTy9h2KBxMX4UYL7FNglKoca8kmIM\n9HkBTwKJUDAUCAvHkzErNLq8+VsjUJTTmZICwM9+9GOssinssaNHMdPinnRKTThT1iHnxKfb7U5g\nZK39Bq6k9I2CtTU+iSh14flqZIdAnxGAf/9prY7VVVpI4zh+iqvlWVwHHOidc8/UQzK3GoqTu0Ap\npCk/22Ls4aqigC/BO2Ph/KEi8BBkOeqgMUNjJ5lp4uEWPfPZO4+QF7RANWoxLM+t7ijz95JnmVdS\nLSzM49gKleAtHKqpa4z2qkCrHcp8+oRRW4uclZ7awBvZBkGEmA9vkNKr9nqjLkYdHp/dHtaWiXRy\nsquxcYybwJohrrz9AQAgDgdI2PbDqToUox7pky7qlhb5YuEcxjwXx/vbCFA9cwnL48EKBcPzyGqL\nUE233lhjYEVlOSE9l84Ygx4rTY2OsMAN4jvtGNsMbyppUG8QfBNHyqNSrfllDMfsAu8KWJ5nUga+\nZ5+zdmIsKYQ/AJS1GlZXad48fLyHYZ82JRVFEDwPrLO+ofU0EQQTuwJrLfwQd3Ji82IKXLpINjJf\n2PxV/J//+s8BAGHawsDSc+jlBZI5ep8zyys4yu9z7eKrKDiRbdXrmKtxj9iFOThOXrLCYW2ZNuTf\n+vVP48+2yXLA5BkUw/JGG4igasg94ZpNE9QCk373VFPgy0w9ubgR4MU1+nkcPMTtq/Scb17ZQxLT\nGHnz3TH6KXX6uDXaxuNF+rv3b2V4jcfm6K33EeeU5C4dOYf336fD/sc2cjQNzfVgto75Zeb5jWq4\n/i793e98/3vYZOuTMMiwcYwSrpcuruCTr52f+h5nGzFOcl9IoRRkVazQFpppCya2iGbp+TsA2kPJ\nzh/UhRO+j2yWjdFlHmpeGNghH551QV4hIKPOnBV/ziqMeKzeunMX7S5N2Hq9BsvrsdaFP6DmRQaL\n6TqDAIcw32EcxmEcxmEcxmEcxi8VH2llKi8LxJr+ZFmUk5OuswAq2//Ql7wBB8dMfLgAYKBMuQBO\n0anHGemhvYM6MupSz6cDK3wZ1dpJzyXKeKtrMJPeYHZSFdKm9O0Mpom21mjz39p0wCZXjmYzC8eY\nXCAlUj5tR7CeLB7ZEDFX65QMYRly6JcaJZ/mWnGEBp+kiwIYsCfN3MuvYW6eTQPjOk6yCqRz/xZ+\n/nMiZ97d2ka/6jauDRpnSKWxNxzDTnmLhbUY82lGhXUk3HJBhhGq3NzkmYdeMx3i+z8mhU/n3Aos\nGD5LChw5QpDD/KZBp2RzzuYx1Pg0fD5oYSZmuCetIWGyfT1JEIFNADc3UfI7VJCwmn1fyjG67PEl\nnIDA9Kfh7nCA9nUiWj56sonVZaqwrK+vIeCStFTSw6fD4cjD0TJQ3scsCBQiU5kblgdaWyhfjarX\n6x4S0AfI7kLAq6SEEBOoA466yQOAk09BIM+i5it1OWk5ZAyCsvpOi5SVg6PRCDnfVxQliEDXsxAr\nXDhHz+T2tU0kIT2ThYUUTfZpGowK7O/TyU8XdV9dKoxGp83VgsEQcYP+1o0HHTxaJ/L6pRdO+d5y\nOjMIWagShCHidDpzWYDViL63mUMQVuogUoMBQF4Aj3a5GhhYRExwhykxz9d26cJx37fz3tV3sDxD\nEMuZF5qQUUU96CNepc9HuwrICW5xeR/NhNaqxfk+th5s8/NJkDKM0ajXfGuLfDxGze1OdX/1Wt2L\nZg6KJqRSvo3RcFx6eG5+aQENhrGGwwKKfcyKLMf9RzRHzz13HF2GTsRw3xN8rYYX7lhjvAGtCgPf\n13M8HvsxmKY16B1W7Uk1MfGV8NczTZTFgSqdA6yoqqMG9gD9QvHa84nXPobvvvEWAOD6zUc4cXyF\nr9NgwFX5uN7A0mla+5ZcAsFwq3UaARs+ZUWOolJKQ/i/dfToGj7+OvUH/M63voXc0vNcXV7CmI2Y\nw1ri14ZpwrguZrjC9Ye//Vn81mcJPhtvP8DWY7qGx4+28aN36Po3OzFq7Nc4CGOMq0oiCtxp01gb\nOYWhnOHrLyEDus790Racpff++LHExQWGXHWMrMstiNJFnP0YmWp+ruUgBEHAJ1daXhz0aHMf/+v/\nTBW6f/4v/uBD7zFqKPRYYSr3gRr3VpWtpvcehFLe184Bvn+pcwZBJcyxJXTVo3c4wqhP925GOTLu\n4TgqxrBM8VHNxFuxhUkKXUxaein+TL3ewONHBN2ORkOkNVZodrpozUzvMfnRmnaWOYSjCxWA3zis\ns085TldGjQI+v4E1ZqIIh4OqOFMqOCDJ95Vf/keVTME3/rVaw7JqSDoHwyV4q61fgKybiP6NKQH3\nDL35VjdQzt4HAAzbbfzq578EANh662fYekw8k0gIhMwhiJRCxCXwtDBe/ppC+BL+G/0BHrB77K+J\nJXyay9VpFKDxCmH5L/3BHyLjBDAWAW5/5zsAgGvtDr7xkGwVdssMA7732R2DV4+QYqPZaMGK6Tap\nzd4IBUOyTjYQ8YSNkwglL2hDqxCwU/VLn2riLENXtnRoztOkDmsWfV4oL31iHYL/fp461JlnpkOF\n3pBhl/EASxElbstLs1Bsh7C/uQ1dCTVhkXOyOCyHHo6UQiEQ079DK+A5asMix6279wAADzYfocky\n8yNr634zzLPc2yFIQY2MAaAsBQLWYCdpOpF4H0AAwjDwiYY2xi8mRV7g4QPiurz4/PNIWIVpjfVb\nkbGTcerwty0d/qEIrYCuIEglYdmqY7bRAq9bmJmZgeTrDwOFmOeTFQa/9VmCVR7e66LNSetzp45h\ndZGeSWfvobdSACyG3vzOIuL7TVSAoMroRIjv/YgUU9kox8vnybJEHmiILaSGiqYvpusiR8kSKyeU\nP6MZI1Dy381KB8cqpi4k1vn9zsw4xLxXp80UGbuLD9q3sXiM+X1iBFOwe7aSCBIae6OlBsoObTrd\ny9+CHbwBADjTGmLtDEGZVzdX8WSX+w+q2MNgQRAgdtM1kJWBRMIUgeFg4I3xpVK0LoIOjBXtwLg+\nWgyjqDDCgJvfFk5j8wn3JJydwfoKQWC7PYvekBK7YgSAPo7CwvPkvjm5AAAAIABJREFU4CaydV1q\nnxTGceQPy8YaCF1tmOJAd4QPj7IonhrX1bnZiQlnUUB4o9l6LcGrL1Oyc/PmPawu0lq51gjQY1PH\n0WiEPpsdS20Q8kHLSOcPzqXWsAeg9cqF3TiHkxcIrnrn3bcw5LUtDELUWEW4sDD3bA3IizES5izO\n1BVWj7Dq9/TzyPfpoedxCy/xuGg+GeLKA+JDDfoCwxGN32HZQbNG19Ns1GAp/8dmOcL1O9xPMFfQ\nVaJtTiB+jp5P8mKKTK3wvTTRyLjPoB3gwR2C+X7w7Z/g6m0aJ9c2+3gwovfyz//Fh9/ilctv48F9\nslJoNutYXGTV79w8GqwertfrvtNDLU3R4MNMqQtPqbDaeJhvNBr59w441NgaKNKNCX1HT5JaAYEy\nr3qETighCgIFHwjiOMGZs9TMeXl52fPypolDmO8wDuMwDuMwDuMwDuOXiI+0MmVt6bNBYzRCTxwP\nDhh0WUxYhtafeqQQkFXTJQs4bk/hhCTTMxCEV2Wq1mhv1Gm08f3AyICKydxlOfG50RP/KWs1bNVq\nRZco8ul9UcLaElaOk+nX3mCAc+cuAAAGm4/R3bxL96sk8qotgqaWKwAQSqDOt9iEwA5Xzd4dG/TZ\nCOoneh8XFqn0uJIoCG4J0Zqfx7g6YWmNm1tUHfvhtffxmE9bmbFQ/JnYWRSPqb9dcOoU1MLiVPf3\nrTdvo2QPICUewmlu0VBLPYxSWo2wam2jQqRs7R8lEcQtJlvLEoKrBksLKVRYnXSBBisLN/fHiAVd\ne5IIRHN0Ys50gr0OnzwMUPC40OUQg4xOYEOdwTDhX5sYhZ3+3LC/1/Y9n6I49oopPSqR9eikPu6M\nvE+JyR0EVwK0LqHtpFKqS/67UnoFkRLC+6RloyFiVswJKSC4YlmWBp0Od1DvDZEuVqadZuK7M+Fl\nQjv7TAT0Y+vLsFWJTMCrS8NATcw2rYLmeaN16SsBWigsztC9f/lLl/Ctt+/S5xNA1em5zcklb3zr\n9KSVTl7miLmMvt8Z+D5q42KM0ZgrKFmJsBJoKokoroxDBZR6BiizKKBc1aon9CRr5xQsw+DCON8m\nxUEiK6p3p1FWEJrtAZqubS7NEPC706XycxdawGRcmR22sd2nd9e9ewUNQxXG9HiK+QVaSz71PPDd\nd+h0vrmjILjFSmwHmFWdqe5vrHNEDDs3ZhrIGeYoD0JMLgS4j1s+LrBbsLptbgZ1Vo0VeoiyS797\n7+o9nD1HEM/Sygocw+wj1Yfi+YSRRFkJog94ylkNmIINa+MIwlVogIJgVaAzCi54BtVpOfaVCIJ6\nuKLIrbkAMvb0gg6p8Px5gslajTok7w3zCy082SYoJ1YhHBtvjgoNyWuDC/AUbC485C58xcqaCeTU\nmJ1Dm3vBBgBmuZKyND+Lfn96D6bAJhgN6W/9y698G4LViF/40qtYPkPVoudOHcPJPj2Hi4/38dlH\nVB3L8x6GJXtdmQJlTnBtlC5imXvq1ctNqOfo+f9KOod4htaw8+vzEClVhfbzPvbJHhH33/opbtwk\nFOX23T5ubdP1PDYWPd4vcxFhlEzj9kZhzQiXr5AH1l53D3Wu/C/NLaLHz8rBeZVzo9nAJz/5Gt1L\nFHgUa2vzCYYjWuNraQ2vvkrITL2eIObv3NnZxdYTetfz87P+nUoRoho/J06eRJvb2IRhgC73jrTW\noJZWa7/y5rTTxEeaTMVRCG2qTTBEld8gmkwSpZQ35RJSTNyY5YQbpQIFWTH9de43lzAIvJLKaON5\nT1KJSW82If1iY4yj5A3EG/HKJWv9hiKkmDTOnCLae3uwzCFprW9gYZ6SFBFFXhcgVXjAfG5iaJ0p\n46W2TkXYrFSHaRPPrZJb+JPHt3CdB996EmL/2hUAwBv/+/+B5TOkAlGNOo6vnqDv+fjr6Lf/CgBQ\ntDsI+A8nkcT+Js2e2tIS0pmVqe5vb3/L9ymzRiMfcZk7VIi5VG2Vg6isC7SEYAf29WOrmOfebcPR\n2PNrzp447je3nW6OMSsXV9Zj9PYq+KmGtEa/azUQsaNyIR2yKlkshhjmNNFKEXmYtCgFCj1d70GA\nbBUquDDPcxxjx93l+QVU+8Dq/BIGBRst3r/t/5Y1xk9eFYSTvmLGouSxL8IQFf8PQiBlCC+QCnsM\nTbpoos7bb7eRNgl+yqz24z3RE3d2I0gFN200ZmIU1Y4Ih5wtKEbjzH9/HMfeisAYB1GpsCy8KeG5\nE4u4v0/wQ2E1rtwgSHQ2TXFslSClMAyRMkSLPEOWsdLUARmr/Hb3Rmhxuf/CmWXEISdBQegNP60x\ncMxBq/Sb/1BobZBXRqABvMLVGH43ID5dxU20zqHH3LGgWQMCfiadNsyQk5AFC8djNR8XiJkfpwuN\nmDPAWAr0uAtCv5f5Db3XLhCEND6X6o+xwIeMyw9nfEP0xdAAepIofFhU0HEgpHfbV2JipOqsPmBf\nIqAZWm/v7aM1T+9nfi7EPh9Cdts7KK/T764Xa2itnAAAhI1dDFihqMvMj3FjBJxXTAqMGfKN48RD\n3Nq5yeHUTXhs00Sej5BxMpUmiadxWGv9PpHnOZo8P4osR515tvNzM77/aK1ZQ86qMVtqOB53AvGB\nhujw+wEwsRqRUk4O5kb7BdvJAG1Wax9ZWcJqi55nrITn70wTzmXImOZweTfD//BvqfPFtbv38Zu/\n9jEAwOkXn8McO+/Pn1zF8klS50H0MeoxtN4bYGGB9gAhBRiBRB3nsfgccfiyPEO/yw2NP9jFw4cE\nvV1//zHuPqB9ZWuniztsXTCyEUpuetxVEWxIc1SqGMJOz0OdadQx1yKIu9Nt+yJGnhVe9VmUBZSq\nGmLvY/80cbXW1lbRYlPn23fuIGd7gyQJUfB6X6/VcOMaQZ9f/epXfZP43/v9L6M1R2PDQSPnJLw0\nFjEnbrVaDbUG3fve7jYyfnC97sDP6WniEOY7jMM4jMM4jMM4jMP4JeIjrUwVReEhuTSJPWznTAHD\nJ0IRJlCygqtKCFkRewNfapVG+LKfVNITeI01vr2CsxNfHBUcUPw5MSFPSgVzsA9ZdeoptfdOyfMc\nxUFFyYeELksMOCsuwxidNp1o+6MxuvzzOHBefRI5h6qJekxdo+h7hESficwnTp3FF79ApnT/+s/+\nFe72qLRcLMyjxuTS3e99F4oJlicuvIjjXHIOkwQPGBLdb7Uwc47IdZu7u7h3nQwWL7Vavo3Jh0UU\nJb5HHqSCjBmiDAWkqowH4RVYhTb+JKGExSKrR1QoUSF7MlKozoOzsxLMfcT8TAv9HVbU6EmvtzzX\n0Ky66ZclTFXp0AZZVe6UdVg2YxzpLQzH7anuDyCoIGKlx0ytjhluHzGf1LEyR6zOZpziYYfK5cZa\nGK58Gms9jCxhEbBqxcD46w/C0Cvm5ubmMNugE+eg0/OVL0QRFEONj59s4soNUhf2xiM/9sss9yd1\nJwUMj/f/5r/7bz/0HoWQsJXoQxsYU11bgIjNdKNwMiasVX4OOSu8r1ZgSqzO0PXceDLAfpfmytUr\nD7G5RnD0yZPHkTQZAhvkGHQKvhfl/arWjizhOPtMrSw2kbOKTBgBU5HIHXxLm2kijiIPyVkI5Pw9\nxhqkfG8Owj9Dega8TgQJBPeFtG5CWHcQYMQS+bgk02BQ9VuwyKVei5Hyi3ySGaRhdQrXyIZs6Doe\nIXT0/TVl4XgtrLkOhJ2uT+ZBk1ZSL/NcjCI0GNrLxhq6epbKockE3zSNfNVRKI2VNXr2xayFqFR+\nhcbOZofvr5ggCYAnkVsHOBYvWC0xHtG7bbRqCLlSHagQpamqxBb2GSoacAUCrqyVWQbIiiYgEXIl\nDs6hP6AKhTQZIu4zeOToEto7tCYmaYJ9Jp0/3ttGqySBgwhC7wUn4ZCVE1gn4DFSltkET7cWBfex\nVNJhYZ6rRc06zpyntTVUwq9504S1GiVX60oF3Bhzxfv7l/Gzd6jSe+HYIi6ep3d0/vnTWDtCEHHa\nmsMwpzkxGAwhC4LedLaLXoe+Z39rhIdMWN97+BCP71KFcWe3wL02wWG73SGGPJ6GAsi5d6WIQwgw\nxUBEMNX+ZB0sphf1PNl6glaLKvwvvPACclYgjvp9NBpV/9LQr21RHKJer+a6xcICEeXPnjuPJrek\ny8cDr2zu9/r45je+BQDYerLtKRXb27uoc6uYvMxw7x7RX25dv4GQq05pmmLMAhklJcoxzeNBd4D8\nGYbqR8uZMhZx5VLqrF/EtLGoZqrSGtJVC5SCUNUC7iCZL6EgPOQgJKo1BNpa71AtxAQ+y7MM0lWm\nXBqmaioJMlMECCudmMMZn7hprZGNp1vcAGD16AnssaN5f3AL3//+9wEAN+7cR4dx+m5pUOONsqFC\nzDDvoW4VKjQys8bDgi+cOY1jxwnme/GFF3DnO98AANzd3cZqgyZYEMX/P3tvFmvZdZ6JfWvt+Yx3\nvnVvTbc4VJUkUqREypIst+zYRg+G02kjQNAPnc7QUdAd+CEPCToB0m9pJEDykjz1U946fkgCJ3a3\n07HbaY9N0ZRsiiLFYhVrvHXr1p3PvKc15OH/99qnKFJ1StUgAmN/AMFT5+6z917zP34/7n34DgDg\n0e4tTJl5++DxHu6fkfClLu5g+UUiWjs5/R4mAb3nxqXLWF7ZWrCFtibs02Yu06ZOfxYQiDzODrQa\nZSVcqhIdrtc1S4GCydSU8lyduCQqoGbMet5K0O9X0sIEbqA9iYzdCWfTATxmQC+Nh4rT0TPG9WVp\nUmSVhLYAtpbXsNKmTbITxi42Kh1NUMTMEhy1nEtZqZo8UQjhNt6yKF3WqRDSzXdPSnSZ3XxtbQ19\nJgpU49Qxf3dXl+FxrNb+8SHOrREVwYsXLkHywf7+D9/HY2bbH08n0PPs6E+BNtoVchUG6CRVuwBR\npZ/bWuCSwBwzt3EEpFZrvHCBBMyP7t1FOaBNqSctjh/Su2XDDEmLxrfUFgHPn16vh9Mp104LNVIW\ndmZliCiq51Voa/d+nRr/dERRiCSiNmalQDFi90AYuHHRytQZXIV2stQkUohFFS+mkFV1/UqDlJn7\ng8iDV2XzRYGLsfE9ifV1mjMP72TIc7omnxmkCcedlRbtNo3v+moLmtO9e+kBoBeL05ifa8Iat6/B\nAAGzcSfdNk7P2GUqrCt6nLRC+Mzyq1SBQtLzg5aF71eksxO3n87S0s0vMzd3QuvDcqbeZJbi4IAU\njJWNa05ZVkYh5vkFoZ+JeNUIibysxtxDUrlnhXLKsoWFz/MiaMWopun25Q3MJhSns7S0jHO8h07n\nsgnLMkfJ6zjwPEdkC1AaPgDk5QRCV2vFQ8aEqFApXn+F4mORl7hyiWI69wZnKJ6hoKspZb2nWgOP\nx2UkYnwwJDfijeNH+Jc/pO+v79zFpXXa9ztJ7IqjCymR8p6ajU+R8tqC10HOsWz7+7s4OSbFcmY9\nTKvwBAgYv6pXKABWVpXyHKGl8fw5Q4SEFYtLGg/uPUAYk+u7u9RBm8+B1bVlbPq0t/l+4M7gMAqg\nOF7p8eN9R6JsNOAxNdDpyQi3b1aVGA5w7x4JjGEYOFqFyWSE0Yjm/NHRIe7c/pjvk5PWDyBPNVpM\nu7OxsuGy/bPpFKIi910AjZuvQYMGDRo0aNDgOfD5uvl06bS3LEsReHVJjUpZKPPCEcIFnnQ8DxrG\nBTT6njfnIjQuaFBKiap0lxBzAYRW1kSduoDmAFKl6nIyUkhXQkbpOmNKKYXyGTT+lfUtCjAHEIYt\n3LpBledFkCBZI9PyNB1jUlW7znMkkq0RoYe+T9pqy/MRsOWo31+Cz0HKV69ex4f/6ncBAAfDESy7\n+Xw/xEFG9/mgvA1ZEUEKixscKO09vI/v/cb/St9PJ9h5gbJeotYKDBbjmVJKOTeWgHVu2DCoTbQG\nxvHBeJ5AnNRug0qj7ffbeDyhPrBGuIBgGA3LvF7ZLHdWDCgPJVsHvEigZCvV6WiCgANIvSiGQsUr\nVJOwRmGMOKrrZj0NiR8irLTqaebKflhjcXjMhIrWIrdVHcUSupqPvldno2rjeKOk57m5XCqFGVs7\npechZO1nudOFV7kChXAuaOQaL65SwOmV5U0ItspdfXMZKQdUDkbDZ4nrhVLKWXmEqINqy9Ii5zkl\nhHAkpUJ4qMPd67IecZwgYqvKZDTFVp/cSL/6q69C8LpUMPCYg0fDg+Kaid1uB3/yF5TpdvtggAds\nUggTH6/vkIswDupAfKHxTGtRCqoUD1SlZPg+VjjXfalMTQ4IiyKrSlVYxC0OJZACHs+fXKVIObg7\naQEh814VhUHMrxYIizXOpNrZCXFwh541HhoIj347HmSIesxLtNGDOiWXuz86hMGCA5kDGVugu60E\nXpUQq5XT6oeTHOWM22EMZqLK+Jsg4CKf3e4avICso2fHJ3jEmVBWF1jqkUUpaLepJiqAMKi5v7QU\nsBVXGLSrbVhmAkZTn01mQ3TYlRZFoUsMWgR/+GcfOTdcHCeOn0/a0mXVEblttScp+OxeDIMY60y2\nKgHs7FBAs6dSKLaC5lpB8N6T5mVdA056LvFIIHIlSYQ1yPhzv9vFpStk7bp75y4mPBadVoJBtngA\nurEWle9YCMDwIZahQBlw4LsX4Zj3v0c3d9G6Qe6/tu+7eoJpmmF4Ql4IrbXLKo7bHbS6tJ5KK5Ex\n0XJRZBCVlyZXUPzcwocrb2Q9DyaoreudNj2rFfdc7dtFEHgCowFZxNJs7BISrEHNxRcnjqg4DCPc\nv097Q1kUeO+HP+I7CWdVPhucIeVA+bIo0GcC6zDs4eyMnlXkGW7dJP66B7sPUPBetbW1BlGV/Qp8\n9HrMf+h7jhHA9323/y2Cz1WYGozHiP0qlT52Ne/CQkFG1UFs64MVcDFWWhtHoqYUkfkBbOKtqm5a\n64ogAtaR2GmlnMtPwLp0RwnPxWflRe4I55SqXX5FWbpMjkXQ7XQRMcHbyso61rgu1tUvvooB1xE6\nOHyEo33y5Y9OTjAd0sA/VinOOD28k+aY8dJOWm3HXHx8eoqsitmwEhUVYl4WuMNm3feKDGssfG2E\nMSTHaYhCI2H3yaXr13D9ta/T/ds9RMEi+VFE66BVdfjACQ5WStgqjkJbt5ADT0JWLj9BxH4AECdt\nRBzzQG4QzrqSBn7IzO8npwgsM6N7nhPEIYQjYMwLiZki83HsefA88rMLqxFxrFMY9xCUixEhAoDS\nytWMk6HnBF/fD5BxLEQxOMaI55G21mVhQsIx+PtCOGHTWOPoOdJUuXiSLMswY+E7zdJaAQDQ7pB5\nWocaM3YtnM4MAvbpy0Ciy33YX9mYY6x9OozWyJnyo8wzeBXzvhc6AjthLcrqAG0lLg5BqdLFKmgt\nndC0tr2JSxz3tLHace6qQipnAzcWUAUTvUoPX3uFFIxZ6SHk2DFYHzOmGYhFiYzdLWEQ1iy+i7aT\nM83yIkOnRX0urUTJCpW1mKuRZ5F0mDSwFUFWrq/AR17SVjlVAaZTep9Wx6AK4dLaoMiYlFUaVFGA\n58/XhcknwwwZu7Af7ymEJREgtuxNpGPKylXpECJZXqxtEG4eKTNXMDsK4bPQkSRAMaEXSKcKgyGl\nzvvaoMXEt7kuEXo01zrtPuJtatT+7i7u39zn9mlXzzCIJZzkJn1IjguMkxY0FzJ/58+/j+GEFYYg\nwmxC38dtgShe3D30/XdvukLj7XbiyE2tlU5REUI4ItxWUKLNa6JMM1zkDDKVZni8T27n7bU+Tk5o\nL947HkCyoEy3oxsFge/muABgeN37UuDuHXIt9ftdzPhwlu0Igt3ysiiRPEMWmDW10gUhnLtW28Jl\nIQtrnNIIqZ1rclAWSCcswE6zORqfGFZWsUgeRlx1wObKZdSHvkRURWzMSsdEHnoCGc/ZIvRqYVkb\nlLxPaC9w8VOLYGUpQcbn6JVrL1OxTAAqLzHh7PThcIgBC0GwcCE+8wKNnd9rAVfnUUqBzU2qZdpq\nJUg5Pu7WzduYMZUCBFUNAACYWlFcW1tDp8Nktp7njDl038Wdd42br0GDBg0aNGjQ4Dnw+QagQ6Jg\nKTdQFtO0ygoL0Klcez5g2VxqbQh/TjIsWWO2uib5DOJgLhARzqJE1ij6bZlNnSWDys9UtdDgtABV\nlM70bwycKdFoheIZiLvaSYyAJd4yMghYdV3q9ZBmlYnxPE7Ok0Z+enKEkxNyHR0fH2F6Sp8nszGm\nKVlTDo+OXRV4YyxStliNhajr9PkShoRrXCgTxF6VbVNnLnmtNl6+/goA4MUvvorNizsAgKTjO+35\naTAix4wzdlRhKJAPwCzwkDDZprGGs4tAWYKsMVsBVFHh0gq0W6x5eNLxhiVx7EzAsJaIuABErQhR\nVLmcxJz7RiCt6g2WdakWg9LVQjTCh5KLWxeVJ3CaUd/HYQRbmbyVgmXtUE+nGHEGyLx7TRjrLER+\nEDguHAjp+JKEFGhVnFnGuPp3Igqw8wLVDBOBB8EZkYf5KfbOKJC2vbKFmN8nH6YQA/rcabVcXbFF\nkOe5s6R4IqxJLI12LlHP81yHllojz2vrnsuAEj4ku23aERCHdM9JNgFslRkHZ7W02sIwV5T1LfrL\n9PnNVy9Ccb/1WwnikNd3EsBzSQ4C3mIGVH43iYI5iqwqEFZzw5KmDxAJalm5ygMfa1zfMgktDFsd\nLAQ0WyaGuUCb10oytugtVVmBQJFX5UcUah+Rh5VN6s92P8BszK7eUkHnZCnB9BR2ynXLPAtvQauG\nCeBqTmpjkXM/Zcq48klry12nsUdRC4MBZecdnxyg5LU7mUzduIm4hM/r7MJLW1jnLL/HuycYj2lf\nzrWAF1KbZBRBsCXeRAIzy5aayENbcOJGrtyY5zOLuLX4Wlxd6rtsrys7F7Dc5UQJpVyIRp5nzqtQ\nCoEgorV1sLeLKferEBIh92vo+Ti3Ttlww1RB89ljAUcIqZR2lqkiU/B5Px0Nj9Fb5hqoQYCPb5N7\nduPCNgL2BgxHY4hgQVctP3c+O7LKrBWmJDcMAKkBr6rt6fswYbWnWlc2SxUGugqUR+G8BiaD43VC\nkaNgq2muJGbVs6yBx3tzCA9+VWdVChjnHcowYvfl6PQYIlw8dGJzcwWWrVr5ZOI4p5Y2an7Dvb2H\nuHPnHr2PFM5K/wSBKuAIWqkeKYd+SOmiELQxiNk6+Wj/sbOoSykxY/4v35OOOBQyQMH7X6/bRSuu\nQ1d8f/EA9M83ZqosUbCwk8xRFGhtoNh1JCFgZG3GU7xQhRB1AWRL6coAJQG6pWltfdhpXWclAa4Y\nZxAKF7tSFJmLl9C6Zkkvy5rcS6nUuUMWwdrqEsYjWsClNsh1tfMG8KZ0nzCJHAHl8uo6tvlQnk6m\nODggVvKj4wM8ekh+8Vs3b+GFFyk1fjwYIuN3/sF4grsskApPIuMFUFgPJ1wsONMFOIwB3ixDf0AH\n4stxjICFH18KmAWZSSW0KyZsNBAEn1KM19b16TAXdwMNV3A6LzXGI/rcvhy6mB2jydUEALoskLKL\nsh+qOh0fcDWcaB+sss8SV8Sz0AUUp5inpUGmFqe38JPYvf+wzBCweyPLUudqlp6HKsJC+B68auEb\n60zJ0pNIOTYqCANIWbnSPLdIi6LAiE3erTBClzdqIQTaPXK9iFBizCSQI1kg5xiGcT5GYCpKER+t\ncHFJo8gNWFZAGPgIoypLql5PxsLVrgTgNmpPSiiO3zCmdOtYlDnSAb1buuS5QqIe4Fw1nue7GLEw\nDhDyxnU5sk4RCmRQm9eFRcj9Zox2VByLIC8UyinN98CTkFVtQathKmb3skTBB0Qr6SKspqpSsK5m\nmw+f3zmdFhjMaH4GZxnaPY73aIfIeC0WpYCtjP6y3vwhgYglMal8l+UXiCl8jo2xQsCrfC9PQRJ6\nKDhOEka49kkRodeiWKHIa+OI67ul+chRS6yuXIFlIbhQGdKC9ixtCyjLSoI1CDrU1vOvnMeIGbgH\nowyKiRytkNDV4QwLy5m10rPweWwjKVHMqhqoAvlscVft+e1l9Jgxv+NbBOyiinwP/Ra5hfO8nved\nbtdlpZ2dPsZgxO6kMMJLL1Pc4f6Nj3HE1DGr631opoLIJjkSFqxKVbh96LQY4YSVXD+UuPDCDgAg\nDiKsTSnLzPM9nB1xnE6hYLLFFXCtCyd8WyOccUBaAcEVFISVrkC01Z6jiEChYFkp0oWE4fNGQLsM\neVvW8cNGl6jKJAprHSUDBFFDAECuNQSq33pOKRJWQFaKpTSwi2+pAHysrRC9wXCU4t5tcpUaY51g\nNUtnLnt0voCplNK9v7BwcgB9V+1DwrkIN8+dc8qe73uIosBdX8Vae750dU3zPEOW0Vh3O21nDPGk\nhHgGIuTGzdegQYMGDRo0aPAc+FwtU3lRYMJmtjis3WHWGmeyjcMEAZMGCoHaZSKl498wpnSSpzXC\nWZfoXny971PdEQCFsc6dJ5SCKatAdl2TUaEOEFa6RFkFFxvjSossgqVe22m3WZZjVtV0Mr7jEilz\nDz5f1O72oFmLUcbg3DZpT8cnh9jeJt6Sg72HeOe7bwMA7t6+jZxNkg8g4VXEpKWq6f097WrFwfPQ\n7ZMWtrW5jS+9QrUCz5/fdObPPLcQ7cXIEAV8F9wazJFzBhCQlfYDuIykWZYhqd5FeMiZqt+gwBnX\nA/MD6SxcuiggKgK7QmPKLphgapGldE0vWUEY0vsm7TZm7F4RXunMvllWuLpypZ06d88i0MLAVhxM\n0nNWiQjElQXQ/K3IYpVWdY28vIRkzTjPUpe5FPotF9hIFisuoVDkjssp8D3EbF1aWVp2Ney6SQt5\nQtaCgUqxxBxYI1ugx6SXwXIH7XZ34TZmmYHl5W+9EJX/LAhC12/miTqZlJ0KkPl7voZZwS6w115c\nrwxQiJM2wspSJrTL7gyC0AXl+750mbiBNJC2Wt8FfL9yIQhY1O+jprRWFtm4RqMRBIcMJK0Y1hX6\ntG4vsVDQugou7roMyijy0emRJn3u/GWMTihY/PDRXQyZrNVGV5M/AAAgAElEQVRMCoSHVTIL0I55\njwksPHZth6GEraxdxrikGAkg8Cq+Ld8F5Oo8gGwvllkrSoUeW5qKrETKySuBtJhaJmw8G6FgE4IW\nGkdc01KUGhGXBul0VtHrkiUrTgyUJmveLB+7AGhdzFzwdysSjsPI2prP0ooABVsjfasA9jD4gYRo\n0W+zmYIpF9fhPaNw+JiSdY5h3D4BhE9kXLsSS0FIGxOAjx/cx6VztId6YRuzlILOX7j+BVy6cAEA\nsHt6gIjnqY08lJzlF8ctN3+jKMDqCvWVNiVmE1q7yi8pKQJAkRfOsio9D+oZaoHCahfkba1xCR3Q\ncJY+bU2dBVnW7UWp6T9wmRxd1Zas3V6VpQsgj06dw1FbdgC49aFQZxdaFLW73khXBct68gnr0dMw\ny6RLSlKWzgUAyGapcz0DdcC3mSM/rrwB7pU/BUppjDkUpttuI+P9dWWphzYnnniyDrVotRJnMY7D\nACGHNrSS0D03z/MngtGfhs9VmIKAq6OmjHKZd0QGyJNGl0BZsWr7rvOowCu7GTzpBB9dGGdSl0K6\nWmjGWBgnyFhUM6ssVZ25boWboHmeOxOjKhVmXLtpkhaYzBZPcy2y1M2xOA7r4rZSoN+qfeqxjrgf\ngLISMIxBr0+unZXVZVy6RHFVx8fH+PBHH1CfJF2cu/ACd4p28V9WKbchC09C+pUrReK1r7wKALh2\n7YvocIpsoSVCyTXhwjbkgtl8EDwuoNgot/CFgBS+ey9ZxY0p7WqTlarA2ZA2+XP9NUdQWagC3R6z\ngOeFk2+N1pDVoWcMAm6TJwQCdv+GcQuC61opLRy9xSydIkurmKnRMxUBDsIA3ZAEk1Y7QafKqpuj\nzAj8wAkd8xkmZVE6Ej2ltHuuJz14FdFhFDyRoaIc0axwm4kIJHLOhgvDEBubFFsQByHaVTHQqy8i\nqtLDk5ZL31+ojZ3EuRaSVoKY+9kTBhHHXhlbHwiCGsHv5rsNLpAerOHs1aU2Sm6vEtYJmxLyiZgH\nxQKynosvU8rAaF67tiaDlVK69a2Ngs4WH0ftJwjYVWOj0N3TmFrYaXsJfHYXmcDHsKjiRgR8yZk/\nYRuqxZUbzvlAjxSebDzE/cpFP/TQqdygnu9CpjyPhAlqF6p60kTdUsV7+EAecryTLhF6vYXaNxik\naLfqTDfNYQ1ZlqOoirYHPgRv856VTsmygXHVAtLpPkYTPmREhLgiEe4uI67Y2+3U0ZHAt9ARP6vQ\nroC0EBbSVm7Hev6UhvoEAGRoofPFmbN3ts5B2VV+1syRSXoydsJLlmXIZkwAnBWYTkloWu61YLnO\n4Y8++ACnQ6INePPLr4CHGSrPoaq4Iemj0vuMKZFVoSG+dDQMqhQuu3s+RjfLsppmx/PqIuILQGpB\nBwFI8LFVzKjWTvCxWjm3nTGmjifSBpWELg3c53lCV2vtE2z5FVx29Ceuod9W71M/60nJ2T6TMJWV\ncPGjg+EA+WdQR7hsZiHqWqMLeNqshRuXo6MDBLyfra8sO4E3igOETD0UhiF8lxlqa6HJWOiqhuNc\nPy+Cxs3XoEGDBg0aNGjwHBDPInk1aNCgQYMGDRo0eBKNZapBgwYNGjRo0OA50AhTDRo0aNCgQYMG\nz4FGmGrQoEGDBg0aNHgONMJUgwYNGjRo0KDBc6ARpho0aNCgQYMGDZ4DjTDVoEGDBg0aNGjwHGiE\nqQYNGjRo0KBBg+dAI0w1aNCgQYMGDRo8BxphqkGDBg0aNGjQ4DnQCFMNGjRo0KBBgwbPgUaYatCg\nQYMGDRo0eA40wlSDBg0aNGjQoMFzoBGmGjRo0KBBgwYNngONMNWgQYMGDRo0aPAcaISpBg0aNGjQ\noEGD50AjTDVo0KBBgwYNGjwH/M/zYf/of/yn1lr7GX8Vn/qN/ZQrPuseQtT3sPjENbb+n/jk3z4J\nW//ezj33H//Dv/vjL/kJfOfX/l17ojQAQHsCKz2PPhcZlAroIhkgDEmONUUKVWYAgFZnGb1uGwDw\nL//k+8hLuvylF3ZwtPcAABCIEm9+5VUAwIroo5fwEHYEvvk3fg0A8MVv/Bw87gspfYyyKQDg5u09\n7N9/SPcxKSaTAQAgz6YwZQEA+E//wa//xDb+V792xQYsgseBj8Cnf/iehOd5/EwJz6PvPc+D73v8\na/HEKCtj6Pm6RF5SY/NSIef+KzX9BwCF0jA87tZaNwesFSi4n7JCISvonlmpUCi+f6FQFHSj7340\neeoY/s2/8x1bXSQtIOami6kn4dw71J+NsPVFGhDQ3A8Gpab30VZiOhkDAN5/913MxiPqQ+FBWOo3\nZS2+8rWvAQDe/NmvQ/EtDSyMUXy9xcHDfQDAW3/yDjpJBwDw8Y23ntrGn//GOTuY0vv4Frh0keZR\nmHjYfTgDAAymHsDt0ga4vBYCADY2A8yyHADw+MjiG19qAQBGY4G4T/e//3gGndFrHO5rXH+JrimM\nQprR+8ddgUhGAIDdwwyDGb3PWjuCKunznd0pZjymf+V6D5dWYwDA//ybt57axr/sGD34yKp3fwcA\n0OpkKDX162SQI5vQetbpFAfHNNd0mWMlovFsCYvxiK6HMPDbNP5xJ0LJX+vcoLS8hozCmMezVCFy\n0Fz4wcEJ3r5/DAAIuucxUTSe9x6e4fE+PdeaAlafAgD+h//uH+If/P3/GADged5Tx3D55XNW8mo0\nWrm16PkBhE//EFIAgtaNlQKW39laBelRu4SQAK+t0I/gV/tWIGF5V5o/V4QQKHLqQ98PEQTUXlgL\n8P2DMHRnjtD13iY8gSCkvf6df/EnT23j3/mffs9aQ/vE/A5pAVRHmhD1qWXpQve95IusAKyl9koY\neCirF4K19X3dO1u49Q0AQkp+B1ufnwL1/a2AcfaX+n7/y3/27ae2caRhjdbVC0Dw+0gAnqD+9KSF\n5DESdq4nhHVmH0/K+hwA3DkHAOPhCQDgg1sfQ/v0/fc/eBu/9y/+LwDAweER7u/dAwAEicDqBm1W\n60sBYGjeSpFge+sFAMB/81/+Y7x47uWqtU9tY2OZatCgQYMGDRo0eA58rpYpa2wtCYtPCnqfYW36\nlL//2C+dheCTP7T1P+zc1/yPzxI17dzNnlX93XzjK9hW9Nsw8BH61MVaKwSSPiujEAb0uUwnyNIJ\nAKDdW0VpSJt4+eUzDE+HAIB0MkRRpgCA9fOr+I++Q5rdxsoWpuMjAMBweIj+2jIAYDIa4XREFovx\n7BRlekb3FwleXCe1c3B2hqF6DAC4vf8+Iu8p1jqG0XCanDGA0WyRQa3xSCGdJmSthWaLTPU3+v+c\n3XHO/CeEgGQLlyeEmycWAiVrNsYYNz7GAtpWFh8D5T7buXcQTitdBPMaqrVPvua8NWr+evdva+ml\n+HMcUltWlnsYjEhTn2UlJGui0hpnKRWwqGx4SmnMZjQvjNaw3tzMrd5BWGi27hV5jkFR9/PT0BUR\nDqd0/7jlo8yofw4HBaygtyhshvGIPrfjEP3uKgCg05JIZ/QOb14BAo8snyUULFuXeqGPlNuYWwPF\nlkd4PjzWnlGWOM3IKlta4GxIc7NIjbNIKm1hef68dWOG0Xm9cBv/ssNmxxj94LcAACco0ErYGlwU\nyIc8B1WJaEzjM5hp7LVpDLfOrWGS0b7QC4DY6wEAJpMCpxMahzRTqGbUyEj4QZeuUSU+PKK9Y3dk\nEK6Q9n6WRRgOaY77VsOPSNu/0JfIsiUAQBiEP+41+AmQQsJWFg1bW27IisJrCMLt/apQ8CO2srY6\nUGy2tsq6z9p6lXEJ1kpnvTLGOquWlBJBQNalKEkQcFustShzmrNGGwR+dYRKKLbuC2UBvfg8FaI2\nf897VwRsbUUStW3kiWNOCEhRvQGghHaf2ZYGCwHzxG+q+1M7q/vUz7aw3Lfzx7QFWdXnn70o9vb2\n0O+T5VxKgThq8T08sixW71A3HpUxTSnlrIR7e3tYX9+g+3gSh4eHAIDH+49w48YNAMCj3QcINI31\nfnmC0xOyih7tP0aRUrv8IEEgEwCA1hathMZ679E+wog+v/XO76P9s3TN1uqFp7bxcxWmnjRVis90\nt4kn/v+EcfMpsJ/6cbHf/vjzfxp8/49+35n7ukmEVocGo91bw4VtmgQ6H0Mk9P1Kt42EJ0cSd4AW\nufmuXX8ZsxMSlPYfPsTZkF0vsxmGM5pYl19aQ7JGm+OavY6iOkx1CZPuAgBuf/g7WIro0Lx+7XXI\niCb0F774VVxPfwYAMPtdhfObnYXaZ0y1hQFaWGdmtVLUG5SsVwIJU/XGYnnTsFI4IWh+cxVCwOPF\nRWIGffbgu+daa2HnTNu1V83OCVbW7WdaP9PeRu/xtL8L8enuZmtrU73VaMfkltpaX0Yrou9Hoyki\n8Bhur2E8pmsC6UMYdj9EMc5trAEAjFWACOYf7v5nWGAp8hxlkS7cvlbchRdk/C8fN+/S5uMFQCum\nd/iFN17H3l0Syo9mKSJ216azFpa61M+j6Qxxh96nKAuELAgvtQN8dIfuubkcY3uD3n+iNN7bpcP6\n3JbA5fO0Dqa3MyyxMLB3ViJgNzGkdIJ+qjX+9MbZwm38yw+JOKH+PhtI7JckEF1pDbG9Sd8fDX1Y\n9hGvdn3s2hUAwH3VwvJSzHfJUbJvL02BslIGfA/Sb/M1AcY5CUoPM4U0uUiXRFsopzQHrR1DCxrP\nTlfhiz2ajyuhxIMTur8U5gm3+dNgYWEqZUMKVM4U6QXQPPdLYyAkqyHSoPpopYDP6w+5gslYGStK\nyJCOPiuAMpvxbwVkQD/24UHws3ShYJyQ5ZPLEEBZpjAcPuB7PiqpRkgJoxdXbISAW9Mk21R757yb\nb054mfc5CYGQ/xGYAikrQkb6ENbjy+u9mX5b7R/2CSXWbVsW9f5d/Yj/7z2hky4+kP/8d34LEe9/\neTHF6699FQDw1S+/gVbU5ttJt68/Pn6ExyePAAB7u3sYndAZ9t57P8TFizT3Al/ibEAGh3GmcDSi\na877Aq+0yIV35cI5tDn24IfBX+DWvdsAgFLnODsk93RycRUFh9poneHgmM7Of/q//ROcPKYz+D//\nzj96ahsbN1+DBg0aNGjQoMFz4PO1TFnrAnKlACzLcsbO2wHs0wPEf/zG1U9/anx2YPyz4bXXvo5+\nn0yYAYwzP08KgaRLErLwfAxHpGEfHg8h2FWWZyP0WqTBGykxOiONydMlDLsI00zg/Q8+BgB8/evf\nRqFI+1dKIM8pkDkQGhvt8wCA8/0NCEta4e7gPsaKtMXXehcxGZJU/8LFdXzrjW8u1D5javOrNXO2\nWMh6PA1q7dBacssxrKwDx+cDCSsIKcDxiJBCwDgrjHSBkGbOvDznhYMBWaToHQyUpuu0NtD6Wce3\nNnk/068EzXMAKIscEqSptyIfskVj2PZjbCyREX5rpQXFgfLWWOc2jds9zKrAW6MgRRUAiydc0NbM\n9aFYXBt+YVkgMmw17cYo2UVxOtGwmsbx1RWLqyG5Z96/HyLhZIcHj4+wtU4u5bc+OsD2Mc3ZaSEQ\nsJthY8XCGpoE692We88yBYKQ5nUkO8imbKVaNQg9siIcDhVabCGAZ1CwGyYuNBB/rlvW/68hhAR7\nkbERTWBzmi9Z6SP02GKpBTptclH1WwJdSf19XKQYGNqPBqUHPyetPkAGLeh6IQOkmlyEjwenOM5o\nryk7X4DfuwIASHSIUtL33Vig26bEhLOJh0jTWB1OCwxz+n6Sa7cfVC7tnwQzH4UN2jvBX1UhA8po\nSHaDh2E8l/Ayl0hkLXy2mlptodgSVyoFydfIwIPvB9WDoDgRxhcSgs3fSinMh81XbVGmhODMHKsF\nhF18LXqytsBXLi9+ibnPFlLWQdvz8NmJZ6Yn0CFZeUSyBAtqC1mg+H1E7RKdd+3Z+agLIQBbJw05\n6xXmknGe0X1z794t/PkP3uZ/Kbz11h8AAP7+d34dv/itvwaAko1mGZ1P//tv/x9494PvAgDySYEY\nNFfb7Tbu3blDdzElvID2jInoYmzJu1KMTtEb09i9fPUaXn7tGwCAn/3qN/Fn73wPAPDx3Q/xwe3v\nAwBOHg+weZ6sut1+C0fHdI4Ozob4ffV/A1jMMvU5u/ksDMdLFHOZTr4wc/7gT06mTzvMngyO+mll\nqX9TAtQ8znWWsbxzFQBgygJshUc3jtFq04DFnkAY8SJUCjNe2Fk6QTE6AABMpjlGQzrg8vEBTtn0\nmPoBti+R/9YIi6ODPQBAlHQgWYIppzMsrVB8w/m1TYw4W8wihJrSQTYdPEK+TybMdvYA6SEdjt3e\nF39i+0jU5U1D+M4Xr6yGNydYVWOiTS1QWlh47G8LhAfD26kRgAX1gYGo5TMhIHkTkKLeTIQUsOy7\nt3Z+xtSxUUprlFVWoDJQzyxM/fSo9v7ZZIJRwOOcrcGzdOi0Q41qS0y8BEFIG4LWBordA37cxtGY\nTM+ZsE/EA86HKlQxU8YYGKUWfsdAANe2aOP1rY9WQArAuJcjY7fQ6NEZEnZTX1j1kfGBcq4TYHRI\nmTPb/RB7R+wilAIzjo26fyidYDiYnWL1iA7oS2ttGEv3/IPvD9BtUz9cfzHG4QnNd2kFWnwgvnR+\nFbmhDXb/QGE4rVyTDbSVGMxoTKZjD5Gk+d7uCmjqSrSiFgRLXCeZj5hlhZ3ODA9y2ouPC+AR32ep\nu4zlNn0+OnmIRxyrcqC6mHHcZlkoBG0a29WOjxUew8EMiMMqltFgMOH3DEpYSUJZWmjnip9zXH8m\npBC1S99oKEXvY0wJn+OVhDEoZ/RuKgigOdYpiAU8/lwoBWtqgaJ2XIk6TEAb2JTvH1goDtzTWgMs\nqHqehOLF6EsfPgv9RV5AFCyUSVkLZYu0cS5lWAjhlDGB2s8nqKHUD6IWqKyxmM24bw/34SW0juPN\nFhCwi1bkc2ERPqSt4qqs20vm46qsqPdgIeay/CzgsVKkn1GYenRwF8fHFGfnSQ/DMzIm/PY//z9R\nlnTPa1e/jLyg9f2nb7+Nm7feBwBc2biA7Z1LAIBI+LAZjVGyvgUT0F5y+zDEYEoC+yvbLbQs9cn4\nnfcQsczx4pdeQnZGz7rYuYBXXnkNAPDg4U0MUjoL7x/exWxE7+AZD/vsClwEjZuvQYMGDRo0aNDg\nOfA5Z/MZxCBJr5MYKDbLTVXLcZsIYVCHnptP8G6Q7CxQZ3nN+3kWFZadpfIJA9e8w+inR5lZzO7d\nBQDsn5zgzmMKonvji1/AhQ65ai7sXEArJLNlPpnBtKkf7MkI6zlpNOPJFCsc3FjKFUSaLAFXt9fx\n5jYFkd58+w8Bn67p7lzE4RFlLWgzRWWIycYHiDsUpF5aha0lCmruBTEGhiTwjd4ayvFiGr+xFoat\nP9oIKFtl2FniWAIZh2yl7j3hehLO7C4MUPL0055FyVpjaSwg/Pq3TmNDPebSc65hyvSp7llbpowW\nzsqjtYZa3OpO932mxIfayikgUUV7alXAY/ecVimkqLKSLAxrYLYonbbthSES1nQVcgi2NEgJ5xKF\n0RDMMyWETwRQ9ACEHNS+CL728y+iTOvMJc2fp9MZEg7OLQsPA7Zk7vSAEWeFbfeWkPbI7GB1G0fn\nOPPHWhheo6NU4yRjKxuAswlZrF68uIXYJ0tpP/CwwqYSqzUOQJplJAXGOfXD+3dnMJzhmiuFJU7c\naABoK6AKGquZ6SDvbgMA1pY9DI+ojx/OPPgFu7shYFPq75UwAXyyFi73NFKem9OyQDqmfeQULYjt\nnwMAxNMSjz56FwAQRiE6fpU8ApyNySpUKAPF9qZux0OLLWLHZ1OkMT0ronTgxduotbO4SikhBH3W\nxkLn1byTSGKaF76UmE5pnqrMwItp/XnCh/SqsJKaO8kTEuC2f/tb30KHLTt37t/HKQc0e8LDpfPk\nDeh1Wzg8IO9Br7+MkwGdZ3d3HzhXoISFfQaXuy/tXJ/UNiIJUdFn0XvzXmgE/Q0g3iWP+/bC1ZcR\nMbfUmRUwAV3vwWKqqt9Kd+h7Vj2xy7kAd1mftRCCz2SyvPjVNYv4aOdw+84NZBklMOR5gSik8frT\nt/4YH974EADwN/7qr+GXf/lX+RqF/V3K1NtqrSLiOdbTHgLOttvPPNw8pP1pN/cR+DR2djnC6tYW\nAGC4dwDBbuhOHLrs+tHxBDuvkgep0+ogZP61t7//xzi+R1Yq61tMJ5OF2/i5ClPGWkhDL9dSZ+4g\niEULNqbGT3QbBbsZ1Fw2l7CoXTtzE24ue57+9hkL1f6Ef/2bxKPHe9hu8yZy5xHevUXZA0vtJUzZ\nBL6UxIBHA/+bv/X/YuvCDgDg0vAeVo+ISHPp4QCd/jkAQLJ5Ga/sMvnn8RHwT34DANDt92E71Cfp\n5dsoeDJlQuPBhDbEtshw7iptBNoMcXBCcVKTvXt4eJcEtKVzfXT79Pn8V35y+7Q10JUABemEFCnq\nrBsDAx9Vyu18X1tUIm/pSSeAKF2irAQxCNR5vLKOeRB6LjbKzn2P2oQt5+K5QNl99M7WEWYugidc\nh3MyNsUlffr19R8kVElCQbcbYXOD3KfWpNBQ7hpwJpIpCycwevAhPU7BFhIFHyI6QJ2yaOuYMl8p\nRAULOIlBP4wWbuMDOUZ/hQ8g30fEJIMbfhchu9jKCZCc0DWPHs5QRByH8MIaWpZiqYbDAi+ysFOk\nCjw1MJuljujhcJSi3V4HALzw6iV4IGXjS6sl2l51KAR4ZYN+vDfK8dY9cgOURiGU9G5ZplFy7E0D\nwIoQU5+UshIa1pLg8MOzEH94m+bU7thDmw/VJAR6CV1zZbOLpSUKO+h5x7BTIvPNWivQ8YsAgMGZ\ngRrQgXZ2+BgpC8edENg/oP2ik2RIOM09SLoISs6uGs4gOFZLFQk2dkgBvHhuFeYZFBvhCXg8/kQE\nzOeB1lheJuHx1dd/Bm+8SZnJa/02dm/9CADw4c338NFdii+djFMoVS/k5SV6n0vb53Fhi+bmX//F\nX3QZq/ce7uHxIc3BNMtwaZue1e92MZrQwT7NcmhU5LW/iXRGB7vRgPQX94MFUriYQiHsHDGmfOJw\nq8KpBCw49BRSSHhBxP0DDI9J0DtOz9DukJsvjAIE7PKDF8yRdkq3PwvUFC30nLkM66rPAVTSXfCM\nR+hkPEPGMXdFriBZ6NMqx/0HNwEAf/hHv4d/6xd+BQCw1F9Byu48ow0CFmz1aQrbpbCI0nTQXbkM\nAFhLS1S+7TgFTh7S2HmdBMkStV0VOdp9+tzqJOi1aQ/74M4NXN2hM/Ly1lX8a/sWACBpSxdGsQga\nN1+DBg0aNGjQoMFz4HPnmZqAssyybB3lhFxgAaZYWiazdHb2EFvLpDEZHSLnVwxaEjlnGExVC6Vh\nnhAroSteFKHhuWh0+xkmq7nvnlAe5t18NeHjs+Ltv/gzdBOyRvT8xJk2p9NTfO8Bff743i6ufvlL\nAIAP9x7BtDh76ms7ePvPKOju8BS4wBL41ZU2tn5Iv+0/HMJ8yC65KILi7Dx/pYfNa3TPm5tr8Pqk\nseo0xhHzUvkry7j5Qwpkn+b38WBK/dk7WEZ6RFkOP/OrP7l92tG5MTGmqVyvFqLK0rHaWakoy6ZW\nYyxrNtMUmAzYMrYcQ3KkvrZwpQYgaregtrp2Iwrx6dxSxjp3mIF13DDKGvd5cXxaNt+TgeBPJjBU\nljULpnrBua11rCyTCzcQheNOCoMAw5RdEUYh9mmchRTQqDKUJMAZnL6QALv2dFmgGJP1cni0B7VH\nls+rXYXkWSyuVkFzQHypcowrl6iwEGxRimWICQcdT8ZTnNshF7HekCi5dE0XBoZLv3hGwK9I/YwE\nV/vAlbxEzvdMJLBzmdzOe3vaBQuXkwxLG2QF22yF+LVzTBCaAC0muL378AReo/85aOHhCKRpf3gy\nwP1d2iOOUom0cncLjSGXeNlIOvC5XNVxu43HM5p3sdeGDmi/MHEfUGTVHg1uY8rcTK2NV7G5TmM4\nmqYYK7Zeziw6hvZuIaYYcsmZ6STHtODEGtnBapueO9C9ZyLt7PRbEOw6NNY4QtxXr7+Gb37rlwAA\na5uX0F4lz8ZKr43Xv0CBxb9w9m2MU3q3s+EUd+/TeTMtFDoJnzHpDEu8z966uwdZudK0Ruizi7Dt\nYTImi5tQGiVzaZU6wMYmzdONlQ08LIiTTRkFXy8+T31hXZazcGlZtKNw7DfvO/NWJII0tR3r0d4e\n7n5E58dACazz3nN55wqSPvVhKAsI5qyzoKB+APClqLMaYZ0blJ43d3bOWf7NM1htTk+Gbr9cXlqG\nUjm3SyFmV+zx6QmG3M/Ly8vwuPG+7yPg/aPV6WDKIRL9IsVE0Zy/uhJipUNJV93JEOmNe9SWlWX4\nU37puIOV8+Tt6d9/hKUezYE3X/0yJIdalEpjxETCgU4gn8Gf+fnmGVtTD1jYRhFQw04nE4zHNEGP\nDw4QtOn72dkjxNzIc8sK22tk6ovawHFBG/tIn8ekoIWa6wCqSidHTZwmYZ6oR2TnXUoOpk5LNQFg\nq+wy80xewYcnQ/R6tHl1vCle54yQa4dn+MLP/iwA4MOHR2gxGd5/8vf+PShFQsV3f/B97E1okvVe\n/RL+9YgevB8abFwnIfRqug7/MfuS79yDN6HJpw5OkHLW3h+f6+CuRxN0bXUVGxvUn9vZRZzbID9x\nN/Jw9kNKMb198xamZ7sLtc/MCS/KGLf0BWpzsLa1V0ra+dRaAcN9/NGdI8SKzOIr/U3oyrVr5mTc\nOWZxZeHci3puO9HWuhp/ympHjaDnvIUU5/VsdmkX2/XJ7z/rPq5+lUEQcGbUUgshf46FD8Nm6LJQ\nEJzt48cSSYfcJAaWMnsAhBZo82/HoxOoGS3w2ckxxoeUwWnGZwg19WEg8spzuBBmaemITL1QIKky\noISLlkBpUyzzXP7Gt6/hEegdTvAAo4zrMFrhdJZgjsrC+hIRp6IHSehE8JkeYfsqPeviFy5DMkmp\nKRUqkvQsFTg5oWdNMoWzKoNo1cMsbRjQK0yVxR89oHo5CRIAACAASURBVE770YMcnZhGboAOOgnt\nX8PUx0qX5pcfC/gr5M5orQWAJbLglZV13P4RuTbS8QCtLrm9sLWD0yNyl2ihEVap+WGEJUHKgDQp\nplMan8ArMStozFe7Gn0Wpk7HQ2RT2u8eHpw4l9YiKLMcqDJ9S431DXLrfOMX/hY2V8lNk09HyFng\n3j07wMOU1kQ5G6HNa6vX28T1a7QPKuthOKS98vTgIQZjrkDRbaHVowMZAq5mpjQlQt57Qt/AZ3oJ\nKzzcu0c1U1+4vIOT8Rn3cwxVLD5PfWGeiNGs9lFrDbxKMxO1m08aU8d8QaDym3bWltFpvwEAmHgd\nJEyS2UtiKK6lidkpopD6RPoBIhZkDOBiYeUn6YkclwKgeA8Txjr29EUQRBk8dqEKbwbLLtfj4zMk\nLNgmkcRv/AaFsNzbvwefqSaEJ+GzoDTVCpMjUvDa0zE2X6L9aXUlBNOzIj4cYfQeuXp3Wwle+mu/\nTO9QwskfazubkB61ZTPLMWUhDpOJG4vxKH2ms79R8xo0aNCgQYMGDZ4Dn6tlSs6VAzBGIYn4c2Fh\nmXwSQRdDS5LzWdFFyJr6waDE8XtkPXnpwhKW2pQBcG7pz3F94woAYDy7jOMZaVsjJChYsy9NMOcK\nNK5MAKyAZY3DQsJqzlBKT4GQtBghgjnH1gIIQ1zl2lDfWVnHhWuvAgD81XUEU3ruTn8NIWfzdUwb\n9wekAf1gEODv/of/PgBg8/wW/vCP3wEA7D7YQ3mReDbarS7UO39B7/lg34nDypRol6SR/WJL4E9b\n9P5FsoTgFgVhRh/dxsoymaXXX7qKX2IeyFs33sad7HSh5llR18IrjX4i86QOpBaunpo0NUmc70sM\nRvSODx8e46+8Qm1aaXXxeEp9UEq4DECq9E4/LrVyFqjSGFfyQtuat8ZYWwedw7pyfFpY1FXGFmjj\njxd55D98+vXzNaWMVkhiNknHAQLOzhNGQpVVqRuBC1e+QG1RJQ6PHvKPM3STKtjWQyHp+sOD+xjv\nk4vCn52iw6UPhAVM1UYvhg4q3WyBNkqBgk1ZXinmrLQW4Oeue0u4whlipSlw/4P7AIDetRZW2jTH\nPek5EkMDi5zrnymravJSo5xLwHoCua64gub4crxaFw5jgZVVuum69VBlObyALjhutQGAXAs8nvB8\nVwq5oH0TRuF0SHvZ1KzgvE+a/I17p/jr18jqVExXEYRkrYgjHxPO5tzf3cWFHZpH3biLC1xy5myW\no9Xi5IjZCJIt361AY8ouv6QTIU7Jan46PMbRgK2yXggzpSDj43sdaP03F25jHCeo/OZ+O8BX33gT\nAHBudQXpKWVdweZQHAiuyhIeJ3EIXyPLqB/Go2MUBYc7+InLHo4iBV1WXG1AzpxHfhggYVe2LFMY\nTvQYTs8Q8jqLgi46nI0abV1C9DGdSbMyRzlb/MyQqC1TUgpXIkoIwFTup7KEZWJdnaUuAD2JIpeh\n5nsaxicPT97dxiETQx+9/x6Gd6lu3fjhbcfP1W538JU3yJJ17bU3YTx2XwKQqDKGhSufI2DhMX1W\nYIXrz0Ww/UK3TroxgNRcF8/mMFxHL9dnePv7/wwAMM1T9HkPUHaGk+qcbsWIzpNLt9dbRm+ZLVbH\nj9Dlsy1NPBSvUr3IBzfuIDimOalvfYwx7z0//6VryB5TJubpuzeQcp3SIh0hCWhuT2cZymy6cBs/\nV2EqL5QrJEmV+WiRjGcFhKXF4NkSmNEkSPzcZQB4QQsnOXVcx76A4ykJULcnBqsTWjyyHKAbUKdn\nZyUi9hmj3YHmunVTFbq0eiJFo0uktBAnf0zPtX+GNPp5AIBpvfkMxzBw4YXr2GaD4+Wvfw1bXyUS\nTLG1jYqueKPIoe6Tq2by8QNsa5q4f+/q19HlQrHq6ARXz20CAI7f+xhXbpBL7ly4hDYXpR2Opyh1\n1RaNQJIp/fXVDbx8idyCjza+juXf+m0AwNadH6CUlElV3H+A8zsvAAB+/Y038V/8q/9nsQbOMZdr\nYRzTr7FwpJrWzhmJBdyYK+O5elpfee1lvHKdsoZWVxIc/4h8/alWtbvV1oVHjREuC2i+wLI2cwLU\nfGyU1XPFTAWehbPT2rrA6BMFjWE/1c0nhKhjx3SJNqf9hoGHKGaTuhII2zSe3ZV1rK6R0D+bDnF4\nQovdlKkjyPPDCCHP5V4cQBlaH6HNEXhVTTKJktPb/f4Sgu5i9RUBwA+EY4oOfd9lRHoCTkDudrYx\nHZH5Ox8OMD2gDWf3YIJvvkEbmte2KF3KuYCUtBGp0mI4IaHP1wbJKn0vrQW8qpabgK7i44yA4Q1z\nqowTvgptXN9aQynTDQjCE+hwvM9RABwym/xonGF/SH326ss9dFokdBSjd3F2l7K98uJlZDkXRsYv\nY3RKhIpaSMwUfd8TGqs9Gp9AAoJP8HHYQsbK73o3RKfPVBrjE6SClCUFgYCLxk0zhXhwDwAwG2w+\nU/xi3E2cxiD9GD3OxpLjRzATUsCUlFApKYO2zBDG5DYK2h34PB+toLprACj+sKIxMAZddnXlRQbR\n4gK81sJHvQecTmkdfPjxh+gxPccXX/wCTMpFj+MVfPl1Ekw+uPEudLB4G6lSRqWUSqrFCSLBzTgz\n2GSZMzjYMoNiH/1oNiJ6BwDtVoyIM9S6yBGyYrZ2aRuHJZ2pj7NTPH5Eitnu8RHGTHa6deUqljaY\nPV0pR41gtHYFnI0pkXKW+MGDh/j41i0AwH/9H/zKU9s4yxUku0cD30eL51UUU11RAJByDM+nNia5\ngWLBNuoaDDwWfpMESY9phToJAnat6uMBSg4rGEvA/xqlpS/7LWTMqv7ohz+A5f3yZp7h9ndJwNTD\nE1zc4uLJcRsdrus3Hhcw5bMIxQ0aNGjQoEGDBg1+any+2XxQc7wWApIlSc+zyGek9c6mIyRL5PbY\n6T/GH91mzcgDAqbNP9vX2L7M9PL+BPvHpJEL4WNzha4fmhwY0LNWA+ksJYEADGpzY2Vp6Kgb6Ec/\nAADYoA+bkbVgWhxC+r2F2+gPR0i+SbWA9loJ7v63/z29ZxQ5S5nf76HFHBptLRCcJytS3O9j9l16\nrtjewkvbVB17/fgM3XeJMK977XXkBWl/Us8Q8fu3tYQdUP+U7SuI+qzNP/ieswSYc+cRTUgzjc72\nkY/pPl+9sI2//fO/tFgD5zj3rJwj4bQGwjqnDZSusolqV50pC3SY++TLr1yFx6R72lpEEWnYjw6P\nILn+lh8ISFlpSAKatUljpXMjKm1Q0ccYYd3Y2vlobCvoPZ4FLil0zjJln7RMzVuvKkuKbxQin54V\n+QECLncQt3tY3aTg2f7meYxGlIUStX2cP78DADg9vA+vRZmgpYxg2U3d7q8i4wBMVU5RsuVABD46\nS8wz1Gohny8a9hT4oQevsgB6VIGdG+WsVHv5bfTYrl8OUzfWRw+OcZe11V47hxdRG5XRiJmk9EwZ\nqPOk5ScXE6R8vbDWuYOlkE9kzVYBrRKArSyuwqvXrue7+mcNACk86JDmxf1TD8ZyFpKUuLBK37+4\nESDiLLOt/gwP7pJVYny2h3RIYzUazdDbIiv1i1/+CsrKfVOeYn+fskV1adFdJcvqyxe3cMahCWHY\nxmTKlgvPR2E4kcELsSToubdPx5iy9eFylHwmF+CnYfX8uttXfIQuYzU72UVZkdwFPQhZBTcHgKJ9\n0KYWiPhssBZBlZ1nJQRbekuVodWha/JJ4dxqQSChOezjdHyMm1wKZRgEyHmP+eh0F8vsDTjdn8LE\nNGc3N9dRlIvzoUljateetXU5GSEQVHUpe323Xuez+Yw2yAq27EDjV36OMhl3Lm67MmJHhxs4+iKd\nMXfuXccf/NGfAAA+uL2LlUvkHXh0eIjjI/KWpKNTZDmdDXk6xYwtgKbMMD4j19iDe/efSJZ/Gtqt\nGMoU1UtjyqVfhoMCEdf8jOMU1WrXpnSeK8Civ0QWt/7GFkZDymZGLhDy5u8HIYZn9L3X9WHYinfu\n5RegBZfxunkXKz3iF7t3eILv3SU5o+XnWP8Sebo6pYKpShAVBr63eFmgz1WYUtnAHaxSSCgeDV3O\nMDilgQxkiNhShkSsP0asqPG+meFcTJP7+sUDfPOrtClE4UO8c4s6or18HTsRucP27waYWRKC8kLh\nsMvZUACGI3ruKBV4eYPMt7/00tuYzciE+SD9MsCT+PjgA9w7XVm4jWubW7j4Em1MD4aHyHapLcl0\nCi8lc2MAizYfHN3OEpZXKI4h2ViCVx06/R5av0hZCObBfYx5gM3xAQRPeqEL9Nxi82Ek3T/rLMPf\noGzHK/feAdZoYdhLGzAfsGk8EdDf/AXqk/dv4d/59rcWap8xphamLCDZ/PrEJgA4U762NUWBtcDO\nOr2Xn45wuk+CXdxZxeiEhIuTxxMXI9FbaiFOIr5PAVW5C2Fc/JS2NQm4MXMpfAI1Czvg/P6LoKYE\nBad/1n+b3z/ma0IaXdXxKlzWjedHCGI61NpLm2jxQrbaOB/96koPweVr1C4/RPUwM8ng8wERJgmC\nhO5TnJ45V2DYa0FyHIvwBAL7DBlEFgiqatRSuBRsIXSd1RMAOfMbqFLDcq3DXjeC6DAhow0g86o2\nnw/Fe09HeDi7TRtmcq6PoMN/MDWjslJ1pqwxc1lMRrthzIoCit3g0qqfomD1X174vsRqj+kNEg+K\n4wjXkwQvnSfBZ8U7xe1d6j+/s4wzrnTw+CDHKbN3HwXn8Le+/m8DAJJWF4f3KVZTTe6js0TZf8nm\nMjbPkzJgEWA0oD1IF8rFDYVtBVnQOjZ5joFPisHKUoE0oti7Qqw9U03U5eUlJzrYEphM6cDMgpZz\nDyEwCFhJs2Xu3EmeJyEVCVC+rbO1JQQE/1aoGXxXjDyC4rR4vxVgoGiN3h49RC7p+k63hYrz46TM\noZi+RPoGJwM6S4J+C2HwDEz9nu8USClcRC+ElPBEHbtU7UrG1pnTRkoUJe3pf/Ub1/HGNXK/Hz+8\nj5OHXLc17kJwIWuhcgSVu/b0AJusyL//vbcwPubYzWIIw5Q72WwKxVQES/0ueKkjDoA4WpwkOJ1m\nLstZK2AwYmoE5aHV4fnQM2DGGBjro2Tm/okwCPj800oh5JimlZVVWM6a9PwYGQt9YncfUcREnd0+\nPCab3VjpOwV4Ok5RFkxAurKKlDv98Ee3MdznrEwRQJjFz41GzWvQoEGDBg0aNHgOfK6Wqbe++7bj\nGEkii6sXSKta8kpkTBTnRUs4PmQ+Gx3B8Csa0cJSm75/48IhfmaVuXaERv8q/fZI7SG7R5J5Z7SN\n4IRMs340xs/8bTJXp/0UN+6TxvThgzZeO0fXvHZxHz+6T9rEyYNdGCYIHR0GuH1rcS1jZX0TSZvc\nG4OBgmJisEh6sKw9KWXBHk6UqkTOWl5rcIigqjZ+bxerOy8BAN6HwTtcymMnKPBNNoteDpcQsNbg\nrWZAh8kfyxIlGcTQ8i6j3P1darv/AOkpk0K2Ikhu44NxgfXxeKH26TnOJiGsI7nzBJzLRqIO+C6N\ncZqoMRbdPllnut0W7twgN8Dje3v4+BG5N9MSjrNpcHyGtRXqs2Q5hOE6hAWMKz+jLeZcRQK2KmNj\n6lIJVohnMkmTeWuetI5AGW+y/o7bZY1Bzhpt7ANhi4k6wxZaXZprydIyJkwgWJ6Mkc6ov8/EFDEH\nVPa3diCYe2uqD6DZ9a3iCFGX5lEqAyRcm8rvxVCsbQcCEOXiGv//196b9FiWnFlix4Y7vtHnITzm\niJwHMskki6gqdbFAESi1SlJBQC9aC/0F7bSStNFeWqkFaCEI0EJQo9SQWt2t7lYXq6RmFWcmc86M\nyJgHn/3NdzQzLey7dj1IVucLBJAQ2HYWAU/P967fwa7ZZ9/3nXOyskZO2TQpBUJKqXNmnB+Yrhga\nf5iaK/fzlfWus/jQTEGm9v2IAomTEypBM44mv3T//RPsfYdEEhmDaXZ7hjtdLRHwc6VVR/xBKhiU\nsuO9qGrUz8Os/R0HYxwJ2cPsrXDnb7q30sO1Ffsfo9EUu9dsu8C9x/eRrlhh3+urKfhtOydu7lxC\nNbO78Tt3P8PJk48AALs7245UUlYLRKG99500QLFqn+HxwSNMiJgwGlXQlEUM4g4uX7LZKKXX8ZP3\n7YQkohhCLL/srHQYQOyzKtd4um+Ps9e56rwoVZUhn9m/u5ieYnNos7gy4Aio7Mg0XOkHnIFTkzfT\nCiB2bCq7GNE7FzAJI22mabDOMKhsFqYnJZIulRR5ANK0RRxKiAN7nFFROOHbpZCPnCaigkGRNw3Z\nDDnNK7PZ3BFD8sUcqknHM4Y1yk5XH9f4i5/8NQDgww8+wIjaKDp7u/j07j0AwOHZFPtkWZYKjZN7\ntgk7DDmqsZ2PpSkgKPsWcY2EMo+JFK4xvVYMeba8b10x1ajpsc/mGTTNAcyEODmm56g6JPIM6LrG\n4YGdS+T2or1VeY6ysPfk0f1HuLRH7T4D6YRPjx7fRUoZveL+I8hPaOxtd2E6VBlb5Ogo+4zyuUJG\nLTKdKMG1Tfu+3Hr0GDOqJi2DrzSYenr/ruvH4Mxgdmr//JXNGLsb9oENkxEGMakuT2qYvl2AitIg\nq+xnPvwixmZqB8owZVjQ4DuaHuP4npUiWHvtVRRPybBw+iNc37UB18pghg2atU8PAxhSgf58FGLR\nLCg6R0YpwJCXrafTEjg9PQKUPZ/OSgeHxLCKkx4q6nWqTyYoKvvwAmhktHrVqkRNfWEyCHH3p1ZI\n7x+pBXrftezClb0L+Jc/tDXvP60FbmzYEqGafuHq/fzBCI9m5DH1y59i94z6s4oCE0pvn3Y7KH/2\nvj1pKRCVy11jbVqmFc6lpA1re3CURitjcK4sY4zGT9+zrL0P5AAfvWcH+cmoQNS392mjk2JzzQYg\nGjWmYzvJT06miPt24aiYAmkDkpdf07vE20mMKffiN46Oy+NcIHVeu45xaDq+DduotFdXaBQw+2vr\n6A7sM5FxDywkHymjUZR28tHVGJzMN/O8BqNs+XBtEyDKMMtLzEl8UOoKyZDuyeYaBKhsK5hjAUGz\nZ/vEvgSGMYiGUi05KgqUBJdObZ0ZDUN9JsGlDuSRDQDXNzrYP7bnL1OGLnmwBQIYS/qujLH/2JaR\nShlhW9mgWHLu7imTrZEr09rNDVWtXDqec+EU8XkowJnXRmigjUZBBrD1NMf2mg3KL3cV5md2k1hw\nA8bsO1TXPbzxyncAAP3hCr7x7nft7yuFBUUF88UpZuTHN+YZHu7/GADw9juvIR/bz0Sd34OK7SI2\nmt3CypqVYZHsFDsbtrfl0dEMB0RJv3zxAnY3qNzdSfA8O5s3rnXQIYmCPGP4V7dt7+hkNsEm+ZKq\n8hScmNJhd45GvVEVCwSN+LICVNNbJCU4qYCLMEZFJTBTVkhk06M7xvUL9udrZhWnI7uAh6FAn2RB\nsrxAHtnjDzdj9FftO7rIgUAsP9/88B//z6jIh7OTpjg5sSLOqqrduzJbzDEY2A3JfDzGhT1bnnvn\nG9/AxoqdM/6Pf/x/Qo/ssz48PMYNYhdOnu7jx39j15LOyjoY9TVGkkGQr2Y+X0CQKnmFAhWVL8E5\nQJs0lddu88wNkCTLl/nGZyU6XTJ9LwQS+jntSRw8sff29LjC9gX6fT9EntPugCsn54AgcG0UqqiR\nk5hxwTRSUvevhj2AxH3T/REqGifV8RlCCq67MUNv246r46Jyzgrrb76Eb03tvX18+E8xHi8fTPky\nn4eHh4eHh4fHC+ArzUwlaeR2nAAHkcnw2VOO+8c24u11QvS7Nj18IZHYWbO74SSsMBnbyHmaMfz4\nU3vqG4MKFWUFxqUEZQwxK+YoiF0RyS7+t39td0xcpCiIKfTxxzl+9vOmRBFiezOkczAoqdl2d3cL\n30xeWfoav/uHv4+1gY147z9+iCfUxLgerCEf0O5sbRPFvhUgVacnYMTsU8wgF41gW4WfPrYiicW3\n38HXb1jWxbSuod54AwDwN7/4BXYL+92Eb8NM7G7UnH6OWwvblH9HJvhaYnes2fQQ+5SZCr77fVz4\nD/7M3qu79/E0O1nq+hS003WCMdYuBpZVwt1mzDiRVG1a0U4GhpORvR9HZzOUdaM1EiAlTZQkFJCs\npN9HGHRslufp00eItd19GgZkVN6EFK4kpCrtLFKMZuBN2oMbPIfzAQy4a4A2jLnr0uf0s8433BtV\nuWxO2hmg07dN9kl/CEOO7tZqjxoe4xim8ZaEcY3mqtaumV7xACIm3RddAwlldgYDaPJLU7qEoQtm\nWrUN5UuAmcqJnc4N0KX0WAAGQaVmo3RT2YPpa+y9a5+FuZMjI4FYPpLYuWbfremixp1HNpP89qux\nu/a33t2GCBu7IOZEcOtaOVsMyThqeue4kG05Qde2UR2W/KCfxzPndx0GGAY2s3AjzvAN8jwsdIVb\nROioE4M6JwuN3TdRKPtM7j0auezJ2iAC8UiwvrKCh+T9+cnnH2O4YlsWuryH//V/+REAIN2b4+W3\nrHhmXWTorNqMSacjIZoM1zxHTCzPsgSCwM6JUTJ8rgb0MAMiGgvFHJhNqJQ2WWCtYzNBjBe4cOUC\nfaGEIT9UM9UoiVSkCwZQZqrmACcWZMgj5/kZRALdnr0/RXXg3rOAB2C6Jde4RnamMVxpBDPnCMhu\naSUJMRykS1/j3c/ec6K5w8EQc7K6EYwhpCZvUVcIqdxtZIUtElP9/h9+y1l3/e//5M8RUSlzzAts\nkk7doN/H4ZHNEq+KyBEJvrh3D5s7ti2GMekYz1wIyNDOAXWhwEl4OO0MYCq6tzB4HvG++aR0xYEg\nEC6LHkjuMlzziUKxIJ2pOMAqadP1I9Fa6YzHMAs79/QvXMYRZT/nixluXLdrpJQROIlD92qD6k1L\n8Bl9egdBUxKdZ6g02Q6ZEGVjfdWJcGFAGcbpzJWtl8FXGky99eZrCEJ7gxisyjMA9Ho955UExiHo\nQY4ONaqJZaWMFwyS2xTm6zfXcUjiYXcfTSG0/TlbALdv2xpwWT12vnHrGzOszkkEsArBaRIJAoXI\nUD9GwSAEpcx5D0VNLJnoJq5fu7r8Nb7yMg6Jovnjn/wNfvHUimTeUk+wu2Ff+KuXrmH1a+/Y40+m\nqB/aoKm8dx+GDMp0wjAf2EXq3W99G9d3bSr9Z+//CpfpfA4O9/HpP/8BAODtKzegDk/oXs1wMrCf\n39nYRPTpZwCAO+UxHtOAfucP/g6SHtGqf/UBZtfWl7q+8+w8gLkeOBs8tQtdIzhvwJ8p2TS+iHEi\nsBXbIA/ZAoFs5CqmkLxZYDVSEtFLA4kOqftub6/iFgWaZ4s5DI2jujYuGDFolXs50xDPEWjQAegK\nW3kEoRVE40VotGvsMcUMgu7JcNBHSjIGQdKBoSiOcYE4pd/rLqSrHzJkpMA8mVQwjQAmAghi8AUw\nCLqk5CwCaLoWwYNzYR8AtvzrbAwHp/J1J5CuTFnpNqBjkju3AK0NoqGdiDJZgFX29++djPDpv7C9\nJdNS4eP75HElE6xv2M+v9kLHslyUGRgxc7iw5wEABsqJiBoDFwhXumpNyRhzmxwPWy3bGlI/584Q\nQZfMiifHqDK76I2MRKdj54vVtevoD23AVZtTnBzZHhltulgheYCL2+v4oNl4CNO0YeInv3yIz2/b\n+UUe/hBrQzseX92pcfjYLmgRB85o8PR7a5ArtvdkOp7hlDbO1yWDrpdfoCJ2DapsWN8Fssx+9+To\nDK+SPE7Q2cHhhARrRYx+bE9adEuYmEQ16xKafEwlDOYLG1hFpoKkvjMwoKLGM2UinN2b0n02iOmY\n5cLg4WPbihGGEnFCcgUhR12S9I3kmFbPYQI8miKkdXFzK8V8ao+vjQEnZnMUCARE008Hq+h2qIcy\nL3E2suvNG9euoTq2z/Qwm+C1Pbt2bl17Dfe//yf2OJ2+26TNCoUerTGz+QjFyL5bSVjACLoPjEGQ\n8OlKL8aYeouUUuDPIVMS8NgJZzNUbkNe7hdY0NIvA6CmdpPV4QBzGsMRL50UTnVwhKLxQFxdd8Kk\nk0nlWh6UUrh9bNn+K/sL9C/ZTWAVBBiTcCsXEimVgFEDydDez+OnTzBZULsMM3ajvCR8mc/Dw8PD\nw8PD4wXwlWamBr3U6UUYo1003ulESEMbIXe7HTCKGI8LibWLNp0cHZ1gfEjpQPkubo+tD9JKJ8GQ\nGq/1yRMMuY08jyXAyQG8t3sR8QqVEbnCnNLeVa6xSRHpYp7jeGp1j67uXIagUt3ZIkR9drT0Na70\nUgxISPHbX38Xs2P73f2HD3BwYnU8Ho0PcIWc2V95+Q28/vf/E3s+8zOcfGCZNMe3biEhVsrKcIgx\n7aR6gxXcv2u99sYsxNW+TUm+NS9wStYfd8sCdWV3jnssxHTT7kYP7h1CkAbLk3/w3yAn4b1xt4eX\n/uy/WOr6lCI9JwAwBrpp7zbnGXOtTx+YQVNjU7UGbU7AObBKApWD4QoUNVVnZQZB3z07HsNU9qCn\nmcRxbq/vne1VrNBOcTpfYEqWQ9pwNBvCCsbZBhlwcLb8TjEqJ9Zr0B4UjS8NNwqcmjTrWjlLh0Ab\nrK7bzN6gFzmmptbaJeuYsVooAFCVCjWl4xkYFGVHlbYlTACQQYIgooyYqhFQE27YG6Ik6yVdzFoB\nTOv3sfQ1SikQE0snkLyR9oIxBgE1n87rHLJh2xnpvLjSG130Tu2Ffe2dC+Ax/V0J/B59/vAHZ5iQ\nKM2krG2pEjbJxEv7c1YULguWdNoWAA6DsmgaXQPHmmRaIcLyInq/6+BcoBvSs5IaC2pGZ7Ops+aZ\nFRwLaqJ95SLw+ivWNuP+A4O6prLU6jpuXiE9qU4XG5d+YT/z49vgNJ8Ggcbf+4/sGN8/nWEjtNlu\nVDGqJlvIJAaUyio6u5jRy342nSOO7LO9vq3B2PLZxbiz5sRcR4tjCDTsVQ5F79/W+gpOyAvvbJ5h\nSiWeOEpQm4YNHgJUaozjGMkaeUuqOcyUfC8Z5391KwAAIABJREFUoInkVNV9FKR5pHQFKHp3lcLp\niDz+BIegUtraaowOZdG50liMlmNHA8CFrT1srto146Vrl3FEBJYOM5gRAae/soqI5rCiKKBJ0+pH\nf/EDrG/bZ/df/uf/FX7+5/8dAOCf/Plt3NizGcn1y9fx8g3rVVfUHPtH9pibG5cw2LQVjCwb4Syw\n79kgKKHJYzNcS11WrpMmOE3o+RYZknj5BvQiKxHRXLW+0UGnT60NugJftcdZ3wwRhna8bW4BUtp1\na3SYYEZj+9KlPeiSyruDDhRlrUPJERERBoscsjnnV7YQpvbnbpTgcGzLnelggNU1u/Z//uk9fHrL\njrFbD27jdGyf3WDQQ/H/1zKf1go9KoEkUQghWsPhpi47zzJ88OEHAIDNrsBlYjGdne6jT30XPabQ\noRfD6ACc21S3TAzCoU15xqaCIs8llQwRrdiJoJdEqM5soHGSn6K3buvHO5c7+H/+2k4iE7WNK+Rt\nN6yeTyhQMIMelc++90ffwyUyX/zko4/wi0/s8T+/dQtPjiwt+c7JA9x5aH++efNVrN60BrgiL5CQ\nghnjEoImzTDt4uH7loUnwwRf0DU+fPwAR6RaeySAtam9D90qx1FtgyZugFXYAXd69w6Od+xLuPf3\n/kNc+va3l7q+ujRwsp2mXfyfFRNoVa4ZN66Uk9fKebHVhcaEegyCSGJIAzuRA4wm9roPxyOUpOoc\ndQdYUJr+4NERNjbsfQUPceuJDVJneYGKhnSlWevNB+N6c5ZBNL7vype8uTgARteuZ0eIVt08SFP0\nKd2MOgMz1LjHjGOi6aoGJ5V3JAJVRgGgUmCBPWemmeufCtCac4tiAdOU8GQMBHbSVmXh/NIUY3ge\nxmJlFBSl1KUSbrELpURNDJ80iFy5ttYGqgmKJRD1qbzUA8K06f9irocuvtHFz35M/pOzdaTEqDGM\noyRKu0gipCSxUJsSiiauQgM1BQNZViGme1KW6ll65b/lYIyB073JFwWGAVH8GXNSHeP5DIm0C+aT\nx0fo9yyD9uDpE4xP7fu0vb2Jx/vUWxQWeO3bluWXZft4eteaqo8nOc5szIE07uD4if3uKMiwSx6i\nh8chFrmd+3Z3Ulxft8/wV9kMp8EGnbNwjLBloHQOQYxSVeeISLCxWuROvDYOEwwooEuFRk2lHBlo\nzOfEVisZCorcT6ZjcNow9GIJRrIK/U4ISSb1WkoMNmzgWdXlOYHQEN0VMnzWzAlRGhOiLEg5uyqh\nzfKBxh//yX+Md79mJStW+ykeUNl0dnAf/+pf/DMAwPf+zh9i9NQ+uztffIG3vvk1AMDVl1/GP/8L\n6yl7VuaQ6/Y+D2+8hLVrVjx6sLWODgVrvNDYpnlIRyOM583aoJBScmNrbQ2LObW8AJhTYKWkRtil\nvjw2x8G0lSz4MrzyeoL1LXtPhqsxBLV1xEkKSSryjBVgxGaGNmAlrVUHMzy9/ZcAgP3dC+hTomPx\n8B4YjY0Lly5iTG2/6uQMl29QILl7AfsP7cB9dOsWTqif7uHoDEeHdsw/ORvjkwd2nJcM2Nyy78uV\nyxexc2Fv6Wv0ZT4PDw8PDw8PjxfAV5qZWsznWL9BIlvh+cjduKjuzsMn2D+2Ee9oKjH9uW0oH5/u\nY0SN3WpwihUqpRX5HIcktHZWZxiTWFeltStjHU2mOKMG99XV1XMO3RqgXTjTBW5etTusOJROk8Ro\nBSxfIcLjJ0+xSbeVByGGXZsRe/3Ga1ilc764toUPbn8MALj76D4+vWUzVhuf/hLXYht178oAbMey\nGnsrQ5ye2fOPowjvfOtbAIAPPvgYtyk1+161cFmQvCwg71pbnUdBB6PC7iKrjS0s9mykba5cxUXy\nEPzm97+PWC7HPilVjSYHxRiDbm4O460Ji0FbmjGApvR0VSrXPF3XBujZXYWOA4zIvfzC3iZCcmUX\nUiInpiPnARZk+6CKGvmEShpViY3U7mwW05FjfhkuASoXc7SlxmUQZUeOCBAI4awbam2gyXXcyBAB\n6ZpESQdRZK9Lq4WzYmC6D94w48BdFo9xuPumjXJlTVvOoIZ10bIRmTKOtVcDzsJCBSmEbN4jA6OX\nT0kXWWk1fwBwXTvdHV1rW+8AoExrxMg5h6kbhh1Qkz5bGCbOxsTAOOG8dCfB3oYVaK3mCgHt5oui\ndoQBKQ0UeaSFQYCwIRKUHLm295BHQNU0+kvL2PSwMMagJJ2dOl8gIc25eRk4FmY5nePuqZ1rHh9X\nuHXLzqf79z/FeGbnzQ9+8pd4+12rSfSt3/8OXnnN7szfvvmf4pc/s03k7/3yfRyTnyQWKYYr9g8U\nucCAGG2DFYOC3pWNdY598v47qa5jQqLAi9EUulq+zNdPE7dWnCUJEmoTKRZzhERYkAEDIwZwwBgi\nyrAEUqIzoKwva22MqjrCZGbHXb6Y4z4JBs+6HVy5OaDjAJSkgtYxqrDNvhp6LxeLHIZudBhLLEgX\nLs8K9Kj9Yhl8MVIIH9v7Ex9l7phnoxGe0vMdXr6M44ktUVVJiJWLtnLy5rfehSamb39tiFf+2NoC\nXfnOHyOiJnWFEBeo0nJ8OkFILSPaFAgFsaJNAB3Y9S+JBGo0Tf8VMnrv7z0+QU1im53eCqp0uPQ1\nvvF2H1w0IsEtISiKQkDb51vmAry0xzQGaAjb3UDh5NgSjv6vD99DRVn6OBQQxBjupgm6ZCGzrRlO\nx3bNE1/cw+2PbevM/u3bGFFL0KgsXSUljWLUob0uEQi89oplBW6urYGx5YlLX2kwtbk+dBR4rWpX\nelFKgZEqblnVEIG9KcejU2jYUsF8Osf+ib1B9a/ex9/9nvWSSyTDY0o3bm9v4Cal92QgnRAajMYO\n9Q2laeTUY4uqxpDkCkytsbJif9aaoWrUpFntavPL4NHTfcypV2Bjd8eZO2ql0e/atPHFzRk0LdbD\n3gD3H9sy1dPTYxzNbImrV2qs2Cwkbp4d4/DA1rnf/PrX8PFHVgJhNpuhJubjvbLAHr3kaW8D91bs\nxHrc6SOvbUC3fvUisGLPYcINXrtuFdZlp4fpzL7MO/g3q71Xyrh6Hm/1MgHeLnLGGDdQOeNusV0U\nZauMngFPYS/w4tW3kAj7gq/1BQxNtqtJB1ISQ4lJDNZsCXQwWMEnn9hFIctLrNKzGk0+w+yETE6F\ndi8vZy2deRkEde5Ye9IIgIQ6BRPQVGZQnR44sadEEKAlC+aoKZWs4q4zYNWhxHxOaXFVo2hKuMag\niYdElKJpsqq0Rp6T+ff4FCUxW3jAAaJLK62ccrJgreTAMlhP+07J3sBAlU2Qq8EpMKxUgYo+U2qF\nmK5daqCiID5kxlE3GYC4KdeXGRIS4OslAaKGey8ZikYgljHwRt1aa5QUNMlAOINRs7DXBgBMaJTL\nx4v/VqAROl3MF5iSMnShDLqJ3Rx1+BRPj+17djz/BCnJc4h6gTUqvV5YfYK9VbtxC8o7uPOFnXMX\nRQ9pz/7+9/4gwez0cwDA+CxCt0Nz6OIA47E9fhIPgcjOoXcOV/BoZDeGoyJxG4af3c7xd0lQcRnH\nU8nQisiq2rJoASRRgJzmrAAcXerl4Zy7d0Jy4frwlFJYNN6oQYidTTI3znPc+Yz6v3SIdepTLSvt\nAn0hBEpS5l7kFTRNYmmSuNJ0ICQ2V+0VFUXh5HqWwWf7E3z00IqjMq3xzdeuAADiyRyra3buDmSM\nOLLP9Ob1G+hSALW1toV//9+1G+SqNjBbe3Rdczx9YHtrmTHY7NsgpcNDzGd2Hrq4OcBsYddFXWlM\nzuz9nMzm6NDGP6tr5Mf0+9MaMclRLIIUFY+XvkamuwiEXVt0CVT0jFiZoFx06BwUeE3zpa7QtCv1\nkwQvXbXnmVU5Huw3cydDRetldSYwoynmgAM/J4b8XGuoJirTgGoYwzKAoN1tyQBBv+93E6yQ72i3\nmyKUy5drfZnPw8PDw8PDw+MF8JVmpr7x9dcQR6QzxZjT7ymLEpIayW5cvYA792ym5k+++018jQS3\n/u+/+hmOf/gzAMAr1y/h6mW7Y5rNMuzs2bR0FLd6NpIz5ysFtJpWcRK7v6vO+cYZA9R1Y6NhXKZF\na2GNnZbENMuhzmwWCVEMQ83UwrTNxZ3eGi5foma8tR0Mu3bXMHj0APsjy/47HY9wTA7pDx48wJWr\nVjh0NB6hoAyHNgpT2uTvhxJXqSmfJzGO5zYl/MH0wPmZ1Ytj7Bd2d7Z17SIufmYzU+nG2tLMjPP2\nMJwzOEVLZlpBVub+gT7n06cMUNbN/RY4GNvrO1pM8b3ftw2V/eoMurA7oZPTY0jyiAp7HZeKvTca\n45j6QYscjg23e/EaIG3W7unREVST6QglgnD5oS6qEpzGBZfcNYgrHoNFNnUe91cA2g1LbmB0c0Iz\nqMxmUDMeQjZMJ26cGKaqSuRUYhFoxT+ZUa7hW9cVzo7se3B69NiVnSVnCOh8jI5RNEKE2sBg+ezb\n49mZa1dPZeieY8iAVDTlP6DbsG9l4JhUTDKAdnK6VOBUFmRgMI1m1mGNkMo/imVY5Pb95pwjps/P\nZ8Aos5nbSiuESdNQrCGaRv9zmSxuNAL5nHphv8PQAEKyK5otKhxP7VhgtQIRQbEbSQypbLQ/HgFE\nFri8keD6RftMdne7mBNr7P/9qx9hSI3XScxQElNWVRVUaecOyXMoctnodCIM1m01QIhtHKq3AADX\ntl7CMCZ2Mavw6ft2vB8eTFBUy6cXlVKuMlDVldOpG6wMMCLWVVnVLlukVe3YfwbGEUkCGSBtNKE4\nd6zyOAwxHNr5d219iJh8LwXXULrRWFNIKbMz7MOdj1LK/S0Ng4LYq4JxR6haBjwM0KOSu9bGiZ1W\n8wUubNjSW53lePsNa5X28s3rEMI+u/nZxNmgVZVG0figQiEkXT6jDG5csUSrYr7AybHt1K4DYFHY\nNePg0RNs3rTlLSZjZJQVn+UFTj6wBKnuhkSaUBkOHIVZPhcTiguYUwWpVjU0I2utooKgSk4UhtCc\nmJhJDFU1YtYz1B37+XhVY4taUnTFcHxE/qXgbv6bFDkMtfsYxl2bBrhBRC0kVaVQ53YQd1f7eOtt\nK4R9YXsLu5v2nodRpxV+XgJfaTCVV5YO3aDpXTLGOBPV1ZU1/Hvf/yMAQBKHGM/sDb1wYQfv0gVf\n2ruI49P2wTSox4tWXdcYRw/WWrteGs6Fo/DbgK45GeWoaYzZlwkAai2gn2PQZLWCpv6f8GQEc2wD\nBl5XCDp24PaGQ2fUG2nj/IiYiBFF9jOd8ASHIxsQ/eUPfoD/7Ju2rDlYW8etz2y6/fDwADmlMN+P\nOBi313s028ddovA/YAwlLb5Sc2jSp1tlwIe/+ikAQMQx3n7rW0tdX1m3EwgHc2wygLVyAueUEaBt\nQGV/ZFC6VbMOyPj58/uP0SXz5j/65qvY3rti7832CHNSdKtqgX/2L21v2Q9/eRt1Qf1QRqM/sMe5\nce0KLl22PR5JIvB01Kq6p9HyKelEcuc/yLgAp7o8lz2Ivi2f8jBFTeFItxOjTxMgQw1NJblMMXAK\n0IMogOjaQKwsCyxm9rqkqaBLSlsLgTmV/4xWmFKwWRdTF+wyBE7mwcCgot2DYoDQbaD7ZYhk4DYb\nTDBIKv9EYewkHyIurAExAGVqSNqQcMNhVinAEYCh8ylrDYqNEHUDSNenxjAdkzLzosaMpEnGkxJZ\nQf0nWQ0pWhfFgALnfk+iSz9LABUxQD0AwGCFAvrA1NgnL1KRDpF07DsRT6d4K6XN47hGY6sZsRq8\nspNBfqogY1uqM7nBGUnEBOsJInr+pszBqFTbHXRRCfseiGQPJ3O7mQ023sSrN20wtaFOcfCpXYSL\no0eYHNqS07WrF8CfQ8WeM+bmmziOnPpHGEeuHzEIQqBZPI1pgymlXeDzjOq6MVCqkSYBKt28o6Hr\nsxQMji1Ya+16FqXgCChQqhlcmU9phbBh5RruvrsM0gBtP5fRYLT2/Omf/Sn6FGStb++gQ3N3d20N\nVUk9a3Xt5qqyUjDEJI67MQz1TJ0cHmJCnn3XLl/GQ2IFDoYb2NiyZcTFeIzVTfuzETEGFGQtygr8\nY1v27Q63wBsR31qh8xybt/2ze8hoXQzCCDJoFNAD8IbVL2tkJNcxz3JkpHRuUGM2a1iZsr3/EEi7\nJHOUVZhlOX2etWem1TMc55S+m/Q66MT2ei9fXMcbL1nm40q/D0ZBtN1QP8dYXfqTHh4eHh4eHh4e\nv4GvNDN1TA3kgN0ptCU24zJHda1cpD0aT881f3NcoazDPCswfWhl8402jkWmtcFv831izIChyTSE\n7a7h3C6GcwZDmSnBeUv+Ysp9dxnkSkGRzkmIEUROGbRFBk6Rs4xCV8aIGFASY6Df33A+c5EInPXO\n4WiE/+l//B8AAC+/9iY+fN9qYpydnWB0anejD/I5Pgmp5MMEKiqnGiYcc0IYg1XyHeqlPWjyKHx0\n+1Ps7jZ6Gm/8G6+v1Lr1UzMGnI7BTJuO4vKcMTxv/fvA20ygYtplW84mc3xy22qBDIIYN2/aXcju\n5T1Uld2ZffjZLbz3CXkVVoAh53OlckxpXJ3NP8PFdds4ubfTx+aabQidz+ZI4+WHutYajLIwmjPk\npLOiwwCSNJ4MF9C0i2WCo0tlAFPlmGVUkgtqGEWsUFUCJNSpixwl6bsssgkMjXcRCNTK7izLsoCk\nnXevmyCh9HSZZ07QkoE5liIX4jlUpmy5sJdSOY9zaGLnCa4REY0pCkKXPZ5nDIYEM/O6hurYgbpY\nlIiphFobhil59nVWOQJqmBXCgGSsEPdDXKJsh0AKQSUKo7mz8mCMOXHXuq7d25cVJbRaviH0dx0M\nHBkxQCqlMAiJ6FFN0SWGq1rpoHNk35VX8hxTyl6n8wyrpK+0meaItc1wJT2NUFIGKpGW3QlgAY2D\nqX3O92Z9mNSWAudsC4NLds54ZesqNqTNyn726V2MqNH57kcfYYfGy80+hyHx1+UukoHTuyiEAKdM\nuJQCWW7frSRJUVMzOuetfZXW5lxJ3CAksg5jbaaKMYGKyEBCCIRNWVtYfT8AUEq3xzQGgo4JXkOT\n1Q3T2r3H8+nsuQgvWZ654xdlBS5spu8P/uDfQZeaoUUSIaBzrmsNSHvOg94Qp9RWcvDkCWp6/15/\n83WkZBVTFyVKWnvCNMbFK1cAAEGcuPvzzjfexYxYfrNFARHY8ZBPGM5IvLSuOEAZvboq8Ty6drU8\nBUsoo6RqBKDxaTjmhS3V8SrAgqxc8gwwNDeoUgAVza9qjmxmM1yGtc/FAK3QoTH4LWEAALgy7ne+\n8QZ2N+36ECURAhpjqsjdesk4QyCXFwn+SoOp0Wjq0qJaKygqgRRVbQX5YAeuciU55oQ92bmXRHDu\nfNfYuTSwXcxpQWft54EajUUt58KxmJRqfea4bk1stdHguukDqcGwvD9PUdWuR2hca4RE7Wd1BUP9\nSnzmZC/BuUDavLRRgpKkEcoow9oqLaab2xjTZPFP/9E/RFE06U+gIKqnTFIoqqMLKSGJHRlKiZjY\nX71uBymxfMAFckqjikWGspH7/RIoMBcpKQZH5xOaAbKVQ2hUwJkwro+Nu38AEUnHaOwmXZyN7cv+\n0XsfY3JkA6tf/upDPD605zjLC6yv2Xtz4UKCKU3Uqo6cPMDjgymenlBprJpghZg5SRigEyz/UrCo\nC9kECEw62YA6EChBZQAjIOmYWWlwMiGvryACa8xJwxig8lmWLSBonBbTYxgq7UWCYUosoyI3SJIm\nkJFuHA2GK44CnC0WTpFdcAZJgXip8EyP4JchL3JXbumGEUJSMWe6gqYSalbWkBS0mtqgJrFNrQUi\nYtt1uylApQUmGGISMYSSMLD3pMwDBM14FAIFvQcRlzBU0lDcQJNnZsQZurRolnWFWWM4K/FcMiW/\n62AATsmgelKHzesHXZc4OqG5hge4fs32y6ThU+yf2iCe1RqPT+x9nU4y9EL7DHspkFDke68EZnP7\nmSejEieZfeZraY3+OjFNL8dQsG4Ud2e38Et6j6cLBkZ9N7LTgSSx4Nt3910QtAy0qlE2pTpdI6Rx\nsbk+xJMj+67v7x+h3yOF8roEawJ0YyCIhceZcnMV4xw59RoKmbgNZl1UCKh3d5HNwVQTcDFnwl0p\nDV637SONMDBnkdvU93odJ3y7DGql3FpVVSU4HTQbL2DIOFqUEQQZw0veLtuT8dj1Ee5e2HS9wYwJ\n5FN7/3tJgiEpoJdliStkCLzIMsypdxNMIGoM1yVzx5llJU4mdmzUFZwgqtbafWYZjEYVFLGuJWfQ\n5IOrjUBeNAr6CoLZOT6QsRMtLuscJwe25SXL5m7DacCQL6i8W5nfHtu1yxUMA6rKPvejg6dI6IXZ\nubjn+lnLsgKjeZHXCrJaPkTyZT4PDw8PDw8PjxfAV9uAnheuARlgzmaE8xBheE57Bk3qzpxrFj8f\n9zEXBZpzLDJzPr1nDByjzDC4zksYtD/hGTZf83mrQ9U2o8vnYPMVVeV2UloEbgcka4WIt6wk1E2p\nxqAhmkUA+pQ5qpMUinZzV1666ZqCdx7ewxe3rC5KkS1gKHMnDFzJRzCGgH4vRZsVEIzDkFBPXRSo\naWcRhdHfmhb9dTQ7PQD2Bp77T+etxltdJyuW95sZkzgMsUosmsFgFUcHVjhP6RwF6UyVkykWJMi6\nub6OMXmM9foMr920bM5Xb1xBEtid5X/7D/4h8jpw59mIWKZhF2m8fAN6urGLkEpdNQzmlDXVPIAh\nfSUhgCS1u6h+f9U5qyOMEMaCfuTtM5ESi4ndSWejIzcWAilQUSYrK0vkTZNmHEOGZFcTd2EoA2UF\nA+m7nKMX288UCihmy2UX7bUIN3YWSiEkJlIAgJMVxnDYw4S0i/K6QELluQoCVMmEYAuUNKaCIACj\nRmBojorYONLk1hsNQD8ZQKnGq9FAyKZZWMHQ788WNSJKx2dKYELHMUrjOZJvv/MwMOiTTl46XAUE\nkTICIKMde1WH2F2xjcg7VxMgsu0R2ckEmp65HGmA23s8CQ1OqCyflcBhbue+oGbYICbg6tYW1NDq\n/pj5PSxymzW4f7yCDukffX0Y4IOpLb8rBgiyAnvyaPxcmanJokJBrKu8qHHzZctok0kXpbLj/dGj\nJ7h22TKwptMpOFkUJWmCuinZSOneY6VrTOf2u9PZCQ7IXuzx4TH2qJXEqBLGNOKyAmVT6gdzDeJl\nWbjStNZwHnaMwXlOLgNuzDmRY4Pxib2fx0+fYGWV/P4yiZDORynlSp+BlBCk1abDwLWqnI7PHDsd\ngGsTSNMUGa1JWtUIzs3TTTdGJIVlxgM4PvkCIyLCREkHAc1bhnOw5yjzTY+5YymKFFjQGBA6Aq8a\nhl0II6n8VwMnp3as5tkMFZ1zEEpwZa89y6tzhLNf+4NNZwlvM1OcA7OFfe4/f/9jfHr7LgDgyrUr\nuH7VMlK31jYc0UaVCmL5/vOvNpja2FhrBw1rF18bKDV1bv1MANXUobXR0A1bySikxAZgqCGIZbLI\nFcqKGBjKoKY0bVEyVBUtcIFw9NrzkYDWOBeInf99m+JdBoa1/SdZWSCkwVozOB8tU9VOMCyNIpd6\nDJVCRWXQUHKs0kS5d2UPEyprxUGA6cSm6ienx66nLOD8WQWHptqitCutWkowCS8a+x0A6G1uNaXw\nL4WlijZl1d/+GcZ4W3JirP0gg5OHGHY66JMB5Uo/xs6alWlYHB9iOic14F4HAU3CeTbCSs8O169/\n7Qa+9nWbtt7sJJgc2wfXkdo98zCM0KG+sW4coxMtX+YzUdTodCIQHBFr1McFNL0xQrT06sHqBrpd\nG9CVtYJuSoEB3OKv6ho5eQvyunD/o6gqNC7DjAUoKK2vUKOf2PMvitptAWoFRwEOpABIDTgIw3Nb\njC+HAHc9CXEYOfPZIGIAbXKOFhOUVOKWIkC1sD8nEcNCUdAacsQkaVDUFbo0voq8tCbFAOIOx2hK\ngpLz1q9QMGFpUwDyUruFqdAlaioBl6VpWs1QVq2wpwcAxhBQMJprjcOcShUKWBNtj8+jqb2B62kH\n/dUdAIAMIoRndtFezGY4oXssCqCmcsxMayec2Bl2MLxqe3nkIHECsVuBQo/K75WSuMjsMQdFiUHT\nXnChj+NjO/YXiylgli+BfXz/CJpaGWIpsEpSAWVeYH3LXkuvN3AeGmEUQ+tmPLZMvUWRYb5oTcol\nyXMUeYX+qg0MO0noPhNwuGvUhqGhETJw1Lph03JXitLGICM/RG2e4ZN9ObRynp9G19jft0HE3/z1\nv3atDWESoUN9TEkSIUoa8+EOQrrPMkoQkFp8GAaIKCgIwwiGSvfz2YmTjFGmhqL3TNW1E0sOOHNC\nuY8f76OmxSFF1bqHCInn6Zna6G1hQZu9/loHghTiu+E6eGYDqKePxhis2WA2zzMcPLYsQhgGST6o\nURg5IeRLV9Zx55ZljM5Gc3fHWbuHfabMx9AmTyrGcTq3z+vs/U9w74FtLXnztdfw5hu2B1DGEdRz\nrP2+zOfh4eHh4eHh8QL4SjNTu9tDl2mCaQUztUErumY0mhhPcOGa+oxRbeoOBjGlpTkzLt1Y1K2m\nkTFtZa9WbfnPwDhhRBh2rkTYsjFwLmtWVRqLRbj0Nda1hqBsQa0rp2fCVY2KdgeBUuhQ03Sga2JG\nAFKECChLEQkBQ2ljKQUkNRkmaYz+CjVMlhVqaiJntXIMQc3hPIU0b7N7oZBOC0UyhvVd65PY37qI\nLFsy9c7YM0wVtwMz7V7sN0t7rfZXoz2UBiFi2j2Pjp5idYXsDvodt/NL0h4uUxP59Wt70JVNx9+8\nvo3LO3Y3KcsCNSkUxpIjo/x6JAVSykaloUDyHGKPSRqAUVqfKYOgyaSAQemmlNmyJIuyABbEJmIA\no2ZGjbAVps0XjhUaBIFrIjcKKKt2/ILKYVozzGknlxU17QStp6EMbepfMiCnEhuPQmysby59jSpj\nGM8o4xaVSHuUHROt/tssK5CkjfCfAKONeg3jAAALuUlEQVSsU2VqxLG9D1EUQjVl0MBAN5Ix3RiK\nUvlFyWGokXNSZ+jSMbtJgIJSH1ldg/MmO8ahm6ZjGCcWGnGGwCxfrv1dB2Ot0PBoPEEp7b1RvAPN\nqHSymCMLiegRRxCUuVgdDhAHdmd+lGW4TbZ7YwAX6BmuaCDq2c+nNy5iuGOzQsJwdHtkx6JDrIhG\na+kBytyO2Qe8g/U+kWl0gh/dtzpTY8NRPIfVSiIFVlatHlAcMiQN0zRKwGmeVdpgSvqFZamgmoqE\nUihpboXWjpTT7yeISLssFIGzNOKCoyKmYVEbl91gwkDSZ5SBa0y3QryNtlRbOSkL9VxkEDDt/pbg\ncNZqJ9M5qGKJpKoxKalsqgtXQmecu+wJV8yRjYIwdHNwEAStIDUAQcdnkXDplJBLRJRpT5IEnJjk\nn9+6hcnkjI6fubUzihOXvVoG1dxgd/0KAGB10MWciA2n+wukgZ1veisr2LtsyRKah4j7lm2XFVNM\nZ7bU+Oj+LQzo99euXMXTB1YzKztXBbCZqYZA1v6rjXZrFFfa6U3LIMKgY9eZs9MzvPfhewCAre0d\nrK9sLX2NX2kwJUXgjFB/o+HmvKYaa/qJ2n8Nfi112tBEz/vAiXNHNG13v0QbcIEDpjGUe0bk0Nn0\n0mLS9mH1eoOlr7GsKoAmC641FJXwTFUioIU+MAYxmTKeTiZoQrVuJ0FKbL6srjEjCvx0PEdOKeSq\nKLC5ZR/w5GwEEOU1FkDcsHkYUDUGu0oDNFhDGTi2yubuZVy8Zr3u5lntyktfBq0NuHs+bWDFeSuN\n0Pw/4PxdtWgYIAHnqEg2otMJcXT40P7cXUWvbwMlLhi+8x2rjH71+h4eP7Q17m4vAad+siAIwWmx\nCOMIkp5tEgdIaUJIw8h5xi0DEUSNdh90bVx/gjEhGKmDMxY4Jk8+nyGnHowwFAipbyTirRFonHSQ\ndO1iV07PkM1JuXe+sGMGVGp2E3IOTQFuGCaQdC0G2pkkV7pGSRNpFJnnYtcUurZm0ADOVAZoG6DN\nZyUSmpDTJEJNF6lrDYZzooQ0aGdFiYT+bp/FKKgmN8tyxCR9IRkH3TYkMoKiMk+NwpVnup0YAaON\nhwgxW5AoYVUAvLnGEPnCN001MGBohnUqanBS4WeMgTNSiWYBtphdDOXpE4wy+yBe3VpF3LHv2cm6\nwIDb8csNg+KNp6JEtGY3bhs7FzGkheXR2QypsuM3z8YQuZVn2QlL8KHtz9qvBB6NrBDo4XSCgHpw\nNvpDV15eBm/f2HEzSFVXzkFhMs8xJYXY0TR3G8aA1Yhpw9jtpOiTF+xwOEDcBES1wtMjW44UMG4j\nZwyDoHKeZsa1UGhTO3VzxoXbINVKIWiOqQFDG4NuJ3bv8VI4p6QeSYkpBXS/+OyW2zReuXoZfdrM\npIMU29RvGoaBCwDrLHfl8clkgjGZ/eZ5jowYw3met0KmqnYZh06cuPc+SRJUtIGczTP0KSguZqdg\nFMBC1a3Y5hK4sncFnCaN04Mz1CQp0Y+72CTF8TTtgFPv9LQ2WCefwTiWODsl/9r7n+PgqV0rTo+e\nYEEtITY4btmXbQvRuZYd1Rp2CMlcDxdEiJR+Nkbh81tWFPvegwd45frrS1+jL/N5eHh4eHh4eLwA\nvtLM1HQ6cxpPjJ3T2ALONaa38d353NX5zNT5bMczn3nGMuBvP4921/DsX3jmq7+lSrUMqqqCKlof\ntSbyr1WNikpHIZcoaMeflwVkYlOMotN3O5SgmoPRDmIxmmKRN5kj7ZgZcRigpON0iwJxc11hAnRs\nNq0sCxhKs/RW1rC+bptIL1x/ybEmp+MRNF/OL4sZtA3EnLlnwsGdJQIMfu05tzezeUZRIFGRFY7R\nAYak9QIeoijbEm6TXtecIyYhwjRJwCmfx6WAjO3nkzRBRKXUThAgpQb0OJSIg+exBBIQxCzThkGR\nx1VnsIFo1d6/+WKGstmtmpkTMtWFRkU6SgwMgnY83cEAa+s2Pa3zdRw9sburs/G9dgestEvHGzDX\naAnGXDkBzLimYMaZE3bVqkY2bUVxvwzduC1BTpWGana3wjgGizZwWbBQRuDS5QigNJ2bZI40MVOt\nRouQIQJud7pFXkLT/YkDCdUwWbVE3LD5tABrBChrg2xqz0cwDUZ/N5tXttzvYcGYE0bdHA4x4iTC\nGqboxHZO2YhCdLXNIm2wDMRjwTTsoaTSxs1XUlyhLOW0qNGn92xl2HPin8NOgCC2f+v1IEFAzyQ3\nHNdID49nGs0stcdTvFkR+SYIMKP3VRmGmzeuLn2JB+MCi8KOhUVeOF+/WmlitgKdOMSQbFd6aezY\n10konU6hUhUqarmQQYw+iexyBsigEQBWcDqFBrbUAVtKq52fYCsUGQjh3nvGBUTQrE82s7UsyqKE\noQxznETOImrONMbkjTieF5gRe5GPFTZoLdne2nKZc6QxYkkM450t7NBcUlWVq2zMs4VrlEdRoiKf\nV6OUZbfACgA3Dfe7u9uoS3tv62yAnEr6WZZjaQo4gGyeI4romNt72KRWFclDl+2Kwgg5aUwenY4Q\n9W3G6umTR3j/538FAJgeH6Kk7HcumGPeWaHv5lkw56l3Xhyca+NEWYe9PkJaR4uyLf/Np1PndxpF\nMYpieebpVxpMAXAP4BlTVtYGSMbUjk30rJ1SS1WzKre/cchnbtz5/69Na3hpTCulwMB+zafvXEB1\njqXxPKjr2n23VgrQrXdT0z8lZIAxUTS1qpHQA+5evIJ18keK78SoHtl68HQ0QkkicDJJkDaTXdpF\nxW0Kv89qMAqatBBIaaIseIC0b1PvL339HcQ9+3vIACGVYdbE0BnXfhmYkZCmUbA+1xvF25+1No4b\nLMQ5buo5bz4uJaSxk9jZaO582bioIKWdkjudBBkp4hojXWAloVxK3QiGJs5IYumE2NIQzlcskAzP\nEUthXjLEzashJJDY+5eubIBRcNSTAjkJqaqqRELMRGOMUwlmukRF1PIqTVHTfcsqgzMy/ZzNF05l\nWpl2mxBGiVNg5lI6lo6Bdj0P/Fw/XFGVqBbLSyNUhQannrVUxeB0zoOwA7LHwsEkwyC1Y3NmZghI\nRX7QjVGT+XCWLRDyRry0cpIcYDnGI5Ky6EaYUnDUr9tejigQmDbKzJIDtOBqoxFQH5wCUJfkCVi3\nitYe1nz42jvfAQD8/f/6v0fVvGdCujFi7ysFslI05ElkRtgGHQCSc+dzV+u2JcKg3dxar7qWfc0p\nCFbanJsrNXpN2Zad66E8txG2sgHL6wZ8eO/QnXM3jRzDuZOEiBo/SWEQUb1TyBA1zT1aacAJbwpU\nFCzUpkISNWrozMnOGNX6uDHWEv8ZABmce+eaxZnzZ8pITsW8KH6rE8ffBg6OjDw5dVlie53kLtLE\nOT2MxzNAN2KVNSq6RsaAhHprORNuPuh0Oo5trGobMNjvStdzycMU/ZV1+q5BTTIoQkrXDnJkDnE6\npmB50HdtBWVVPSO98GW4duUael0bwEoRIuKN8LB0rh+LRYZ9El2W8Zrr+51OZjg5tNI5UHW7VDEG\nRmNPMH5uvLVC3lq1AtlxnKBDa2en28GiaARIWTvOpURIwXUYhlihoG8Z+DKfh4eHh4eHh8cLgD1P\nBO3h4eHh4eHh4fEsfGbKw8PDw8PDw+MF4IMpDw8PDw8PD48XgA+mPDw8PDw8PDxeAD6Y8vDw8PDw\n8PB4AfhgysPDw8PDw8PjBeCDKQ8PDw8PDw+PF4APpjw8PDw8PDw8XgA+mPLw8PDw8PDweAH4YMrD\nw8PDw8PD4wXggykPDw8PDw8PjxeAD6Y8PDw8PDw8PF4APpjy8PDw8PDw8HgB+GDKw8PDw8PDw+MF\n4IMpDw8PDw8PD48XgA+mPDw8PDw8PDxeAD6Y8vDw8PDw8PB4AfhgysPDw8PDw8PjBeCDKQ8PDw8P\nDw+PF4APpjw8PDw8PDw8XgA+mPLw8PDw8PDweAH4YMrDw8PDw8PD4wXggykPDw8PDw8PjxeAD6Y8\nPDw8PDw8PF4A/x+sjndCLqkJ8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09d53270f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for cls_idx, cls in enumerate(classes):\n",
    "    cls_data = [datum for datum in test_data if datum[1] == cls_idx]\n",
    "    rnd_idxs = np.random.randint(0, len(cls_data), samples_per_class)\n",
    "    rnd_cls_data = [datum for i, datum in enumerate(cls_data) if i in rnd_idxs]\n",
    "    for i, cls_datum in enumerate(rnd_cls_data):\n",
    "        plt_idx = i * num_classes + cls_idx + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(cls_datum[0].numpy().transpose(1,2,0) + mean_image.transpose(1,2,0))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture and Forward Pass \n",
    "\n",
    "After you understood the core concepts of PyTorch and have a rough idea on how to implement your own model, complete the initialization and forward methods of the `ClassificationCNN` in the `dl4cv/classifiers/classification_cnn.py` file. Note that we do not have to implement a backward pass since this is automatically handled by the `autograd` package.\n",
    "\n",
    "Use the cell below to check your results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1:  5 5 32\n",
      "after maxpool:  2 2 32\n",
      "Difference between the correct and your forward pass:\n",
      "[[-0.012747    0.05964366  0.03898075]\n",
      " [-0.01286935  0.05963349  0.03903975]]\n",
      "1.95201428952e-07\n"
     ]
    }
   ],
   "source": [
    "from dl4cv.classifiers.classification_cnn import ClassificationCNN\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "X = np.random.randn(2, 3, 5, 5).astype(np.float32)\n",
    "X_tensor = torch.from_numpy(X.copy())\n",
    "inputs = Variable(X_tensor)\n",
    "\n",
    "model = ClassificationCNN(input_dim=(3, 5, 5), num_classes=3)\n",
    "#print(\"input size = \", input.size)\n",
    "outputs = model.forward(inputs)\n",
    "correct_outputs = np.array([[-0.012747,    0.05964366,  0.03898076],\n",
    "                            [-0.01286934,  0.05963349,  0.03903975]])\n",
    "\n",
    "# The difference should be very small. We get < 1e-6\n",
    "print('Difference between the correct and your forward pass:')\n",
    "print(outputs.data.numpy())\n",
    "print(rel_error(correct_outputs, outputs.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation with the Solver\n",
    "We train and validate our previously generated model with a seperate `Solver` class defined in `dl4cv/solver.py`. Complete the `.train()` method and try to come up with an efficient iteration scheme as well as an informative training logger.\n",
    "\n",
    "Use the cells below to test your solver. A nice trick is to train your model with just a few training samples. You should be able to overfit small datasets, which will result in very high training accuracy and comparatively low validation accuracy.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Note</h3>\n",
    "    <p>As seen below, the design of our `Solver` class is indepdenent of the particular model or data pipeline. This facilitates the reuse of the class and its modular structure allows the training of different models.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1:  32 32 32\n",
      "after maxpool:  16 16 32\n",
      "START TRAIN.\n",
      "[epoch 0 Iteration 0/2] TRAIN loss:  2.310\n",
      "[epoch 0 Iteration 1/2] TRAIN loss:  4.424\n",
      "[epoch 0/20] TRAIN acc/loss:  0.130/4.424\n",
      "[epoch 0/20] VAL acc/loss:  0.111/2.475\n",
      "[epoch 1 Iteration 0/2] TRAIN loss:  2.569\n",
      "[epoch 1 Iteration 1/2] TRAIN loss:  2.725\n",
      "[epoch 1/20] TRAIN acc/loss:  0.100/2.725\n",
      "[epoch 1/20] VAL acc/loss:  0.100/2.756\n",
      "[epoch 2 Iteration 0/2] TRAIN loss:  2.903\n",
      "[epoch 2 Iteration 1/2] TRAIN loss:  2.277\n",
      "[epoch 2/20] TRAIN acc/loss:  0.150/2.277\n",
      "[epoch 2/20] VAL acc/loss:  0.140/2.271\n",
      "[epoch 3 Iteration 0/2] TRAIN loss:  2.228\n",
      "[epoch 3 Iteration 1/2] TRAIN loss:  2.003\n",
      "[epoch 3/20] TRAIN acc/loss:  0.310/2.003\n",
      "[epoch 3/20] VAL acc/loss:  0.168/2.131\n",
      "[epoch 4 Iteration 0/2] TRAIN loss:  2.008\n",
      "[epoch 4 Iteration 1/2] TRAIN loss:  1.766\n",
      "[epoch 4/20] TRAIN acc/loss:  0.350/1.766\n",
      "[epoch 4/20] VAL acc/loss:  0.191/2.153\n",
      "[epoch 5 Iteration 0/2] TRAIN loss:  1.808\n",
      "[epoch 5 Iteration 1/2] TRAIN loss:  1.422\n",
      "[epoch 5/20] TRAIN acc/loss:  0.460/1.422\n",
      "[epoch 5/20] VAL acc/loss:  0.197/2.366\n",
      "[epoch 6 Iteration 0/2] TRAIN loss:  1.617\n",
      "[epoch 6 Iteration 1/2] TRAIN loss:  1.165\n",
      "[epoch 6/20] TRAIN acc/loss:  0.520/1.165\n",
      "[epoch 6/20] VAL acc/loss:  0.204/2.573\n",
      "[epoch 7 Iteration 0/2] TRAIN loss:  1.402\n",
      "[epoch 7 Iteration 1/2] TRAIN loss:  0.936\n",
      "[epoch 7/20] TRAIN acc/loss:  0.630/0.936\n",
      "[epoch 7/20] VAL acc/loss:  0.208/2.973\n",
      "[epoch 8 Iteration 0/2] TRAIN loss:  1.203\n",
      "[epoch 8 Iteration 1/2] TRAIN loss:  0.728\n",
      "[epoch 8/20] TRAIN acc/loss:  0.700/0.728\n",
      "[epoch 8/20] VAL acc/loss:  0.207/3.409\n",
      "[epoch 9 Iteration 0/2] TRAIN loss:  0.868\n",
      "[epoch 9 Iteration 1/2] TRAIN loss:  0.631\n",
      "[epoch 9/20] TRAIN acc/loss:  0.760/0.631\n",
      "[epoch 9/20] VAL acc/loss:  0.208/3.884\n",
      "[epoch 10 Iteration 0/2] TRAIN loss:  0.648\n",
      "[epoch 10 Iteration 1/2] TRAIN loss:  0.497\n",
      "[epoch 10/20] TRAIN acc/loss:  0.790/0.497\n",
      "[epoch 10/20] VAL acc/loss:  0.208/4.427\n",
      "[epoch 11 Iteration 0/2] TRAIN loss:  0.523\n",
      "[epoch 11 Iteration 1/2] TRAIN loss:  0.360\n",
      "[epoch 11/20] TRAIN acc/loss:  0.850/0.360\n",
      "[epoch 11/20] VAL acc/loss:  0.198/5.030\n",
      "[epoch 12 Iteration 0/2] TRAIN loss:  0.416\n",
      "[epoch 12 Iteration 1/2] TRAIN loss:  0.228\n",
      "[epoch 12/20] TRAIN acc/loss:  0.900/0.228\n",
      "[epoch 12/20] VAL acc/loss:  0.203/5.650\n",
      "[epoch 13 Iteration 0/2] TRAIN loss:  0.333\n",
      "[epoch 13 Iteration 1/2] TRAIN loss:  0.154\n",
      "[epoch 13/20] TRAIN acc/loss:  0.930/0.154\n",
      "[epoch 13/20] VAL acc/loss:  0.201/6.244\n",
      "[epoch 14 Iteration 0/2] TRAIN loss:  0.245\n",
      "[epoch 14 Iteration 1/2] TRAIN loss:  0.094\n",
      "[epoch 14/20] TRAIN acc/loss:  0.960/0.094\n",
      "[epoch 14/20] VAL acc/loss:  0.198/7.048\n",
      "[epoch 15 Iteration 0/2] TRAIN loss:  0.158\n",
      "[epoch 15 Iteration 1/2] TRAIN loss:  0.055\n",
      "[epoch 15/20] TRAIN acc/loss:  0.980/0.055\n",
      "[epoch 15/20] VAL acc/loss:  0.195/7.965\n",
      "[epoch 16 Iteration 0/2] TRAIN loss:  0.103\n",
      "[epoch 16 Iteration 1/2] TRAIN loss:  0.037\n",
      "[epoch 16/20] TRAIN acc/loss:  0.990/0.037\n",
      "[epoch 16/20] VAL acc/loss:  0.198/8.917\n",
      "[epoch 17 Iteration 0/2] TRAIN loss:  0.062\n",
      "[epoch 17 Iteration 1/2] TRAIN loss:  0.029\n",
      "[epoch 17/20] TRAIN acc/loss:  1.000/0.029\n",
      "[epoch 17/20] VAL acc/loss:  0.201/9.804\n",
      "[epoch 18 Iteration 0/2] TRAIN loss:  0.037\n",
      "[epoch 18 Iteration 1/2] TRAIN loss:  0.016\n",
      "[epoch 18/20] TRAIN acc/loss:  1.000/0.016\n",
      "[epoch 18/20] VAL acc/loss:  0.200/10.553\n",
      "[epoch 19 Iteration 0/2] TRAIN loss:  0.023\n",
      "[epoch 19 Iteration 1/2] TRAIN loss:  0.008\n",
      "[epoch 19/20] TRAIN acc/loss:  1.000/0.008\n",
      "[epoch 19/20] VAL acc/loss:  0.201/11.284\n",
      "FINISH.\n"
     ]
    }
   ],
   "source": [
    "from dl4cv.classifiers.classification_cnn import ClassificationCNN\n",
    "from dl4cv.solver import Solver\n",
    "\n",
    "num_train = 100\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=50, shuffle=False, num_workers=4,\n",
    "                                           sampler=OverfitSampler(num_train))\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=50, shuffle=False, num_workers=4)\n",
    "\n",
    "overfit_model = ClassificationCNN()\n",
    "overfit_solver = Solver(optim_args={\"lr\": 1e-2})\n",
    "overfit_solver.train(overfit_model, train_loader, val_loader, log_nth=1, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the loss, training accuracy, and validation accuracy should show clear overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAHjCAYAAACNTANBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns4T9P9yIph3Nu4fcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09d53d63c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(overfit_solver.train_loss_history, 'o')\n",
    "plt.plot(overfit_solver.val_loss_history, 'o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(overfit_solver.train_acc_history, '-o')\n",
    "plt.plot(overfit_solver.val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "Now train your model with the full dataset. By training a `ThreeLayerCNN` model for one epoch, you should already achieve greater than 40% accuracy on the validation set. If your training is painfully slow check if you did not forget to call the `nn.Module.cuda()` method.\n",
    "\n",
    "For the overfitting example we provided you with a set of hyperparamters (`hidden_dim`, `lr`, `weight_decay`, ...). You can start with the same parameter values but in order to maximize your accuracy you should try to train multiple models with different sets of hyperparamters. This process is called hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1:  32 32 32\n",
      "after maxpool:  16 16 32\n",
      "START TRAIN.\n",
      "[epoch 0 Iteration 0/960] TRAIN loss:  2.293\n",
      "[epoch 0 Iteration 1/960] TRAIN loss:  2.317\n",
      "[epoch 0 Iteration 2/960] TRAIN loss:  2.325\n",
      "[epoch 0 Iteration 3/960] TRAIN loss:  2.296\n",
      "[epoch 0 Iteration 4/960] TRAIN loss:  2.298\n",
      "[epoch 0 Iteration 5/960] TRAIN loss:  2.331\n",
      "[epoch 0 Iteration 6/960] TRAIN loss:  2.301\n",
      "[epoch 0 Iteration 7/960] TRAIN loss:  2.309\n",
      "[epoch 0 Iteration 8/960] TRAIN loss:  2.308\n",
      "[epoch 0 Iteration 9/960] TRAIN loss:  2.274\n",
      "[epoch 0 Iteration 10/960] TRAIN loss:  2.303\n",
      "[epoch 0 Iteration 11/960] TRAIN loss:  2.268\n",
      "[epoch 0 Iteration 12/960] TRAIN loss:  2.286\n",
      "[epoch 0 Iteration 13/960] TRAIN loss:  2.285\n",
      "[epoch 0 Iteration 14/960] TRAIN loss:  2.249\n",
      "[epoch 0 Iteration 15/960] TRAIN loss:  2.271\n",
      "[epoch 0 Iteration 16/960] TRAIN loss:  2.163\n",
      "[epoch 0 Iteration 17/960] TRAIN loss:  2.185\n",
      "[epoch 0 Iteration 18/960] TRAIN loss:  2.198\n",
      "[epoch 0 Iteration 19/960] TRAIN loss:  2.189\n",
      "[epoch 0 Iteration 20/960] TRAIN loss:  2.141\n",
      "[epoch 0 Iteration 21/960] TRAIN loss:  2.183\n",
      "[epoch 0 Iteration 22/960] TRAIN loss:  2.141\n",
      "[epoch 0 Iteration 23/960] TRAIN loss:  2.140\n",
      "[epoch 0 Iteration 24/960] TRAIN loss:  2.166\n",
      "[epoch 0 Iteration 25/960] TRAIN loss:  2.061\n",
      "[epoch 0 Iteration 26/960] TRAIN loss:  2.077\n",
      "[epoch 0 Iteration 27/960] TRAIN loss:  2.247\n",
      "[epoch 0 Iteration 28/960] TRAIN loss:  2.038\n",
      "[epoch 0 Iteration 29/960] TRAIN loss:  2.118\n",
      "[epoch 0 Iteration 30/960] TRAIN loss:  2.005\n",
      "[epoch 0 Iteration 31/960] TRAIN loss:  1.988\n",
      "[epoch 0 Iteration 32/960] TRAIN loss:  1.971\n",
      "[epoch 0 Iteration 33/960] TRAIN loss:  2.025\n",
      "[epoch 0 Iteration 34/960] TRAIN loss:  2.190\n",
      "[epoch 0 Iteration 35/960] TRAIN loss:  2.082\n",
      "[epoch 0 Iteration 36/960] TRAIN loss:  2.086\n",
      "[epoch 0 Iteration 37/960] TRAIN loss:  2.135\n",
      "[epoch 0 Iteration 38/960] TRAIN loss:  1.942\n",
      "[epoch 0 Iteration 39/960] TRAIN loss:  2.003\n",
      "[epoch 0 Iteration 40/960] TRAIN loss:  2.042\n",
      "[epoch 0 Iteration 41/960] TRAIN loss:  2.052\n",
      "[epoch 0 Iteration 42/960] TRAIN loss:  2.121\n",
      "[epoch 0 Iteration 43/960] TRAIN loss:  1.904\n",
      "[epoch 0 Iteration 44/960] TRAIN loss:  2.179\n",
      "[epoch 0 Iteration 45/960] TRAIN loss:  1.996\n",
      "[epoch 0 Iteration 46/960] TRAIN loss:  2.027\n",
      "[epoch 0 Iteration 47/960] TRAIN loss:  2.086\n",
      "[epoch 0 Iteration 48/960] TRAIN loss:  1.957\n",
      "[epoch 0 Iteration 49/960] TRAIN loss:  1.834\n",
      "[epoch 0 Iteration 50/960] TRAIN loss:  2.182\n",
      "[epoch 0 Iteration 51/960] TRAIN loss:  1.989\n",
      "[epoch 0 Iteration 52/960] TRAIN loss:  1.996\n",
      "[epoch 0 Iteration 53/960] TRAIN loss:  1.944\n",
      "[epoch 0 Iteration 54/960] TRAIN loss:  2.004\n",
      "[epoch 0 Iteration 55/960] TRAIN loss:  1.946\n",
      "[epoch 0 Iteration 56/960] TRAIN loss:  2.075\n",
      "[epoch 0 Iteration 57/960] TRAIN loss:  2.067\n",
      "[epoch 0 Iteration 58/960] TRAIN loss:  2.009\n",
      "[epoch 0 Iteration 59/960] TRAIN loss:  2.048\n",
      "[epoch 0 Iteration 60/960] TRAIN loss:  2.030\n",
      "[epoch 0 Iteration 61/960] TRAIN loss:  1.919\n",
      "[epoch 0 Iteration 62/960] TRAIN loss:  1.908\n",
      "[epoch 0 Iteration 63/960] TRAIN loss:  2.000\n",
      "[epoch 0 Iteration 64/960] TRAIN loss:  2.015\n",
      "[epoch 0 Iteration 65/960] TRAIN loss:  1.906\n",
      "[epoch 0 Iteration 66/960] TRAIN loss:  1.943\n",
      "[epoch 0 Iteration 67/960] TRAIN loss:  1.964\n",
      "[epoch 0 Iteration 68/960] TRAIN loss:  1.899\n",
      "[epoch 0 Iteration 69/960] TRAIN loss:  1.940\n",
      "[epoch 0 Iteration 70/960] TRAIN loss:  1.756\n",
      "[epoch 0 Iteration 71/960] TRAIN loss:  1.810\n",
      "[epoch 0 Iteration 72/960] TRAIN loss:  1.931\n",
      "[epoch 0 Iteration 73/960] TRAIN loss:  1.916\n",
      "[epoch 0 Iteration 74/960] TRAIN loss:  2.098\n",
      "[epoch 0 Iteration 75/960] TRAIN loss:  1.978\n",
      "[epoch 0 Iteration 76/960] TRAIN loss:  1.792\n",
      "[epoch 0 Iteration 77/960] TRAIN loss:  1.796\n",
      "[epoch 0 Iteration 78/960] TRAIN loss:  2.113\n",
      "[epoch 0 Iteration 79/960] TRAIN loss:  1.900\n",
      "[epoch 0 Iteration 80/960] TRAIN loss:  1.931\n",
      "[epoch 0 Iteration 81/960] TRAIN loss:  2.104\n",
      "[epoch 0 Iteration 82/960] TRAIN loss:  1.788\n",
      "[epoch 0 Iteration 83/960] TRAIN loss:  1.804\n",
      "[epoch 0 Iteration 84/960] TRAIN loss:  2.004\n",
      "[epoch 0 Iteration 85/960] TRAIN loss:  2.100\n",
      "[epoch 0 Iteration 86/960] TRAIN loss:  1.774\n",
      "[epoch 0 Iteration 87/960] TRAIN loss:  1.917\n",
      "[epoch 0 Iteration 88/960] TRAIN loss:  1.910\n",
      "[epoch 0 Iteration 89/960] TRAIN loss:  1.835\n",
      "[epoch 0 Iteration 90/960] TRAIN loss:  1.897\n",
      "[epoch 0 Iteration 91/960] TRAIN loss:  1.798\n",
      "[epoch 0 Iteration 92/960] TRAIN loss:  2.168\n",
      "[epoch 0 Iteration 93/960] TRAIN loss:  1.912\n",
      "[epoch 0 Iteration 94/960] TRAIN loss:  1.943\n",
      "[epoch 0 Iteration 95/960] TRAIN loss:  2.041\n",
      "[epoch 0 Iteration 96/960] TRAIN loss:  1.925\n",
      "[epoch 0 Iteration 97/960] TRAIN loss:  1.847\n",
      "[epoch 0 Iteration 98/960] TRAIN loss:  1.905\n",
      "[epoch 0 Iteration 99/960] TRAIN loss:  1.710\n",
      "[epoch 0 Iteration 100/960] TRAIN loss:  2.011\n",
      "[epoch 0 Iteration 101/960] TRAIN loss:  1.731\n",
      "[epoch 0 Iteration 102/960] TRAIN loss:  1.893\n",
      "[epoch 0 Iteration 103/960] TRAIN loss:  1.694\n",
      "[epoch 0 Iteration 104/960] TRAIN loss:  1.788\n",
      "[epoch 0 Iteration 105/960] TRAIN loss:  1.978\n",
      "[epoch 0 Iteration 106/960] TRAIN loss:  1.952\n",
      "[epoch 0 Iteration 107/960] TRAIN loss:  2.004\n",
      "[epoch 0 Iteration 108/960] TRAIN loss:  1.740\n",
      "[epoch 0 Iteration 109/960] TRAIN loss:  1.811\n",
      "[epoch 0 Iteration 110/960] TRAIN loss:  2.082\n",
      "[epoch 0 Iteration 111/960] TRAIN loss:  1.988\n",
      "[epoch 0 Iteration 112/960] TRAIN loss:  1.780\n",
      "[epoch 0 Iteration 113/960] TRAIN loss:  1.912\n",
      "[epoch 0 Iteration 114/960] TRAIN loss:  1.981\n",
      "[epoch 0 Iteration 115/960] TRAIN loss:  2.003\n",
      "[epoch 0 Iteration 116/960] TRAIN loss:  1.979\n",
      "[epoch 0 Iteration 117/960] TRAIN loss:  1.935\n",
      "[epoch 0 Iteration 118/960] TRAIN loss:  1.919\n",
      "[epoch 0 Iteration 119/960] TRAIN loss:  1.761\n",
      "[epoch 0 Iteration 120/960] TRAIN loss:  1.741\n",
      "[epoch 0 Iteration 121/960] TRAIN loss:  1.707\n",
      "[epoch 0 Iteration 122/960] TRAIN loss:  1.713\n",
      "[epoch 0 Iteration 123/960] TRAIN loss:  1.986\n",
      "[epoch 0 Iteration 124/960] TRAIN loss:  1.817\n",
      "[epoch 0 Iteration 125/960] TRAIN loss:  1.719\n",
      "[epoch 0 Iteration 126/960] TRAIN loss:  2.092\n",
      "[epoch 0 Iteration 127/960] TRAIN loss:  1.721\n",
      "[epoch 0 Iteration 128/960] TRAIN loss:  1.785\n",
      "[epoch 0 Iteration 129/960] TRAIN loss:  2.013\n",
      "[epoch 0 Iteration 130/960] TRAIN loss:  1.820\n",
      "[epoch 0 Iteration 131/960] TRAIN loss:  1.527\n",
      "[epoch 0 Iteration 132/960] TRAIN loss:  1.929\n",
      "[epoch 0 Iteration 133/960] TRAIN loss:  1.694\n",
      "[epoch 0 Iteration 134/960] TRAIN loss:  1.720\n",
      "[epoch 0 Iteration 135/960] TRAIN loss:  1.888\n",
      "[epoch 0 Iteration 136/960] TRAIN loss:  1.989\n",
      "[epoch 0 Iteration 137/960] TRAIN loss:  1.897\n",
      "[epoch 0 Iteration 138/960] TRAIN loss:  1.762\n",
      "[epoch 0 Iteration 139/960] TRAIN loss:  1.891\n",
      "[epoch 0 Iteration 140/960] TRAIN loss:  1.772\n",
      "[epoch 0 Iteration 141/960] TRAIN loss:  1.862\n",
      "[epoch 0 Iteration 142/960] TRAIN loss:  1.860\n",
      "[epoch 0 Iteration 143/960] TRAIN loss:  1.852\n",
      "[epoch 0 Iteration 144/960] TRAIN loss:  2.019\n",
      "[epoch 0 Iteration 145/960] TRAIN loss:  1.570\n",
      "[epoch 0 Iteration 146/960] TRAIN loss:  1.907\n",
      "[epoch 0 Iteration 147/960] TRAIN loss:  1.639\n",
      "[epoch 0 Iteration 148/960] TRAIN loss:  1.756\n",
      "[epoch 0 Iteration 149/960] TRAIN loss:  1.831\n",
      "[epoch 0 Iteration 150/960] TRAIN loss:  1.871\n",
      "[epoch 0 Iteration 151/960] TRAIN loss:  1.675\n",
      "[epoch 0 Iteration 152/960] TRAIN loss:  1.739\n",
      "[epoch 0 Iteration 153/960] TRAIN loss:  1.708\n",
      "[epoch 0 Iteration 154/960] TRAIN loss:  1.575\n",
      "[epoch 0 Iteration 155/960] TRAIN loss:  1.729\n",
      "[epoch 0 Iteration 156/960] TRAIN loss:  1.722\n",
      "[epoch 0 Iteration 157/960] TRAIN loss:  1.740\n",
      "[epoch 0 Iteration 158/960] TRAIN loss:  1.748\n",
      "[epoch 0 Iteration 159/960] TRAIN loss:  1.887\n",
      "[epoch 0 Iteration 160/960] TRAIN loss:  1.759\n",
      "[epoch 0 Iteration 161/960] TRAIN loss:  1.722\n",
      "[epoch 0 Iteration 162/960] TRAIN loss:  1.772\n",
      "[epoch 0 Iteration 163/960] TRAIN loss:  1.922\n",
      "[epoch 0 Iteration 164/960] TRAIN loss:  1.765\n",
      "[epoch 0 Iteration 165/960] TRAIN loss:  1.852\n",
      "[epoch 0 Iteration 166/960] TRAIN loss:  1.879\n",
      "[epoch 0 Iteration 167/960] TRAIN loss:  1.974\n",
      "[epoch 0 Iteration 168/960] TRAIN loss:  1.909\n",
      "[epoch 0 Iteration 169/960] TRAIN loss:  1.768\n",
      "[epoch 0 Iteration 170/960] TRAIN loss:  1.573\n",
      "[epoch 0 Iteration 171/960] TRAIN loss:  1.734\n",
      "[epoch 0 Iteration 172/960] TRAIN loss:  1.770\n",
      "[epoch 0 Iteration 173/960] TRAIN loss:  1.875\n",
      "[epoch 0 Iteration 174/960] TRAIN loss:  2.027\n",
      "[epoch 0 Iteration 175/960] TRAIN loss:  1.827\n",
      "[epoch 0 Iteration 176/960] TRAIN loss:  1.909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0 Iteration 177/960] TRAIN loss:  1.641\n",
      "[epoch 0 Iteration 178/960] TRAIN loss:  1.781\n",
      "[epoch 0 Iteration 179/960] TRAIN loss:  1.794\n",
      "[epoch 0 Iteration 180/960] TRAIN loss:  1.401\n",
      "[epoch 0 Iteration 181/960] TRAIN loss:  1.847\n",
      "[epoch 0 Iteration 182/960] TRAIN loss:  1.586\n",
      "[epoch 0 Iteration 183/960] TRAIN loss:  1.669\n",
      "[epoch 0 Iteration 184/960] TRAIN loss:  1.674\n",
      "[epoch 0 Iteration 185/960] TRAIN loss:  1.608\n",
      "[epoch 0 Iteration 186/960] TRAIN loss:  1.623\n",
      "[epoch 0 Iteration 187/960] TRAIN loss:  1.828\n",
      "[epoch 0 Iteration 188/960] TRAIN loss:  1.721\n",
      "[epoch 0 Iteration 189/960] TRAIN loss:  1.844\n",
      "[epoch 0 Iteration 190/960] TRAIN loss:  1.809\n",
      "[epoch 0 Iteration 191/960] TRAIN loss:  1.577\n",
      "[epoch 0 Iteration 192/960] TRAIN loss:  1.762\n",
      "[epoch 0 Iteration 193/960] TRAIN loss:  1.926\n",
      "[epoch 0 Iteration 194/960] TRAIN loss:  1.538\n",
      "[epoch 0 Iteration 195/960] TRAIN loss:  1.586\n",
      "[epoch 0 Iteration 196/960] TRAIN loss:  1.739\n",
      "[epoch 0 Iteration 197/960] TRAIN loss:  1.938\n",
      "[epoch 0 Iteration 198/960] TRAIN loss:  1.915\n",
      "[epoch 0 Iteration 199/960] TRAIN loss:  1.751\n",
      "[epoch 0 Iteration 200/960] TRAIN loss:  1.819\n",
      "[epoch 0 Iteration 201/960] TRAIN loss:  1.987\n",
      "[epoch 0 Iteration 202/960] TRAIN loss:  1.634\n",
      "[epoch 0 Iteration 203/960] TRAIN loss:  1.924\n",
      "[epoch 0 Iteration 204/960] TRAIN loss:  1.746\n",
      "[epoch 0 Iteration 205/960] TRAIN loss:  1.786\n",
      "[epoch 0 Iteration 206/960] TRAIN loss:  1.877\n",
      "[epoch 0 Iteration 207/960] TRAIN loss:  1.594\n",
      "[epoch 0 Iteration 208/960] TRAIN loss:  1.821\n",
      "[epoch 0 Iteration 209/960] TRAIN loss:  1.702\n",
      "[epoch 0 Iteration 210/960] TRAIN loss:  1.831\n",
      "[epoch 0 Iteration 211/960] TRAIN loss:  1.568\n",
      "[epoch 0 Iteration 212/960] TRAIN loss:  1.819\n",
      "[epoch 0 Iteration 213/960] TRAIN loss:  1.596\n",
      "[epoch 0 Iteration 214/960] TRAIN loss:  1.484\n",
      "[epoch 0 Iteration 215/960] TRAIN loss:  1.555\n",
      "[epoch 0 Iteration 216/960] TRAIN loss:  1.817\n",
      "[epoch 0 Iteration 217/960] TRAIN loss:  1.758\n",
      "[epoch 0 Iteration 218/960] TRAIN loss:  1.685\n",
      "[epoch 0 Iteration 219/960] TRAIN loss:  1.684\n",
      "[epoch 0 Iteration 220/960] TRAIN loss:  1.694\n",
      "[epoch 0 Iteration 221/960] TRAIN loss:  1.863\n",
      "[epoch 0 Iteration 222/960] TRAIN loss:  1.723\n",
      "[epoch 0 Iteration 223/960] TRAIN loss:  1.575\n",
      "[epoch 0 Iteration 224/960] TRAIN loss:  1.935\n",
      "[epoch 0 Iteration 225/960] TRAIN loss:  1.755\n",
      "[epoch 0 Iteration 226/960] TRAIN loss:  1.703\n",
      "[epoch 0 Iteration 227/960] TRAIN loss:  1.514\n",
      "[epoch 0 Iteration 228/960] TRAIN loss:  1.822\n",
      "[epoch 0 Iteration 229/960] TRAIN loss:  1.712\n",
      "[epoch 0 Iteration 230/960] TRAIN loss:  1.810\n",
      "[epoch 0 Iteration 231/960] TRAIN loss:  1.903\n",
      "[epoch 0 Iteration 232/960] TRAIN loss:  1.810\n",
      "[epoch 0 Iteration 233/960] TRAIN loss:  1.766\n",
      "[epoch 0 Iteration 234/960] TRAIN loss:  1.451\n",
      "[epoch 0 Iteration 235/960] TRAIN loss:  1.561\n",
      "[epoch 0 Iteration 236/960] TRAIN loss:  1.842\n",
      "[epoch 0 Iteration 237/960] TRAIN loss:  1.507\n",
      "[epoch 0 Iteration 238/960] TRAIN loss:  1.707\n",
      "[epoch 0 Iteration 239/960] TRAIN loss:  1.693\n",
      "[epoch 0 Iteration 240/960] TRAIN loss:  1.726\n",
      "[epoch 0 Iteration 241/960] TRAIN loss:  1.631\n",
      "[epoch 0 Iteration 242/960] TRAIN loss:  1.830\n",
      "[epoch 0 Iteration 243/960] TRAIN loss:  1.538\n",
      "[epoch 0 Iteration 244/960] TRAIN loss:  1.630\n",
      "[epoch 0 Iteration 245/960] TRAIN loss:  1.663\n",
      "[epoch 0 Iteration 246/960] TRAIN loss:  1.715\n",
      "[epoch 0 Iteration 247/960] TRAIN loss:  1.728\n",
      "[epoch 0 Iteration 248/960] TRAIN loss:  1.621\n",
      "[epoch 0 Iteration 249/960] TRAIN loss:  1.407\n",
      "[epoch 0 Iteration 250/960] TRAIN loss:  1.847\n",
      "[epoch 0 Iteration 251/960] TRAIN loss:  1.665\n",
      "[epoch 0 Iteration 252/960] TRAIN loss:  1.738\n",
      "[epoch 0 Iteration 253/960] TRAIN loss:  1.567\n",
      "[epoch 0 Iteration 254/960] TRAIN loss:  1.737\n",
      "[epoch 0 Iteration 255/960] TRAIN loss:  1.801\n",
      "[epoch 0 Iteration 256/960] TRAIN loss:  1.593\n",
      "[epoch 0 Iteration 257/960] TRAIN loss:  1.523\n",
      "[epoch 0 Iteration 258/960] TRAIN loss:  1.954\n",
      "[epoch 0 Iteration 259/960] TRAIN loss:  1.639\n",
      "[epoch 0 Iteration 260/960] TRAIN loss:  1.662\n",
      "[epoch 0 Iteration 261/960] TRAIN loss:  1.783\n",
      "[epoch 0 Iteration 262/960] TRAIN loss:  1.800\n",
      "[epoch 0 Iteration 263/960] TRAIN loss:  1.740\n",
      "[epoch 0 Iteration 264/960] TRAIN loss:  1.607\n",
      "[epoch 0 Iteration 265/960] TRAIN loss:  1.642\n",
      "[epoch 0 Iteration 266/960] TRAIN loss:  1.665\n",
      "[epoch 0 Iteration 267/960] TRAIN loss:  1.544\n",
      "[epoch 0 Iteration 268/960] TRAIN loss:  1.717\n",
      "[epoch 0 Iteration 269/960] TRAIN loss:  1.724\n",
      "[epoch 0 Iteration 270/960] TRAIN loss:  1.643\n",
      "[epoch 0 Iteration 271/960] TRAIN loss:  1.876\n",
      "[epoch 0 Iteration 272/960] TRAIN loss:  1.587\n",
      "[epoch 0 Iteration 273/960] TRAIN loss:  1.900\n",
      "[epoch 0 Iteration 274/960] TRAIN loss:  1.708\n",
      "[epoch 0 Iteration 275/960] TRAIN loss:  1.787\n",
      "[epoch 0 Iteration 276/960] TRAIN loss:  1.643\n",
      "[epoch 0 Iteration 277/960] TRAIN loss:  1.565\n",
      "[epoch 0 Iteration 278/960] TRAIN loss:  1.610\n",
      "[epoch 0 Iteration 279/960] TRAIN loss:  1.487\n",
      "[epoch 0 Iteration 280/960] TRAIN loss:  1.565\n",
      "[epoch 0 Iteration 281/960] TRAIN loss:  1.527\n",
      "[epoch 0 Iteration 282/960] TRAIN loss:  1.459\n",
      "[epoch 0 Iteration 283/960] TRAIN loss:  1.867\n",
      "[epoch 0 Iteration 284/960] TRAIN loss:  1.584\n",
      "[epoch 0 Iteration 285/960] TRAIN loss:  1.520\n",
      "[epoch 0 Iteration 286/960] TRAIN loss:  1.697\n",
      "[epoch 0 Iteration 287/960] TRAIN loss:  1.532\n",
      "[epoch 0 Iteration 288/960] TRAIN loss:  1.609\n",
      "[epoch 0 Iteration 289/960] TRAIN loss:  1.483\n",
      "[epoch 0 Iteration 290/960] TRAIN loss:  1.495\n",
      "[epoch 0 Iteration 291/960] TRAIN loss:  1.749\n",
      "[epoch 0 Iteration 292/960] TRAIN loss:  1.464\n",
      "[epoch 0 Iteration 293/960] TRAIN loss:  1.864\n",
      "[epoch 0 Iteration 294/960] TRAIN loss:  1.520\n",
      "[epoch 0 Iteration 295/960] TRAIN loss:  1.533\n",
      "[epoch 0 Iteration 296/960] TRAIN loss:  1.693\n",
      "[epoch 0 Iteration 297/960] TRAIN loss:  1.409\n",
      "[epoch 0 Iteration 298/960] TRAIN loss:  1.552\n",
      "[epoch 0 Iteration 299/960] TRAIN loss:  1.621\n",
      "[epoch 0 Iteration 300/960] TRAIN loss:  1.754\n",
      "[epoch 0 Iteration 301/960] TRAIN loss:  1.618\n",
      "[epoch 0 Iteration 302/960] TRAIN loss:  1.863\n",
      "[epoch 0 Iteration 303/960] TRAIN loss:  1.829\n",
      "[epoch 0 Iteration 304/960] TRAIN loss:  1.650\n",
      "[epoch 0 Iteration 305/960] TRAIN loss:  1.622\n",
      "[epoch 0 Iteration 306/960] TRAIN loss:  1.726\n",
      "[epoch 0 Iteration 307/960] TRAIN loss:  1.611\n",
      "[epoch 0 Iteration 308/960] TRAIN loss:  1.718\n",
      "[epoch 0 Iteration 309/960] TRAIN loss:  1.490\n",
      "[epoch 0 Iteration 310/960] TRAIN loss:  1.888\n",
      "[epoch 0 Iteration 311/960] TRAIN loss:  1.406\n",
      "[epoch 0 Iteration 312/960] TRAIN loss:  1.450\n",
      "[epoch 0 Iteration 313/960] TRAIN loss:  1.743\n",
      "[epoch 0 Iteration 314/960] TRAIN loss:  1.763\n",
      "[epoch 0 Iteration 315/960] TRAIN loss:  1.643\n",
      "[epoch 0 Iteration 316/960] TRAIN loss:  1.622\n",
      "[epoch 0 Iteration 317/960] TRAIN loss:  1.622\n",
      "[epoch 0 Iteration 318/960] TRAIN loss:  1.653\n",
      "[epoch 0 Iteration 319/960] TRAIN loss:  1.713\n",
      "[epoch 0 Iteration 320/960] TRAIN loss:  1.644\n",
      "[epoch 0 Iteration 321/960] TRAIN loss:  1.699\n",
      "[epoch 0 Iteration 322/960] TRAIN loss:  1.601\n",
      "[epoch 0 Iteration 323/960] TRAIN loss:  1.726\n",
      "[epoch 0 Iteration 324/960] TRAIN loss:  1.439\n",
      "[epoch 0 Iteration 325/960] TRAIN loss:  1.661\n",
      "[epoch 0 Iteration 326/960] TRAIN loss:  1.738\n",
      "[epoch 0 Iteration 327/960] TRAIN loss:  1.874\n",
      "[epoch 0 Iteration 328/960] TRAIN loss:  1.856\n",
      "[epoch 0 Iteration 329/960] TRAIN loss:  1.689\n",
      "[epoch 0 Iteration 330/960] TRAIN loss:  1.662\n",
      "[epoch 0 Iteration 331/960] TRAIN loss:  1.605\n",
      "[epoch 0 Iteration 332/960] TRAIN loss:  1.829\n",
      "[epoch 0 Iteration 333/960] TRAIN loss:  1.479\n",
      "[epoch 0 Iteration 334/960] TRAIN loss:  1.642\n",
      "[epoch 0 Iteration 335/960] TRAIN loss:  1.586\n",
      "[epoch 0 Iteration 336/960] TRAIN loss:  1.590\n",
      "[epoch 0 Iteration 337/960] TRAIN loss:  1.585\n",
      "[epoch 0 Iteration 338/960] TRAIN loss:  1.677\n",
      "[epoch 0 Iteration 339/960] TRAIN loss:  1.460\n",
      "[epoch 0 Iteration 340/960] TRAIN loss:  1.657\n",
      "[epoch 0 Iteration 341/960] TRAIN loss:  1.775\n",
      "[epoch 0 Iteration 342/960] TRAIN loss:  1.527\n",
      "[epoch 0 Iteration 343/960] TRAIN loss:  1.666\n",
      "[epoch 0 Iteration 344/960] TRAIN loss:  1.505\n",
      "[epoch 0 Iteration 345/960] TRAIN loss:  1.625\n",
      "[epoch 0 Iteration 346/960] TRAIN loss:  1.705\n",
      "[epoch 0 Iteration 347/960] TRAIN loss:  1.585\n",
      "[epoch 0 Iteration 348/960] TRAIN loss:  1.711\n",
      "[epoch 0 Iteration 349/960] TRAIN loss:  1.728\n",
      "[epoch 0 Iteration 350/960] TRAIN loss:  1.421\n",
      "[epoch 0 Iteration 351/960] TRAIN loss:  1.676\n",
      "[epoch 0 Iteration 352/960] TRAIN loss:  1.426\n",
      "[epoch 0 Iteration 353/960] TRAIN loss:  1.591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0 Iteration 354/960] TRAIN loss:  1.617\n",
      "[epoch 0 Iteration 355/960] TRAIN loss:  1.790\n",
      "[epoch 0 Iteration 356/960] TRAIN loss:  1.392\n",
      "[epoch 0 Iteration 357/960] TRAIN loss:  1.478\n",
      "[epoch 0 Iteration 358/960] TRAIN loss:  1.876\n",
      "[epoch 0 Iteration 359/960] TRAIN loss:  1.604\n",
      "[epoch 0 Iteration 360/960] TRAIN loss:  1.708\n",
      "[epoch 0 Iteration 361/960] TRAIN loss:  1.796\n",
      "[epoch 0 Iteration 362/960] TRAIN loss:  1.624\n",
      "[epoch 0 Iteration 363/960] TRAIN loss:  1.671\n",
      "[epoch 0 Iteration 364/960] TRAIN loss:  1.712\n",
      "[epoch 0 Iteration 365/960] TRAIN loss:  1.498\n",
      "[epoch 0 Iteration 366/960] TRAIN loss:  1.573\n",
      "[epoch 0 Iteration 367/960] TRAIN loss:  1.650\n",
      "[epoch 0 Iteration 368/960] TRAIN loss:  1.570\n",
      "[epoch 0 Iteration 369/960] TRAIN loss:  1.621\n",
      "[epoch 0 Iteration 370/960] TRAIN loss:  1.641\n",
      "[epoch 0 Iteration 371/960] TRAIN loss:  1.376\n",
      "[epoch 0 Iteration 372/960] TRAIN loss:  1.656\n",
      "[epoch 0 Iteration 373/960] TRAIN loss:  1.787\n",
      "[epoch 0 Iteration 374/960] TRAIN loss:  1.481\n",
      "[epoch 0 Iteration 375/960] TRAIN loss:  1.693\n",
      "[epoch 0 Iteration 376/960] TRAIN loss:  1.661\n",
      "[epoch 0 Iteration 377/960] TRAIN loss:  1.517\n",
      "[epoch 0 Iteration 378/960] TRAIN loss:  1.429\n",
      "[epoch 0 Iteration 379/960] TRAIN loss:  1.581\n",
      "[epoch 0 Iteration 380/960] TRAIN loss:  1.473\n",
      "[epoch 0 Iteration 381/960] TRAIN loss:  1.575\n",
      "[epoch 0 Iteration 382/960] TRAIN loss:  1.615\n",
      "[epoch 0 Iteration 383/960] TRAIN loss:  1.560\n",
      "[epoch 0 Iteration 384/960] TRAIN loss:  1.574\n",
      "[epoch 0 Iteration 385/960] TRAIN loss:  1.706\n",
      "[epoch 0 Iteration 386/960] TRAIN loss:  1.602\n",
      "[epoch 0 Iteration 387/960] TRAIN loss:  1.755\n",
      "[epoch 0 Iteration 388/960] TRAIN loss:  1.750\n",
      "[epoch 0 Iteration 389/960] TRAIN loss:  1.512\n",
      "[epoch 0 Iteration 390/960] TRAIN loss:  1.772\n",
      "[epoch 0 Iteration 391/960] TRAIN loss:  1.561\n",
      "[epoch 0 Iteration 392/960] TRAIN loss:  1.490\n",
      "[epoch 0 Iteration 393/960] TRAIN loss:  1.680\n",
      "[epoch 0 Iteration 394/960] TRAIN loss:  1.687\n",
      "[epoch 0 Iteration 395/960] TRAIN loss:  1.566\n",
      "[epoch 0 Iteration 396/960] TRAIN loss:  1.860\n",
      "[epoch 0 Iteration 397/960] TRAIN loss:  1.441\n",
      "[epoch 0 Iteration 398/960] TRAIN loss:  1.636\n",
      "[epoch 0 Iteration 399/960] TRAIN loss:  1.382\n",
      "[epoch 0 Iteration 400/960] TRAIN loss:  1.502\n",
      "[epoch 0 Iteration 401/960] TRAIN loss:  1.723\n",
      "[epoch 0 Iteration 402/960] TRAIN loss:  1.673\n",
      "[epoch 0 Iteration 403/960] TRAIN loss:  1.562\n",
      "[epoch 0 Iteration 404/960] TRAIN loss:  1.753\n",
      "[epoch 0 Iteration 405/960] TRAIN loss:  1.559\n",
      "[epoch 0 Iteration 406/960] TRAIN loss:  1.365\n",
      "[epoch 0 Iteration 407/960] TRAIN loss:  1.310\n",
      "[epoch 0 Iteration 408/960] TRAIN loss:  1.532\n",
      "[epoch 0 Iteration 409/960] TRAIN loss:  1.597\n",
      "[epoch 0 Iteration 410/960] TRAIN loss:  1.513\n",
      "[epoch 0 Iteration 411/960] TRAIN loss:  1.578\n",
      "[epoch 0 Iteration 412/960] TRAIN loss:  1.429\n",
      "[epoch 0 Iteration 413/960] TRAIN loss:  1.707\n",
      "[epoch 0 Iteration 414/960] TRAIN loss:  1.342\n",
      "[epoch 0 Iteration 415/960] TRAIN loss:  1.886\n",
      "[epoch 0 Iteration 416/960] TRAIN loss:  1.462\n",
      "[epoch 0 Iteration 417/960] TRAIN loss:  1.728\n",
      "[epoch 0 Iteration 418/960] TRAIN loss:  1.362\n",
      "[epoch 0 Iteration 419/960] TRAIN loss:  1.740\n",
      "[epoch 0 Iteration 420/960] TRAIN loss:  1.655\n",
      "[epoch 0 Iteration 421/960] TRAIN loss:  1.793\n",
      "[epoch 0 Iteration 422/960] TRAIN loss:  1.687\n",
      "[epoch 0 Iteration 423/960] TRAIN loss:  1.584\n",
      "[epoch 0 Iteration 424/960] TRAIN loss:  1.506\n",
      "[epoch 0 Iteration 425/960] TRAIN loss:  1.492\n",
      "[epoch 0 Iteration 426/960] TRAIN loss:  1.585\n",
      "[epoch 0 Iteration 427/960] TRAIN loss:  1.478\n",
      "[epoch 0 Iteration 428/960] TRAIN loss:  1.714\n",
      "[epoch 0 Iteration 429/960] TRAIN loss:  1.509\n",
      "[epoch 0 Iteration 430/960] TRAIN loss:  1.416\n",
      "[epoch 0 Iteration 431/960] TRAIN loss:  1.392\n",
      "[epoch 0 Iteration 432/960] TRAIN loss:  1.483\n",
      "[epoch 0 Iteration 433/960] TRAIN loss:  1.456\n",
      "[epoch 0 Iteration 434/960] TRAIN loss:  1.365\n",
      "[epoch 0 Iteration 435/960] TRAIN loss:  1.671\n",
      "[epoch 0 Iteration 436/960] TRAIN loss:  1.748\n",
      "[epoch 0 Iteration 437/960] TRAIN loss:  1.556\n",
      "[epoch 0 Iteration 438/960] TRAIN loss:  1.490\n",
      "[epoch 0 Iteration 439/960] TRAIN loss:  1.382\n",
      "[epoch 0 Iteration 440/960] TRAIN loss:  1.326\n",
      "[epoch 0 Iteration 441/960] TRAIN loss:  1.708\n",
      "[epoch 0 Iteration 442/960] TRAIN loss:  1.497\n",
      "[epoch 0 Iteration 443/960] TRAIN loss:  1.496\n",
      "[epoch 0 Iteration 444/960] TRAIN loss:  1.635\n",
      "[epoch 0 Iteration 445/960] TRAIN loss:  1.463\n",
      "[epoch 0 Iteration 446/960] TRAIN loss:  1.384\n",
      "[epoch 0 Iteration 447/960] TRAIN loss:  1.434\n",
      "[epoch 0 Iteration 448/960] TRAIN loss:  1.416\n",
      "[epoch 0 Iteration 449/960] TRAIN loss:  1.491\n",
      "[epoch 0 Iteration 450/960] TRAIN loss:  1.433\n",
      "[epoch 0 Iteration 451/960] TRAIN loss:  1.349\n",
      "[epoch 0 Iteration 452/960] TRAIN loss:  1.454\n",
      "[epoch 0 Iteration 453/960] TRAIN loss:  1.475\n",
      "[epoch 0 Iteration 454/960] TRAIN loss:  1.762\n",
      "[epoch 0 Iteration 455/960] TRAIN loss:  1.712\n",
      "[epoch 0 Iteration 456/960] TRAIN loss:  1.711\n",
      "[epoch 0 Iteration 457/960] TRAIN loss:  1.548\n",
      "[epoch 0 Iteration 458/960] TRAIN loss:  1.399\n",
      "[epoch 0 Iteration 459/960] TRAIN loss:  1.239\n",
      "[epoch 0 Iteration 460/960] TRAIN loss:  1.406\n",
      "[epoch 0 Iteration 461/960] TRAIN loss:  1.470\n",
      "[epoch 0 Iteration 462/960] TRAIN loss:  1.878\n",
      "[epoch 0 Iteration 463/960] TRAIN loss:  1.319\n",
      "[epoch 0 Iteration 464/960] TRAIN loss:  1.749\n",
      "[epoch 0 Iteration 465/960] TRAIN loss:  1.236\n",
      "[epoch 0 Iteration 466/960] TRAIN loss:  1.381\n",
      "[epoch 0 Iteration 467/960] TRAIN loss:  1.471\n",
      "[epoch 0 Iteration 468/960] TRAIN loss:  1.201\n",
      "[epoch 0 Iteration 469/960] TRAIN loss:  1.542\n",
      "[epoch 0 Iteration 470/960] TRAIN loss:  1.492\n",
      "[epoch 0 Iteration 471/960] TRAIN loss:  1.524\n",
      "[epoch 0 Iteration 472/960] TRAIN loss:  1.444\n",
      "[epoch 0 Iteration 473/960] TRAIN loss:  1.776\n",
      "[epoch 0 Iteration 474/960] TRAIN loss:  1.230\n",
      "[epoch 0 Iteration 475/960] TRAIN loss:  1.679\n",
      "[epoch 0 Iteration 476/960] TRAIN loss:  1.616\n",
      "[epoch 0 Iteration 477/960] TRAIN loss:  1.485\n",
      "[epoch 0 Iteration 478/960] TRAIN loss:  1.423\n",
      "[epoch 0 Iteration 479/960] TRAIN loss:  1.528\n",
      "[epoch 0 Iteration 480/960] TRAIN loss:  1.481\n",
      "[epoch 0 Iteration 481/960] TRAIN loss:  1.364\n",
      "[epoch 0 Iteration 482/960] TRAIN loss:  1.389\n",
      "[epoch 0 Iteration 483/960] TRAIN loss:  1.418\n",
      "[epoch 0 Iteration 484/960] TRAIN loss:  1.411\n",
      "[epoch 0 Iteration 485/960] TRAIN loss:  1.638\n",
      "[epoch 0 Iteration 486/960] TRAIN loss:  1.477\n",
      "[epoch 0 Iteration 487/960] TRAIN loss:  1.481\n",
      "[epoch 0 Iteration 488/960] TRAIN loss:  1.650\n",
      "[epoch 0 Iteration 489/960] TRAIN loss:  1.507\n",
      "[epoch 0 Iteration 490/960] TRAIN loss:  1.724\n",
      "[epoch 0 Iteration 491/960] TRAIN loss:  1.435\n",
      "[epoch 0 Iteration 492/960] TRAIN loss:  1.461\n",
      "[epoch 0 Iteration 493/960] TRAIN loss:  1.473\n",
      "[epoch 0 Iteration 494/960] TRAIN loss:  1.848\n",
      "[epoch 0 Iteration 495/960] TRAIN loss:  1.654\n",
      "[epoch 0 Iteration 496/960] TRAIN loss:  1.493\n",
      "[epoch 0 Iteration 497/960] TRAIN loss:  1.348\n",
      "[epoch 0 Iteration 498/960] TRAIN loss:  1.844\n",
      "[epoch 0 Iteration 499/960] TRAIN loss:  1.464\n",
      "[epoch 0 Iteration 500/960] TRAIN loss:  1.876\n",
      "[epoch 0 Iteration 501/960] TRAIN loss:  1.523\n",
      "[epoch 0 Iteration 502/960] TRAIN loss:  1.693\n",
      "[epoch 0 Iteration 503/960] TRAIN loss:  1.881\n",
      "[epoch 0 Iteration 504/960] TRAIN loss:  1.272\n",
      "[epoch 0 Iteration 505/960] TRAIN loss:  1.658\n",
      "[epoch 0 Iteration 506/960] TRAIN loss:  1.633\n",
      "[epoch 0 Iteration 507/960] TRAIN loss:  1.809\n",
      "[epoch 0 Iteration 508/960] TRAIN loss:  1.415\n",
      "[epoch 0 Iteration 509/960] TRAIN loss:  1.546\n",
      "[epoch 0 Iteration 510/960] TRAIN loss:  1.301\n",
      "[epoch 0 Iteration 511/960] TRAIN loss:  1.407\n",
      "[epoch 0 Iteration 512/960] TRAIN loss:  1.467\n",
      "[epoch 0 Iteration 513/960] TRAIN loss:  1.492\n",
      "[epoch 0 Iteration 514/960] TRAIN loss:  1.580\n",
      "[epoch 0 Iteration 515/960] TRAIN loss:  1.520\n",
      "[epoch 0 Iteration 516/960] TRAIN loss:  1.757\n",
      "[epoch 0 Iteration 517/960] TRAIN loss:  1.362\n",
      "[epoch 0 Iteration 518/960] TRAIN loss:  1.399\n",
      "[epoch 0 Iteration 519/960] TRAIN loss:  1.551\n",
      "[epoch 0 Iteration 520/960] TRAIN loss:  1.368\n",
      "[epoch 0 Iteration 521/960] TRAIN loss:  1.592\n",
      "[epoch 0 Iteration 522/960] TRAIN loss:  1.354\n",
      "[epoch 0 Iteration 523/960] TRAIN loss:  1.440\n",
      "[epoch 0 Iteration 524/960] TRAIN loss:  1.600\n",
      "[epoch 0 Iteration 525/960] TRAIN loss:  1.367\n",
      "[epoch 0 Iteration 526/960] TRAIN loss:  1.474\n",
      "[epoch 0 Iteration 527/960] TRAIN loss:  1.337\n",
      "[epoch 0 Iteration 528/960] TRAIN loss:  1.391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0 Iteration 529/960] TRAIN loss:  1.459\n",
      "[epoch 0 Iteration 530/960] TRAIN loss:  1.315\n",
      "[epoch 0 Iteration 531/960] TRAIN loss:  1.475\n",
      "[epoch 0 Iteration 532/960] TRAIN loss:  1.808\n",
      "[epoch 0 Iteration 533/960] TRAIN loss:  1.369\n",
      "[epoch 0 Iteration 534/960] TRAIN loss:  1.268\n",
      "[epoch 0 Iteration 535/960] TRAIN loss:  1.392\n",
      "[epoch 0 Iteration 536/960] TRAIN loss:  1.530\n",
      "[epoch 0 Iteration 537/960] TRAIN loss:  1.694\n",
      "[epoch 0 Iteration 538/960] TRAIN loss:  1.525\n",
      "[epoch 0 Iteration 539/960] TRAIN loss:  1.467\n",
      "[epoch 0 Iteration 540/960] TRAIN loss:  1.398\n",
      "[epoch 0 Iteration 541/960] TRAIN loss:  1.468\n",
      "[epoch 0 Iteration 542/960] TRAIN loss:  1.239\n",
      "[epoch 0 Iteration 543/960] TRAIN loss:  1.517\n",
      "[epoch 0 Iteration 544/960] TRAIN loss:  1.548\n",
      "[epoch 0 Iteration 545/960] TRAIN loss:  1.576\n",
      "[epoch 0 Iteration 546/960] TRAIN loss:  1.877\n",
      "[epoch 0 Iteration 547/960] TRAIN loss:  1.568\n",
      "[epoch 0 Iteration 548/960] TRAIN loss:  1.428\n",
      "[epoch 0 Iteration 549/960] TRAIN loss:  1.662\n",
      "[epoch 0 Iteration 550/960] TRAIN loss:  1.622\n",
      "[epoch 0 Iteration 551/960] TRAIN loss:  1.580\n",
      "[epoch 0 Iteration 552/960] TRAIN loss:  1.470\n",
      "[epoch 0 Iteration 553/960] TRAIN loss:  1.357\n",
      "[epoch 0 Iteration 554/960] TRAIN loss:  1.626\n",
      "[epoch 0 Iteration 555/960] TRAIN loss:  1.508\n",
      "[epoch 0 Iteration 556/960] TRAIN loss:  1.616\n",
      "[epoch 0 Iteration 557/960] TRAIN loss:  1.722\n",
      "[epoch 0 Iteration 558/960] TRAIN loss:  1.619\n",
      "[epoch 0 Iteration 559/960] TRAIN loss:  1.618\n",
      "[epoch 0 Iteration 560/960] TRAIN loss:  1.296\n",
      "[epoch 0 Iteration 561/960] TRAIN loss:  1.509\n",
      "[epoch 0 Iteration 562/960] TRAIN loss:  1.538\n",
      "[epoch 0 Iteration 563/960] TRAIN loss:  1.668\n",
      "[epoch 0 Iteration 564/960] TRAIN loss:  1.462\n",
      "[epoch 0 Iteration 565/960] TRAIN loss:  1.286\n",
      "[epoch 0 Iteration 566/960] TRAIN loss:  1.414\n",
      "[epoch 0 Iteration 567/960] TRAIN loss:  1.196\n",
      "[epoch 0 Iteration 568/960] TRAIN loss:  1.453\n",
      "[epoch 0 Iteration 569/960] TRAIN loss:  1.246\n",
      "[epoch 0 Iteration 570/960] TRAIN loss:  1.713\n",
      "[epoch 0 Iteration 571/960] TRAIN loss:  1.466\n",
      "[epoch 0 Iteration 572/960] TRAIN loss:  1.229\n",
      "[epoch 0 Iteration 573/960] TRAIN loss:  1.602\n",
      "[epoch 0 Iteration 574/960] TRAIN loss:  1.311\n",
      "[epoch 0 Iteration 575/960] TRAIN loss:  1.396\n",
      "[epoch 0 Iteration 576/960] TRAIN loss:  1.419\n",
      "[epoch 0 Iteration 577/960] TRAIN loss:  1.243\n",
      "[epoch 0 Iteration 578/960] TRAIN loss:  1.507\n",
      "[epoch 0 Iteration 579/960] TRAIN loss:  1.513\n",
      "[epoch 0 Iteration 580/960] TRAIN loss:  1.613\n",
      "[epoch 0 Iteration 581/960] TRAIN loss:  1.329\n",
      "[epoch 0 Iteration 582/960] TRAIN loss:  1.511\n",
      "[epoch 0 Iteration 583/960] TRAIN loss:  1.392\n",
      "[epoch 0 Iteration 584/960] TRAIN loss:  1.171\n",
      "[epoch 0 Iteration 585/960] TRAIN loss:  1.389\n",
      "[epoch 0 Iteration 586/960] TRAIN loss:  1.241\n",
      "[epoch 0 Iteration 587/960] TRAIN loss:  1.459\n",
      "[epoch 0 Iteration 588/960] TRAIN loss:  1.407\n",
      "[epoch 0 Iteration 589/960] TRAIN loss:  1.459\n",
      "[epoch 0 Iteration 590/960] TRAIN loss:  1.486\n",
      "[epoch 0 Iteration 591/960] TRAIN loss:  1.646\n",
      "[epoch 0 Iteration 592/960] TRAIN loss:  1.262\n",
      "[epoch 0 Iteration 593/960] TRAIN loss:  1.617\n",
      "[epoch 0 Iteration 594/960] TRAIN loss:  1.428\n",
      "[epoch 0 Iteration 595/960] TRAIN loss:  1.364\n",
      "[epoch 0 Iteration 596/960] TRAIN loss:  1.391\n",
      "[epoch 0 Iteration 597/960] TRAIN loss:  1.511\n",
      "[epoch 0 Iteration 598/960] TRAIN loss:  1.657\n",
      "[epoch 0 Iteration 599/960] TRAIN loss:  1.473\n",
      "[epoch 0 Iteration 600/960] TRAIN loss:  1.473\n",
      "[epoch 0 Iteration 601/960] TRAIN loss:  1.432\n",
      "[epoch 0 Iteration 602/960] TRAIN loss:  1.469\n",
      "[epoch 0 Iteration 603/960] TRAIN loss:  1.522\n",
      "[epoch 0 Iteration 604/960] TRAIN loss:  1.498\n",
      "[epoch 0 Iteration 605/960] TRAIN loss:  1.434\n",
      "[epoch 0 Iteration 606/960] TRAIN loss:  1.679\n",
      "[epoch 0 Iteration 607/960] TRAIN loss:  1.610\n",
      "[epoch 0 Iteration 608/960] TRAIN loss:  1.584\n",
      "[epoch 0 Iteration 609/960] TRAIN loss:  1.424\n",
      "[epoch 0 Iteration 610/960] TRAIN loss:  1.496\n",
      "[epoch 0 Iteration 611/960] TRAIN loss:  1.465\n",
      "[epoch 0 Iteration 612/960] TRAIN loss:  1.326\n",
      "[epoch 0 Iteration 613/960] TRAIN loss:  1.501\n",
      "[epoch 0 Iteration 614/960] TRAIN loss:  1.508\n",
      "[epoch 0 Iteration 615/960] TRAIN loss:  1.237\n",
      "[epoch 0 Iteration 616/960] TRAIN loss:  1.440\n",
      "[epoch 0 Iteration 617/960] TRAIN loss:  1.544\n",
      "[epoch 0 Iteration 618/960] TRAIN loss:  1.403\n",
      "[epoch 0 Iteration 619/960] TRAIN loss:  1.225\n",
      "[epoch 0 Iteration 620/960] TRAIN loss:  1.402\n",
      "[epoch 0 Iteration 621/960] TRAIN loss:  1.253\n",
      "[epoch 0 Iteration 622/960] TRAIN loss:  1.299\n",
      "[epoch 0 Iteration 623/960] TRAIN loss:  1.420\n",
      "[epoch 0 Iteration 624/960] TRAIN loss:  1.529\n",
      "[epoch 0 Iteration 625/960] TRAIN loss:  1.301\n",
      "[epoch 0 Iteration 626/960] TRAIN loss:  1.328\n",
      "[epoch 0 Iteration 627/960] TRAIN loss:  1.403\n",
      "[epoch 0 Iteration 628/960] TRAIN loss:  1.674\n",
      "[epoch 0 Iteration 629/960] TRAIN loss:  1.505\n",
      "[epoch 0 Iteration 630/960] TRAIN loss:  1.249\n",
      "[epoch 0 Iteration 631/960] TRAIN loss:  1.475\n",
      "[epoch 0 Iteration 632/960] TRAIN loss:  1.797\n",
      "[epoch 0 Iteration 633/960] TRAIN loss:  1.562\n",
      "[epoch 0 Iteration 634/960] TRAIN loss:  1.265\n",
      "[epoch 0 Iteration 635/960] TRAIN loss:  1.595\n",
      "[epoch 0 Iteration 636/960] TRAIN loss:  1.596\n",
      "[epoch 0 Iteration 637/960] TRAIN loss:  1.434\n",
      "[epoch 0 Iteration 638/960] TRAIN loss:  1.636\n",
      "[epoch 0 Iteration 639/960] TRAIN loss:  1.337\n",
      "[epoch 0 Iteration 640/960] TRAIN loss:  1.496\n",
      "[epoch 0 Iteration 641/960] TRAIN loss:  1.185\n",
      "[epoch 0 Iteration 642/960] TRAIN loss:  1.511\n",
      "[epoch 0 Iteration 643/960] TRAIN loss:  1.425\n",
      "[epoch 0 Iteration 644/960] TRAIN loss:  1.272\n",
      "[epoch 0 Iteration 645/960] TRAIN loss:  1.275\n",
      "[epoch 0 Iteration 646/960] TRAIN loss:  1.768\n",
      "[epoch 0 Iteration 647/960] TRAIN loss:  1.398\n",
      "[epoch 0 Iteration 648/960] TRAIN loss:  1.418\n",
      "[epoch 0 Iteration 649/960] TRAIN loss:  1.314\n",
      "[epoch 0 Iteration 650/960] TRAIN loss:  1.254\n",
      "[epoch 0 Iteration 651/960] TRAIN loss:  1.241\n",
      "[epoch 0 Iteration 652/960] TRAIN loss:  1.567\n",
      "[epoch 0 Iteration 653/960] TRAIN loss:  1.541\n",
      "[epoch 0 Iteration 654/960] TRAIN loss:  1.362\n",
      "[epoch 0 Iteration 655/960] TRAIN loss:  1.700\n",
      "[epoch 0 Iteration 656/960] TRAIN loss:  1.444\n",
      "[epoch 0 Iteration 657/960] TRAIN loss:  2.052\n",
      "[epoch 0 Iteration 658/960] TRAIN loss:  1.292\n",
      "[epoch 0 Iteration 659/960] TRAIN loss:  1.398\n",
      "[epoch 0 Iteration 660/960] TRAIN loss:  1.261\n",
      "[epoch 0 Iteration 661/960] TRAIN loss:  1.434\n",
      "[epoch 0 Iteration 662/960] TRAIN loss:  1.411\n",
      "[epoch 0 Iteration 663/960] TRAIN loss:  1.312\n",
      "[epoch 0 Iteration 664/960] TRAIN loss:  1.480\n",
      "[epoch 0 Iteration 665/960] TRAIN loss:  1.321\n",
      "[epoch 0 Iteration 666/960] TRAIN loss:  1.371\n",
      "[epoch 0 Iteration 667/960] TRAIN loss:  1.563\n",
      "[epoch 0 Iteration 668/960] TRAIN loss:  1.442\n",
      "[epoch 0 Iteration 669/960] TRAIN loss:  1.284\n",
      "[epoch 0 Iteration 670/960] TRAIN loss:  1.474\n",
      "[epoch 0 Iteration 671/960] TRAIN loss:  1.660\n",
      "[epoch 0 Iteration 672/960] TRAIN loss:  1.433\n",
      "[epoch 0 Iteration 673/960] TRAIN loss:  1.374\n",
      "[epoch 0 Iteration 674/960] TRAIN loss:  1.589\n",
      "[epoch 0 Iteration 675/960] TRAIN loss:  1.447\n",
      "[epoch 0 Iteration 676/960] TRAIN loss:  1.329\n",
      "[epoch 0 Iteration 677/960] TRAIN loss:  1.503\n",
      "[epoch 0 Iteration 678/960] TRAIN loss:  1.424\n",
      "[epoch 0 Iteration 679/960] TRAIN loss:  1.155\n",
      "[epoch 0 Iteration 680/960] TRAIN loss:  1.267\n",
      "[epoch 0 Iteration 681/960] TRAIN loss:  1.342\n",
      "[epoch 0 Iteration 682/960] TRAIN loss:  1.364\n",
      "[epoch 0 Iteration 683/960] TRAIN loss:  1.374\n",
      "[epoch 0 Iteration 684/960] TRAIN loss:  1.565\n",
      "[epoch 0 Iteration 685/960] TRAIN loss:  1.331\n",
      "[epoch 0 Iteration 686/960] TRAIN loss:  1.491\n",
      "[epoch 0 Iteration 687/960] TRAIN loss:  1.460\n",
      "[epoch 0 Iteration 688/960] TRAIN loss:  1.410\n",
      "[epoch 0 Iteration 689/960] TRAIN loss:  1.577\n",
      "[epoch 0 Iteration 690/960] TRAIN loss:  1.286\n",
      "[epoch 0 Iteration 691/960] TRAIN loss:  1.224\n",
      "[epoch 0 Iteration 692/960] TRAIN loss:  1.526\n",
      "[epoch 0 Iteration 693/960] TRAIN loss:  1.496\n",
      "[epoch 0 Iteration 694/960] TRAIN loss:  1.218\n",
      "[epoch 0 Iteration 695/960] TRAIN loss:  1.398\n",
      "[epoch 0 Iteration 696/960] TRAIN loss:  1.545\n",
      "[epoch 0 Iteration 697/960] TRAIN loss:  1.377\n",
      "[epoch 0 Iteration 698/960] TRAIN loss:  1.057\n",
      "[epoch 0 Iteration 699/960] TRAIN loss:  1.113\n",
      "[epoch 0 Iteration 700/960] TRAIN loss:  1.458\n",
      "[epoch 0 Iteration 701/960] TRAIN loss:  1.388\n",
      "[epoch 0 Iteration 702/960] TRAIN loss:  1.526\n",
      "[epoch 0 Iteration 703/960] TRAIN loss:  1.441\n",
      "[epoch 0 Iteration 704/960] TRAIN loss:  1.619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0 Iteration 705/960] TRAIN loss:  1.420\n",
      "[epoch 0 Iteration 706/960] TRAIN loss:  1.524\n",
      "[epoch 0 Iteration 707/960] TRAIN loss:  1.479\n",
      "[epoch 0 Iteration 708/960] TRAIN loss:  1.414\n",
      "[epoch 0 Iteration 709/960] TRAIN loss:  1.852\n",
      "[epoch 0 Iteration 710/960] TRAIN loss:  1.367\n",
      "[epoch 0 Iteration 711/960] TRAIN loss:  1.065\n",
      "[epoch 0 Iteration 712/960] TRAIN loss:  1.590\n",
      "[epoch 0 Iteration 713/960] TRAIN loss:  1.361\n",
      "[epoch 0 Iteration 714/960] TRAIN loss:  1.571\n",
      "[epoch 0 Iteration 715/960] TRAIN loss:  1.536\n",
      "[epoch 0 Iteration 716/960] TRAIN loss:  1.385\n",
      "[epoch 0 Iteration 717/960] TRAIN loss:  1.546\n",
      "[epoch 0 Iteration 718/960] TRAIN loss:  1.288\n",
      "[epoch 0 Iteration 719/960] TRAIN loss:  1.390\n",
      "[epoch 0 Iteration 720/960] TRAIN loss:  1.395\n",
      "[epoch 0 Iteration 721/960] TRAIN loss:  1.387\n",
      "[epoch 0 Iteration 722/960] TRAIN loss:  1.244\n",
      "[epoch 0 Iteration 723/960] TRAIN loss:  1.410\n",
      "[epoch 0 Iteration 724/960] TRAIN loss:  1.396\n",
      "[epoch 0 Iteration 725/960] TRAIN loss:  1.207\n",
      "[epoch 0 Iteration 726/960] TRAIN loss:  1.391\n",
      "[epoch 0 Iteration 727/960] TRAIN loss:  1.365\n",
      "[epoch 0 Iteration 728/960] TRAIN loss:  1.249\n",
      "[epoch 0 Iteration 729/960] TRAIN loss:  1.353\n",
      "[epoch 0 Iteration 730/960] TRAIN loss:  1.394\n",
      "[epoch 0 Iteration 731/960] TRAIN loss:  1.505\n",
      "[epoch 0 Iteration 732/960] TRAIN loss:  1.372\n",
      "[epoch 0 Iteration 733/960] TRAIN loss:  1.166\n",
      "[epoch 0 Iteration 734/960] TRAIN loss:  1.250\n",
      "[epoch 0 Iteration 735/960] TRAIN loss:  1.176\n",
      "[epoch 0 Iteration 736/960] TRAIN loss:  1.330\n",
      "[epoch 0 Iteration 737/960] TRAIN loss:  1.593\n",
      "[epoch 0 Iteration 738/960] TRAIN loss:  1.109\n",
      "[epoch 0 Iteration 739/960] TRAIN loss:  1.634\n",
      "[epoch 0 Iteration 740/960] TRAIN loss:  1.694\n",
      "[epoch 0 Iteration 741/960] TRAIN loss:  1.193\n",
      "[epoch 0 Iteration 742/960] TRAIN loss:  1.247\n",
      "[epoch 0 Iteration 743/960] TRAIN loss:  1.301\n",
      "[epoch 0 Iteration 744/960] TRAIN loss:  1.179\n",
      "[epoch 0 Iteration 745/960] TRAIN loss:  1.390\n",
      "[epoch 0 Iteration 746/960] TRAIN loss:  1.117\n",
      "[epoch 0 Iteration 747/960] TRAIN loss:  1.240\n",
      "[epoch 0 Iteration 748/960] TRAIN loss:  1.355\n",
      "[epoch 0 Iteration 749/960] TRAIN loss:  1.464\n",
      "[epoch 0 Iteration 750/960] TRAIN loss:  1.360\n",
      "[epoch 0 Iteration 751/960] TRAIN loss:  1.470\n",
      "[epoch 0 Iteration 752/960] TRAIN loss:  1.281\n",
      "[epoch 0 Iteration 753/960] TRAIN loss:  1.285\n",
      "[epoch 0 Iteration 754/960] TRAIN loss:  1.494\n",
      "[epoch 0 Iteration 755/960] TRAIN loss:  1.269\n",
      "[epoch 0 Iteration 756/960] TRAIN loss:  1.475\n",
      "[epoch 0 Iteration 757/960] TRAIN loss:  1.206\n",
      "[epoch 0 Iteration 758/960] TRAIN loss:  1.489\n",
      "[epoch 0 Iteration 759/960] TRAIN loss:  1.317\n",
      "[epoch 0 Iteration 760/960] TRAIN loss:  1.363\n",
      "[epoch 0 Iteration 761/960] TRAIN loss:  1.414\n",
      "[epoch 0 Iteration 762/960] TRAIN loss:  1.642\n",
      "[epoch 0 Iteration 763/960] TRAIN loss:  1.374\n",
      "[epoch 0 Iteration 764/960] TRAIN loss:  1.377\n",
      "[epoch 0 Iteration 765/960] TRAIN loss:  1.406\n",
      "[epoch 0 Iteration 766/960] TRAIN loss:  1.468\n",
      "[epoch 0 Iteration 767/960] TRAIN loss:  1.214\n",
      "[epoch 0 Iteration 768/960] TRAIN loss:  1.280\n",
      "[epoch 0 Iteration 769/960] TRAIN loss:  1.579\n",
      "[epoch 0 Iteration 770/960] TRAIN loss:  1.773\n",
      "[epoch 0 Iteration 771/960] TRAIN loss:  1.306\n",
      "[epoch 0 Iteration 772/960] TRAIN loss:  1.170\n",
      "[epoch 0 Iteration 773/960] TRAIN loss:  1.742\n",
      "[epoch 0 Iteration 774/960] TRAIN loss:  1.666\n",
      "[epoch 0 Iteration 775/960] TRAIN loss:  1.240\n",
      "[epoch 0 Iteration 776/960] TRAIN loss:  1.406\n",
      "[epoch 0 Iteration 777/960] TRAIN loss:  1.508\n",
      "[epoch 0 Iteration 778/960] TRAIN loss:  1.169\n",
      "[epoch 0 Iteration 779/960] TRAIN loss:  1.360\n",
      "[epoch 0 Iteration 780/960] TRAIN loss:  1.740\n",
      "[epoch 0 Iteration 781/960] TRAIN loss:  1.511\n",
      "[epoch 0 Iteration 782/960] TRAIN loss:  1.322\n",
      "[epoch 0 Iteration 783/960] TRAIN loss:  1.421\n",
      "[epoch 0 Iteration 784/960] TRAIN loss:  1.537\n",
      "[epoch 0 Iteration 785/960] TRAIN loss:  1.274\n",
      "[epoch 0 Iteration 786/960] TRAIN loss:  1.504\n",
      "[epoch 0 Iteration 787/960] TRAIN loss:  1.117\n",
      "[epoch 0 Iteration 788/960] TRAIN loss:  1.229\n",
      "[epoch 0 Iteration 789/960] TRAIN loss:  1.172\n",
      "[epoch 0 Iteration 790/960] TRAIN loss:  1.516\n",
      "[epoch 0 Iteration 791/960] TRAIN loss:  1.289\n",
      "[epoch 0 Iteration 792/960] TRAIN loss:  1.174\n",
      "[epoch 0 Iteration 793/960] TRAIN loss:  1.386\n",
      "[epoch 0 Iteration 794/960] TRAIN loss:  1.355\n",
      "[epoch 0 Iteration 795/960] TRAIN loss:  1.222\n",
      "[epoch 0 Iteration 796/960] TRAIN loss:  1.231\n",
      "[epoch 0 Iteration 797/960] TRAIN loss:  1.260\n",
      "[epoch 0 Iteration 798/960] TRAIN loss:  1.692\n",
      "[epoch 0 Iteration 799/960] TRAIN loss:  1.572\n",
      "[epoch 0 Iteration 800/960] TRAIN loss:  1.296\n",
      "[epoch 0 Iteration 801/960] TRAIN loss:  1.397\n",
      "[epoch 0 Iteration 802/960] TRAIN loss:  1.344\n",
      "[epoch 0 Iteration 803/960] TRAIN loss:  1.149\n",
      "[epoch 0 Iteration 804/960] TRAIN loss:  1.310\n",
      "[epoch 0 Iteration 805/960] TRAIN loss:  1.305\n",
      "[epoch 0 Iteration 806/960] TRAIN loss:  1.213\n",
      "[epoch 0 Iteration 807/960] TRAIN loss:  1.237\n",
      "[epoch 0 Iteration 808/960] TRAIN loss:  1.353\n",
      "[epoch 0 Iteration 809/960] TRAIN loss:  1.406\n",
      "[epoch 0 Iteration 810/960] TRAIN loss:  1.154\n",
      "[epoch 0 Iteration 811/960] TRAIN loss:  1.385\n",
      "[epoch 0 Iteration 812/960] TRAIN loss:  1.179\n",
      "[epoch 0 Iteration 813/960] TRAIN loss:  1.588\n",
      "[epoch 0 Iteration 814/960] TRAIN loss:  1.375\n",
      "[epoch 0 Iteration 815/960] TRAIN loss:  1.605\n",
      "[epoch 0 Iteration 816/960] TRAIN loss:  1.469\n",
      "[epoch 0 Iteration 817/960] TRAIN loss:  1.321\n",
      "[epoch 0 Iteration 818/960] TRAIN loss:  1.312\n",
      "[epoch 0 Iteration 819/960] TRAIN loss:  1.356\n",
      "[epoch 0 Iteration 820/960] TRAIN loss:  1.311\n",
      "[epoch 0 Iteration 821/960] TRAIN loss:  1.448\n",
      "[epoch 0 Iteration 822/960] TRAIN loss:  1.606\n",
      "[epoch 0 Iteration 823/960] TRAIN loss:  1.580\n",
      "[epoch 0 Iteration 824/960] TRAIN loss:  1.448\n",
      "[epoch 0 Iteration 825/960] TRAIN loss:  1.475\n",
      "[epoch 0 Iteration 826/960] TRAIN loss:  1.346\n",
      "[epoch 0 Iteration 827/960] TRAIN loss:  1.501\n",
      "[epoch 0 Iteration 828/960] TRAIN loss:  1.565\n",
      "[epoch 0 Iteration 829/960] TRAIN loss:  1.214\n",
      "[epoch 0 Iteration 830/960] TRAIN loss:  1.207\n",
      "[epoch 0 Iteration 831/960] TRAIN loss:  1.413\n",
      "[epoch 0 Iteration 832/960] TRAIN loss:  1.398\n",
      "[epoch 0 Iteration 833/960] TRAIN loss:  1.315\n",
      "[epoch 0 Iteration 834/960] TRAIN loss:  1.387\n",
      "[epoch 0 Iteration 835/960] TRAIN loss:  1.455\n",
      "[epoch 0 Iteration 836/960] TRAIN loss:  1.255\n",
      "[epoch 0 Iteration 837/960] TRAIN loss:  1.165\n",
      "[epoch 0 Iteration 838/960] TRAIN loss:  1.491\n",
      "[epoch 0 Iteration 839/960] TRAIN loss:  1.399\n",
      "[epoch 0 Iteration 840/960] TRAIN loss:  1.361\n",
      "[epoch 0 Iteration 841/960] TRAIN loss:  1.491\n",
      "[epoch 0 Iteration 842/960] TRAIN loss:  1.181\n",
      "[epoch 0 Iteration 843/960] TRAIN loss:  1.740\n",
      "[epoch 0 Iteration 844/960] TRAIN loss:  1.394\n",
      "[epoch 0 Iteration 845/960] TRAIN loss:  1.468\n",
      "[epoch 0 Iteration 846/960] TRAIN loss:  1.327\n",
      "[epoch 0 Iteration 847/960] TRAIN loss:  1.386\n",
      "[epoch 0 Iteration 848/960] TRAIN loss:  1.217\n",
      "[epoch 0 Iteration 849/960] TRAIN loss:  1.264\n",
      "[epoch 0 Iteration 850/960] TRAIN loss:  1.470\n",
      "[epoch 0 Iteration 851/960] TRAIN loss:  1.395\n",
      "[epoch 0 Iteration 852/960] TRAIN loss:  1.416\n",
      "[epoch 0 Iteration 853/960] TRAIN loss:  1.305\n",
      "[epoch 0 Iteration 854/960] TRAIN loss:  1.420\n",
      "[epoch 0 Iteration 855/960] TRAIN loss:  1.412\n",
      "[epoch 0 Iteration 856/960] TRAIN loss:  1.221\n",
      "[epoch 0 Iteration 857/960] TRAIN loss:  1.208\n",
      "[epoch 0 Iteration 858/960] TRAIN loss:  1.469\n",
      "[epoch 0 Iteration 859/960] TRAIN loss:  1.105\n",
      "[epoch 0 Iteration 860/960] TRAIN loss:  1.440\n",
      "[epoch 0 Iteration 861/960] TRAIN loss:  1.217\n",
      "[epoch 0 Iteration 862/960] TRAIN loss:  1.490\n",
      "[epoch 0 Iteration 863/960] TRAIN loss:  1.492\n",
      "[epoch 0 Iteration 864/960] TRAIN loss:  1.301\n",
      "[epoch 0 Iteration 865/960] TRAIN loss:  1.605\n",
      "[epoch 0 Iteration 866/960] TRAIN loss:  1.638\n",
      "[epoch 0 Iteration 867/960] TRAIN loss:  1.342\n",
      "[epoch 0 Iteration 868/960] TRAIN loss:  1.146\n",
      "[epoch 0 Iteration 869/960] TRAIN loss:  1.635\n",
      "[epoch 0 Iteration 870/960] TRAIN loss:  1.558\n",
      "[epoch 0 Iteration 871/960] TRAIN loss:  1.348\n",
      "[epoch 0 Iteration 872/960] TRAIN loss:  1.321\n",
      "[epoch 0 Iteration 873/960] TRAIN loss:  1.469\n",
      "[epoch 0 Iteration 874/960] TRAIN loss:  1.815\n",
      "[epoch 0 Iteration 875/960] TRAIN loss:  1.666\n",
      "[epoch 0 Iteration 876/960] TRAIN loss:  1.284\n",
      "[epoch 0 Iteration 877/960] TRAIN loss:  1.268\n",
      "[epoch 0 Iteration 878/960] TRAIN loss:  1.372\n",
      "[epoch 0 Iteration 879/960] TRAIN loss:  1.850\n",
      "[epoch 0 Iteration 880/960] TRAIN loss:  1.366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0 Iteration 881/960] TRAIN loss:  1.387\n",
      "[epoch 0 Iteration 882/960] TRAIN loss:  1.496\n",
      "[epoch 0 Iteration 883/960] TRAIN loss:  1.451\n",
      "[epoch 0 Iteration 884/960] TRAIN loss:  1.517\n",
      "[epoch 0 Iteration 885/960] TRAIN loss:  1.580\n",
      "[epoch 0 Iteration 886/960] TRAIN loss:  1.159\n",
      "[epoch 0 Iteration 887/960] TRAIN loss:  1.507\n",
      "[epoch 0 Iteration 888/960] TRAIN loss:  1.203\n",
      "[epoch 0 Iteration 889/960] TRAIN loss:  1.501\n",
      "[epoch 0 Iteration 890/960] TRAIN loss:  1.412\n",
      "[epoch 0 Iteration 891/960] TRAIN loss:  1.515\n",
      "[epoch 0 Iteration 892/960] TRAIN loss:  1.513\n",
      "[epoch 0 Iteration 893/960] TRAIN loss:  1.365\n",
      "[epoch 0 Iteration 894/960] TRAIN loss:  1.345\n",
      "[epoch 0 Iteration 895/960] TRAIN loss:  1.445\n",
      "[epoch 0 Iteration 896/960] TRAIN loss:  1.277\n",
      "[epoch 0 Iteration 897/960] TRAIN loss:  1.443\n",
      "[epoch 0 Iteration 898/960] TRAIN loss:  1.398\n",
      "[epoch 0 Iteration 899/960] TRAIN loss:  1.303\n",
      "[epoch 0 Iteration 900/960] TRAIN loss:  1.470\n",
      "[epoch 0 Iteration 901/960] TRAIN loss:  1.618\n",
      "[epoch 0 Iteration 902/960] TRAIN loss:  1.601\n",
      "[epoch 0 Iteration 903/960] TRAIN loss:  1.302\n",
      "[epoch 0 Iteration 904/960] TRAIN loss:  1.531\n",
      "[epoch 0 Iteration 905/960] TRAIN loss:  1.407\n",
      "[epoch 0 Iteration 906/960] TRAIN loss:  1.237\n",
      "[epoch 0 Iteration 907/960] TRAIN loss:  1.382\n",
      "[epoch 0 Iteration 908/960] TRAIN loss:  1.488\n",
      "[epoch 0 Iteration 909/960] TRAIN loss:  1.421\n",
      "[epoch 0 Iteration 910/960] TRAIN loss:  1.302\n",
      "[epoch 0 Iteration 911/960] TRAIN loss:  1.325\n",
      "[epoch 0 Iteration 912/960] TRAIN loss:  1.410\n",
      "[epoch 0 Iteration 913/960] TRAIN loss:  1.252\n",
      "[epoch 0 Iteration 914/960] TRAIN loss:  1.397\n",
      "[epoch 0 Iteration 915/960] TRAIN loss:  1.381\n",
      "[epoch 0 Iteration 916/960] TRAIN loss:  1.393\n",
      "[epoch 0 Iteration 917/960] TRAIN loss:  1.389\n",
      "[epoch 0 Iteration 918/960] TRAIN loss:  1.266\n",
      "[epoch 0 Iteration 919/960] TRAIN loss:  1.340\n",
      "[epoch 0 Iteration 920/960] TRAIN loss:  1.510\n",
      "[epoch 0 Iteration 921/960] TRAIN loss:  1.328\n",
      "[epoch 0 Iteration 922/960] TRAIN loss:  1.312\n",
      "[epoch 0 Iteration 923/960] TRAIN loss:  1.263\n",
      "[epoch 0 Iteration 924/960] TRAIN loss:  1.389\n",
      "[epoch 0 Iteration 925/960] TRAIN loss:  1.225\n",
      "[epoch 0 Iteration 926/960] TRAIN loss:  1.404\n",
      "[epoch 0 Iteration 927/960] TRAIN loss:  1.101\n",
      "[epoch 0 Iteration 928/960] TRAIN loss:  1.167\n",
      "[epoch 0 Iteration 929/960] TRAIN loss:  1.408\n",
      "[epoch 0 Iteration 930/960] TRAIN loss:  1.405\n",
      "[epoch 0 Iteration 931/960] TRAIN loss:  1.514\n",
      "[epoch 0 Iteration 932/960] TRAIN loss:  1.712\n",
      "[epoch 0 Iteration 933/960] TRAIN loss:  1.236\n",
      "[epoch 0 Iteration 934/960] TRAIN loss:  1.226\n",
      "[epoch 0 Iteration 935/960] TRAIN loss:  1.344\n",
      "[epoch 0 Iteration 936/960] TRAIN loss:  1.358\n",
      "[epoch 0 Iteration 937/960] TRAIN loss:  1.384\n",
      "[epoch 0 Iteration 938/960] TRAIN loss:  1.464\n",
      "[epoch 0 Iteration 939/960] TRAIN loss:  1.492\n",
      "[epoch 0 Iteration 940/960] TRAIN loss:  1.449\n",
      "[epoch 0 Iteration 941/960] TRAIN loss:  1.301\n",
      "[epoch 0 Iteration 942/960] TRAIN loss:  1.344\n",
      "[epoch 0 Iteration 943/960] TRAIN loss:  1.185\n",
      "[epoch 0 Iteration 944/960] TRAIN loss:  1.161\n",
      "[epoch 0 Iteration 945/960] TRAIN loss:  1.583\n",
      "[epoch 0 Iteration 946/960] TRAIN loss:  1.299\n",
      "[epoch 0 Iteration 947/960] TRAIN loss:  1.324\n",
      "[epoch 0 Iteration 948/960] TRAIN loss:  1.499\n",
      "[epoch 0 Iteration 949/960] TRAIN loss:  1.228\n",
      "[epoch 0 Iteration 950/960] TRAIN loss:  1.231\n",
      "[epoch 0 Iteration 951/960] TRAIN loss:  1.236\n",
      "[epoch 0 Iteration 952/960] TRAIN loss:  1.555\n",
      "[epoch 0 Iteration 953/960] TRAIN loss:  1.240\n",
      "[epoch 0 Iteration 954/960] TRAIN loss:  1.277\n",
      "[epoch 0 Iteration 955/960] TRAIN loss:  1.352\n",
      "[epoch 0 Iteration 956/960] TRAIN loss:  1.535\n",
      "[epoch 0 Iteration 957/960] TRAIN loss:  1.394\n",
      "[epoch 0 Iteration 958/960] TRAIN loss:  1.500\n",
      "[epoch 0 Iteration 959/960] TRAIN loss:  1.385\n",
      "[epoch 0/15] TRAIN acc/loss:  0.431/1.385\n",
      "[epoch 0/15] VAL acc/loss:  0.506/1.102\n",
      "[epoch 1 Iteration 0/960] TRAIN loss:  1.093\n",
      "[epoch 1 Iteration 1/960] TRAIN loss:  1.188\n",
      "[epoch 1 Iteration 2/960] TRAIN loss:  1.493\n",
      "[epoch 1 Iteration 3/960] TRAIN loss:  1.401\n",
      "[epoch 1 Iteration 4/960] TRAIN loss:  1.458\n",
      "[epoch 1 Iteration 5/960] TRAIN loss:  1.079\n",
      "[epoch 1 Iteration 6/960] TRAIN loss:  1.467\n",
      "[epoch 1 Iteration 7/960] TRAIN loss:  1.528\n",
      "[epoch 1 Iteration 8/960] TRAIN loss:  1.149\n",
      "[epoch 1 Iteration 9/960] TRAIN loss:  1.388\n",
      "[epoch 1 Iteration 10/960] TRAIN loss:  1.436\n",
      "[epoch 1 Iteration 11/960] TRAIN loss:  1.471\n",
      "[epoch 1 Iteration 12/960] TRAIN loss:  1.301\n",
      "[epoch 1 Iteration 13/960] TRAIN loss:  1.296\n",
      "[epoch 1 Iteration 14/960] TRAIN loss:  1.305\n",
      "[epoch 1 Iteration 15/960] TRAIN loss:  1.402\n",
      "[epoch 1 Iteration 16/960] TRAIN loss:  1.404\n",
      "[epoch 1 Iteration 17/960] TRAIN loss:  1.196\n",
      "[epoch 1 Iteration 18/960] TRAIN loss:  1.421\n",
      "[epoch 1 Iteration 19/960] TRAIN loss:  1.333\n",
      "[epoch 1 Iteration 20/960] TRAIN loss:  1.255\n",
      "[epoch 1 Iteration 21/960] TRAIN loss:  1.443\n",
      "[epoch 1 Iteration 22/960] TRAIN loss:  1.230\n",
      "[epoch 1 Iteration 23/960] TRAIN loss:  1.218\n",
      "[epoch 1 Iteration 24/960] TRAIN loss:  1.509\n",
      "[epoch 1 Iteration 25/960] TRAIN loss:  1.236\n",
      "[epoch 1 Iteration 26/960] TRAIN loss:  1.708\n",
      "[epoch 1 Iteration 27/960] TRAIN loss:  1.413\n",
      "[epoch 1 Iteration 28/960] TRAIN loss:  1.306\n",
      "[epoch 1 Iteration 29/960] TRAIN loss:  1.398\n",
      "[epoch 1 Iteration 30/960] TRAIN loss:  1.251\n",
      "[epoch 1 Iteration 31/960] TRAIN loss:  1.102\n",
      "[epoch 1 Iteration 32/960] TRAIN loss:  1.272\n",
      "[epoch 1 Iteration 33/960] TRAIN loss:  1.377\n",
      "[epoch 1 Iteration 34/960] TRAIN loss:  1.362\n",
      "[epoch 1 Iteration 35/960] TRAIN loss:  1.242\n",
      "[epoch 1 Iteration 36/960] TRAIN loss:  1.378\n",
      "[epoch 1 Iteration 37/960] TRAIN loss:  1.203\n",
      "[epoch 1 Iteration 38/960] TRAIN loss:  1.538\n",
      "[epoch 1 Iteration 39/960] TRAIN loss:  1.150\n",
      "[epoch 1 Iteration 40/960] TRAIN loss:  1.400\n",
      "[epoch 1 Iteration 41/960] TRAIN loss:  1.271\n",
      "[epoch 1 Iteration 42/960] TRAIN loss:  1.487\n",
      "[epoch 1 Iteration 43/960] TRAIN loss:  1.216\n",
      "[epoch 1 Iteration 44/960] TRAIN loss:  1.332\n",
      "[epoch 1 Iteration 45/960] TRAIN loss:  1.104\n",
      "[epoch 1 Iteration 46/960] TRAIN loss:  1.218\n",
      "[epoch 1 Iteration 47/960] TRAIN loss:  1.294\n",
      "[epoch 1 Iteration 48/960] TRAIN loss:  1.182\n",
      "[epoch 1 Iteration 49/960] TRAIN loss:  1.517\n",
      "[epoch 1 Iteration 50/960] TRAIN loss:  1.502\n",
      "[epoch 1 Iteration 51/960] TRAIN loss:  1.320\n",
      "[epoch 1 Iteration 52/960] TRAIN loss:  1.322\n",
      "[epoch 1 Iteration 53/960] TRAIN loss:  1.106\n",
      "[epoch 1 Iteration 54/960] TRAIN loss:  1.322\n",
      "[epoch 1 Iteration 55/960] TRAIN loss:  1.078\n",
      "[epoch 1 Iteration 56/960] TRAIN loss:  1.305\n",
      "[epoch 1 Iteration 57/960] TRAIN loss:  1.266\n",
      "[epoch 1 Iteration 58/960] TRAIN loss:  1.592\n",
      "[epoch 1 Iteration 59/960] TRAIN loss:  1.600\n",
      "[epoch 1 Iteration 60/960] TRAIN loss:  1.285\n",
      "[epoch 1 Iteration 61/960] TRAIN loss:  1.279\n",
      "[epoch 1 Iteration 62/960] TRAIN loss:  1.405\n",
      "[epoch 1 Iteration 63/960] TRAIN loss:  1.348\n",
      "[epoch 1 Iteration 64/960] TRAIN loss:  1.225\n",
      "[epoch 1 Iteration 65/960] TRAIN loss:  1.349\n",
      "[epoch 1 Iteration 66/960] TRAIN loss:  1.371\n",
      "[epoch 1 Iteration 67/960] TRAIN loss:  1.294\n",
      "[epoch 1 Iteration 68/960] TRAIN loss:  1.225\n",
      "[epoch 1 Iteration 69/960] TRAIN loss:  1.073\n",
      "[epoch 1 Iteration 70/960] TRAIN loss:  1.319\n",
      "[epoch 1 Iteration 71/960] TRAIN loss:  1.276\n",
      "[epoch 1 Iteration 72/960] TRAIN loss:  1.102\n",
      "[epoch 1 Iteration 73/960] TRAIN loss:  1.385\n",
      "[epoch 1 Iteration 74/960] TRAIN loss:  1.337\n",
      "[epoch 1 Iteration 75/960] TRAIN loss:  1.256\n",
      "[epoch 1 Iteration 76/960] TRAIN loss:  1.250\n",
      "[epoch 1 Iteration 77/960] TRAIN loss:  1.236\n",
      "[epoch 1 Iteration 78/960] TRAIN loss:  1.090\n",
      "[epoch 1 Iteration 79/960] TRAIN loss:  1.158\n",
      "[epoch 1 Iteration 80/960] TRAIN loss:  1.356\n",
      "[epoch 1 Iteration 81/960] TRAIN loss:  1.133\n",
      "[epoch 1 Iteration 82/960] TRAIN loss:  1.233\n",
      "[epoch 1 Iteration 83/960] TRAIN loss:  1.061\n",
      "[epoch 1 Iteration 84/960] TRAIN loss:  1.578\n",
      "[epoch 1 Iteration 85/960] TRAIN loss:  1.399\n",
      "[epoch 1 Iteration 86/960] TRAIN loss:  1.207\n",
      "[epoch 1 Iteration 87/960] TRAIN loss:  1.375\n",
      "[epoch 1 Iteration 88/960] TRAIN loss:  1.216\n",
      "[epoch 1 Iteration 89/960] TRAIN loss:  1.442\n",
      "[epoch 1 Iteration 90/960] TRAIN loss:  1.116\n",
      "[epoch 1 Iteration 91/960] TRAIN loss:  1.289\n",
      "[epoch 1 Iteration 92/960] TRAIN loss:  1.465\n",
      "[epoch 1 Iteration 93/960] TRAIN loss:  1.526\n",
      "[epoch 1 Iteration 94/960] TRAIN loss:  1.254\n",
      "[epoch 1 Iteration 95/960] TRAIN loss:  1.256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1 Iteration 96/960] TRAIN loss:  0.994\n",
      "[epoch 1 Iteration 97/960] TRAIN loss:  1.459\n",
      "[epoch 1 Iteration 98/960] TRAIN loss:  1.232\n",
      "[epoch 1 Iteration 99/960] TRAIN loss:  1.140\n",
      "[epoch 1 Iteration 100/960] TRAIN loss:  1.194\n",
      "[epoch 1 Iteration 101/960] TRAIN loss:  1.066\n",
      "[epoch 1 Iteration 102/960] TRAIN loss:  1.255\n",
      "[epoch 1 Iteration 103/960] TRAIN loss:  1.532\n",
      "[epoch 1 Iteration 104/960] TRAIN loss:  1.429\n",
      "[epoch 1 Iteration 105/960] TRAIN loss:  1.431\n",
      "[epoch 1 Iteration 106/960] TRAIN loss:  1.299\n",
      "[epoch 1 Iteration 107/960] TRAIN loss:  1.258\n",
      "[epoch 1 Iteration 108/960] TRAIN loss:  1.796\n",
      "[epoch 1 Iteration 109/960] TRAIN loss:  1.399\n",
      "[epoch 1 Iteration 110/960] TRAIN loss:  1.452\n",
      "[epoch 1 Iteration 111/960] TRAIN loss:  1.362\n",
      "[epoch 1 Iteration 112/960] TRAIN loss:  1.244\n",
      "[epoch 1 Iteration 113/960] TRAIN loss:  1.308\n",
      "[epoch 1 Iteration 114/960] TRAIN loss:  1.235\n",
      "[epoch 1 Iteration 115/960] TRAIN loss:  1.321\n",
      "[epoch 1 Iteration 116/960] TRAIN loss:  1.364\n",
      "[epoch 1 Iteration 117/960] TRAIN loss:  1.375\n",
      "[epoch 1 Iteration 118/960] TRAIN loss:  1.292\n",
      "[epoch 1 Iteration 119/960] TRAIN loss:  1.533\n",
      "[epoch 1 Iteration 120/960] TRAIN loss:  1.366\n",
      "[epoch 1 Iteration 121/960] TRAIN loss:  1.445\n",
      "[epoch 1 Iteration 122/960] TRAIN loss:  1.168\n",
      "[epoch 1 Iteration 123/960] TRAIN loss:  1.154\n",
      "[epoch 1 Iteration 124/960] TRAIN loss:  1.708\n",
      "[epoch 1 Iteration 125/960] TRAIN loss:  1.273\n",
      "[epoch 1 Iteration 126/960] TRAIN loss:  1.232\n",
      "[epoch 1 Iteration 127/960] TRAIN loss:  1.296\n",
      "[epoch 1 Iteration 128/960] TRAIN loss:  1.250\n",
      "[epoch 1 Iteration 129/960] TRAIN loss:  1.456\n",
      "[epoch 1 Iteration 130/960] TRAIN loss:  1.211\n",
      "[epoch 1 Iteration 131/960] TRAIN loss:  1.179\n",
      "[epoch 1 Iteration 132/960] TRAIN loss:  1.412\n",
      "[epoch 1 Iteration 133/960] TRAIN loss:  1.350\n",
      "[epoch 1 Iteration 134/960] TRAIN loss:  1.426\n",
      "[epoch 1 Iteration 135/960] TRAIN loss:  1.027\n",
      "[epoch 1 Iteration 136/960] TRAIN loss:  1.328\n",
      "[epoch 1 Iteration 137/960] TRAIN loss:  1.319\n",
      "[epoch 1 Iteration 138/960] TRAIN loss:  1.513\n",
      "[epoch 1 Iteration 139/960] TRAIN loss:  1.448\n",
      "[epoch 1 Iteration 140/960] TRAIN loss:  1.114\n",
      "[epoch 1 Iteration 141/960] TRAIN loss:  1.305\n",
      "[epoch 1 Iteration 142/960] TRAIN loss:  1.109\n",
      "[epoch 1 Iteration 143/960] TRAIN loss:  1.434\n",
      "[epoch 1 Iteration 144/960] TRAIN loss:  1.466\n",
      "[epoch 1 Iteration 145/960] TRAIN loss:  1.605\n",
      "[epoch 1 Iteration 146/960] TRAIN loss:  1.202\n",
      "[epoch 1 Iteration 147/960] TRAIN loss:  1.234\n",
      "[epoch 1 Iteration 148/960] TRAIN loss:  1.254\n",
      "[epoch 1 Iteration 149/960] TRAIN loss:  1.203\n",
      "[epoch 1 Iteration 150/960] TRAIN loss:  1.297\n",
      "[epoch 1 Iteration 151/960] TRAIN loss:  1.298\n",
      "[epoch 1 Iteration 152/960] TRAIN loss:  1.310\n",
      "[epoch 1 Iteration 153/960] TRAIN loss:  1.269\n",
      "[epoch 1 Iteration 154/960] TRAIN loss:  1.203\n",
      "[epoch 1 Iteration 155/960] TRAIN loss:  1.226\n",
      "[epoch 1 Iteration 156/960] TRAIN loss:  1.362\n",
      "[epoch 1 Iteration 157/960] TRAIN loss:  1.606\n",
      "[epoch 1 Iteration 158/960] TRAIN loss:  1.327\n",
      "[epoch 1 Iteration 159/960] TRAIN loss:  1.151\n",
      "[epoch 1 Iteration 160/960] TRAIN loss:  1.703\n",
      "[epoch 1 Iteration 161/960] TRAIN loss:  1.341\n",
      "[epoch 1 Iteration 162/960] TRAIN loss:  1.332\n",
      "[epoch 1 Iteration 163/960] TRAIN loss:  1.218\n",
      "[epoch 1 Iteration 164/960] TRAIN loss:  1.083\n",
      "[epoch 1 Iteration 165/960] TRAIN loss:  1.181\n",
      "[epoch 1 Iteration 166/960] TRAIN loss:  1.491\n",
      "[epoch 1 Iteration 167/960] TRAIN loss:  1.288\n",
      "[epoch 1 Iteration 168/960] TRAIN loss:  1.331\n",
      "[epoch 1 Iteration 169/960] TRAIN loss:  1.438\n",
      "[epoch 1 Iteration 170/960] TRAIN loss:  1.128\n",
      "[epoch 1 Iteration 171/960] TRAIN loss:  1.238\n",
      "[epoch 1 Iteration 172/960] TRAIN loss:  1.318\n",
      "[epoch 1 Iteration 173/960] TRAIN loss:  1.395\n",
      "[epoch 1 Iteration 174/960] TRAIN loss:  1.149\n",
      "[epoch 1 Iteration 175/960] TRAIN loss:  1.243\n",
      "[epoch 1 Iteration 176/960] TRAIN loss:  1.202\n",
      "[epoch 1 Iteration 177/960] TRAIN loss:  1.463\n",
      "[epoch 1 Iteration 178/960] TRAIN loss:  1.270\n",
      "[epoch 1 Iteration 179/960] TRAIN loss:  1.370\n",
      "[epoch 1 Iteration 180/960] TRAIN loss:  1.293\n",
      "[epoch 1 Iteration 181/960] TRAIN loss:  0.929\n",
      "[epoch 1 Iteration 182/960] TRAIN loss:  1.231\n",
      "[epoch 1 Iteration 183/960] TRAIN loss:  1.374\n",
      "[epoch 1 Iteration 184/960] TRAIN loss:  1.088\n",
      "[epoch 1 Iteration 185/960] TRAIN loss:  1.334\n",
      "[epoch 1 Iteration 186/960] TRAIN loss:  1.339\n",
      "[epoch 1 Iteration 187/960] TRAIN loss:  1.339\n",
      "[epoch 1 Iteration 188/960] TRAIN loss:  1.310\n",
      "[epoch 1 Iteration 189/960] TRAIN loss:  1.149\n",
      "[epoch 1 Iteration 190/960] TRAIN loss:  1.565\n",
      "[epoch 1 Iteration 191/960] TRAIN loss:  1.449\n",
      "[epoch 1 Iteration 192/960] TRAIN loss:  1.275\n",
      "[epoch 1 Iteration 193/960] TRAIN loss:  1.443\n",
      "[epoch 1 Iteration 194/960] TRAIN loss:  1.359\n",
      "[epoch 1 Iteration 195/960] TRAIN loss:  1.162\n",
      "[epoch 1 Iteration 196/960] TRAIN loss:  1.409\n",
      "[epoch 1 Iteration 197/960] TRAIN loss:  1.493\n",
      "[epoch 1 Iteration 198/960] TRAIN loss:  1.503\n",
      "[epoch 1 Iteration 199/960] TRAIN loss:  1.304\n",
      "[epoch 1 Iteration 200/960] TRAIN loss:  1.294\n",
      "[epoch 1 Iteration 201/960] TRAIN loss:  1.330\n",
      "[epoch 1 Iteration 202/960] TRAIN loss:  1.060\n",
      "[epoch 1 Iteration 203/960] TRAIN loss:  1.387\n",
      "[epoch 1 Iteration 204/960] TRAIN loss:  1.281\n",
      "[epoch 1 Iteration 205/960] TRAIN loss:  1.241\n",
      "[epoch 1 Iteration 206/960] TRAIN loss:  1.185\n",
      "[epoch 1 Iteration 207/960] TRAIN loss:  1.226\n",
      "[epoch 1 Iteration 208/960] TRAIN loss:  1.257\n",
      "[epoch 1 Iteration 209/960] TRAIN loss:  1.271\n",
      "[epoch 1 Iteration 210/960] TRAIN loss:  1.304\n",
      "[epoch 1 Iteration 211/960] TRAIN loss:  1.319\n",
      "[epoch 1 Iteration 212/960] TRAIN loss:  1.440\n",
      "[epoch 1 Iteration 213/960] TRAIN loss:  1.322\n",
      "[epoch 1 Iteration 214/960] TRAIN loss:  1.213\n",
      "[epoch 1 Iteration 215/960] TRAIN loss:  1.134\n",
      "[epoch 1 Iteration 216/960] TRAIN loss:  1.376\n",
      "[epoch 1 Iteration 217/960] TRAIN loss:  1.171\n",
      "[epoch 1 Iteration 218/960] TRAIN loss:  1.395\n",
      "[epoch 1 Iteration 219/960] TRAIN loss:  1.309\n",
      "[epoch 1 Iteration 220/960] TRAIN loss:  1.268\n",
      "[epoch 1 Iteration 221/960] TRAIN loss:  1.491\n",
      "[epoch 1 Iteration 222/960] TRAIN loss:  1.406\n",
      "[epoch 1 Iteration 223/960] TRAIN loss:  1.260\n",
      "[epoch 1 Iteration 224/960] TRAIN loss:  1.436\n",
      "[epoch 1 Iteration 225/960] TRAIN loss:  1.359\n",
      "[epoch 1 Iteration 226/960] TRAIN loss:  1.224\n",
      "[epoch 1 Iteration 227/960] TRAIN loss:  1.319\n",
      "[epoch 1 Iteration 228/960] TRAIN loss:  1.217\n",
      "[epoch 1 Iteration 229/960] TRAIN loss:  1.364\n",
      "[epoch 1 Iteration 230/960] TRAIN loss:  1.538\n",
      "[epoch 1 Iteration 231/960] TRAIN loss:  1.407\n",
      "[epoch 1 Iteration 232/960] TRAIN loss:  1.404\n",
      "[epoch 1 Iteration 233/960] TRAIN loss:  1.238\n",
      "[epoch 1 Iteration 234/960] TRAIN loss:  1.352\n",
      "[epoch 1 Iteration 235/960] TRAIN loss:  1.556\n",
      "[epoch 1 Iteration 236/960] TRAIN loss:  1.461\n",
      "[epoch 1 Iteration 237/960] TRAIN loss:  1.350\n",
      "[epoch 1 Iteration 238/960] TRAIN loss:  1.322\n",
      "[epoch 1 Iteration 239/960] TRAIN loss:  1.412\n",
      "[epoch 1 Iteration 240/960] TRAIN loss:  1.257\n",
      "[epoch 1 Iteration 241/960] TRAIN loss:  1.161\n",
      "[epoch 1 Iteration 242/960] TRAIN loss:  1.350\n",
      "[epoch 1 Iteration 243/960] TRAIN loss:  1.157\n",
      "[epoch 1 Iteration 244/960] TRAIN loss:  1.164\n",
      "[epoch 1 Iteration 245/960] TRAIN loss:  1.141\n",
      "[epoch 1 Iteration 246/960] TRAIN loss:  1.406\n",
      "[epoch 1 Iteration 247/960] TRAIN loss:  1.467\n",
      "[epoch 1 Iteration 248/960] TRAIN loss:  1.412\n",
      "[epoch 1 Iteration 249/960] TRAIN loss:  1.332\n",
      "[epoch 1 Iteration 250/960] TRAIN loss:  1.101\n",
      "[epoch 1 Iteration 251/960] TRAIN loss:  1.240\n",
      "[epoch 1 Iteration 252/960] TRAIN loss:  1.304\n",
      "[epoch 1 Iteration 253/960] TRAIN loss:  1.053\n",
      "[epoch 1 Iteration 254/960] TRAIN loss:  1.345\n",
      "[epoch 1 Iteration 255/960] TRAIN loss:  1.205\n",
      "[epoch 1 Iteration 256/960] TRAIN loss:  1.183\n",
      "[epoch 1 Iteration 257/960] TRAIN loss:  1.314\n",
      "[epoch 1 Iteration 258/960] TRAIN loss:  1.328\n",
      "[epoch 1 Iteration 259/960] TRAIN loss:  1.289\n",
      "[epoch 1 Iteration 260/960] TRAIN loss:  1.057\n",
      "[epoch 1 Iteration 261/960] TRAIN loss:  1.118\n",
      "[epoch 1 Iteration 262/960] TRAIN loss:  1.481\n",
      "[epoch 1 Iteration 263/960] TRAIN loss:  1.397\n",
      "[epoch 1 Iteration 264/960] TRAIN loss:  1.383\n",
      "[epoch 1 Iteration 265/960] TRAIN loss:  1.374\n",
      "[epoch 1 Iteration 266/960] TRAIN loss:  0.975\n",
      "[epoch 1 Iteration 267/960] TRAIN loss:  1.326\n",
      "[epoch 1 Iteration 268/960] TRAIN loss:  1.409\n",
      "[epoch 1 Iteration 269/960] TRAIN loss:  1.455\n",
      "[epoch 1 Iteration 270/960] TRAIN loss:  1.346\n",
      "[epoch 1 Iteration 271/960] TRAIN loss:  1.229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1 Iteration 272/960] TRAIN loss:  1.295\n",
      "[epoch 1 Iteration 273/960] TRAIN loss:  1.446\n",
      "[epoch 1 Iteration 274/960] TRAIN loss:  1.278\n",
      "[epoch 1 Iteration 275/960] TRAIN loss:  1.370\n",
      "[epoch 1 Iteration 276/960] TRAIN loss:  1.402\n",
      "[epoch 1 Iteration 277/960] TRAIN loss:  1.325\n",
      "[epoch 1 Iteration 278/960] TRAIN loss:  1.486\n",
      "[epoch 1 Iteration 279/960] TRAIN loss:  1.228\n",
      "[epoch 1 Iteration 280/960] TRAIN loss:  1.229\n",
      "[epoch 1 Iteration 281/960] TRAIN loss:  1.409\n",
      "[epoch 1 Iteration 282/960] TRAIN loss:  1.336\n",
      "[epoch 1 Iteration 283/960] TRAIN loss:  1.478\n",
      "[epoch 1 Iteration 284/960] TRAIN loss:  1.268\n",
      "[epoch 1 Iteration 285/960] TRAIN loss:  1.305\n",
      "[epoch 1 Iteration 286/960] TRAIN loss:  1.418\n",
      "[epoch 1 Iteration 287/960] TRAIN loss:  1.500\n",
      "[epoch 1 Iteration 288/960] TRAIN loss:  1.073\n",
      "[epoch 1 Iteration 289/960] TRAIN loss:  1.212\n",
      "[epoch 1 Iteration 290/960] TRAIN loss:  1.561\n",
      "[epoch 1 Iteration 291/960] TRAIN loss:  1.186\n",
      "[epoch 1 Iteration 292/960] TRAIN loss:  1.252\n",
      "[epoch 1 Iteration 293/960] TRAIN loss:  1.252\n",
      "[epoch 1 Iteration 294/960] TRAIN loss:  1.456\n",
      "[epoch 1 Iteration 295/960] TRAIN loss:  1.190\n",
      "[epoch 1 Iteration 296/960] TRAIN loss:  0.997\n",
      "[epoch 1 Iteration 297/960] TRAIN loss:  1.800\n",
      "[epoch 1 Iteration 298/960] TRAIN loss:  1.338\n",
      "[epoch 1 Iteration 299/960] TRAIN loss:  1.486\n",
      "[epoch 1 Iteration 300/960] TRAIN loss:  1.187\n",
      "[epoch 1 Iteration 301/960] TRAIN loss:  1.324\n",
      "[epoch 1 Iteration 302/960] TRAIN loss:  1.345\n",
      "[epoch 1 Iteration 303/960] TRAIN loss:  1.143\n",
      "[epoch 1 Iteration 304/960] TRAIN loss:  1.623\n",
      "[epoch 1 Iteration 305/960] TRAIN loss:  1.142\n",
      "[epoch 1 Iteration 306/960] TRAIN loss:  1.360\n",
      "[epoch 1 Iteration 307/960] TRAIN loss:  1.060\n",
      "[epoch 1 Iteration 308/960] TRAIN loss:  1.154\n",
      "[epoch 1 Iteration 309/960] TRAIN loss:  1.040\n",
      "[epoch 1 Iteration 310/960] TRAIN loss:  1.293\n",
      "[epoch 1 Iteration 311/960] TRAIN loss:  1.426\n",
      "[epoch 1 Iteration 312/960] TRAIN loss:  1.360\n",
      "[epoch 1 Iteration 313/960] TRAIN loss:  1.203\n",
      "[epoch 1 Iteration 314/960] TRAIN loss:  1.514\n",
      "[epoch 1 Iteration 315/960] TRAIN loss:  1.390\n",
      "[epoch 1 Iteration 316/960] TRAIN loss:  1.171\n",
      "[epoch 1 Iteration 317/960] TRAIN loss:  1.174\n",
      "[epoch 1 Iteration 318/960] TRAIN loss:  1.139\n",
      "[epoch 1 Iteration 319/960] TRAIN loss:  1.235\n",
      "[epoch 1 Iteration 320/960] TRAIN loss:  1.304\n",
      "[epoch 1 Iteration 321/960] TRAIN loss:  1.162\n",
      "[epoch 1 Iteration 322/960] TRAIN loss:  1.565\n",
      "[epoch 1 Iteration 323/960] TRAIN loss:  1.321\n",
      "[epoch 1 Iteration 324/960] TRAIN loss:  1.167\n",
      "[epoch 1 Iteration 325/960] TRAIN loss:  1.240\n",
      "[epoch 1 Iteration 326/960] TRAIN loss:  1.419\n",
      "[epoch 1 Iteration 327/960] TRAIN loss:  1.275\n",
      "[epoch 1 Iteration 328/960] TRAIN loss:  1.286\n",
      "[epoch 1 Iteration 329/960] TRAIN loss:  1.257\n",
      "[epoch 1 Iteration 330/960] TRAIN loss:  1.396\n",
      "[epoch 1 Iteration 331/960] TRAIN loss:  1.343\n",
      "[epoch 1 Iteration 332/960] TRAIN loss:  1.381\n",
      "[epoch 1 Iteration 333/960] TRAIN loss:  1.107\n",
      "[epoch 1 Iteration 334/960] TRAIN loss:  1.100\n",
      "[epoch 1 Iteration 335/960] TRAIN loss:  1.407\n",
      "[epoch 1 Iteration 336/960] TRAIN loss:  1.424\n",
      "[epoch 1 Iteration 337/960] TRAIN loss:  1.396\n",
      "[epoch 1 Iteration 338/960] TRAIN loss:  1.220\n",
      "[epoch 1 Iteration 339/960] TRAIN loss:  1.203\n",
      "[epoch 1 Iteration 340/960] TRAIN loss:  1.538\n",
      "[epoch 1 Iteration 341/960] TRAIN loss:  1.253\n",
      "[epoch 1 Iteration 342/960] TRAIN loss:  1.192\n",
      "[epoch 1 Iteration 343/960] TRAIN loss:  1.135\n",
      "[epoch 1 Iteration 344/960] TRAIN loss:  1.283\n",
      "[epoch 1 Iteration 345/960] TRAIN loss:  1.266\n",
      "[epoch 1 Iteration 346/960] TRAIN loss:  1.223\n",
      "[epoch 1 Iteration 347/960] TRAIN loss:  1.512\n",
      "[epoch 1 Iteration 348/960] TRAIN loss:  1.208\n",
      "[epoch 1 Iteration 349/960] TRAIN loss:  1.420\n",
      "[epoch 1 Iteration 350/960] TRAIN loss:  1.060\n",
      "[epoch 1 Iteration 351/960] TRAIN loss:  0.796\n",
      "[epoch 1 Iteration 352/960] TRAIN loss:  1.309\n",
      "[epoch 1 Iteration 353/960] TRAIN loss:  1.061\n",
      "[epoch 1 Iteration 354/960] TRAIN loss:  0.924\n",
      "[epoch 1 Iteration 355/960] TRAIN loss:  1.250\n",
      "[epoch 1 Iteration 356/960] TRAIN loss:  1.265\n",
      "[epoch 1 Iteration 357/960] TRAIN loss:  1.220\n",
      "[epoch 1 Iteration 358/960] TRAIN loss:  1.517\n",
      "[epoch 1 Iteration 359/960] TRAIN loss:  1.311\n",
      "[epoch 1 Iteration 360/960] TRAIN loss:  1.098\n",
      "[epoch 1 Iteration 361/960] TRAIN loss:  1.205\n",
      "[epoch 1 Iteration 362/960] TRAIN loss:  1.116\n",
      "[epoch 1 Iteration 363/960] TRAIN loss:  1.038\n",
      "[epoch 1 Iteration 364/960] TRAIN loss:  1.347\n",
      "[epoch 1 Iteration 365/960] TRAIN loss:  1.217\n",
      "[epoch 1 Iteration 366/960] TRAIN loss:  1.377\n",
      "[epoch 1 Iteration 367/960] TRAIN loss:  1.334\n",
      "[epoch 1 Iteration 368/960] TRAIN loss:  1.221\n",
      "[epoch 1 Iteration 369/960] TRAIN loss:  1.122\n",
      "[epoch 1 Iteration 370/960] TRAIN loss:  1.321\n",
      "[epoch 1 Iteration 371/960] TRAIN loss:  1.181\n",
      "[epoch 1 Iteration 372/960] TRAIN loss:  1.073\n",
      "[epoch 1 Iteration 373/960] TRAIN loss:  1.033\n",
      "[epoch 1 Iteration 374/960] TRAIN loss:  1.260\n",
      "[epoch 1 Iteration 375/960] TRAIN loss:  1.311\n",
      "[epoch 1 Iteration 376/960] TRAIN loss:  1.234\n",
      "[epoch 1 Iteration 377/960] TRAIN loss:  1.115\n",
      "[epoch 1 Iteration 378/960] TRAIN loss:  1.437\n",
      "[epoch 1 Iteration 379/960] TRAIN loss:  1.251\n",
      "[epoch 1 Iteration 380/960] TRAIN loss:  1.360\n",
      "[epoch 1 Iteration 381/960] TRAIN loss:  1.376\n",
      "[epoch 1 Iteration 382/960] TRAIN loss:  1.215\n",
      "[epoch 1 Iteration 383/960] TRAIN loss:  1.055\n",
      "[epoch 1 Iteration 384/960] TRAIN loss:  1.181\n",
      "[epoch 1 Iteration 385/960] TRAIN loss:  1.090\n",
      "[epoch 1 Iteration 386/960] TRAIN loss:  1.148\n",
      "[epoch 1 Iteration 387/960] TRAIN loss:  1.496\n",
      "[epoch 1 Iteration 388/960] TRAIN loss:  1.146\n",
      "[epoch 1 Iteration 389/960] TRAIN loss:  0.980\n",
      "[epoch 1 Iteration 390/960] TRAIN loss:  1.186\n",
      "[epoch 1 Iteration 391/960] TRAIN loss:  1.350\n",
      "[epoch 1 Iteration 392/960] TRAIN loss:  1.236\n",
      "[epoch 1 Iteration 393/960] TRAIN loss:  1.071\n",
      "[epoch 1 Iteration 394/960] TRAIN loss:  1.102\n",
      "[epoch 1 Iteration 395/960] TRAIN loss:  1.049\n",
      "[epoch 1 Iteration 396/960] TRAIN loss:  1.228\n",
      "[epoch 1 Iteration 397/960] TRAIN loss:  1.183\n",
      "[epoch 1 Iteration 398/960] TRAIN loss:  1.245\n",
      "[epoch 1 Iteration 399/960] TRAIN loss:  1.271\n",
      "[epoch 1 Iteration 400/960] TRAIN loss:  1.101\n",
      "[epoch 1 Iteration 401/960] TRAIN loss:  1.326\n",
      "[epoch 1 Iteration 402/960] TRAIN loss:  1.065\n",
      "[epoch 1 Iteration 403/960] TRAIN loss:  1.274\n",
      "[epoch 1 Iteration 404/960] TRAIN loss:  1.439\n",
      "[epoch 1 Iteration 405/960] TRAIN loss:  0.860\n",
      "[epoch 1 Iteration 406/960] TRAIN loss:  1.306\n",
      "[epoch 1 Iteration 407/960] TRAIN loss:  1.184\n",
      "[epoch 1 Iteration 408/960] TRAIN loss:  1.338\n",
      "[epoch 1 Iteration 409/960] TRAIN loss:  1.131\n",
      "[epoch 1 Iteration 410/960] TRAIN loss:  1.347\n",
      "[epoch 1 Iteration 411/960] TRAIN loss:  1.237\n",
      "[epoch 1 Iteration 412/960] TRAIN loss:  1.189\n",
      "[epoch 1 Iteration 413/960] TRAIN loss:  1.190\n",
      "[epoch 1 Iteration 414/960] TRAIN loss:  1.237\n",
      "[epoch 1 Iteration 415/960] TRAIN loss:  1.128\n",
      "[epoch 1 Iteration 416/960] TRAIN loss:  1.532\n",
      "[epoch 1 Iteration 417/960] TRAIN loss:  1.561\n",
      "[epoch 1 Iteration 418/960] TRAIN loss:  1.413\n",
      "[epoch 1 Iteration 419/960] TRAIN loss:  1.380\n",
      "[epoch 1 Iteration 420/960] TRAIN loss:  1.735\n",
      "[epoch 1 Iteration 421/960] TRAIN loss:  1.205\n",
      "[epoch 1 Iteration 422/960] TRAIN loss:  0.976\n",
      "[epoch 1 Iteration 423/960] TRAIN loss:  1.120\n",
      "[epoch 1 Iteration 424/960] TRAIN loss:  1.488\n",
      "[epoch 1 Iteration 425/960] TRAIN loss:  1.476\n",
      "[epoch 1 Iteration 426/960] TRAIN loss:  1.171\n",
      "[epoch 1 Iteration 427/960] TRAIN loss:  1.128\n",
      "[epoch 1 Iteration 428/960] TRAIN loss:  1.322\n",
      "[epoch 1 Iteration 429/960] TRAIN loss:  1.171\n",
      "[epoch 1 Iteration 430/960] TRAIN loss:  1.644\n",
      "[epoch 1 Iteration 431/960] TRAIN loss:  1.235\n",
      "[epoch 1 Iteration 432/960] TRAIN loss:  1.099\n",
      "[epoch 1 Iteration 433/960] TRAIN loss:  1.231\n",
      "[epoch 1 Iteration 434/960] TRAIN loss:  1.175\n",
      "[epoch 1 Iteration 435/960] TRAIN loss:  1.154\n",
      "[epoch 1 Iteration 436/960] TRAIN loss:  1.192\n",
      "[epoch 1 Iteration 437/960] TRAIN loss:  0.954\n",
      "[epoch 1 Iteration 438/960] TRAIN loss:  1.080\n",
      "[epoch 1 Iteration 439/960] TRAIN loss:  1.310\n",
      "[epoch 1 Iteration 440/960] TRAIN loss:  1.304\n",
      "[epoch 1 Iteration 441/960] TRAIN loss:  0.961\n",
      "[epoch 1 Iteration 442/960] TRAIN loss:  1.498\n",
      "[epoch 1 Iteration 443/960] TRAIN loss:  1.124\n",
      "[epoch 1 Iteration 444/960] TRAIN loss:  1.063\n",
      "[epoch 1 Iteration 445/960] TRAIN loss:  1.313\n",
      "[epoch 1 Iteration 446/960] TRAIN loss:  1.262\n",
      "[epoch 1 Iteration 447/960] TRAIN loss:  1.177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1 Iteration 448/960] TRAIN loss:  1.099\n",
      "[epoch 1 Iteration 449/960] TRAIN loss:  1.303\n",
      "[epoch 1 Iteration 450/960] TRAIN loss:  1.253\n",
      "[epoch 1 Iteration 451/960] TRAIN loss:  1.409\n",
      "[epoch 1 Iteration 452/960] TRAIN loss:  1.501\n",
      "[epoch 1 Iteration 453/960] TRAIN loss:  1.384\n",
      "[epoch 1 Iteration 454/960] TRAIN loss:  1.289\n",
      "[epoch 1 Iteration 455/960] TRAIN loss:  1.237\n",
      "[epoch 1 Iteration 456/960] TRAIN loss:  1.190\n",
      "[epoch 1 Iteration 457/960] TRAIN loss:  1.130\n",
      "[epoch 1 Iteration 458/960] TRAIN loss:  1.180\n",
      "[epoch 1 Iteration 459/960] TRAIN loss:  0.993\n",
      "[epoch 1 Iteration 460/960] TRAIN loss:  1.214\n",
      "[epoch 1 Iteration 461/960] TRAIN loss:  1.074\n",
      "[epoch 1 Iteration 462/960] TRAIN loss:  1.100\n",
      "[epoch 1 Iteration 463/960] TRAIN loss:  1.325\n",
      "[epoch 1 Iteration 464/960] TRAIN loss:  1.362\n",
      "[epoch 1 Iteration 465/960] TRAIN loss:  1.095\n",
      "[epoch 1 Iteration 466/960] TRAIN loss:  1.204\n",
      "[epoch 1 Iteration 467/960] TRAIN loss:  1.317\n",
      "[epoch 1 Iteration 468/960] TRAIN loss:  1.373\n",
      "[epoch 1 Iteration 469/960] TRAIN loss:  1.250\n",
      "[epoch 1 Iteration 470/960] TRAIN loss:  1.396\n",
      "[epoch 1 Iteration 471/960] TRAIN loss:  1.355\n",
      "[epoch 1 Iteration 472/960] TRAIN loss:  1.521\n",
      "[epoch 1 Iteration 473/960] TRAIN loss:  1.241\n",
      "[epoch 1 Iteration 474/960] TRAIN loss:  1.195\n",
      "[epoch 1 Iteration 475/960] TRAIN loss:  1.413\n",
      "[epoch 1 Iteration 476/960] TRAIN loss:  1.686\n",
      "[epoch 1 Iteration 477/960] TRAIN loss:  1.296\n",
      "[epoch 1 Iteration 478/960] TRAIN loss:  1.252\n",
      "[epoch 1 Iteration 479/960] TRAIN loss:  1.175\n",
      "[epoch 1 Iteration 480/960] TRAIN loss:  1.639\n",
      "[epoch 1 Iteration 481/960] TRAIN loss:  1.425\n",
      "[epoch 1 Iteration 482/960] TRAIN loss:  1.326\n",
      "[epoch 1 Iteration 483/960] TRAIN loss:  1.070\n",
      "[epoch 1 Iteration 484/960] TRAIN loss:  1.434\n",
      "[epoch 1 Iteration 485/960] TRAIN loss:  1.087\n",
      "[epoch 1 Iteration 486/960] TRAIN loss:  1.178\n",
      "[epoch 1 Iteration 487/960] TRAIN loss:  1.072\n",
      "[epoch 1 Iteration 488/960] TRAIN loss:  1.066\n",
      "[epoch 1 Iteration 489/960] TRAIN loss:  1.307\n",
      "[epoch 1 Iteration 490/960] TRAIN loss:  1.219\n",
      "[epoch 1 Iteration 491/960] TRAIN loss:  1.425\n",
      "[epoch 1 Iteration 492/960] TRAIN loss:  1.402\n",
      "[epoch 1 Iteration 493/960] TRAIN loss:  1.338\n",
      "[epoch 1 Iteration 494/960] TRAIN loss:  1.146\n",
      "[epoch 1 Iteration 495/960] TRAIN loss:  0.968\n",
      "[epoch 1 Iteration 496/960] TRAIN loss:  1.128\n",
      "[epoch 1 Iteration 497/960] TRAIN loss:  1.313\n",
      "[epoch 1 Iteration 498/960] TRAIN loss:  1.182\n",
      "[epoch 1 Iteration 499/960] TRAIN loss:  1.204\n",
      "[epoch 1 Iteration 500/960] TRAIN loss:  1.010\n",
      "[epoch 1 Iteration 501/960] TRAIN loss:  1.436\n",
      "[epoch 1 Iteration 502/960] TRAIN loss:  1.140\n",
      "[epoch 1 Iteration 503/960] TRAIN loss:  1.225\n",
      "[epoch 1 Iteration 504/960] TRAIN loss:  1.138\n",
      "[epoch 1 Iteration 505/960] TRAIN loss:  1.197\n",
      "[epoch 1 Iteration 506/960] TRAIN loss:  1.019\n",
      "[epoch 1 Iteration 507/960] TRAIN loss:  1.238\n",
      "[epoch 1 Iteration 508/960] TRAIN loss:  1.281\n",
      "[epoch 1 Iteration 509/960] TRAIN loss:  1.076\n",
      "[epoch 1 Iteration 510/960] TRAIN loss:  1.445\n",
      "[epoch 1 Iteration 511/960] TRAIN loss:  1.385\n",
      "[epoch 1 Iteration 512/960] TRAIN loss:  0.929\n",
      "[epoch 1 Iteration 513/960] TRAIN loss:  1.199\n",
      "[epoch 1 Iteration 514/960] TRAIN loss:  1.025\n",
      "[epoch 1 Iteration 515/960] TRAIN loss:  1.136\n",
      "[epoch 1 Iteration 516/960] TRAIN loss:  1.297\n",
      "[epoch 1 Iteration 517/960] TRAIN loss:  1.370\n",
      "[epoch 1 Iteration 518/960] TRAIN loss:  1.069\n",
      "[epoch 1 Iteration 519/960] TRAIN loss:  1.408\n",
      "[epoch 1 Iteration 520/960] TRAIN loss:  1.096\n",
      "[epoch 1 Iteration 521/960] TRAIN loss:  1.567\n",
      "[epoch 1 Iteration 522/960] TRAIN loss:  1.215\n",
      "[epoch 1 Iteration 523/960] TRAIN loss:  1.247\n",
      "[epoch 1 Iteration 524/960] TRAIN loss:  1.368\n",
      "[epoch 1 Iteration 525/960] TRAIN loss:  0.971\n",
      "[epoch 1 Iteration 526/960] TRAIN loss:  1.136\n",
      "[epoch 1 Iteration 527/960] TRAIN loss:  1.616\n",
      "[epoch 1 Iteration 528/960] TRAIN loss:  1.297\n",
      "[epoch 1 Iteration 529/960] TRAIN loss:  1.081\n",
      "[epoch 1 Iteration 530/960] TRAIN loss:  1.311\n",
      "[epoch 1 Iteration 531/960] TRAIN loss:  1.225\n",
      "[epoch 1 Iteration 532/960] TRAIN loss:  1.164\n",
      "[epoch 1 Iteration 533/960] TRAIN loss:  1.059\n",
      "[epoch 1 Iteration 534/960] TRAIN loss:  1.107\n",
      "[epoch 1 Iteration 535/960] TRAIN loss:  1.034\n",
      "[epoch 1 Iteration 536/960] TRAIN loss:  1.566\n",
      "[epoch 1 Iteration 537/960] TRAIN loss:  1.424\n",
      "[epoch 1 Iteration 538/960] TRAIN loss:  1.249\n",
      "[epoch 1 Iteration 539/960] TRAIN loss:  1.129\n",
      "[epoch 1 Iteration 540/960] TRAIN loss:  1.029\n",
      "[epoch 1 Iteration 541/960] TRAIN loss:  1.029\n",
      "[epoch 1 Iteration 542/960] TRAIN loss:  1.130\n",
      "[epoch 1 Iteration 543/960] TRAIN loss:  1.063\n",
      "[epoch 1 Iteration 544/960] TRAIN loss:  1.197\n",
      "[epoch 1 Iteration 545/960] TRAIN loss:  1.454\n",
      "[epoch 1 Iteration 546/960] TRAIN loss:  1.272\n",
      "[epoch 1 Iteration 547/960] TRAIN loss:  1.326\n",
      "[epoch 1 Iteration 548/960] TRAIN loss:  1.130\n",
      "[epoch 1 Iteration 549/960] TRAIN loss:  1.242\n",
      "[epoch 1 Iteration 550/960] TRAIN loss:  1.138\n",
      "[epoch 1 Iteration 551/960] TRAIN loss:  1.376\n",
      "[epoch 1 Iteration 552/960] TRAIN loss:  1.295\n",
      "[epoch 1 Iteration 553/960] TRAIN loss:  1.220\n",
      "[epoch 1 Iteration 554/960] TRAIN loss:  1.178\n",
      "[epoch 1 Iteration 555/960] TRAIN loss:  1.287\n",
      "[epoch 1 Iteration 556/960] TRAIN loss:  1.395\n",
      "[epoch 1 Iteration 557/960] TRAIN loss:  1.447\n",
      "[epoch 1 Iteration 558/960] TRAIN loss:  1.183\n",
      "[epoch 1 Iteration 559/960] TRAIN loss:  1.624\n",
      "[epoch 1 Iteration 560/960] TRAIN loss:  1.279\n",
      "[epoch 1 Iteration 561/960] TRAIN loss:  1.010\n",
      "[epoch 1 Iteration 562/960] TRAIN loss:  1.052\n",
      "[epoch 1 Iteration 563/960] TRAIN loss:  1.142\n",
      "[epoch 1 Iteration 564/960] TRAIN loss:  1.182\n",
      "[epoch 1 Iteration 565/960] TRAIN loss:  1.118\n",
      "[epoch 1 Iteration 566/960] TRAIN loss:  1.149\n",
      "[epoch 1 Iteration 567/960] TRAIN loss:  1.093\n",
      "[epoch 1 Iteration 568/960] TRAIN loss:  1.392\n",
      "[epoch 1 Iteration 569/960] TRAIN loss:  1.422\n",
      "[epoch 1 Iteration 570/960] TRAIN loss:  0.971\n",
      "[epoch 1 Iteration 571/960] TRAIN loss:  1.260\n",
      "[epoch 1 Iteration 572/960] TRAIN loss:  1.193\n",
      "[epoch 1 Iteration 573/960] TRAIN loss:  1.121\n",
      "[epoch 1 Iteration 574/960] TRAIN loss:  1.314\n",
      "[epoch 1 Iteration 575/960] TRAIN loss:  1.063\n",
      "[epoch 1 Iteration 576/960] TRAIN loss:  1.142\n",
      "[epoch 1 Iteration 577/960] TRAIN loss:  1.218\n",
      "[epoch 1 Iteration 578/960] TRAIN loss:  1.043\n",
      "[epoch 1 Iteration 579/960] TRAIN loss:  1.293\n",
      "[epoch 1 Iteration 580/960] TRAIN loss:  1.327\n",
      "[epoch 1 Iteration 581/960] TRAIN loss:  1.148\n",
      "[epoch 1 Iteration 582/960] TRAIN loss:  1.258\n",
      "[epoch 1 Iteration 583/960] TRAIN loss:  1.064\n",
      "[epoch 1 Iteration 584/960] TRAIN loss:  1.143\n",
      "[epoch 1 Iteration 585/960] TRAIN loss:  1.201\n",
      "[epoch 1 Iteration 586/960] TRAIN loss:  1.296\n",
      "[epoch 1 Iteration 587/960] TRAIN loss:  1.277\n",
      "[epoch 1 Iteration 588/960] TRAIN loss:  1.302\n",
      "[epoch 1 Iteration 589/960] TRAIN loss:  1.441\n",
      "[epoch 1 Iteration 590/960] TRAIN loss:  1.568\n",
      "[epoch 1 Iteration 591/960] TRAIN loss:  1.014\n",
      "[epoch 1 Iteration 592/960] TRAIN loss:  1.380\n",
      "[epoch 1 Iteration 593/960] TRAIN loss:  1.209\n",
      "[epoch 1 Iteration 594/960] TRAIN loss:  1.325\n",
      "[epoch 1 Iteration 595/960] TRAIN loss:  1.174\n",
      "[epoch 1 Iteration 596/960] TRAIN loss:  1.166\n",
      "[epoch 1 Iteration 597/960] TRAIN loss:  1.276\n",
      "[epoch 1 Iteration 598/960] TRAIN loss:  1.173\n",
      "[epoch 1 Iteration 599/960] TRAIN loss:  1.273\n",
      "[epoch 1 Iteration 600/960] TRAIN loss:  1.609\n",
      "[epoch 1 Iteration 601/960] TRAIN loss:  0.861\n",
      "[epoch 1 Iteration 602/960] TRAIN loss:  1.408\n",
      "[epoch 1 Iteration 603/960] TRAIN loss:  1.612\n",
      "[epoch 1 Iteration 604/960] TRAIN loss:  1.112\n",
      "[epoch 1 Iteration 605/960] TRAIN loss:  1.241\n",
      "[epoch 1 Iteration 606/960] TRAIN loss:  1.191\n",
      "[epoch 1 Iteration 607/960] TRAIN loss:  1.281\n",
      "[epoch 1 Iteration 608/960] TRAIN loss:  1.173\n",
      "[epoch 1 Iteration 609/960] TRAIN loss:  1.214\n",
      "[epoch 1 Iteration 610/960] TRAIN loss:  1.454\n",
      "[epoch 1 Iteration 611/960] TRAIN loss:  1.340\n",
      "[epoch 1 Iteration 612/960] TRAIN loss:  0.967\n",
      "[epoch 1 Iteration 613/960] TRAIN loss:  1.386\n",
      "[epoch 1 Iteration 614/960] TRAIN loss:  1.169\n",
      "[epoch 1 Iteration 615/960] TRAIN loss:  1.114\n",
      "[epoch 1 Iteration 616/960] TRAIN loss:  1.196\n",
      "[epoch 1 Iteration 617/960] TRAIN loss:  1.080\n",
      "[epoch 1 Iteration 618/960] TRAIN loss:  1.256\n",
      "[epoch 1 Iteration 619/960] TRAIN loss:  1.186\n",
      "[epoch 1 Iteration 620/960] TRAIN loss:  1.204\n",
      "[epoch 1 Iteration 621/960] TRAIN loss:  1.350\n",
      "[epoch 1 Iteration 622/960] TRAIN loss:  1.210\n",
      "[epoch 1 Iteration 623/960] TRAIN loss:  1.427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1 Iteration 624/960] TRAIN loss:  1.253\n",
      "[epoch 1 Iteration 625/960] TRAIN loss:  1.096\n",
      "[epoch 1 Iteration 626/960] TRAIN loss:  1.210\n",
      "[epoch 1 Iteration 627/960] TRAIN loss:  1.183\n",
      "[epoch 1 Iteration 628/960] TRAIN loss:  1.377\n",
      "[epoch 1 Iteration 629/960] TRAIN loss:  1.212\n",
      "[epoch 1 Iteration 630/960] TRAIN loss:  1.192\n",
      "[epoch 1 Iteration 631/960] TRAIN loss:  1.540\n",
      "[epoch 1 Iteration 632/960] TRAIN loss:  1.251\n",
      "[epoch 1 Iteration 633/960] TRAIN loss:  1.041\n",
      "[epoch 1 Iteration 634/960] TRAIN loss:  1.200\n",
      "[epoch 1 Iteration 635/960] TRAIN loss:  0.895\n",
      "[epoch 1 Iteration 636/960] TRAIN loss:  1.055\n",
      "[epoch 1 Iteration 637/960] TRAIN loss:  1.106\n",
      "[epoch 1 Iteration 638/960] TRAIN loss:  1.166\n",
      "[epoch 1 Iteration 639/960] TRAIN loss:  1.090\n",
      "[epoch 1 Iteration 640/960] TRAIN loss:  1.071\n",
      "[epoch 1 Iteration 641/960] TRAIN loss:  1.514\n",
      "[epoch 1 Iteration 642/960] TRAIN loss:  1.593\n",
      "[epoch 1 Iteration 643/960] TRAIN loss:  1.100\n",
      "[epoch 1 Iteration 644/960] TRAIN loss:  1.164\n",
      "[epoch 1 Iteration 645/960] TRAIN loss:  1.116\n",
      "[epoch 1 Iteration 646/960] TRAIN loss:  1.165\n",
      "[epoch 1 Iteration 647/960] TRAIN loss:  1.225\n",
      "[epoch 1 Iteration 648/960] TRAIN loss:  1.168\n",
      "[epoch 1 Iteration 649/960] TRAIN loss:  1.026\n",
      "[epoch 1 Iteration 650/960] TRAIN loss:  0.944\n",
      "[epoch 1 Iteration 651/960] TRAIN loss:  1.244\n",
      "[epoch 1 Iteration 652/960] TRAIN loss:  1.046\n",
      "[epoch 1 Iteration 653/960] TRAIN loss:  1.018\n",
      "[epoch 1 Iteration 654/960] TRAIN loss:  1.147\n",
      "[epoch 1 Iteration 655/960] TRAIN loss:  1.215\n",
      "[epoch 1 Iteration 656/960] TRAIN loss:  1.279\n",
      "[epoch 1 Iteration 657/960] TRAIN loss:  1.193\n",
      "[epoch 1 Iteration 658/960] TRAIN loss:  1.047\n",
      "[epoch 1 Iteration 659/960] TRAIN loss:  1.148\n",
      "[epoch 1 Iteration 660/960] TRAIN loss:  1.213\n",
      "[epoch 1 Iteration 661/960] TRAIN loss:  1.071\n",
      "[epoch 1 Iteration 662/960] TRAIN loss:  1.376\n",
      "[epoch 1 Iteration 663/960] TRAIN loss:  1.277\n",
      "[epoch 1 Iteration 664/960] TRAIN loss:  1.190\n",
      "[epoch 1 Iteration 665/960] TRAIN loss:  1.193\n",
      "[epoch 1 Iteration 666/960] TRAIN loss:  1.427\n",
      "[epoch 1 Iteration 667/960] TRAIN loss:  1.338\n",
      "[epoch 1 Iteration 668/960] TRAIN loss:  1.422\n",
      "[epoch 1 Iteration 669/960] TRAIN loss:  1.294\n",
      "[epoch 1 Iteration 670/960] TRAIN loss:  1.192\n",
      "[epoch 1 Iteration 671/960] TRAIN loss:  1.366\n",
      "[epoch 1 Iteration 672/960] TRAIN loss:  1.360\n",
      "[epoch 1 Iteration 673/960] TRAIN loss:  1.059\n",
      "[epoch 1 Iteration 674/960] TRAIN loss:  1.316\n",
      "[epoch 1 Iteration 675/960] TRAIN loss:  1.487\n",
      "[epoch 1 Iteration 676/960] TRAIN loss:  1.318\n",
      "[epoch 1 Iteration 677/960] TRAIN loss:  1.461\n",
      "[epoch 1 Iteration 678/960] TRAIN loss:  1.263\n",
      "[epoch 1 Iteration 679/960] TRAIN loss:  1.486\n",
      "[epoch 1 Iteration 680/960] TRAIN loss:  0.968\n",
      "[epoch 1 Iteration 681/960] TRAIN loss:  1.233\n",
      "[epoch 1 Iteration 682/960] TRAIN loss:  1.560\n",
      "[epoch 1 Iteration 683/960] TRAIN loss:  1.175\n",
      "[epoch 1 Iteration 684/960] TRAIN loss:  1.176\n",
      "[epoch 1 Iteration 685/960] TRAIN loss:  1.392\n",
      "[epoch 1 Iteration 686/960] TRAIN loss:  1.322\n",
      "[epoch 1 Iteration 687/960] TRAIN loss:  1.255\n",
      "[epoch 1 Iteration 688/960] TRAIN loss:  1.140\n",
      "[epoch 1 Iteration 689/960] TRAIN loss:  1.466\n",
      "[epoch 1 Iteration 690/960] TRAIN loss:  1.251\n",
      "[epoch 1 Iteration 691/960] TRAIN loss:  1.372\n",
      "[epoch 1 Iteration 692/960] TRAIN loss:  1.715\n",
      "[epoch 1 Iteration 693/960] TRAIN loss:  1.383\n",
      "[epoch 1 Iteration 694/960] TRAIN loss:  1.671\n",
      "[epoch 1 Iteration 695/960] TRAIN loss:  1.027\n",
      "[epoch 1 Iteration 696/960] TRAIN loss:  1.172\n",
      "[epoch 1 Iteration 697/960] TRAIN loss:  1.060\n",
      "[epoch 1 Iteration 698/960] TRAIN loss:  1.220\n",
      "[epoch 1 Iteration 699/960] TRAIN loss:  1.173\n",
      "[epoch 1 Iteration 700/960] TRAIN loss:  1.329\n",
      "[epoch 1 Iteration 701/960] TRAIN loss:  1.043\n",
      "[epoch 1 Iteration 702/960] TRAIN loss:  1.233\n",
      "[epoch 1 Iteration 703/960] TRAIN loss:  1.049\n",
      "[epoch 1 Iteration 704/960] TRAIN loss:  1.627\n",
      "[epoch 1 Iteration 705/960] TRAIN loss:  1.348\n",
      "[epoch 1 Iteration 706/960] TRAIN loss:  1.293\n",
      "[epoch 1 Iteration 707/960] TRAIN loss:  1.153\n",
      "[epoch 1 Iteration 708/960] TRAIN loss:  1.347\n",
      "[epoch 1 Iteration 709/960] TRAIN loss:  1.429\n",
      "[epoch 1 Iteration 710/960] TRAIN loss:  0.823\n",
      "[epoch 1 Iteration 711/960] TRAIN loss:  1.257\n",
      "[epoch 1 Iteration 712/960] TRAIN loss:  1.127\n",
      "[epoch 1 Iteration 713/960] TRAIN loss:  0.976\n",
      "[epoch 1 Iteration 714/960] TRAIN loss:  1.274\n",
      "[epoch 1 Iteration 715/960] TRAIN loss:  1.418\n",
      "[epoch 1 Iteration 716/960] TRAIN loss:  1.225\n",
      "[epoch 1 Iteration 717/960] TRAIN loss:  1.256\n",
      "[epoch 1 Iteration 718/960] TRAIN loss:  1.420\n",
      "[epoch 1 Iteration 719/960] TRAIN loss:  1.635\n",
      "[epoch 1 Iteration 720/960] TRAIN loss:  1.101\n",
      "[epoch 1 Iteration 721/960] TRAIN loss:  1.243\n",
      "[epoch 1 Iteration 722/960] TRAIN loss:  1.318\n",
      "[epoch 1 Iteration 723/960] TRAIN loss:  1.141\n",
      "[epoch 1 Iteration 724/960] TRAIN loss:  1.443\n",
      "[epoch 1 Iteration 725/960] TRAIN loss:  1.248\n",
      "[epoch 1 Iteration 726/960] TRAIN loss:  1.285\n",
      "[epoch 1 Iteration 727/960] TRAIN loss:  1.022\n",
      "[epoch 1 Iteration 728/960] TRAIN loss:  1.282\n",
      "[epoch 1 Iteration 729/960] TRAIN loss:  1.434\n",
      "[epoch 1 Iteration 730/960] TRAIN loss:  1.125\n",
      "[epoch 1 Iteration 731/960] TRAIN loss:  1.184\n",
      "[epoch 1 Iteration 732/960] TRAIN loss:  1.211\n",
      "[epoch 1 Iteration 733/960] TRAIN loss:  1.238\n",
      "[epoch 1 Iteration 734/960] TRAIN loss:  1.209\n",
      "[epoch 1 Iteration 735/960] TRAIN loss:  1.264\n",
      "[epoch 1 Iteration 736/960] TRAIN loss:  1.034\n",
      "[epoch 1 Iteration 737/960] TRAIN loss:  1.089\n",
      "[epoch 1 Iteration 738/960] TRAIN loss:  1.274\n",
      "[epoch 1 Iteration 739/960] TRAIN loss:  1.143\n",
      "[epoch 1 Iteration 740/960] TRAIN loss:  1.330\n",
      "[epoch 1 Iteration 741/960] TRAIN loss:  1.233\n",
      "[epoch 1 Iteration 742/960] TRAIN loss:  1.216\n",
      "[epoch 1 Iteration 743/960] TRAIN loss:  1.059\n",
      "[epoch 1 Iteration 744/960] TRAIN loss:  1.166\n",
      "[epoch 1 Iteration 745/960] TRAIN loss:  1.323\n",
      "[epoch 1 Iteration 746/960] TRAIN loss:  1.214\n",
      "[epoch 1 Iteration 747/960] TRAIN loss:  1.114\n",
      "[epoch 1 Iteration 748/960] TRAIN loss:  1.108\n",
      "[epoch 1 Iteration 749/960] TRAIN loss:  1.205\n",
      "[epoch 1 Iteration 750/960] TRAIN loss:  1.261\n",
      "[epoch 1 Iteration 751/960] TRAIN loss:  1.291\n",
      "[epoch 1 Iteration 752/960] TRAIN loss:  1.148\n",
      "[epoch 1 Iteration 753/960] TRAIN loss:  1.225\n",
      "[epoch 1 Iteration 754/960] TRAIN loss:  1.105\n",
      "[epoch 1 Iteration 755/960] TRAIN loss:  1.121\n",
      "[epoch 1 Iteration 756/960] TRAIN loss:  1.149\n",
      "[epoch 1 Iteration 757/960] TRAIN loss:  1.108\n",
      "[epoch 1 Iteration 758/960] TRAIN loss:  1.232\n",
      "[epoch 1 Iteration 759/960] TRAIN loss:  1.311\n",
      "[epoch 1 Iteration 760/960] TRAIN loss:  1.434\n",
      "[epoch 1 Iteration 761/960] TRAIN loss:  1.247\n",
      "[epoch 1 Iteration 762/960] TRAIN loss:  1.049\n",
      "[epoch 1 Iteration 763/960] TRAIN loss:  1.012\n",
      "[epoch 1 Iteration 764/960] TRAIN loss:  1.115\n",
      "[epoch 1 Iteration 765/960] TRAIN loss:  1.312\n",
      "[epoch 1 Iteration 766/960] TRAIN loss:  1.339\n",
      "[epoch 1 Iteration 767/960] TRAIN loss:  1.332\n",
      "[epoch 1 Iteration 768/960] TRAIN loss:  1.183\n",
      "[epoch 1 Iteration 769/960] TRAIN loss:  1.113\n",
      "[epoch 1 Iteration 770/960] TRAIN loss:  1.226\n",
      "[epoch 1 Iteration 771/960] TRAIN loss:  1.178\n",
      "[epoch 1 Iteration 772/960] TRAIN loss:  1.244\n",
      "[epoch 1 Iteration 773/960] TRAIN loss:  1.234\n",
      "[epoch 1 Iteration 774/960] TRAIN loss:  1.055\n",
      "[epoch 1 Iteration 775/960] TRAIN loss:  1.281\n",
      "[epoch 1 Iteration 776/960] TRAIN loss:  1.438\n",
      "[epoch 1 Iteration 777/960] TRAIN loss:  1.263\n",
      "[epoch 1 Iteration 778/960] TRAIN loss:  1.244\n",
      "[epoch 1 Iteration 779/960] TRAIN loss:  1.210\n",
      "[epoch 1 Iteration 780/960] TRAIN loss:  1.449\n",
      "[epoch 1 Iteration 781/960] TRAIN loss:  1.212\n",
      "[epoch 1 Iteration 782/960] TRAIN loss:  1.246\n",
      "[epoch 1 Iteration 783/960] TRAIN loss:  1.353\n",
      "[epoch 1 Iteration 784/960] TRAIN loss:  1.189\n",
      "[epoch 1 Iteration 785/960] TRAIN loss:  1.293\n",
      "[epoch 1 Iteration 786/960] TRAIN loss:  1.273\n",
      "[epoch 1 Iteration 787/960] TRAIN loss:  1.284\n",
      "[epoch 1 Iteration 788/960] TRAIN loss:  1.328\n",
      "[epoch 1 Iteration 789/960] TRAIN loss:  1.236\n",
      "[epoch 1 Iteration 790/960] TRAIN loss:  1.209\n",
      "[epoch 1 Iteration 791/960] TRAIN loss:  1.480\n",
      "[epoch 1 Iteration 792/960] TRAIN loss:  0.944\n",
      "[epoch 1 Iteration 793/960] TRAIN loss:  1.133\n",
      "[epoch 1 Iteration 794/960] TRAIN loss:  1.379\n",
      "[epoch 1 Iteration 795/960] TRAIN loss:  1.119\n",
      "[epoch 1 Iteration 796/960] TRAIN loss:  1.296\n",
      "[epoch 1 Iteration 797/960] TRAIN loss:  0.933\n",
      "[epoch 1 Iteration 798/960] TRAIN loss:  1.373\n",
      "[epoch 1 Iteration 799/960] TRAIN loss:  1.198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1 Iteration 800/960] TRAIN loss:  1.209\n",
      "[epoch 1 Iteration 801/960] TRAIN loss:  1.325\n",
      "[epoch 1 Iteration 802/960] TRAIN loss:  1.332\n",
      "[epoch 1 Iteration 803/960] TRAIN loss:  0.987\n",
      "[epoch 1 Iteration 804/960] TRAIN loss:  1.517\n",
      "[epoch 1 Iteration 805/960] TRAIN loss:  1.534\n",
      "[epoch 1 Iteration 806/960] TRAIN loss:  1.149\n",
      "[epoch 1 Iteration 807/960] TRAIN loss:  1.267\n",
      "[epoch 1 Iteration 808/960] TRAIN loss:  1.547\n",
      "[epoch 1 Iteration 809/960] TRAIN loss:  1.077\n",
      "[epoch 1 Iteration 810/960] TRAIN loss:  1.106\n",
      "[epoch 1 Iteration 811/960] TRAIN loss:  1.155\n",
      "[epoch 1 Iteration 812/960] TRAIN loss:  1.204\n",
      "[epoch 1 Iteration 813/960] TRAIN loss:  1.141\n",
      "[epoch 1 Iteration 814/960] TRAIN loss:  1.330\n",
      "[epoch 1 Iteration 815/960] TRAIN loss:  1.258\n",
      "[epoch 1 Iteration 816/960] TRAIN loss:  1.058\n",
      "[epoch 1 Iteration 817/960] TRAIN loss:  1.355\n",
      "[epoch 1 Iteration 818/960] TRAIN loss:  0.869\n",
      "[epoch 1 Iteration 819/960] TRAIN loss:  1.128\n",
      "[epoch 1 Iteration 820/960] TRAIN loss:  1.016\n",
      "[epoch 1 Iteration 821/960] TRAIN loss:  0.898\n",
      "[epoch 1 Iteration 822/960] TRAIN loss:  1.133\n",
      "[epoch 1 Iteration 823/960] TRAIN loss:  1.573\n",
      "[epoch 1 Iteration 824/960] TRAIN loss:  1.218\n",
      "[epoch 1 Iteration 825/960] TRAIN loss:  1.394\n",
      "[epoch 1 Iteration 826/960] TRAIN loss:  1.379\n",
      "[epoch 1 Iteration 827/960] TRAIN loss:  1.078\n",
      "[epoch 1 Iteration 828/960] TRAIN loss:  1.410\n",
      "[epoch 1 Iteration 829/960] TRAIN loss:  1.250\n",
      "[epoch 1 Iteration 830/960] TRAIN loss:  1.149\n",
      "[epoch 1 Iteration 831/960] TRAIN loss:  1.482\n",
      "[epoch 1 Iteration 832/960] TRAIN loss:  1.197\n",
      "[epoch 1 Iteration 833/960] TRAIN loss:  1.139\n",
      "[epoch 1 Iteration 834/960] TRAIN loss:  1.227\n",
      "[epoch 1 Iteration 835/960] TRAIN loss:  1.080\n",
      "[epoch 1 Iteration 836/960] TRAIN loss:  1.064\n",
      "[epoch 1 Iteration 837/960] TRAIN loss:  1.455\n",
      "[epoch 1 Iteration 838/960] TRAIN loss:  1.186\n",
      "[epoch 1 Iteration 839/960] TRAIN loss:  1.157\n",
      "[epoch 1 Iteration 840/960] TRAIN loss:  1.217\n",
      "[epoch 1 Iteration 841/960] TRAIN loss:  1.394\n",
      "[epoch 1 Iteration 842/960] TRAIN loss:  1.019\n",
      "[epoch 1 Iteration 843/960] TRAIN loss:  1.058\n",
      "[epoch 1 Iteration 844/960] TRAIN loss:  1.153\n",
      "[epoch 1 Iteration 845/960] TRAIN loss:  1.116\n",
      "[epoch 1 Iteration 846/960] TRAIN loss:  1.300\n",
      "[epoch 1 Iteration 847/960] TRAIN loss:  1.464\n",
      "[epoch 1 Iteration 848/960] TRAIN loss:  1.321\n",
      "[epoch 1 Iteration 849/960] TRAIN loss:  1.105\n",
      "[epoch 1 Iteration 850/960] TRAIN loss:  1.646\n",
      "[epoch 1 Iteration 851/960] TRAIN loss:  1.240\n",
      "[epoch 1 Iteration 852/960] TRAIN loss:  1.056\n",
      "[epoch 1 Iteration 853/960] TRAIN loss:  1.105\n",
      "[epoch 1 Iteration 854/960] TRAIN loss:  1.075\n",
      "[epoch 1 Iteration 855/960] TRAIN loss:  1.098\n",
      "[epoch 1 Iteration 856/960] TRAIN loss:  1.171\n",
      "[epoch 1 Iteration 857/960] TRAIN loss:  0.984\n",
      "[epoch 1 Iteration 858/960] TRAIN loss:  1.521\n",
      "[epoch 1 Iteration 859/960] TRAIN loss:  1.498\n",
      "[epoch 1 Iteration 860/960] TRAIN loss:  1.143\n",
      "[epoch 1 Iteration 861/960] TRAIN loss:  1.358\n",
      "[epoch 1 Iteration 862/960] TRAIN loss:  1.202\n",
      "[epoch 1 Iteration 863/960] TRAIN loss:  1.237\n",
      "[epoch 1 Iteration 864/960] TRAIN loss:  1.068\n",
      "[epoch 1 Iteration 865/960] TRAIN loss:  0.913\n",
      "[epoch 1 Iteration 866/960] TRAIN loss:  1.191\n",
      "[epoch 1 Iteration 867/960] TRAIN loss:  1.346\n",
      "[epoch 1 Iteration 868/960] TRAIN loss:  1.303\n",
      "[epoch 1 Iteration 869/960] TRAIN loss:  1.322\n",
      "[epoch 1 Iteration 870/960] TRAIN loss:  1.204\n",
      "[epoch 1 Iteration 871/960] TRAIN loss:  1.275\n",
      "[epoch 1 Iteration 872/960] TRAIN loss:  1.510\n",
      "[epoch 1 Iteration 873/960] TRAIN loss:  1.120\n",
      "[epoch 1 Iteration 874/960] TRAIN loss:  1.655\n",
      "[epoch 1 Iteration 875/960] TRAIN loss:  1.143\n",
      "[epoch 1 Iteration 876/960] TRAIN loss:  1.503\n",
      "[epoch 1 Iteration 877/960] TRAIN loss:  1.146\n",
      "[epoch 1 Iteration 878/960] TRAIN loss:  1.223\n",
      "[epoch 1 Iteration 879/960] TRAIN loss:  1.300\n",
      "[epoch 1 Iteration 880/960] TRAIN loss:  1.342\n",
      "[epoch 1 Iteration 881/960] TRAIN loss:  1.233\n",
      "[epoch 1 Iteration 882/960] TRAIN loss:  1.331\n",
      "[epoch 1 Iteration 883/960] TRAIN loss:  1.011\n",
      "[epoch 1 Iteration 884/960] TRAIN loss:  1.185\n",
      "[epoch 1 Iteration 885/960] TRAIN loss:  1.303\n",
      "[epoch 1 Iteration 886/960] TRAIN loss:  1.144\n",
      "[epoch 1 Iteration 887/960] TRAIN loss:  1.466\n",
      "[epoch 1 Iteration 888/960] TRAIN loss:  1.393\n",
      "[epoch 1 Iteration 889/960] TRAIN loss:  1.274\n",
      "[epoch 1 Iteration 890/960] TRAIN loss:  1.467\n",
      "[epoch 1 Iteration 891/960] TRAIN loss:  1.567\n",
      "[epoch 1 Iteration 892/960] TRAIN loss:  1.179\n",
      "[epoch 1 Iteration 893/960] TRAIN loss:  1.283\n",
      "[epoch 1 Iteration 894/960] TRAIN loss:  1.219\n",
      "[epoch 1 Iteration 895/960] TRAIN loss:  1.261\n",
      "[epoch 1 Iteration 896/960] TRAIN loss:  1.235\n",
      "[epoch 1 Iteration 897/960] TRAIN loss:  1.296\n",
      "[epoch 1 Iteration 898/960] TRAIN loss:  1.222\n",
      "[epoch 1 Iteration 899/960] TRAIN loss:  1.203\n",
      "[epoch 1 Iteration 900/960] TRAIN loss:  0.883\n",
      "[epoch 1 Iteration 901/960] TRAIN loss:  1.434\n",
      "[epoch 1 Iteration 902/960] TRAIN loss:  1.184\n",
      "[epoch 1 Iteration 903/960] TRAIN loss:  1.180\n",
      "[epoch 1 Iteration 904/960] TRAIN loss:  1.360\n",
      "[epoch 1 Iteration 905/960] TRAIN loss:  1.440\n",
      "[epoch 1 Iteration 906/960] TRAIN loss:  1.193\n",
      "[epoch 1 Iteration 907/960] TRAIN loss:  1.228\n",
      "[epoch 1 Iteration 908/960] TRAIN loss:  0.986\n",
      "[epoch 1 Iteration 909/960] TRAIN loss:  1.087\n",
      "[epoch 1 Iteration 910/960] TRAIN loss:  1.158\n",
      "[epoch 1 Iteration 911/960] TRAIN loss:  0.984\n",
      "[epoch 1 Iteration 912/960] TRAIN loss:  1.292\n",
      "[epoch 1 Iteration 913/960] TRAIN loss:  1.415\n",
      "[epoch 1 Iteration 914/960] TRAIN loss:  1.289\n",
      "[epoch 1 Iteration 915/960] TRAIN loss:  1.273\n",
      "[epoch 1 Iteration 916/960] TRAIN loss:  1.310\n",
      "[epoch 1 Iteration 917/960] TRAIN loss:  1.310\n",
      "[epoch 1 Iteration 918/960] TRAIN loss:  1.129\n",
      "[epoch 1 Iteration 919/960] TRAIN loss:  1.319\n",
      "[epoch 1 Iteration 920/960] TRAIN loss:  1.146\n",
      "[epoch 1 Iteration 921/960] TRAIN loss:  1.122\n",
      "[epoch 1 Iteration 922/960] TRAIN loss:  1.356\n",
      "[epoch 1 Iteration 923/960] TRAIN loss:  1.044\n",
      "[epoch 1 Iteration 924/960] TRAIN loss:  1.108\n",
      "[epoch 1 Iteration 925/960] TRAIN loss:  1.361\n",
      "[epoch 1 Iteration 926/960] TRAIN loss:  1.232\n",
      "[epoch 1 Iteration 927/960] TRAIN loss:  1.350\n",
      "[epoch 1 Iteration 928/960] TRAIN loss:  1.105\n",
      "[epoch 1 Iteration 929/960] TRAIN loss:  1.447\n",
      "[epoch 1 Iteration 930/960] TRAIN loss:  1.257\n",
      "[epoch 1 Iteration 931/960] TRAIN loss:  1.163\n",
      "[epoch 1 Iteration 932/960] TRAIN loss:  1.336\n",
      "[epoch 1 Iteration 933/960] TRAIN loss:  1.190\n",
      "[epoch 1 Iteration 934/960] TRAIN loss:  1.228\n",
      "[epoch 1 Iteration 935/960] TRAIN loss:  0.879\n",
      "[epoch 1 Iteration 936/960] TRAIN loss:  1.044\n",
      "[epoch 1 Iteration 937/960] TRAIN loss:  1.365\n",
      "[epoch 1 Iteration 938/960] TRAIN loss:  1.343\n",
      "[epoch 1 Iteration 939/960] TRAIN loss:  1.299\n",
      "[epoch 1 Iteration 940/960] TRAIN loss:  1.233\n",
      "[epoch 1 Iteration 941/960] TRAIN loss:  1.105\n",
      "[epoch 1 Iteration 942/960] TRAIN loss:  1.142\n",
      "[epoch 1 Iteration 943/960] TRAIN loss:  0.833\n",
      "[epoch 1 Iteration 944/960] TRAIN loss:  1.142\n",
      "[epoch 1 Iteration 945/960] TRAIN loss:  1.312\n",
      "[epoch 1 Iteration 946/960] TRAIN loss:  1.354\n",
      "[epoch 1 Iteration 947/960] TRAIN loss:  1.051\n",
      "[epoch 1 Iteration 948/960] TRAIN loss:  1.422\n",
      "[epoch 1 Iteration 949/960] TRAIN loss:  0.950\n",
      "[epoch 1 Iteration 950/960] TRAIN loss:  1.466\n",
      "[epoch 1 Iteration 951/960] TRAIN loss:  1.451\n",
      "[epoch 1 Iteration 952/960] TRAIN loss:  1.014\n",
      "[epoch 1 Iteration 953/960] TRAIN loss:  1.110\n",
      "[epoch 1 Iteration 954/960] TRAIN loss:  1.169\n",
      "[epoch 1 Iteration 955/960] TRAIN loss:  1.256\n",
      "[epoch 1 Iteration 956/960] TRAIN loss:  1.262\n",
      "[epoch 1 Iteration 957/960] TRAIN loss:  1.439\n",
      "[epoch 1 Iteration 958/960] TRAIN loss:  1.102\n",
      "[epoch 1 Iteration 959/960] TRAIN loss:  1.165\n",
      "[epoch 1/15] TRAIN acc/loss:  0.550/1.165\n",
      "[epoch 1/15] VAL acc/loss:  0.549/0.979\n",
      "[epoch 2 Iteration 0/960] TRAIN loss:  1.397\n",
      "[epoch 2 Iteration 1/960] TRAIN loss:  1.453\n",
      "[epoch 2 Iteration 2/960] TRAIN loss:  1.205\n",
      "[epoch 2 Iteration 3/960] TRAIN loss:  1.016\n",
      "[epoch 2 Iteration 4/960] TRAIN loss:  1.125\n",
      "[epoch 2 Iteration 5/960] TRAIN loss:  1.107\n",
      "[epoch 2 Iteration 6/960] TRAIN loss:  0.869\n",
      "[epoch 2 Iteration 7/960] TRAIN loss:  1.258\n",
      "[epoch 2 Iteration 8/960] TRAIN loss:  1.165\n",
      "[epoch 2 Iteration 9/960] TRAIN loss:  1.173\n",
      "[epoch 2 Iteration 10/960] TRAIN loss:  1.009\n",
      "[epoch 2 Iteration 11/960] TRAIN loss:  0.978\n",
      "[epoch 2 Iteration 12/960] TRAIN loss:  1.124\n",
      "[epoch 2 Iteration 13/960] TRAIN loss:  1.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2 Iteration 14/960] TRAIN loss:  1.086\n",
      "[epoch 2 Iteration 15/960] TRAIN loss:  1.113\n",
      "[epoch 2 Iteration 16/960] TRAIN loss:  1.122\n",
      "[epoch 2 Iteration 17/960] TRAIN loss:  1.277\n",
      "[epoch 2 Iteration 18/960] TRAIN loss:  1.492\n",
      "[epoch 2 Iteration 19/960] TRAIN loss:  1.266\n",
      "[epoch 2 Iteration 20/960] TRAIN loss:  1.334\n",
      "[epoch 2 Iteration 21/960] TRAIN loss:  1.428\n",
      "[epoch 2 Iteration 22/960] TRAIN loss:  1.198\n",
      "[epoch 2 Iteration 23/960] TRAIN loss:  1.020\n",
      "[epoch 2 Iteration 24/960] TRAIN loss:  1.115\n",
      "[epoch 2 Iteration 25/960] TRAIN loss:  0.903\n",
      "[epoch 2 Iteration 26/960] TRAIN loss:  1.189\n",
      "[epoch 2 Iteration 27/960] TRAIN loss:  1.044\n",
      "[epoch 2 Iteration 28/960] TRAIN loss:  1.342\n",
      "[epoch 2 Iteration 29/960] TRAIN loss:  1.192\n",
      "[epoch 2 Iteration 30/960] TRAIN loss:  1.190\n",
      "[epoch 2 Iteration 31/960] TRAIN loss:  1.089\n",
      "[epoch 2 Iteration 32/960] TRAIN loss:  1.216\n",
      "[epoch 2 Iteration 33/960] TRAIN loss:  1.099\n",
      "[epoch 2 Iteration 34/960] TRAIN loss:  1.135\n",
      "[epoch 2 Iteration 35/960] TRAIN loss:  1.164\n",
      "[epoch 2 Iteration 36/960] TRAIN loss:  1.223\n",
      "[epoch 2 Iteration 37/960] TRAIN loss:  1.292\n",
      "[epoch 2 Iteration 38/960] TRAIN loss:  1.219\n",
      "[epoch 2 Iteration 39/960] TRAIN loss:  1.666\n",
      "[epoch 2 Iteration 40/960] TRAIN loss:  0.949\n",
      "[epoch 2 Iteration 41/960] TRAIN loss:  1.152\n",
      "[epoch 2 Iteration 42/960] TRAIN loss:  1.144\n",
      "[epoch 2 Iteration 43/960] TRAIN loss:  0.903\n",
      "[epoch 2 Iteration 44/960] TRAIN loss:  1.365\n",
      "[epoch 2 Iteration 45/960] TRAIN loss:  0.927\n",
      "[epoch 2 Iteration 46/960] TRAIN loss:  1.097\n",
      "[epoch 2 Iteration 47/960] TRAIN loss:  0.914\n",
      "[epoch 2 Iteration 48/960] TRAIN loss:  1.398\n",
      "[epoch 2 Iteration 49/960] TRAIN loss:  1.142\n",
      "[epoch 2 Iteration 50/960] TRAIN loss:  1.169\n",
      "[epoch 2 Iteration 51/960] TRAIN loss:  1.215\n",
      "[epoch 2 Iteration 52/960] TRAIN loss:  1.137\n",
      "[epoch 2 Iteration 53/960] TRAIN loss:  1.165\n",
      "[epoch 2 Iteration 54/960] TRAIN loss:  1.264\n",
      "[epoch 2 Iteration 55/960] TRAIN loss:  1.450\n",
      "[epoch 2 Iteration 56/960] TRAIN loss:  1.252\n",
      "[epoch 2 Iteration 57/960] TRAIN loss:  0.865\n",
      "[epoch 2 Iteration 58/960] TRAIN loss:  1.251\n",
      "[epoch 2 Iteration 59/960] TRAIN loss:  1.024\n",
      "[epoch 2 Iteration 60/960] TRAIN loss:  1.126\n",
      "[epoch 2 Iteration 61/960] TRAIN loss:  1.116\n",
      "[epoch 2 Iteration 62/960] TRAIN loss:  1.171\n",
      "[epoch 2 Iteration 63/960] TRAIN loss:  1.259\n",
      "[epoch 2 Iteration 64/960] TRAIN loss:  1.499\n",
      "[epoch 2 Iteration 65/960] TRAIN loss:  1.155\n",
      "[epoch 2 Iteration 66/960] TRAIN loss:  1.162\n",
      "[epoch 2 Iteration 67/960] TRAIN loss:  0.911\n",
      "[epoch 2 Iteration 68/960] TRAIN loss:  1.244\n",
      "[epoch 2 Iteration 69/960] TRAIN loss:  1.170\n",
      "[epoch 2 Iteration 70/960] TRAIN loss:  1.195\n",
      "[epoch 2 Iteration 71/960] TRAIN loss:  1.359\n",
      "[epoch 2 Iteration 72/960] TRAIN loss:  1.229\n",
      "[epoch 2 Iteration 73/960] TRAIN loss:  1.248\n",
      "[epoch 2 Iteration 74/960] TRAIN loss:  1.248\n",
      "[epoch 2 Iteration 75/960] TRAIN loss:  1.160\n",
      "[epoch 2 Iteration 76/960] TRAIN loss:  1.181\n",
      "[epoch 2 Iteration 77/960] TRAIN loss:  1.137\n",
      "[epoch 2 Iteration 78/960] TRAIN loss:  1.194\n",
      "[epoch 2 Iteration 79/960] TRAIN loss:  1.003\n",
      "[epoch 2 Iteration 80/960] TRAIN loss:  1.130\n",
      "[epoch 2 Iteration 81/960] TRAIN loss:  1.231\n",
      "[epoch 2 Iteration 82/960] TRAIN loss:  1.224\n",
      "[epoch 2 Iteration 83/960] TRAIN loss:  0.940\n",
      "[epoch 2 Iteration 84/960] TRAIN loss:  1.162\n",
      "[epoch 2 Iteration 85/960] TRAIN loss:  1.119\n",
      "[epoch 2 Iteration 86/960] TRAIN loss:  0.919\n",
      "[epoch 2 Iteration 87/960] TRAIN loss:  1.186\n",
      "[epoch 2 Iteration 88/960] TRAIN loss:  1.041\n",
      "[epoch 2 Iteration 89/960] TRAIN loss:  1.352\n",
      "[epoch 2 Iteration 90/960] TRAIN loss:  1.311\n",
      "[epoch 2 Iteration 91/960] TRAIN loss:  1.210\n",
      "[epoch 2 Iteration 92/960] TRAIN loss:  1.071\n",
      "[epoch 2 Iteration 93/960] TRAIN loss:  1.067\n",
      "[epoch 2 Iteration 94/960] TRAIN loss:  1.025\n",
      "[epoch 2 Iteration 95/960] TRAIN loss:  1.390\n",
      "[epoch 2 Iteration 96/960] TRAIN loss:  1.271\n",
      "[epoch 2 Iteration 97/960] TRAIN loss:  1.083\n",
      "[epoch 2 Iteration 98/960] TRAIN loss:  1.232\n",
      "[epoch 2 Iteration 99/960] TRAIN loss:  1.476\n",
      "[epoch 2 Iteration 100/960] TRAIN loss:  1.070\n",
      "[epoch 2 Iteration 101/960] TRAIN loss:  1.209\n",
      "[epoch 2 Iteration 102/960] TRAIN loss:  1.049\n",
      "[epoch 2 Iteration 103/960] TRAIN loss:  0.961\n",
      "[epoch 2 Iteration 104/960] TRAIN loss:  1.028\n",
      "[epoch 2 Iteration 105/960] TRAIN loss:  1.212\n",
      "[epoch 2 Iteration 106/960] TRAIN loss:  0.871\n",
      "[epoch 2 Iteration 107/960] TRAIN loss:  1.162\n",
      "[epoch 2 Iteration 108/960] TRAIN loss:  1.375\n",
      "[epoch 2 Iteration 109/960] TRAIN loss:  1.542\n",
      "[epoch 2 Iteration 110/960] TRAIN loss:  1.170\n",
      "[epoch 2 Iteration 111/960] TRAIN loss:  1.054\n",
      "[epoch 2 Iteration 112/960] TRAIN loss:  1.177\n",
      "[epoch 2 Iteration 113/960] TRAIN loss:  1.240\n",
      "[epoch 2 Iteration 114/960] TRAIN loss:  1.138\n",
      "[epoch 2 Iteration 115/960] TRAIN loss:  1.190\n",
      "[epoch 2 Iteration 116/960] TRAIN loss:  1.151\n",
      "[epoch 2 Iteration 117/960] TRAIN loss:  1.097\n",
      "[epoch 2 Iteration 118/960] TRAIN loss:  1.031\n",
      "[epoch 2 Iteration 119/960] TRAIN loss:  1.189\n",
      "[epoch 2 Iteration 120/960] TRAIN loss:  1.254\n",
      "[epoch 2 Iteration 121/960] TRAIN loss:  1.102\n",
      "[epoch 2 Iteration 122/960] TRAIN loss:  1.058\n",
      "[epoch 2 Iteration 123/960] TRAIN loss:  1.144\n",
      "[epoch 2 Iteration 124/960] TRAIN loss:  0.930\n",
      "[epoch 2 Iteration 125/960] TRAIN loss:  1.423\n",
      "[epoch 2 Iteration 126/960] TRAIN loss:  1.127\n",
      "[epoch 2 Iteration 127/960] TRAIN loss:  0.992\n",
      "[epoch 2 Iteration 128/960] TRAIN loss:  1.047\n",
      "[epoch 2 Iteration 129/960] TRAIN loss:  1.257\n",
      "[epoch 2 Iteration 130/960] TRAIN loss:  0.946\n",
      "[epoch 2 Iteration 131/960] TRAIN loss:  1.207\n",
      "[epoch 2 Iteration 132/960] TRAIN loss:  1.622\n",
      "[epoch 2 Iteration 133/960] TRAIN loss:  0.736\n",
      "[epoch 2 Iteration 134/960] TRAIN loss:  1.099\n",
      "[epoch 2 Iteration 135/960] TRAIN loss:  1.009\n",
      "[epoch 2 Iteration 136/960] TRAIN loss:  1.163\n",
      "[epoch 2 Iteration 137/960] TRAIN loss:  1.054\n",
      "[epoch 2 Iteration 138/960] TRAIN loss:  1.457\n",
      "[epoch 2 Iteration 139/960] TRAIN loss:  1.072\n",
      "[epoch 2 Iteration 140/960] TRAIN loss:  1.067\n",
      "[epoch 2 Iteration 141/960] TRAIN loss:  1.197\n",
      "[epoch 2 Iteration 142/960] TRAIN loss:  1.129\n",
      "[epoch 2 Iteration 143/960] TRAIN loss:  1.342\n",
      "[epoch 2 Iteration 144/960] TRAIN loss:  1.062\n",
      "[epoch 2 Iteration 145/960] TRAIN loss:  1.130\n",
      "[epoch 2 Iteration 146/960] TRAIN loss:  1.228\n",
      "[epoch 2 Iteration 147/960] TRAIN loss:  1.303\n",
      "[epoch 2 Iteration 148/960] TRAIN loss:  1.041\n",
      "[epoch 2 Iteration 149/960] TRAIN loss:  1.367\n",
      "[epoch 2 Iteration 150/960] TRAIN loss:  1.016\n",
      "[epoch 2 Iteration 151/960] TRAIN loss:  1.333\n",
      "[epoch 2 Iteration 152/960] TRAIN loss:  1.310\n",
      "[epoch 2 Iteration 153/960] TRAIN loss:  1.393\n",
      "[epoch 2 Iteration 154/960] TRAIN loss:  0.881\n",
      "[epoch 2 Iteration 155/960] TRAIN loss:  0.981\n",
      "[epoch 2 Iteration 156/960] TRAIN loss:  1.210\n",
      "[epoch 2 Iteration 157/960] TRAIN loss:  0.984\n",
      "[epoch 2 Iteration 158/960] TRAIN loss:  0.876\n",
      "[epoch 2 Iteration 159/960] TRAIN loss:  1.203\n",
      "[epoch 2 Iteration 160/960] TRAIN loss:  1.374\n",
      "[epoch 2 Iteration 161/960] TRAIN loss:  0.977\n",
      "[epoch 2 Iteration 162/960] TRAIN loss:  1.390\n",
      "[epoch 2 Iteration 163/960] TRAIN loss:  1.419\n",
      "[epoch 2 Iteration 164/960] TRAIN loss:  1.278\n",
      "[epoch 2 Iteration 165/960] TRAIN loss:  1.240\n",
      "[epoch 2 Iteration 166/960] TRAIN loss:  1.066\n",
      "[epoch 2 Iteration 167/960] TRAIN loss:  1.143\n",
      "[epoch 2 Iteration 168/960] TRAIN loss:  1.062\n",
      "[epoch 2 Iteration 169/960] TRAIN loss:  1.289\n",
      "[epoch 2 Iteration 170/960] TRAIN loss:  1.367\n",
      "[epoch 2 Iteration 171/960] TRAIN loss:  1.293\n",
      "[epoch 2 Iteration 172/960] TRAIN loss:  1.311\n",
      "[epoch 2 Iteration 173/960] TRAIN loss:  1.087\n",
      "[epoch 2 Iteration 174/960] TRAIN loss:  1.350\n",
      "[epoch 2 Iteration 175/960] TRAIN loss:  1.023\n",
      "[epoch 2 Iteration 176/960] TRAIN loss:  1.330\n",
      "[epoch 2 Iteration 177/960] TRAIN loss:  0.979\n",
      "[epoch 2 Iteration 178/960] TRAIN loss:  1.519\n",
      "[epoch 2 Iteration 179/960] TRAIN loss:  0.903\n",
      "[epoch 2 Iteration 180/960] TRAIN loss:  1.070\n",
      "[epoch 2 Iteration 181/960] TRAIN loss:  1.303\n",
      "[epoch 2 Iteration 182/960] TRAIN loss:  1.219\n",
      "[epoch 2 Iteration 183/960] TRAIN loss:  1.216\n",
      "[epoch 2 Iteration 184/960] TRAIN loss:  0.979\n",
      "[epoch 2 Iteration 185/960] TRAIN loss:  1.033\n",
      "[epoch 2 Iteration 186/960] TRAIN loss:  0.957\n",
      "[epoch 2 Iteration 187/960] TRAIN loss:  1.368\n",
      "[epoch 2 Iteration 188/960] TRAIN loss:  0.949\n",
      "[epoch 2 Iteration 189/960] TRAIN loss:  1.001\n",
      "[epoch 2 Iteration 190/960] TRAIN loss:  1.053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2 Iteration 191/960] TRAIN loss:  1.064\n",
      "[epoch 2 Iteration 192/960] TRAIN loss:  1.039\n",
      "[epoch 2 Iteration 193/960] TRAIN loss:  1.251\n",
      "[epoch 2 Iteration 194/960] TRAIN loss:  1.342\n",
      "[epoch 2 Iteration 195/960] TRAIN loss:  0.961\n",
      "[epoch 2 Iteration 196/960] TRAIN loss:  1.086\n",
      "[epoch 2 Iteration 197/960] TRAIN loss:  1.240\n",
      "[epoch 2 Iteration 198/960] TRAIN loss:  1.418\n",
      "[epoch 2 Iteration 199/960] TRAIN loss:  0.906\n",
      "[epoch 2 Iteration 200/960] TRAIN loss:  1.260\n",
      "[epoch 2 Iteration 201/960] TRAIN loss:  1.108\n",
      "[epoch 2 Iteration 202/960] TRAIN loss:  1.157\n",
      "[epoch 2 Iteration 203/960] TRAIN loss:  1.265\n",
      "[epoch 2 Iteration 204/960] TRAIN loss:  1.319\n",
      "[epoch 2 Iteration 205/960] TRAIN loss:  1.170\n",
      "[epoch 2 Iteration 206/960] TRAIN loss:  1.050\n",
      "[epoch 2 Iteration 207/960] TRAIN loss:  1.189\n",
      "[epoch 2 Iteration 208/960] TRAIN loss:  1.394\n",
      "[epoch 2 Iteration 209/960] TRAIN loss:  1.280\n",
      "[epoch 2 Iteration 210/960] TRAIN loss:  1.501\n",
      "[epoch 2 Iteration 211/960] TRAIN loss:  1.314\n",
      "[epoch 2 Iteration 212/960] TRAIN loss:  1.160\n",
      "[epoch 2 Iteration 213/960] TRAIN loss:  0.939\n",
      "[epoch 2 Iteration 214/960] TRAIN loss:  1.200\n",
      "[epoch 2 Iteration 215/960] TRAIN loss:  1.192\n",
      "[epoch 2 Iteration 216/960] TRAIN loss:  0.859\n",
      "[epoch 2 Iteration 217/960] TRAIN loss:  1.327\n",
      "[epoch 2 Iteration 218/960] TRAIN loss:  1.160\n",
      "[epoch 2 Iteration 219/960] TRAIN loss:  1.079\n",
      "[epoch 2 Iteration 220/960] TRAIN loss:  1.145\n",
      "[epoch 2 Iteration 221/960] TRAIN loss:  1.209\n",
      "[epoch 2 Iteration 222/960] TRAIN loss:  1.257\n",
      "[epoch 2 Iteration 223/960] TRAIN loss:  1.022\n",
      "[epoch 2 Iteration 224/960] TRAIN loss:  1.183\n",
      "[epoch 2 Iteration 225/960] TRAIN loss:  1.098\n",
      "[epoch 2 Iteration 226/960] TRAIN loss:  1.390\n",
      "[epoch 2 Iteration 227/960] TRAIN loss:  0.918\n",
      "[epoch 2 Iteration 228/960] TRAIN loss:  1.174\n",
      "[epoch 2 Iteration 229/960] TRAIN loss:  1.141\n",
      "[epoch 2 Iteration 230/960] TRAIN loss:  1.383\n",
      "[epoch 2 Iteration 231/960] TRAIN loss:  1.216\n",
      "[epoch 2 Iteration 232/960] TRAIN loss:  1.093\n",
      "[epoch 2 Iteration 233/960] TRAIN loss:  0.848\n",
      "[epoch 2 Iteration 234/960] TRAIN loss:  1.103\n",
      "[epoch 2 Iteration 235/960] TRAIN loss:  1.167\n",
      "[epoch 2 Iteration 236/960] TRAIN loss:  1.239\n",
      "[epoch 2 Iteration 237/960] TRAIN loss:  0.859\n",
      "[epoch 2 Iteration 238/960] TRAIN loss:  1.094\n",
      "[epoch 2 Iteration 239/960] TRAIN loss:  0.890\n",
      "[epoch 2 Iteration 240/960] TRAIN loss:  0.918\n",
      "[epoch 2 Iteration 241/960] TRAIN loss:  1.127\n",
      "[epoch 2 Iteration 242/960] TRAIN loss:  1.319\n",
      "[epoch 2 Iteration 243/960] TRAIN loss:  1.169\n",
      "[epoch 2 Iteration 244/960] TRAIN loss:  1.094\n",
      "[epoch 2 Iteration 245/960] TRAIN loss:  1.293\n",
      "[epoch 2 Iteration 246/960] TRAIN loss:  1.200\n",
      "[epoch 2 Iteration 247/960] TRAIN loss:  1.124\n",
      "[epoch 2 Iteration 248/960] TRAIN loss:  1.069\n",
      "[epoch 2 Iteration 249/960] TRAIN loss:  1.105\n",
      "[epoch 2 Iteration 250/960] TRAIN loss:  1.102\n",
      "[epoch 2 Iteration 251/960] TRAIN loss:  0.953\n",
      "[epoch 2 Iteration 252/960] TRAIN loss:  1.080\n",
      "[epoch 2 Iteration 253/960] TRAIN loss:  1.202\n",
      "[epoch 2 Iteration 254/960] TRAIN loss:  0.959\n",
      "[epoch 2 Iteration 255/960] TRAIN loss:  1.136\n",
      "[epoch 2 Iteration 256/960] TRAIN loss:  1.067\n",
      "[epoch 2 Iteration 257/960] TRAIN loss:  1.145\n",
      "[epoch 2 Iteration 258/960] TRAIN loss:  1.210\n",
      "[epoch 2 Iteration 259/960] TRAIN loss:  1.123\n",
      "[epoch 2 Iteration 260/960] TRAIN loss:  1.119\n",
      "[epoch 2 Iteration 261/960] TRAIN loss:  1.251\n",
      "[epoch 2 Iteration 262/960] TRAIN loss:  1.163\n",
      "[epoch 2 Iteration 263/960] TRAIN loss:  1.273\n",
      "[epoch 2 Iteration 264/960] TRAIN loss:  1.602\n",
      "[epoch 2 Iteration 265/960] TRAIN loss:  1.415\n",
      "[epoch 2 Iteration 266/960] TRAIN loss:  1.064\n",
      "[epoch 2 Iteration 267/960] TRAIN loss:  1.483\n",
      "[epoch 2 Iteration 268/960] TRAIN loss:  1.270\n",
      "[epoch 2 Iteration 269/960] TRAIN loss:  1.159\n",
      "[epoch 2 Iteration 270/960] TRAIN loss:  1.149\n",
      "[epoch 2 Iteration 271/960] TRAIN loss:  1.061\n",
      "[epoch 2 Iteration 272/960] TRAIN loss:  1.093\n",
      "[epoch 2 Iteration 273/960] TRAIN loss:  0.967\n",
      "[epoch 2 Iteration 274/960] TRAIN loss:  0.823\n",
      "[epoch 2 Iteration 275/960] TRAIN loss:  0.962\n",
      "[epoch 2 Iteration 276/960] TRAIN loss:  0.980\n",
      "[epoch 2 Iteration 277/960] TRAIN loss:  1.145\n",
      "[epoch 2 Iteration 278/960] TRAIN loss:  1.246\n",
      "[epoch 2 Iteration 279/960] TRAIN loss:  1.157\n",
      "[epoch 2 Iteration 280/960] TRAIN loss:  1.096\n",
      "[epoch 2 Iteration 281/960] TRAIN loss:  1.209\n",
      "[epoch 2 Iteration 282/960] TRAIN loss:  0.994\n",
      "[epoch 2 Iteration 283/960] TRAIN loss:  1.172\n",
      "[epoch 2 Iteration 284/960] TRAIN loss:  1.202\n",
      "[epoch 2 Iteration 285/960] TRAIN loss:  0.965\n",
      "[epoch 2 Iteration 286/960] TRAIN loss:  1.181\n",
      "[epoch 2 Iteration 287/960] TRAIN loss:  1.422\n",
      "[epoch 2 Iteration 288/960] TRAIN loss:  0.825\n",
      "[epoch 2 Iteration 289/960] TRAIN loss:  1.388\n",
      "[epoch 2 Iteration 290/960] TRAIN loss:  1.260\n",
      "[epoch 2 Iteration 291/960] TRAIN loss:  1.180\n",
      "[epoch 2 Iteration 292/960] TRAIN loss:  1.027\n",
      "[epoch 2 Iteration 293/960] TRAIN loss:  1.074\n",
      "[epoch 2 Iteration 294/960] TRAIN loss:  1.531\n",
      "[epoch 2 Iteration 295/960] TRAIN loss:  1.021\n",
      "[epoch 2 Iteration 296/960] TRAIN loss:  1.130\n",
      "[epoch 2 Iteration 297/960] TRAIN loss:  1.312\n",
      "[epoch 2 Iteration 298/960] TRAIN loss:  1.304\n",
      "[epoch 2 Iteration 299/960] TRAIN loss:  1.143\n",
      "[epoch 2 Iteration 300/960] TRAIN loss:  1.093\n",
      "[epoch 2 Iteration 301/960] TRAIN loss:  1.339\n",
      "[epoch 2 Iteration 302/960] TRAIN loss:  1.079\n",
      "[epoch 2 Iteration 303/960] TRAIN loss:  1.312\n",
      "[epoch 2 Iteration 304/960] TRAIN loss:  1.321\n",
      "[epoch 2 Iteration 305/960] TRAIN loss:  1.093\n",
      "[epoch 2 Iteration 306/960] TRAIN loss:  1.136\n",
      "[epoch 2 Iteration 307/960] TRAIN loss:  1.376\n",
      "[epoch 2 Iteration 308/960] TRAIN loss:  1.102\n",
      "[epoch 2 Iteration 309/960] TRAIN loss:  0.972\n",
      "[epoch 2 Iteration 310/960] TRAIN loss:  0.946\n",
      "[epoch 2 Iteration 311/960] TRAIN loss:  1.132\n",
      "[epoch 2 Iteration 312/960] TRAIN loss:  1.154\n",
      "[epoch 2 Iteration 313/960] TRAIN loss:  1.182\n",
      "[epoch 2 Iteration 314/960] TRAIN loss:  1.002\n",
      "[epoch 2 Iteration 315/960] TRAIN loss:  1.260\n",
      "[epoch 2 Iteration 316/960] TRAIN loss:  0.954\n",
      "[epoch 2 Iteration 317/960] TRAIN loss:  0.913\n",
      "[epoch 2 Iteration 318/960] TRAIN loss:  1.380\n",
      "[epoch 2 Iteration 319/960] TRAIN loss:  1.149\n",
      "[epoch 2 Iteration 320/960] TRAIN loss:  1.235\n",
      "[epoch 2 Iteration 321/960] TRAIN loss:  1.188\n",
      "[epoch 2 Iteration 322/960] TRAIN loss:  0.989\n",
      "[epoch 2 Iteration 323/960] TRAIN loss:  1.100\n",
      "[epoch 2 Iteration 324/960] TRAIN loss:  1.324\n",
      "[epoch 2 Iteration 325/960] TRAIN loss:  0.861\n",
      "[epoch 2 Iteration 326/960] TRAIN loss:  0.992\n",
      "[epoch 2 Iteration 327/960] TRAIN loss:  1.200\n",
      "[epoch 2 Iteration 328/960] TRAIN loss:  1.204\n",
      "[epoch 2 Iteration 329/960] TRAIN loss:  1.427\n",
      "[epoch 2 Iteration 330/960] TRAIN loss:  0.945\n",
      "[epoch 2 Iteration 331/960] TRAIN loss:  1.443\n",
      "[epoch 2 Iteration 332/960] TRAIN loss:  1.151\n",
      "[epoch 2 Iteration 333/960] TRAIN loss:  1.176\n",
      "[epoch 2 Iteration 334/960] TRAIN loss:  1.067\n",
      "[epoch 2 Iteration 335/960] TRAIN loss:  0.851\n",
      "[epoch 2 Iteration 336/960] TRAIN loss:  0.849\n",
      "[epoch 2 Iteration 337/960] TRAIN loss:  1.123\n",
      "[epoch 2 Iteration 338/960] TRAIN loss:  1.167\n",
      "[epoch 2 Iteration 339/960] TRAIN loss:  1.036\n",
      "[epoch 2 Iteration 340/960] TRAIN loss:  1.135\n",
      "[epoch 2 Iteration 341/960] TRAIN loss:  1.275\n",
      "[epoch 2 Iteration 342/960] TRAIN loss:  1.253\n",
      "[epoch 2 Iteration 343/960] TRAIN loss:  0.971\n",
      "[epoch 2 Iteration 344/960] TRAIN loss:  0.954\n",
      "[epoch 2 Iteration 345/960] TRAIN loss:  1.224\n",
      "[epoch 2 Iteration 346/960] TRAIN loss:  0.910\n",
      "[epoch 2 Iteration 347/960] TRAIN loss:  1.040\n",
      "[epoch 2 Iteration 348/960] TRAIN loss:  1.046\n",
      "[epoch 2 Iteration 349/960] TRAIN loss:  1.142\n",
      "[epoch 2 Iteration 350/960] TRAIN loss:  1.254\n",
      "[epoch 2 Iteration 351/960] TRAIN loss:  1.279\n",
      "[epoch 2 Iteration 352/960] TRAIN loss:  1.263\n",
      "[epoch 2 Iteration 353/960] TRAIN loss:  1.016\n",
      "[epoch 2 Iteration 354/960] TRAIN loss:  1.077\n",
      "[epoch 2 Iteration 355/960] TRAIN loss:  1.119\n",
      "[epoch 2 Iteration 356/960] TRAIN loss:  1.062\n",
      "[epoch 2 Iteration 357/960] TRAIN loss:  1.109\n",
      "[epoch 2 Iteration 358/960] TRAIN loss:  1.091\n",
      "[epoch 2 Iteration 359/960] TRAIN loss:  1.043\n",
      "[epoch 2 Iteration 360/960] TRAIN loss:  1.166\n",
      "[epoch 2 Iteration 361/960] TRAIN loss:  1.122\n",
      "[epoch 2 Iteration 362/960] TRAIN loss:  1.109\n",
      "[epoch 2 Iteration 363/960] TRAIN loss:  0.974\n",
      "[epoch 2 Iteration 364/960] TRAIN loss:  1.028\n",
      "[epoch 2 Iteration 365/960] TRAIN loss:  1.328\n",
      "[epoch 2 Iteration 366/960] TRAIN loss:  0.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2 Iteration 367/960] TRAIN loss:  1.394\n",
      "[epoch 2 Iteration 368/960] TRAIN loss:  1.251\n",
      "[epoch 2 Iteration 369/960] TRAIN loss:  0.913\n",
      "[epoch 2 Iteration 370/960] TRAIN loss:  1.069\n",
      "[epoch 2 Iteration 371/960] TRAIN loss:  1.338\n",
      "[epoch 2 Iteration 372/960] TRAIN loss:  0.898\n",
      "[epoch 2 Iteration 373/960] TRAIN loss:  1.186\n",
      "[epoch 2 Iteration 374/960] TRAIN loss:  1.281\n",
      "[epoch 2 Iteration 375/960] TRAIN loss:  1.007\n",
      "[epoch 2 Iteration 376/960] TRAIN loss:  1.124\n",
      "[epoch 2 Iteration 377/960] TRAIN loss:  0.980\n",
      "[epoch 2 Iteration 378/960] TRAIN loss:  0.977\n",
      "[epoch 2 Iteration 379/960] TRAIN loss:  1.625\n",
      "[epoch 2 Iteration 380/960] TRAIN loss:  1.038\n",
      "[epoch 2 Iteration 381/960] TRAIN loss:  1.189\n",
      "[epoch 2 Iteration 382/960] TRAIN loss:  1.116\n",
      "[epoch 2 Iteration 383/960] TRAIN loss:  1.091\n",
      "[epoch 2 Iteration 384/960] TRAIN loss:  1.141\n",
      "[epoch 2 Iteration 385/960] TRAIN loss:  1.209\n",
      "[epoch 2 Iteration 386/960] TRAIN loss:  1.364\n",
      "[epoch 2 Iteration 387/960] TRAIN loss:  1.217\n",
      "[epoch 2 Iteration 388/960] TRAIN loss:  1.178\n",
      "[epoch 2 Iteration 389/960] TRAIN loss:  1.410\n",
      "[epoch 2 Iteration 390/960] TRAIN loss:  1.062\n",
      "[epoch 2 Iteration 391/960] TRAIN loss:  1.345\n",
      "[epoch 2 Iteration 392/960] TRAIN loss:  1.122\n",
      "[epoch 2 Iteration 393/960] TRAIN loss:  1.143\n",
      "[epoch 2 Iteration 394/960] TRAIN loss:  0.959\n",
      "[epoch 2 Iteration 395/960] TRAIN loss:  1.087\n",
      "[epoch 2 Iteration 396/960] TRAIN loss:  0.957\n",
      "[epoch 2 Iteration 397/960] TRAIN loss:  1.093\n",
      "[epoch 2 Iteration 398/960] TRAIN loss:  1.104\n",
      "[epoch 2 Iteration 399/960] TRAIN loss:  1.175\n",
      "[epoch 2 Iteration 400/960] TRAIN loss:  1.082\n",
      "[epoch 2 Iteration 401/960] TRAIN loss:  1.098\n",
      "[epoch 2 Iteration 402/960] TRAIN loss:  1.174\n",
      "[epoch 2 Iteration 403/960] TRAIN loss:  1.098\n",
      "[epoch 2 Iteration 404/960] TRAIN loss:  1.148\n",
      "[epoch 2 Iteration 405/960] TRAIN loss:  1.024\n",
      "[epoch 2 Iteration 406/960] TRAIN loss:  0.885\n",
      "[epoch 2 Iteration 407/960] TRAIN loss:  1.247\n",
      "[epoch 2 Iteration 408/960] TRAIN loss:  1.191\n",
      "[epoch 2 Iteration 409/960] TRAIN loss:  1.133\n",
      "[epoch 2 Iteration 410/960] TRAIN loss:  0.908\n",
      "[epoch 2 Iteration 411/960] TRAIN loss:  1.257\n",
      "[epoch 2 Iteration 412/960] TRAIN loss:  1.076\n",
      "[epoch 2 Iteration 413/960] TRAIN loss:  0.918\n",
      "[epoch 2 Iteration 414/960] TRAIN loss:  1.340\n",
      "[epoch 2 Iteration 415/960] TRAIN loss:  0.983\n",
      "[epoch 2 Iteration 416/960] TRAIN loss:  1.069\n",
      "[epoch 2 Iteration 417/960] TRAIN loss:  1.072\n",
      "[epoch 2 Iteration 418/960] TRAIN loss:  1.013\n",
      "[epoch 2 Iteration 419/960] TRAIN loss:  1.124\n",
      "[epoch 2 Iteration 420/960] TRAIN loss:  1.419\n",
      "[epoch 2 Iteration 421/960] TRAIN loss:  1.081\n",
      "[epoch 2 Iteration 422/960] TRAIN loss:  1.028\n",
      "[epoch 2 Iteration 423/960] TRAIN loss:  1.144\n",
      "[epoch 2 Iteration 424/960] TRAIN loss:  1.142\n",
      "[epoch 2 Iteration 425/960] TRAIN loss:  1.034\n",
      "[epoch 2 Iteration 426/960] TRAIN loss:  1.252\n",
      "[epoch 2 Iteration 427/960] TRAIN loss:  1.180\n",
      "[epoch 2 Iteration 428/960] TRAIN loss:  1.245\n",
      "[epoch 2 Iteration 429/960] TRAIN loss:  0.839\n",
      "[epoch 2 Iteration 430/960] TRAIN loss:  1.090\n",
      "[epoch 2 Iteration 431/960] TRAIN loss:  1.637\n",
      "[epoch 2 Iteration 432/960] TRAIN loss:  1.010\n",
      "[epoch 2 Iteration 433/960] TRAIN loss:  1.412\n",
      "[epoch 2 Iteration 434/960] TRAIN loss:  0.964\n",
      "[epoch 2 Iteration 435/960] TRAIN loss:  1.001\n",
      "[epoch 2 Iteration 436/960] TRAIN loss:  0.894\n",
      "[epoch 2 Iteration 437/960] TRAIN loss:  1.201\n",
      "[epoch 2 Iteration 438/960] TRAIN loss:  1.023\n",
      "[epoch 2 Iteration 439/960] TRAIN loss:  1.029\n",
      "[epoch 2 Iteration 440/960] TRAIN loss:  1.041\n",
      "[epoch 2 Iteration 441/960] TRAIN loss:  1.346\n",
      "[epoch 2 Iteration 442/960] TRAIN loss:  1.054\n",
      "[epoch 2 Iteration 443/960] TRAIN loss:  1.142\n",
      "[epoch 2 Iteration 444/960] TRAIN loss:  1.018\n",
      "[epoch 2 Iteration 445/960] TRAIN loss:  1.195\n",
      "[epoch 2 Iteration 446/960] TRAIN loss:  1.233\n",
      "[epoch 2 Iteration 447/960] TRAIN loss:  0.977\n",
      "[epoch 2 Iteration 448/960] TRAIN loss:  1.233\n",
      "[epoch 2 Iteration 449/960] TRAIN loss:  1.071\n",
      "[epoch 2 Iteration 450/960] TRAIN loss:  1.387\n",
      "[epoch 2 Iteration 451/960] TRAIN loss:  1.143\n",
      "[epoch 2 Iteration 452/960] TRAIN loss:  1.361\n",
      "[epoch 2 Iteration 453/960] TRAIN loss:  1.194\n",
      "[epoch 2 Iteration 454/960] TRAIN loss:  1.222\n",
      "[epoch 2 Iteration 455/960] TRAIN loss:  1.215\n",
      "[epoch 2 Iteration 456/960] TRAIN loss:  1.022\n",
      "[epoch 2 Iteration 457/960] TRAIN loss:  1.227\n",
      "[epoch 2 Iteration 458/960] TRAIN loss:  1.115\n",
      "[epoch 2 Iteration 459/960] TRAIN loss:  1.280\n",
      "[epoch 2 Iteration 460/960] TRAIN loss:  1.148\n",
      "[epoch 2 Iteration 461/960] TRAIN loss:  1.283\n",
      "[epoch 2 Iteration 462/960] TRAIN loss:  1.211\n",
      "[epoch 2 Iteration 463/960] TRAIN loss:  1.383\n",
      "[epoch 2 Iteration 464/960] TRAIN loss:  1.056\n",
      "[epoch 2 Iteration 465/960] TRAIN loss:  1.169\n",
      "[epoch 2 Iteration 466/960] TRAIN loss:  1.101\n",
      "[epoch 2 Iteration 467/960] TRAIN loss:  1.311\n",
      "[epoch 2 Iteration 468/960] TRAIN loss:  0.848\n",
      "[epoch 2 Iteration 469/960] TRAIN loss:  1.025\n",
      "[epoch 2 Iteration 470/960] TRAIN loss:  1.027\n",
      "[epoch 2 Iteration 471/960] TRAIN loss:  1.296\n",
      "[epoch 2 Iteration 472/960] TRAIN loss:  0.792\n",
      "[epoch 2 Iteration 473/960] TRAIN loss:  1.285\n",
      "[epoch 2 Iteration 474/960] TRAIN loss:  1.171\n",
      "[epoch 2 Iteration 475/960] TRAIN loss:  1.095\n",
      "[epoch 2 Iteration 476/960] TRAIN loss:  1.223\n",
      "[epoch 2 Iteration 477/960] TRAIN loss:  1.200\n",
      "[epoch 2 Iteration 478/960] TRAIN loss:  1.008\n",
      "[epoch 2 Iteration 479/960] TRAIN loss:  1.183\n",
      "[epoch 2 Iteration 480/960] TRAIN loss:  1.377\n",
      "[epoch 2 Iteration 481/960] TRAIN loss:  1.074\n",
      "[epoch 2 Iteration 482/960] TRAIN loss:  1.272\n",
      "[epoch 2 Iteration 483/960] TRAIN loss:  1.069\n",
      "[epoch 2 Iteration 484/960] TRAIN loss:  1.428\n",
      "[epoch 2 Iteration 485/960] TRAIN loss:  1.023\n",
      "[epoch 2 Iteration 486/960] TRAIN loss:  1.094\n",
      "[epoch 2 Iteration 487/960] TRAIN loss:  0.957\n",
      "[epoch 2 Iteration 488/960] TRAIN loss:  1.007\n",
      "[epoch 2 Iteration 489/960] TRAIN loss:  1.210\n",
      "[epoch 2 Iteration 490/960] TRAIN loss:  1.258\n",
      "[epoch 2 Iteration 491/960] TRAIN loss:  1.196\n",
      "[epoch 2 Iteration 492/960] TRAIN loss:  1.088\n",
      "[epoch 2 Iteration 493/960] TRAIN loss:  1.145\n",
      "[epoch 2 Iteration 494/960] TRAIN loss:  1.160\n",
      "[epoch 2 Iteration 495/960] TRAIN loss:  1.086\n",
      "[epoch 2 Iteration 496/960] TRAIN loss:  1.170\n",
      "[epoch 2 Iteration 497/960] TRAIN loss:  1.185\n",
      "[epoch 2 Iteration 498/960] TRAIN loss:  1.094\n",
      "[epoch 2 Iteration 499/960] TRAIN loss:  1.147\n",
      "[epoch 2 Iteration 500/960] TRAIN loss:  1.228\n",
      "[epoch 2 Iteration 501/960] TRAIN loss:  1.240\n",
      "[epoch 2 Iteration 502/960] TRAIN loss:  1.252\n",
      "[epoch 2 Iteration 503/960] TRAIN loss:  1.251\n",
      "[epoch 2 Iteration 504/960] TRAIN loss:  1.156\n",
      "[epoch 2 Iteration 505/960] TRAIN loss:  1.211\n",
      "[epoch 2 Iteration 506/960] TRAIN loss:  0.944\n",
      "[epoch 2 Iteration 507/960] TRAIN loss:  1.010\n",
      "[epoch 2 Iteration 508/960] TRAIN loss:  1.240\n",
      "[epoch 2 Iteration 509/960] TRAIN loss:  0.904\n",
      "[epoch 2 Iteration 510/960] TRAIN loss:  1.215\n",
      "[epoch 2 Iteration 511/960] TRAIN loss:  1.458\n",
      "[epoch 2 Iteration 512/960] TRAIN loss:  1.073\n",
      "[epoch 2 Iteration 513/960] TRAIN loss:  1.231\n",
      "[epoch 2 Iteration 514/960] TRAIN loss:  1.077\n",
      "[epoch 2 Iteration 515/960] TRAIN loss:  1.082\n",
      "[epoch 2 Iteration 516/960] TRAIN loss:  0.997\n",
      "[epoch 2 Iteration 517/960] TRAIN loss:  1.038\n",
      "[epoch 2 Iteration 518/960] TRAIN loss:  1.330\n",
      "[epoch 2 Iteration 519/960] TRAIN loss:  1.215\n",
      "[epoch 2 Iteration 520/960] TRAIN loss:  1.091\n",
      "[epoch 2 Iteration 521/960] TRAIN loss:  1.105\n",
      "[epoch 2 Iteration 522/960] TRAIN loss:  1.126\n",
      "[epoch 2 Iteration 523/960] TRAIN loss:  1.162\n",
      "[epoch 2 Iteration 524/960] TRAIN loss:  1.154\n",
      "[epoch 2 Iteration 525/960] TRAIN loss:  1.333\n",
      "[epoch 2 Iteration 526/960] TRAIN loss:  1.228\n",
      "[epoch 2 Iteration 527/960] TRAIN loss:  1.203\n",
      "[epoch 2 Iteration 528/960] TRAIN loss:  1.432\n",
      "[epoch 2 Iteration 529/960] TRAIN loss:  1.148\n",
      "[epoch 2 Iteration 530/960] TRAIN loss:  1.272\n",
      "[epoch 2 Iteration 531/960] TRAIN loss:  1.087\n",
      "[epoch 2 Iteration 532/960] TRAIN loss:  1.032\n",
      "[epoch 2 Iteration 533/960] TRAIN loss:  0.852\n",
      "[epoch 2 Iteration 534/960] TRAIN loss:  1.177\n",
      "[epoch 2 Iteration 535/960] TRAIN loss:  1.227\n",
      "[epoch 2 Iteration 536/960] TRAIN loss:  1.390\n",
      "[epoch 2 Iteration 537/960] TRAIN loss:  1.015\n",
      "[epoch 2 Iteration 538/960] TRAIN loss:  1.250\n",
      "[epoch 2 Iteration 539/960] TRAIN loss:  1.465\n",
      "[epoch 2 Iteration 540/960] TRAIN loss:  1.076\n",
      "[epoch 2 Iteration 541/960] TRAIN loss:  0.967\n",
      "[epoch 2 Iteration 542/960] TRAIN loss:  0.845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2 Iteration 543/960] TRAIN loss:  1.018\n",
      "[epoch 2 Iteration 544/960] TRAIN loss:  1.344\n",
      "[epoch 2 Iteration 545/960] TRAIN loss:  1.057\n",
      "[epoch 2 Iteration 546/960] TRAIN loss:  1.377\n",
      "[epoch 2 Iteration 547/960] TRAIN loss:  1.448\n",
      "[epoch 2 Iteration 548/960] TRAIN loss:  1.520\n",
      "[epoch 2 Iteration 549/960] TRAIN loss:  1.345\n",
      "[epoch 2 Iteration 550/960] TRAIN loss:  0.893\n",
      "[epoch 2 Iteration 551/960] TRAIN loss:  1.419\n",
      "[epoch 2 Iteration 552/960] TRAIN loss:  1.427\n",
      "[epoch 2 Iteration 553/960] TRAIN loss:  1.080\n",
      "[epoch 2 Iteration 554/960] TRAIN loss:  1.041\n",
      "[epoch 2 Iteration 555/960] TRAIN loss:  0.921\n",
      "[epoch 2 Iteration 556/960] TRAIN loss:  1.318\n",
      "[epoch 2 Iteration 557/960] TRAIN loss:  1.024\n",
      "[epoch 2 Iteration 558/960] TRAIN loss:  1.097\n",
      "[epoch 2 Iteration 559/960] TRAIN loss:  1.036\n",
      "[epoch 2 Iteration 560/960] TRAIN loss:  0.885\n",
      "[epoch 2 Iteration 561/960] TRAIN loss:  0.949\n",
      "[epoch 2 Iteration 562/960] TRAIN loss:  1.159\n",
      "[epoch 2 Iteration 563/960] TRAIN loss:  1.174\n",
      "[epoch 2 Iteration 564/960] TRAIN loss:  1.161\n",
      "[epoch 2 Iteration 565/960] TRAIN loss:  1.204\n",
      "[epoch 2 Iteration 566/960] TRAIN loss:  1.032\n",
      "[epoch 2 Iteration 567/960] TRAIN loss:  1.065\n",
      "[epoch 2 Iteration 568/960] TRAIN loss:  1.213\n",
      "[epoch 2 Iteration 569/960] TRAIN loss:  1.175\n",
      "[epoch 2 Iteration 570/960] TRAIN loss:  1.152\n",
      "[epoch 2 Iteration 571/960] TRAIN loss:  0.885\n",
      "[epoch 2 Iteration 572/960] TRAIN loss:  1.282\n",
      "[epoch 2 Iteration 573/960] TRAIN loss:  1.058\n",
      "[epoch 2 Iteration 574/960] TRAIN loss:  1.108\n",
      "[epoch 2 Iteration 575/960] TRAIN loss:  1.341\n",
      "[epoch 2 Iteration 576/960] TRAIN loss:  1.343\n",
      "[epoch 2 Iteration 577/960] TRAIN loss:  1.171\n",
      "[epoch 2 Iteration 578/960] TRAIN loss:  1.355\n",
      "[epoch 2 Iteration 579/960] TRAIN loss:  1.436\n",
      "[epoch 2 Iteration 580/960] TRAIN loss:  1.076\n",
      "[epoch 2 Iteration 581/960] TRAIN loss:  1.409\n",
      "[epoch 2 Iteration 582/960] TRAIN loss:  1.339\n",
      "[epoch 2 Iteration 583/960] TRAIN loss:  0.949\n",
      "[epoch 2 Iteration 584/960] TRAIN loss:  1.368\n",
      "[epoch 2 Iteration 585/960] TRAIN loss:  1.017\n",
      "[epoch 2 Iteration 586/960] TRAIN loss:  1.081\n",
      "[epoch 2 Iteration 587/960] TRAIN loss:  1.069\n",
      "[epoch 2 Iteration 588/960] TRAIN loss:  1.129\n",
      "[epoch 2 Iteration 589/960] TRAIN loss:  1.335\n",
      "[epoch 2 Iteration 590/960] TRAIN loss:  0.965\n",
      "[epoch 2 Iteration 591/960] TRAIN loss:  1.124\n",
      "[epoch 2 Iteration 592/960] TRAIN loss:  1.269\n",
      "[epoch 2 Iteration 593/960] TRAIN loss:  1.021\n",
      "[epoch 2 Iteration 594/960] TRAIN loss:  1.139\n",
      "[epoch 2 Iteration 595/960] TRAIN loss:  0.938\n",
      "[epoch 2 Iteration 596/960] TRAIN loss:  1.329\n",
      "[epoch 2 Iteration 597/960] TRAIN loss:  1.106\n",
      "[epoch 2 Iteration 598/960] TRAIN loss:  1.130\n",
      "[epoch 2 Iteration 599/960] TRAIN loss:  1.122\n",
      "[epoch 2 Iteration 600/960] TRAIN loss:  1.008\n",
      "[epoch 2 Iteration 601/960] TRAIN loss:  1.137\n",
      "[epoch 2 Iteration 602/960] TRAIN loss:  0.946\n",
      "[epoch 2 Iteration 603/960] TRAIN loss:  1.020\n",
      "[epoch 2 Iteration 604/960] TRAIN loss:  0.863\n",
      "[epoch 2 Iteration 605/960] TRAIN loss:  1.122\n",
      "[epoch 2 Iteration 606/960] TRAIN loss:  0.887\n",
      "[epoch 2 Iteration 607/960] TRAIN loss:  1.151\n",
      "[epoch 2 Iteration 608/960] TRAIN loss:  0.949\n",
      "[epoch 2 Iteration 609/960] TRAIN loss:  1.161\n",
      "[epoch 2 Iteration 610/960] TRAIN loss:  1.154\n",
      "[epoch 2 Iteration 611/960] TRAIN loss:  1.127\n",
      "[epoch 2 Iteration 612/960] TRAIN loss:  1.105\n",
      "[epoch 2 Iteration 613/960] TRAIN loss:  1.280\n",
      "[epoch 2 Iteration 614/960] TRAIN loss:  1.157\n",
      "[epoch 2 Iteration 615/960] TRAIN loss:  1.174\n",
      "[epoch 2 Iteration 616/960] TRAIN loss:  1.094\n",
      "[epoch 2 Iteration 617/960] TRAIN loss:  1.048\n",
      "[epoch 2 Iteration 618/960] TRAIN loss:  1.143\n",
      "[epoch 2 Iteration 619/960] TRAIN loss:  0.999\n",
      "[epoch 2 Iteration 620/960] TRAIN loss:  1.108\n",
      "[epoch 2 Iteration 621/960] TRAIN loss:  1.234\n",
      "[epoch 2 Iteration 622/960] TRAIN loss:  1.122\n",
      "[epoch 2 Iteration 623/960] TRAIN loss:  1.260\n",
      "[epoch 2 Iteration 624/960] TRAIN loss:  1.115\n",
      "[epoch 2 Iteration 625/960] TRAIN loss:  1.190\n",
      "[epoch 2 Iteration 626/960] TRAIN loss:  1.303\n",
      "[epoch 2 Iteration 627/960] TRAIN loss:  1.167\n",
      "[epoch 2 Iteration 628/960] TRAIN loss:  1.243\n",
      "[epoch 2 Iteration 629/960] TRAIN loss:  1.083\n",
      "[epoch 2 Iteration 630/960] TRAIN loss:  1.139\n",
      "[epoch 2 Iteration 631/960] TRAIN loss:  1.174\n",
      "[epoch 2 Iteration 632/960] TRAIN loss:  1.034\n",
      "[epoch 2 Iteration 633/960] TRAIN loss:  1.281\n",
      "[epoch 2 Iteration 634/960] TRAIN loss:  1.233\n",
      "[epoch 2 Iteration 635/960] TRAIN loss:  1.047\n",
      "[epoch 2 Iteration 636/960] TRAIN loss:  1.263\n",
      "[epoch 2 Iteration 637/960] TRAIN loss:  1.036\n",
      "[epoch 2 Iteration 638/960] TRAIN loss:  1.237\n",
      "[epoch 2 Iteration 639/960] TRAIN loss:  1.430\n",
      "[epoch 2 Iteration 640/960] TRAIN loss:  1.031\n",
      "[epoch 2 Iteration 641/960] TRAIN loss:  0.901\n",
      "[epoch 2 Iteration 642/960] TRAIN loss:  1.205\n",
      "[epoch 2 Iteration 643/960] TRAIN loss:  1.343\n",
      "[epoch 2 Iteration 644/960] TRAIN loss:  1.372\n",
      "[epoch 2 Iteration 645/960] TRAIN loss:  1.179\n",
      "[epoch 2 Iteration 646/960] TRAIN loss:  1.343\n",
      "[epoch 2 Iteration 647/960] TRAIN loss:  1.143\n",
      "[epoch 2 Iteration 648/960] TRAIN loss:  1.192\n",
      "[epoch 2 Iteration 649/960] TRAIN loss:  1.212\n",
      "[epoch 2 Iteration 650/960] TRAIN loss:  1.188\n",
      "[epoch 2 Iteration 651/960] TRAIN loss:  1.484\n",
      "[epoch 2 Iteration 652/960] TRAIN loss:  1.196\n",
      "[epoch 2 Iteration 653/960] TRAIN loss:  1.177\n",
      "[epoch 2 Iteration 654/960] TRAIN loss:  1.219\n",
      "[epoch 2 Iteration 655/960] TRAIN loss:  1.109\n",
      "[epoch 2 Iteration 656/960] TRAIN loss:  1.338\n",
      "[epoch 2 Iteration 657/960] TRAIN loss:  1.276\n",
      "[epoch 2 Iteration 658/960] TRAIN loss:  0.937\n",
      "[epoch 2 Iteration 659/960] TRAIN loss:  1.174\n",
      "[epoch 2 Iteration 660/960] TRAIN loss:  1.147\n",
      "[epoch 2 Iteration 661/960] TRAIN loss:  1.288\n",
      "[epoch 2 Iteration 662/960] TRAIN loss:  1.394\n",
      "[epoch 2 Iteration 663/960] TRAIN loss:  1.240\n",
      "[epoch 2 Iteration 664/960] TRAIN loss:  1.152\n",
      "[epoch 2 Iteration 665/960] TRAIN loss:  1.255\n",
      "[epoch 2 Iteration 666/960] TRAIN loss:  0.995\n",
      "[epoch 2 Iteration 667/960] TRAIN loss:  0.984\n",
      "[epoch 2 Iteration 668/960] TRAIN loss:  1.170\n",
      "[epoch 2 Iteration 669/960] TRAIN loss:  1.035\n",
      "[epoch 2 Iteration 670/960] TRAIN loss:  1.192\n",
      "[epoch 2 Iteration 671/960] TRAIN loss:  1.432\n",
      "[epoch 2 Iteration 672/960] TRAIN loss:  1.168\n",
      "[epoch 2 Iteration 673/960] TRAIN loss:  0.933\n",
      "[epoch 2 Iteration 674/960] TRAIN loss:  1.277\n",
      "[epoch 2 Iteration 675/960] TRAIN loss:  1.434\n",
      "[epoch 2 Iteration 676/960] TRAIN loss:  0.849\n",
      "[epoch 2 Iteration 677/960] TRAIN loss:  1.165\n",
      "[epoch 2 Iteration 678/960] TRAIN loss:  1.177\n",
      "[epoch 2 Iteration 679/960] TRAIN loss:  1.184\n",
      "[epoch 2 Iteration 680/960] TRAIN loss:  1.258\n",
      "[epoch 2 Iteration 681/960] TRAIN loss:  0.940\n",
      "[epoch 2 Iteration 682/960] TRAIN loss:  1.161\n",
      "[epoch 2 Iteration 683/960] TRAIN loss:  1.032\n",
      "[epoch 2 Iteration 684/960] TRAIN loss:  1.355\n",
      "[epoch 2 Iteration 685/960] TRAIN loss:  1.121\n",
      "[epoch 2 Iteration 686/960] TRAIN loss:  0.931\n",
      "[epoch 2 Iteration 687/960] TRAIN loss:  1.055\n",
      "[epoch 2 Iteration 688/960] TRAIN loss:  1.058\n",
      "[epoch 2 Iteration 689/960] TRAIN loss:  0.915\n",
      "[epoch 2 Iteration 690/960] TRAIN loss:  1.229\n",
      "[epoch 2 Iteration 691/960] TRAIN loss:  1.403\n",
      "[epoch 2 Iteration 692/960] TRAIN loss:  0.966\n",
      "[epoch 2 Iteration 693/960] TRAIN loss:  1.016\n",
      "[epoch 2 Iteration 694/960] TRAIN loss:  1.098\n",
      "[epoch 2 Iteration 695/960] TRAIN loss:  0.988\n",
      "[epoch 2 Iteration 696/960] TRAIN loss:  1.026\n",
      "[epoch 2 Iteration 697/960] TRAIN loss:  1.005\n",
      "[epoch 2 Iteration 698/960] TRAIN loss:  1.243\n",
      "[epoch 2 Iteration 699/960] TRAIN loss:  1.344\n",
      "[epoch 2 Iteration 700/960] TRAIN loss:  1.115\n",
      "[epoch 2 Iteration 701/960] TRAIN loss:  1.214\n",
      "[epoch 2 Iteration 702/960] TRAIN loss:  1.174\n",
      "[epoch 2 Iteration 703/960] TRAIN loss:  0.918\n",
      "[epoch 2 Iteration 704/960] TRAIN loss:  1.361\n",
      "[epoch 2 Iteration 705/960] TRAIN loss:  1.232\n",
      "[epoch 2 Iteration 706/960] TRAIN loss:  1.283\n",
      "[epoch 2 Iteration 707/960] TRAIN loss:  1.512\n",
      "[epoch 2 Iteration 708/960] TRAIN loss:  1.330\n",
      "[epoch 2 Iteration 709/960] TRAIN loss:  1.210\n",
      "[epoch 2 Iteration 710/960] TRAIN loss:  1.131\n",
      "[epoch 2 Iteration 711/960] TRAIN loss:  1.236\n",
      "[epoch 2 Iteration 712/960] TRAIN loss:  1.010\n",
      "[epoch 2 Iteration 713/960] TRAIN loss:  1.036\n",
      "[epoch 2 Iteration 714/960] TRAIN loss:  1.113\n",
      "[epoch 2 Iteration 715/960] TRAIN loss:  1.320\n",
      "[epoch 2 Iteration 716/960] TRAIN loss:  1.019\n",
      "[epoch 2 Iteration 717/960] TRAIN loss:  1.052\n",
      "[epoch 2 Iteration 718/960] TRAIN loss:  1.436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2 Iteration 719/960] TRAIN loss:  1.153\n",
      "[epoch 2 Iteration 720/960] TRAIN loss:  1.004\n",
      "[epoch 2 Iteration 721/960] TRAIN loss:  1.213\n",
      "[epoch 2 Iteration 722/960] TRAIN loss:  1.217\n",
      "[epoch 2 Iteration 723/960] TRAIN loss:  1.319\n",
      "[epoch 2 Iteration 724/960] TRAIN loss:  1.043\n",
      "[epoch 2 Iteration 725/960] TRAIN loss:  1.184\n",
      "[epoch 2 Iteration 726/960] TRAIN loss:  1.090\n",
      "[epoch 2 Iteration 727/960] TRAIN loss:  1.195\n",
      "[epoch 2 Iteration 728/960] TRAIN loss:  1.304\n",
      "[epoch 2 Iteration 729/960] TRAIN loss:  1.158\n",
      "[epoch 2 Iteration 730/960] TRAIN loss:  0.905\n",
      "[epoch 2 Iteration 731/960] TRAIN loss:  1.203\n",
      "[epoch 2 Iteration 732/960] TRAIN loss:  1.234\n",
      "[epoch 2 Iteration 733/960] TRAIN loss:  0.914\n",
      "[epoch 2 Iteration 734/960] TRAIN loss:  1.067\n",
      "[epoch 2 Iteration 735/960] TRAIN loss:  1.393\n",
      "[epoch 2 Iteration 736/960] TRAIN loss:  1.439\n",
      "[epoch 2 Iteration 737/960] TRAIN loss:  1.112\n",
      "[epoch 2 Iteration 738/960] TRAIN loss:  1.045\n",
      "[epoch 2 Iteration 739/960] TRAIN loss:  1.247\n",
      "[epoch 2 Iteration 740/960] TRAIN loss:  1.154\n",
      "[epoch 2 Iteration 741/960] TRAIN loss:  1.047\n",
      "[epoch 2 Iteration 742/960] TRAIN loss:  1.184\n",
      "[epoch 2 Iteration 743/960] TRAIN loss:  1.113\n",
      "[epoch 2 Iteration 744/960] TRAIN loss:  1.164\n",
      "[epoch 2 Iteration 745/960] TRAIN loss:  0.951\n",
      "[epoch 2 Iteration 746/960] TRAIN loss:  1.117\n",
      "[epoch 2 Iteration 747/960] TRAIN loss:  1.477\n",
      "[epoch 2 Iteration 748/960] TRAIN loss:  1.084\n",
      "[epoch 2 Iteration 749/960] TRAIN loss:  1.270\n",
      "[epoch 2 Iteration 750/960] TRAIN loss:  1.250\n",
      "[epoch 2 Iteration 751/960] TRAIN loss:  1.086\n",
      "[epoch 2 Iteration 752/960] TRAIN loss:  0.984\n",
      "[epoch 2 Iteration 753/960] TRAIN loss:  1.245\n",
      "[epoch 2 Iteration 754/960] TRAIN loss:  1.390\n",
      "[epoch 2 Iteration 755/960] TRAIN loss:  1.051\n",
      "[epoch 2 Iteration 756/960] TRAIN loss:  1.167\n",
      "[epoch 2 Iteration 757/960] TRAIN loss:  1.164\n",
      "[epoch 2 Iteration 758/960] TRAIN loss:  1.147\n",
      "[epoch 2 Iteration 759/960] TRAIN loss:  0.901\n",
      "[epoch 2 Iteration 760/960] TRAIN loss:  1.226\n",
      "[epoch 2 Iteration 761/960] TRAIN loss:  1.008\n",
      "[epoch 2 Iteration 762/960] TRAIN loss:  1.257\n",
      "[epoch 2 Iteration 763/960] TRAIN loss:  1.040\n",
      "[epoch 2 Iteration 764/960] TRAIN loss:  1.042\n",
      "[epoch 2 Iteration 765/960] TRAIN loss:  1.059\n",
      "[epoch 2 Iteration 766/960] TRAIN loss:  1.198\n",
      "[epoch 2 Iteration 767/960] TRAIN loss:  1.180\n",
      "[epoch 2 Iteration 768/960] TRAIN loss:  0.997\n",
      "[epoch 2 Iteration 769/960] TRAIN loss:  1.039\n",
      "[epoch 2 Iteration 770/960] TRAIN loss:  0.953\n",
      "[epoch 2 Iteration 771/960] TRAIN loss:  1.046\n",
      "[epoch 2 Iteration 772/960] TRAIN loss:  1.448\n",
      "[epoch 2 Iteration 773/960] TRAIN loss:  1.478\n",
      "[epoch 2 Iteration 774/960] TRAIN loss:  1.003\n",
      "[epoch 2 Iteration 775/960] TRAIN loss:  1.035\n",
      "[epoch 2 Iteration 776/960] TRAIN loss:  1.008\n",
      "[epoch 2 Iteration 777/960] TRAIN loss:  1.269\n",
      "[epoch 2 Iteration 778/960] TRAIN loss:  0.960\n",
      "[epoch 2 Iteration 779/960] TRAIN loss:  1.156\n",
      "[epoch 2 Iteration 780/960] TRAIN loss:  1.129\n",
      "[epoch 2 Iteration 781/960] TRAIN loss:  1.010\n",
      "[epoch 2 Iteration 782/960] TRAIN loss:  1.554\n",
      "[epoch 2 Iteration 783/960] TRAIN loss:  0.954\n",
      "[epoch 2 Iteration 784/960] TRAIN loss:  1.119\n",
      "[epoch 2 Iteration 785/960] TRAIN loss:  1.070\n",
      "[epoch 2 Iteration 786/960] TRAIN loss:  1.206\n",
      "[epoch 2 Iteration 787/960] TRAIN loss:  0.981\n",
      "[epoch 2 Iteration 788/960] TRAIN loss:  0.974\n",
      "[epoch 2 Iteration 789/960] TRAIN loss:  1.375\n",
      "[epoch 2 Iteration 790/960] TRAIN loss:  1.123\n",
      "[epoch 2 Iteration 791/960] TRAIN loss:  1.177\n",
      "[epoch 2 Iteration 792/960] TRAIN loss:  1.400\n",
      "[epoch 2 Iteration 793/960] TRAIN loss:  0.988\n",
      "[epoch 2 Iteration 794/960] TRAIN loss:  1.186\n",
      "[epoch 2 Iteration 795/960] TRAIN loss:  1.175\n",
      "[epoch 2 Iteration 796/960] TRAIN loss:  1.191\n",
      "[epoch 2 Iteration 797/960] TRAIN loss:  1.201\n",
      "[epoch 2 Iteration 798/960] TRAIN loss:  1.145\n",
      "[epoch 2 Iteration 799/960] TRAIN loss:  1.425\n",
      "[epoch 2 Iteration 800/960] TRAIN loss:  1.033\n",
      "[epoch 2 Iteration 801/960] TRAIN loss:  1.202\n",
      "[epoch 2 Iteration 802/960] TRAIN loss:  1.396\n",
      "[epoch 2 Iteration 803/960] TRAIN loss:  1.161\n",
      "[epoch 2 Iteration 804/960] TRAIN loss:  1.188\n",
      "[epoch 2 Iteration 805/960] TRAIN loss:  0.991\n",
      "[epoch 2 Iteration 806/960] TRAIN loss:  1.073\n",
      "[epoch 2 Iteration 807/960] TRAIN loss:  1.158\n",
      "[epoch 2 Iteration 808/960] TRAIN loss:  1.365\n",
      "[epoch 2 Iteration 809/960] TRAIN loss:  1.066\n",
      "[epoch 2 Iteration 810/960] TRAIN loss:  0.839\n",
      "[epoch 2 Iteration 811/960] TRAIN loss:  1.102\n",
      "[epoch 2 Iteration 812/960] TRAIN loss:  1.240\n",
      "[epoch 2 Iteration 813/960] TRAIN loss:  1.375\n",
      "[epoch 2 Iteration 814/960] TRAIN loss:  1.024\n",
      "[epoch 2 Iteration 815/960] TRAIN loss:  1.087\n",
      "[epoch 2 Iteration 816/960] TRAIN loss:  0.817\n",
      "[epoch 2 Iteration 817/960] TRAIN loss:  1.076\n",
      "[epoch 2 Iteration 818/960] TRAIN loss:  1.156\n",
      "[epoch 2 Iteration 819/960] TRAIN loss:  1.125\n",
      "[epoch 2 Iteration 820/960] TRAIN loss:  1.118\n",
      "[epoch 2 Iteration 821/960] TRAIN loss:  1.345\n",
      "[epoch 2 Iteration 822/960] TRAIN loss:  1.042\n",
      "[epoch 2 Iteration 823/960] TRAIN loss:  1.588\n",
      "[epoch 2 Iteration 824/960] TRAIN loss:  1.422\n",
      "[epoch 2 Iteration 825/960] TRAIN loss:  1.016\n",
      "[epoch 2 Iteration 826/960] TRAIN loss:  1.037\n",
      "[epoch 2 Iteration 827/960] TRAIN loss:  0.897\n",
      "[epoch 2 Iteration 828/960] TRAIN loss:  0.965\n",
      "[epoch 2 Iteration 829/960] TRAIN loss:  1.515\n",
      "[epoch 2 Iteration 830/960] TRAIN loss:  1.175\n",
      "[epoch 2 Iteration 831/960] TRAIN loss:  1.089\n",
      "[epoch 2 Iteration 832/960] TRAIN loss:  1.331\n",
      "[epoch 2 Iteration 833/960] TRAIN loss:  1.242\n",
      "[epoch 2 Iteration 834/960] TRAIN loss:  1.094\n",
      "[epoch 2 Iteration 835/960] TRAIN loss:  1.352\n",
      "[epoch 2 Iteration 836/960] TRAIN loss:  1.006\n",
      "[epoch 2 Iteration 837/960] TRAIN loss:  1.254\n",
      "[epoch 2 Iteration 838/960] TRAIN loss:  1.498\n",
      "[epoch 2 Iteration 839/960] TRAIN loss:  1.222\n",
      "[epoch 2 Iteration 840/960] TRAIN loss:  1.032\n",
      "[epoch 2 Iteration 841/960] TRAIN loss:  1.017\n",
      "[epoch 2 Iteration 842/960] TRAIN loss:  0.986\n",
      "[epoch 2 Iteration 843/960] TRAIN loss:  1.145\n",
      "[epoch 2 Iteration 844/960] TRAIN loss:  1.415\n",
      "[epoch 2 Iteration 845/960] TRAIN loss:  1.315\n",
      "[epoch 2 Iteration 846/960] TRAIN loss:  0.973\n",
      "[epoch 2 Iteration 847/960] TRAIN loss:  1.003\n",
      "[epoch 2 Iteration 848/960] TRAIN loss:  1.140\n",
      "[epoch 2 Iteration 849/960] TRAIN loss:  1.173\n",
      "[epoch 2 Iteration 850/960] TRAIN loss:  1.145\n",
      "[epoch 2 Iteration 851/960] TRAIN loss:  1.256\n",
      "[epoch 2 Iteration 852/960] TRAIN loss:  1.359\n",
      "[epoch 2 Iteration 853/960] TRAIN loss:  1.494\n",
      "[epoch 2 Iteration 854/960] TRAIN loss:  1.231\n",
      "[epoch 2 Iteration 855/960] TRAIN loss:  0.947\n",
      "[epoch 2 Iteration 856/960] TRAIN loss:  1.089\n",
      "[epoch 2 Iteration 857/960] TRAIN loss:  1.039\n",
      "[epoch 2 Iteration 858/960] TRAIN loss:  1.554\n",
      "[epoch 2 Iteration 859/960] TRAIN loss:  0.945\n",
      "[epoch 2 Iteration 860/960] TRAIN loss:  0.949\n",
      "[epoch 2 Iteration 861/960] TRAIN loss:  1.017\n",
      "[epoch 2 Iteration 862/960] TRAIN loss:  1.183\n",
      "[epoch 2 Iteration 863/960] TRAIN loss:  1.143\n",
      "[epoch 2 Iteration 864/960] TRAIN loss:  1.108\n",
      "[epoch 2 Iteration 865/960] TRAIN loss:  1.247\n",
      "[epoch 2 Iteration 866/960] TRAIN loss:  1.081\n",
      "[epoch 2 Iteration 867/960] TRAIN loss:  1.508\n",
      "[epoch 2 Iteration 868/960] TRAIN loss:  0.982\n",
      "[epoch 2 Iteration 869/960] TRAIN loss:  1.373\n",
      "[epoch 2 Iteration 870/960] TRAIN loss:  1.204\n",
      "[epoch 2 Iteration 871/960] TRAIN loss:  1.089\n",
      "[epoch 2 Iteration 872/960] TRAIN loss:  0.922\n",
      "[epoch 2 Iteration 873/960] TRAIN loss:  1.210\n",
      "[epoch 2 Iteration 874/960] TRAIN loss:  0.977\n",
      "[epoch 2 Iteration 875/960] TRAIN loss:  1.330\n",
      "[epoch 2 Iteration 876/960] TRAIN loss:  1.154\n",
      "[epoch 2 Iteration 877/960] TRAIN loss:  0.960\n",
      "[epoch 2 Iteration 878/960] TRAIN loss:  1.109\n",
      "[epoch 2 Iteration 879/960] TRAIN loss:  1.233\n",
      "[epoch 2 Iteration 880/960] TRAIN loss:  0.940\n",
      "[epoch 2 Iteration 881/960] TRAIN loss:  1.063\n",
      "[epoch 2 Iteration 882/960] TRAIN loss:  0.811\n",
      "[epoch 2 Iteration 883/960] TRAIN loss:  1.134\n",
      "[epoch 2 Iteration 884/960] TRAIN loss:  1.048\n",
      "[epoch 2 Iteration 885/960] TRAIN loss:  1.154\n",
      "[epoch 2 Iteration 886/960] TRAIN loss:  1.002\n",
      "[epoch 2 Iteration 887/960] TRAIN loss:  1.054\n",
      "[epoch 2 Iteration 888/960] TRAIN loss:  1.115\n",
      "[epoch 2 Iteration 889/960] TRAIN loss:  1.400\n",
      "[epoch 2 Iteration 890/960] TRAIN loss:  1.247\n",
      "[epoch 2 Iteration 891/960] TRAIN loss:  1.255\n",
      "[epoch 2 Iteration 892/960] TRAIN loss:  1.075\n",
      "[epoch 2 Iteration 893/960] TRAIN loss:  0.904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2 Iteration 894/960] TRAIN loss:  0.935\n",
      "[epoch 2 Iteration 895/960] TRAIN loss:  0.838\n",
      "[epoch 2 Iteration 896/960] TRAIN loss:  1.297\n",
      "[epoch 2 Iteration 897/960] TRAIN loss:  0.828\n",
      "[epoch 2 Iteration 898/960] TRAIN loss:  1.374\n",
      "[epoch 2 Iteration 899/960] TRAIN loss:  1.100\n",
      "[epoch 2 Iteration 900/960] TRAIN loss:  1.358\n",
      "[epoch 2 Iteration 901/960] TRAIN loss:  0.909\n",
      "[epoch 2 Iteration 902/960] TRAIN loss:  1.289\n",
      "[epoch 2 Iteration 903/960] TRAIN loss:  1.001\n",
      "[epoch 2 Iteration 904/960] TRAIN loss:  1.124\n",
      "[epoch 2 Iteration 905/960] TRAIN loss:  1.139\n",
      "[epoch 2 Iteration 906/960] TRAIN loss:  1.283\n",
      "[epoch 2 Iteration 907/960] TRAIN loss:  0.883\n",
      "[epoch 2 Iteration 908/960] TRAIN loss:  0.966\n",
      "[epoch 2 Iteration 909/960] TRAIN loss:  1.098\n",
      "[epoch 2 Iteration 910/960] TRAIN loss:  1.024\n",
      "[epoch 2 Iteration 911/960] TRAIN loss:  0.956\n",
      "[epoch 2 Iteration 912/960] TRAIN loss:  1.068\n",
      "[epoch 2 Iteration 913/960] TRAIN loss:  1.173\n",
      "[epoch 2 Iteration 914/960] TRAIN loss:  1.084\n",
      "[epoch 2 Iteration 915/960] TRAIN loss:  1.212\n",
      "[epoch 2 Iteration 916/960] TRAIN loss:  1.101\n",
      "[epoch 2 Iteration 917/960] TRAIN loss:  1.296\n",
      "[epoch 2 Iteration 918/960] TRAIN loss:  1.103\n",
      "[epoch 2 Iteration 919/960] TRAIN loss:  1.365\n",
      "[epoch 2 Iteration 920/960] TRAIN loss:  1.227\n",
      "[epoch 2 Iteration 921/960] TRAIN loss:  0.928\n",
      "[epoch 2 Iteration 922/960] TRAIN loss:  1.113\n",
      "[epoch 2 Iteration 923/960] TRAIN loss:  1.309\n",
      "[epoch 2 Iteration 924/960] TRAIN loss:  1.408\n",
      "[epoch 2 Iteration 925/960] TRAIN loss:  1.138\n",
      "[epoch 2 Iteration 926/960] TRAIN loss:  1.234\n",
      "[epoch 2 Iteration 927/960] TRAIN loss:  1.153\n",
      "[epoch 2 Iteration 928/960] TRAIN loss:  1.386\n",
      "[epoch 2 Iteration 929/960] TRAIN loss:  1.173\n",
      "[epoch 2 Iteration 930/960] TRAIN loss:  0.971\n",
      "[epoch 2 Iteration 931/960] TRAIN loss:  1.105\n",
      "[epoch 2 Iteration 932/960] TRAIN loss:  1.041\n",
      "[epoch 2 Iteration 933/960] TRAIN loss:  1.381\n",
      "[epoch 2 Iteration 934/960] TRAIN loss:  1.320\n",
      "[epoch 2 Iteration 935/960] TRAIN loss:  0.973\n",
      "[epoch 2 Iteration 936/960] TRAIN loss:  1.155\n",
      "[epoch 2 Iteration 937/960] TRAIN loss:  1.068\n",
      "[epoch 2 Iteration 938/960] TRAIN loss:  1.116\n",
      "[epoch 2 Iteration 939/960] TRAIN loss:  0.809\n",
      "[epoch 2 Iteration 940/960] TRAIN loss:  0.878\n",
      "[epoch 2 Iteration 941/960] TRAIN loss:  1.152\n",
      "[epoch 2 Iteration 942/960] TRAIN loss:  1.290\n",
      "[epoch 2 Iteration 943/960] TRAIN loss:  1.320\n",
      "[epoch 2 Iteration 944/960] TRAIN loss:  1.286\n",
      "[epoch 2 Iteration 945/960] TRAIN loss:  0.907\n",
      "[epoch 2 Iteration 946/960] TRAIN loss:  1.067\n",
      "[epoch 2 Iteration 947/960] TRAIN loss:  1.260\n",
      "[epoch 2 Iteration 948/960] TRAIN loss:  0.890\n",
      "[epoch 2 Iteration 949/960] TRAIN loss:  1.269\n",
      "[epoch 2 Iteration 950/960] TRAIN loss:  1.286\n",
      "[epoch 2 Iteration 951/960] TRAIN loss:  0.927\n",
      "[epoch 2 Iteration 952/960] TRAIN loss:  1.182\n",
      "[epoch 2 Iteration 953/960] TRAIN loss:  1.057\n",
      "[epoch 2 Iteration 954/960] TRAIN loss:  0.847\n",
      "[epoch 2 Iteration 955/960] TRAIN loss:  1.293\n",
      "[epoch 2 Iteration 956/960] TRAIN loss:  0.919\n",
      "[epoch 2 Iteration 957/960] TRAIN loss:  0.950\n",
      "[epoch 2 Iteration 958/960] TRAIN loss:  1.274\n",
      "[epoch 2 Iteration 959/960] TRAIN loss:  1.009\n",
      "[epoch 2/15] TRAIN acc/loss:  0.592/1.009\n",
      "[epoch 2/15] VAL acc/loss:  0.588/0.768\n",
      "[epoch 3 Iteration 0/960] TRAIN loss:  0.870\n",
      "[epoch 3 Iteration 1/960] TRAIN loss:  1.139\n",
      "[epoch 3 Iteration 2/960] TRAIN loss:  0.829\n",
      "[epoch 3 Iteration 3/960] TRAIN loss:  1.055\n",
      "[epoch 3 Iteration 4/960] TRAIN loss:  0.969\n",
      "[epoch 3 Iteration 5/960] TRAIN loss:  0.908\n",
      "[epoch 3 Iteration 6/960] TRAIN loss:  1.095\n",
      "[epoch 3 Iteration 7/960] TRAIN loss:  0.999\n",
      "[epoch 3 Iteration 8/960] TRAIN loss:  1.183\n",
      "[epoch 3 Iteration 9/960] TRAIN loss:  1.078\n",
      "[epoch 3 Iteration 10/960] TRAIN loss:  1.305\n",
      "[epoch 3 Iteration 11/960] TRAIN loss:  1.185\n",
      "[epoch 3 Iteration 12/960] TRAIN loss:  1.126\n",
      "[epoch 3 Iteration 13/960] TRAIN loss:  1.152\n",
      "[epoch 3 Iteration 14/960] TRAIN loss:  1.028\n",
      "[epoch 3 Iteration 15/960] TRAIN loss:  0.827\n",
      "[epoch 3 Iteration 16/960] TRAIN loss:  1.043\n",
      "[epoch 3 Iteration 17/960] TRAIN loss:  0.987\n",
      "[epoch 3 Iteration 18/960] TRAIN loss:  1.012\n",
      "[epoch 3 Iteration 19/960] TRAIN loss:  0.908\n",
      "[epoch 3 Iteration 20/960] TRAIN loss:  1.104\n",
      "[epoch 3 Iteration 21/960] TRAIN loss:  0.812\n",
      "[epoch 3 Iteration 22/960] TRAIN loss:  1.018\n",
      "[epoch 3 Iteration 23/960] TRAIN loss:  1.073\n",
      "[epoch 3 Iteration 24/960] TRAIN loss:  1.264\n",
      "[epoch 3 Iteration 25/960] TRAIN loss:  1.117\n",
      "[epoch 3 Iteration 26/960] TRAIN loss:  1.241\n",
      "[epoch 3 Iteration 27/960] TRAIN loss:  1.304\n",
      "[epoch 3 Iteration 28/960] TRAIN loss:  0.699\n",
      "[epoch 3 Iteration 29/960] TRAIN loss:  1.244\n",
      "[epoch 3 Iteration 30/960] TRAIN loss:  1.118\n",
      "[epoch 3 Iteration 31/960] TRAIN loss:  1.224\n",
      "[epoch 3 Iteration 32/960] TRAIN loss:  0.772\n",
      "[epoch 3 Iteration 33/960] TRAIN loss:  0.961\n",
      "[epoch 3 Iteration 34/960] TRAIN loss:  1.197\n",
      "[epoch 3 Iteration 35/960] TRAIN loss:  1.032\n",
      "[epoch 3 Iteration 36/960] TRAIN loss:  1.145\n",
      "[epoch 3 Iteration 37/960] TRAIN loss:  0.915\n",
      "[epoch 3 Iteration 38/960] TRAIN loss:  1.063\n",
      "[epoch 3 Iteration 39/960] TRAIN loss:  1.019\n",
      "[epoch 3 Iteration 40/960] TRAIN loss:  1.093\n",
      "[epoch 3 Iteration 41/960] TRAIN loss:  1.020\n",
      "[epoch 3 Iteration 42/960] TRAIN loss:  1.103\n",
      "[epoch 3 Iteration 43/960] TRAIN loss:  1.180\n",
      "[epoch 3 Iteration 44/960] TRAIN loss:  1.267\n",
      "[epoch 3 Iteration 45/960] TRAIN loss:  0.915\n",
      "[epoch 3 Iteration 46/960] TRAIN loss:  1.173\n",
      "[epoch 3 Iteration 47/960] TRAIN loss:  0.904\n",
      "[epoch 3 Iteration 48/960] TRAIN loss:  1.225\n",
      "[epoch 3 Iteration 49/960] TRAIN loss:  1.204\n",
      "[epoch 3 Iteration 50/960] TRAIN loss:  1.092\n",
      "[epoch 3 Iteration 51/960] TRAIN loss:  1.035\n",
      "[epoch 3 Iteration 52/960] TRAIN loss:  1.068\n",
      "[epoch 3 Iteration 53/960] TRAIN loss:  1.310\n",
      "[epoch 3 Iteration 54/960] TRAIN loss:  1.450\n",
      "[epoch 3 Iteration 55/960] TRAIN loss:  1.063\n",
      "[epoch 3 Iteration 56/960] TRAIN loss:  1.294\n",
      "[epoch 3 Iteration 57/960] TRAIN loss:  0.970\n",
      "[epoch 3 Iteration 58/960] TRAIN loss:  0.996\n",
      "[epoch 3 Iteration 59/960] TRAIN loss:  0.960\n",
      "[epoch 3 Iteration 60/960] TRAIN loss:  1.116\n",
      "[epoch 3 Iteration 61/960] TRAIN loss:  1.054\n",
      "[epoch 3 Iteration 62/960] TRAIN loss:  0.959\n",
      "[epoch 3 Iteration 63/960] TRAIN loss:  1.183\n",
      "[epoch 3 Iteration 64/960] TRAIN loss:  1.113\n",
      "[epoch 3 Iteration 65/960] TRAIN loss:  1.130\n",
      "[epoch 3 Iteration 66/960] TRAIN loss:  0.867\n",
      "[epoch 3 Iteration 67/960] TRAIN loss:  1.150\n",
      "[epoch 3 Iteration 68/960] TRAIN loss:  1.061\n",
      "[epoch 3 Iteration 69/960] TRAIN loss:  1.130\n",
      "[epoch 3 Iteration 70/960] TRAIN loss:  1.130\n",
      "[epoch 3 Iteration 71/960] TRAIN loss:  1.124\n",
      "[epoch 3 Iteration 72/960] TRAIN loss:  0.835\n",
      "[epoch 3 Iteration 73/960] TRAIN loss:  1.026\n",
      "[epoch 3 Iteration 74/960] TRAIN loss:  0.888\n",
      "[epoch 3 Iteration 75/960] TRAIN loss:  1.153\n",
      "[epoch 3 Iteration 76/960] TRAIN loss:  1.178\n",
      "[epoch 3 Iteration 77/960] TRAIN loss:  1.281\n",
      "[epoch 3 Iteration 78/960] TRAIN loss:  1.085\n",
      "[epoch 3 Iteration 79/960] TRAIN loss:  0.770\n",
      "[epoch 3 Iteration 80/960] TRAIN loss:  1.248\n",
      "[epoch 3 Iteration 81/960] TRAIN loss:  1.067\n",
      "[epoch 3 Iteration 82/960] TRAIN loss:  1.190\n",
      "[epoch 3 Iteration 83/960] TRAIN loss:  0.943\n",
      "[epoch 3 Iteration 84/960] TRAIN loss:  1.153\n",
      "[epoch 3 Iteration 85/960] TRAIN loss:  1.073\n",
      "[epoch 3 Iteration 86/960] TRAIN loss:  0.946\n",
      "[epoch 3 Iteration 87/960] TRAIN loss:  0.970\n",
      "[epoch 3 Iteration 88/960] TRAIN loss:  1.165\n",
      "[epoch 3 Iteration 89/960] TRAIN loss:  1.177\n",
      "[epoch 3 Iteration 90/960] TRAIN loss:  1.342\n",
      "[epoch 3 Iteration 91/960] TRAIN loss:  1.073\n",
      "[epoch 3 Iteration 92/960] TRAIN loss:  1.125\n",
      "[epoch 3 Iteration 93/960] TRAIN loss:  1.179\n",
      "[epoch 3 Iteration 94/960] TRAIN loss:  0.930\n",
      "[epoch 3 Iteration 95/960] TRAIN loss:  0.893\n",
      "[epoch 3 Iteration 96/960] TRAIN loss:  0.884\n",
      "[epoch 3 Iteration 97/960] TRAIN loss:  0.861\n",
      "[epoch 3 Iteration 98/960] TRAIN loss:  1.156\n",
      "[epoch 3 Iteration 99/960] TRAIN loss:  1.410\n",
      "[epoch 3 Iteration 100/960] TRAIN loss:  0.911\n",
      "[epoch 3 Iteration 101/960] TRAIN loss:  1.192\n",
      "[epoch 3 Iteration 102/960] TRAIN loss:  1.044\n",
      "[epoch 3 Iteration 103/960] TRAIN loss:  1.130\n",
      "[epoch 3 Iteration 104/960] TRAIN loss:  0.956\n",
      "[epoch 3 Iteration 105/960] TRAIN loss:  0.915\n",
      "[epoch 3 Iteration 106/960] TRAIN loss:  1.114\n",
      "[epoch 3 Iteration 107/960] TRAIN loss:  1.142\n",
      "[epoch 3 Iteration 108/960] TRAIN loss:  0.891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3 Iteration 109/960] TRAIN loss:  0.937\n",
      "[epoch 3 Iteration 110/960] TRAIN loss:  1.014\n",
      "[epoch 3 Iteration 111/960] TRAIN loss:  0.952\n",
      "[epoch 3 Iteration 112/960] TRAIN loss:  0.793\n",
      "[epoch 3 Iteration 113/960] TRAIN loss:  1.095\n",
      "[epoch 3 Iteration 114/960] TRAIN loss:  1.094\n",
      "[epoch 3 Iteration 115/960] TRAIN loss:  1.123\n",
      "[epoch 3 Iteration 116/960] TRAIN loss:  1.202\n",
      "[epoch 3 Iteration 117/960] TRAIN loss:  1.097\n",
      "[epoch 3 Iteration 118/960] TRAIN loss:  1.467\n",
      "[epoch 3 Iteration 119/960] TRAIN loss:  1.170\n",
      "[epoch 3 Iteration 120/960] TRAIN loss:  1.157\n",
      "[epoch 3 Iteration 121/960] TRAIN loss:  1.160\n",
      "[epoch 3 Iteration 122/960] TRAIN loss:  0.888\n",
      "[epoch 3 Iteration 123/960] TRAIN loss:  1.027\n",
      "[epoch 3 Iteration 124/960] TRAIN loss:  1.036\n",
      "[epoch 3 Iteration 125/960] TRAIN loss:  1.072\n",
      "[epoch 3 Iteration 126/960] TRAIN loss:  1.061\n",
      "[epoch 3 Iteration 127/960] TRAIN loss:  1.140\n",
      "[epoch 3 Iteration 128/960] TRAIN loss:  1.054\n",
      "[epoch 3 Iteration 129/960] TRAIN loss:  0.837\n",
      "[epoch 3 Iteration 130/960] TRAIN loss:  0.956\n",
      "[epoch 3 Iteration 131/960] TRAIN loss:  0.989\n",
      "[epoch 3 Iteration 132/960] TRAIN loss:  1.029\n",
      "[epoch 3 Iteration 133/960] TRAIN loss:  1.025\n",
      "[epoch 3 Iteration 134/960] TRAIN loss:  1.012\n",
      "[epoch 3 Iteration 135/960] TRAIN loss:  1.062\n",
      "[epoch 3 Iteration 136/960] TRAIN loss:  1.025\n",
      "[epoch 3 Iteration 137/960] TRAIN loss:  0.972\n",
      "[epoch 3 Iteration 138/960] TRAIN loss:  1.254\n",
      "[epoch 3 Iteration 139/960] TRAIN loss:  1.095\n",
      "[epoch 3 Iteration 140/960] TRAIN loss:  1.323\n",
      "[epoch 3 Iteration 141/960] TRAIN loss:  0.883\n",
      "[epoch 3 Iteration 142/960] TRAIN loss:  0.985\n",
      "[epoch 3 Iteration 143/960] TRAIN loss:  1.044\n",
      "[epoch 3 Iteration 144/960] TRAIN loss:  1.184\n",
      "[epoch 3 Iteration 145/960] TRAIN loss:  0.968\n",
      "[epoch 3 Iteration 146/960] TRAIN loss:  1.122\n",
      "[epoch 3 Iteration 147/960] TRAIN loss:  1.252\n",
      "[epoch 3 Iteration 148/960] TRAIN loss:  1.112\n",
      "[epoch 3 Iteration 149/960] TRAIN loss:  1.302\n",
      "[epoch 3 Iteration 150/960] TRAIN loss:  1.180\n",
      "[epoch 3 Iteration 151/960] TRAIN loss:  1.114\n",
      "[epoch 3 Iteration 152/960] TRAIN loss:  1.137\n",
      "[epoch 3 Iteration 153/960] TRAIN loss:  0.923\n",
      "[epoch 3 Iteration 154/960] TRAIN loss:  0.897\n",
      "[epoch 3 Iteration 155/960] TRAIN loss:  1.008\n",
      "[epoch 3 Iteration 156/960] TRAIN loss:  0.977\n",
      "[epoch 3 Iteration 157/960] TRAIN loss:  0.986\n",
      "[epoch 3 Iteration 158/960] TRAIN loss:  1.210\n",
      "[epoch 3 Iteration 159/960] TRAIN loss:  1.129\n",
      "[epoch 3 Iteration 160/960] TRAIN loss:  0.709\n",
      "[epoch 3 Iteration 161/960] TRAIN loss:  1.033\n",
      "[epoch 3 Iteration 162/960] TRAIN loss:  1.154\n",
      "[epoch 3 Iteration 163/960] TRAIN loss:  1.269\n",
      "[epoch 3 Iteration 164/960] TRAIN loss:  1.002\n",
      "[epoch 3 Iteration 165/960] TRAIN loss:  0.886\n",
      "[epoch 3 Iteration 166/960] TRAIN loss:  1.202\n",
      "[epoch 3 Iteration 167/960] TRAIN loss:  1.062\n",
      "[epoch 3 Iteration 168/960] TRAIN loss:  1.120\n",
      "[epoch 3 Iteration 169/960] TRAIN loss:  1.242\n",
      "[epoch 3 Iteration 170/960] TRAIN loss:  0.790\n",
      "[epoch 3 Iteration 171/960] TRAIN loss:  1.151\n",
      "[epoch 3 Iteration 172/960] TRAIN loss:  0.907\n",
      "[epoch 3 Iteration 173/960] TRAIN loss:  1.259\n",
      "[epoch 3 Iteration 174/960] TRAIN loss:  1.286\n",
      "[epoch 3 Iteration 175/960] TRAIN loss:  1.176\n",
      "[epoch 3 Iteration 176/960] TRAIN loss:  0.938\n",
      "[epoch 3 Iteration 177/960] TRAIN loss:  0.896\n",
      "[epoch 3 Iteration 178/960] TRAIN loss:  1.169\n",
      "[epoch 3 Iteration 179/960] TRAIN loss:  1.084\n",
      "[epoch 3 Iteration 180/960] TRAIN loss:  1.087\n",
      "[epoch 3 Iteration 181/960] TRAIN loss:  1.309\n",
      "[epoch 3 Iteration 182/960] TRAIN loss:  1.088\n",
      "[epoch 3 Iteration 183/960] TRAIN loss:  0.910\n",
      "[epoch 3 Iteration 184/960] TRAIN loss:  1.381\n",
      "[epoch 3 Iteration 185/960] TRAIN loss:  1.089\n",
      "[epoch 3 Iteration 186/960] TRAIN loss:  1.156\n",
      "[epoch 3 Iteration 187/960] TRAIN loss:  1.066\n",
      "[epoch 3 Iteration 188/960] TRAIN loss:  0.920\n",
      "[epoch 3 Iteration 189/960] TRAIN loss:  1.190\n",
      "[epoch 3 Iteration 190/960] TRAIN loss:  1.069\n",
      "[epoch 3 Iteration 191/960] TRAIN loss:  1.166\n",
      "[epoch 3 Iteration 192/960] TRAIN loss:  1.028\n",
      "[epoch 3 Iteration 193/960] TRAIN loss:  1.114\n",
      "[epoch 3 Iteration 194/960] TRAIN loss:  1.127\n",
      "[epoch 3 Iteration 195/960] TRAIN loss:  1.022\n",
      "[epoch 3 Iteration 196/960] TRAIN loss:  1.017\n",
      "[epoch 3 Iteration 197/960] TRAIN loss:  1.027\n",
      "[epoch 3 Iteration 198/960] TRAIN loss:  1.435\n",
      "[epoch 3 Iteration 199/960] TRAIN loss:  1.132\n",
      "[epoch 3 Iteration 200/960] TRAIN loss:  1.125\n",
      "[epoch 3 Iteration 201/960] TRAIN loss:  1.176\n",
      "[epoch 3 Iteration 202/960] TRAIN loss:  0.912\n",
      "[epoch 3 Iteration 203/960] TRAIN loss:  1.112\n",
      "[epoch 3 Iteration 204/960] TRAIN loss:  0.830\n",
      "[epoch 3 Iteration 205/960] TRAIN loss:  1.385\n",
      "[epoch 3 Iteration 206/960] TRAIN loss:  1.430\n",
      "[epoch 3 Iteration 207/960] TRAIN loss:  0.985\n",
      "[epoch 3 Iteration 208/960] TRAIN loss:  1.098\n",
      "[epoch 3 Iteration 209/960] TRAIN loss:  1.018\n",
      "[epoch 3 Iteration 210/960] TRAIN loss:  0.926\n",
      "[epoch 3 Iteration 211/960] TRAIN loss:  1.053\n",
      "[epoch 3 Iteration 212/960] TRAIN loss:  0.953\n",
      "[epoch 3 Iteration 213/960] TRAIN loss:  1.030\n",
      "[epoch 3 Iteration 214/960] TRAIN loss:  1.046\n",
      "[epoch 3 Iteration 215/960] TRAIN loss:  1.143\n",
      "[epoch 3 Iteration 216/960] TRAIN loss:  1.119\n",
      "[epoch 3 Iteration 217/960] TRAIN loss:  1.086\n",
      "[epoch 3 Iteration 218/960] TRAIN loss:  1.113\n",
      "[epoch 3 Iteration 219/960] TRAIN loss:  1.131\n",
      "[epoch 3 Iteration 220/960] TRAIN loss:  0.985\n",
      "[epoch 3 Iteration 221/960] TRAIN loss:  1.015\n",
      "[epoch 3 Iteration 222/960] TRAIN loss:  1.236\n",
      "[epoch 3 Iteration 223/960] TRAIN loss:  1.041\n",
      "[epoch 3 Iteration 224/960] TRAIN loss:  0.838\n",
      "[epoch 3 Iteration 225/960] TRAIN loss:  0.916\n",
      "[epoch 3 Iteration 226/960] TRAIN loss:  0.804\n",
      "[epoch 3 Iteration 227/960] TRAIN loss:  0.918\n",
      "[epoch 3 Iteration 228/960] TRAIN loss:  0.995\n",
      "[epoch 3 Iteration 229/960] TRAIN loss:  1.150\n",
      "[epoch 3 Iteration 230/960] TRAIN loss:  1.039\n",
      "[epoch 3 Iteration 231/960] TRAIN loss:  0.952\n",
      "[epoch 3 Iteration 232/960] TRAIN loss:  1.122\n",
      "[epoch 3 Iteration 233/960] TRAIN loss:  1.034\n",
      "[epoch 3 Iteration 234/960] TRAIN loss:  0.957\n",
      "[epoch 3 Iteration 235/960] TRAIN loss:  1.008\n",
      "[epoch 3 Iteration 236/960] TRAIN loss:  0.779\n",
      "[epoch 3 Iteration 237/960] TRAIN loss:  1.154\n",
      "[epoch 3 Iteration 238/960] TRAIN loss:  0.831\n",
      "[epoch 3 Iteration 239/960] TRAIN loss:  0.822\n",
      "[epoch 3 Iteration 240/960] TRAIN loss:  1.109\n",
      "[epoch 3 Iteration 241/960] TRAIN loss:  1.099\n",
      "[epoch 3 Iteration 242/960] TRAIN loss:  1.247\n",
      "[epoch 3 Iteration 243/960] TRAIN loss:  1.330\n",
      "[epoch 3 Iteration 244/960] TRAIN loss:  1.043\n",
      "[epoch 3 Iteration 245/960] TRAIN loss:  0.954\n",
      "[epoch 3 Iteration 246/960] TRAIN loss:  1.210\n",
      "[epoch 3 Iteration 247/960] TRAIN loss:  0.987\n",
      "[epoch 3 Iteration 248/960] TRAIN loss:  0.995\n",
      "[epoch 3 Iteration 249/960] TRAIN loss:  1.054\n",
      "[epoch 3 Iteration 250/960] TRAIN loss:  1.149\n",
      "[epoch 3 Iteration 251/960] TRAIN loss:  0.909\n",
      "[epoch 3 Iteration 252/960] TRAIN loss:  1.116\n",
      "[epoch 3 Iteration 253/960] TRAIN loss:  1.267\n",
      "[epoch 3 Iteration 254/960] TRAIN loss:  1.166\n",
      "[epoch 3 Iteration 255/960] TRAIN loss:  1.112\n",
      "[epoch 3 Iteration 256/960] TRAIN loss:  0.987\n",
      "[epoch 3 Iteration 257/960] TRAIN loss:  0.908\n",
      "[epoch 3 Iteration 258/960] TRAIN loss:  1.101\n",
      "[epoch 3 Iteration 259/960] TRAIN loss:  1.054\n",
      "[epoch 3 Iteration 260/960] TRAIN loss:  0.946\n",
      "[epoch 3 Iteration 261/960] TRAIN loss:  0.957\n",
      "[epoch 3 Iteration 262/960] TRAIN loss:  1.488\n",
      "[epoch 3 Iteration 263/960] TRAIN loss:  0.953\n",
      "[epoch 3 Iteration 264/960] TRAIN loss:  1.653\n",
      "[epoch 3 Iteration 265/960] TRAIN loss:  1.108\n",
      "[epoch 3 Iteration 266/960] TRAIN loss:  1.073\n",
      "[epoch 3 Iteration 267/960] TRAIN loss:  0.953\n",
      "[epoch 3 Iteration 268/960] TRAIN loss:  1.095\n",
      "[epoch 3 Iteration 269/960] TRAIN loss:  0.884\n",
      "[epoch 3 Iteration 270/960] TRAIN loss:  1.033\n",
      "[epoch 3 Iteration 271/960] TRAIN loss:  1.022\n",
      "[epoch 3 Iteration 272/960] TRAIN loss:  0.879\n",
      "[epoch 3 Iteration 273/960] TRAIN loss:  0.827\n",
      "[epoch 3 Iteration 274/960] TRAIN loss:  1.246\n",
      "[epoch 3 Iteration 275/960] TRAIN loss:  0.904\n",
      "[epoch 3 Iteration 276/960] TRAIN loss:  0.983\n",
      "[epoch 3 Iteration 277/960] TRAIN loss:  1.050\n",
      "[epoch 3 Iteration 278/960] TRAIN loss:  0.820\n",
      "[epoch 3 Iteration 279/960] TRAIN loss:  0.919\n",
      "[epoch 3 Iteration 280/960] TRAIN loss:  1.110\n",
      "[epoch 3 Iteration 281/960] TRAIN loss:  1.046\n",
      "[epoch 3 Iteration 282/960] TRAIN loss:  1.162\n",
      "[epoch 3 Iteration 283/960] TRAIN loss:  1.067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3 Iteration 284/960] TRAIN loss:  0.843\n",
      "[epoch 3 Iteration 285/960] TRAIN loss:  1.216\n",
      "[epoch 3 Iteration 286/960] TRAIN loss:  0.951\n",
      "[epoch 3 Iteration 287/960] TRAIN loss:  1.328\n",
      "[epoch 3 Iteration 288/960] TRAIN loss:  1.142\n",
      "[epoch 3 Iteration 289/960] TRAIN loss:  1.203\n",
      "[epoch 3 Iteration 290/960] TRAIN loss:  1.027\n",
      "[epoch 3 Iteration 291/960] TRAIN loss:  1.134\n",
      "[epoch 3 Iteration 292/960] TRAIN loss:  0.851\n",
      "[epoch 3 Iteration 293/960] TRAIN loss:  0.864\n",
      "[epoch 3 Iteration 294/960] TRAIN loss:  1.153\n",
      "[epoch 3 Iteration 295/960] TRAIN loss:  1.190\n",
      "[epoch 3 Iteration 296/960] TRAIN loss:  1.002\n",
      "[epoch 3 Iteration 297/960] TRAIN loss:  0.957\n",
      "[epoch 3 Iteration 298/960] TRAIN loss:  1.431\n",
      "[epoch 3 Iteration 299/960] TRAIN loss:  1.252\n",
      "[epoch 3 Iteration 300/960] TRAIN loss:  1.109\n",
      "[epoch 3 Iteration 301/960] TRAIN loss:  1.037\n",
      "[epoch 3 Iteration 302/960] TRAIN loss:  0.821\n",
      "[epoch 3 Iteration 303/960] TRAIN loss:  1.179\n",
      "[epoch 3 Iteration 304/960] TRAIN loss:  0.899\n",
      "[epoch 3 Iteration 305/960] TRAIN loss:  1.253\n",
      "[epoch 3 Iteration 306/960] TRAIN loss:  1.164\n",
      "[epoch 3 Iteration 307/960] TRAIN loss:  0.766\n",
      "[epoch 3 Iteration 308/960] TRAIN loss:  1.015\n",
      "[epoch 3 Iteration 309/960] TRAIN loss:  1.115\n",
      "[epoch 3 Iteration 310/960] TRAIN loss:  0.913\n",
      "[epoch 3 Iteration 311/960] TRAIN loss:  0.964\n",
      "[epoch 3 Iteration 312/960] TRAIN loss:  0.908\n",
      "[epoch 3 Iteration 313/960] TRAIN loss:  0.928\n",
      "[epoch 3 Iteration 314/960] TRAIN loss:  1.143\n",
      "[epoch 3 Iteration 315/960] TRAIN loss:  0.897\n",
      "[epoch 3 Iteration 316/960] TRAIN loss:  1.153\n",
      "[epoch 3 Iteration 317/960] TRAIN loss:  1.435\n",
      "[epoch 3 Iteration 318/960] TRAIN loss:  1.062\n",
      "[epoch 3 Iteration 319/960] TRAIN loss:  1.051\n",
      "[epoch 3 Iteration 320/960] TRAIN loss:  1.049\n",
      "[epoch 3 Iteration 321/960] TRAIN loss:  0.827\n",
      "[epoch 3 Iteration 322/960] TRAIN loss:  1.120\n",
      "[epoch 3 Iteration 323/960] TRAIN loss:  0.889\n",
      "[epoch 3 Iteration 324/960] TRAIN loss:  1.159\n",
      "[epoch 3 Iteration 325/960] TRAIN loss:  0.820\n",
      "[epoch 3 Iteration 326/960] TRAIN loss:  1.352\n",
      "[epoch 3 Iteration 327/960] TRAIN loss:  0.871\n",
      "[epoch 3 Iteration 328/960] TRAIN loss:  1.112\n",
      "[epoch 3 Iteration 329/960] TRAIN loss:  0.945\n",
      "[epoch 3 Iteration 330/960] TRAIN loss:  1.054\n",
      "[epoch 3 Iteration 331/960] TRAIN loss:  1.187\n",
      "[epoch 3 Iteration 332/960] TRAIN loss:  0.949\n",
      "[epoch 3 Iteration 333/960] TRAIN loss:  1.215\n",
      "[epoch 3 Iteration 334/960] TRAIN loss:  1.060\n",
      "[epoch 3 Iteration 335/960] TRAIN loss:  1.175\n",
      "[epoch 3 Iteration 336/960] TRAIN loss:  1.094\n",
      "[epoch 3 Iteration 337/960] TRAIN loss:  1.008\n",
      "[epoch 3 Iteration 338/960] TRAIN loss:  1.379\n",
      "[epoch 3 Iteration 339/960] TRAIN loss:  1.175\n",
      "[epoch 3 Iteration 340/960] TRAIN loss:  1.099\n",
      "[epoch 3 Iteration 341/960] TRAIN loss:  1.235\n",
      "[epoch 3 Iteration 342/960] TRAIN loss:  0.821\n",
      "[epoch 3 Iteration 343/960] TRAIN loss:  1.162\n",
      "[epoch 3 Iteration 344/960] TRAIN loss:  0.843\n",
      "[epoch 3 Iteration 345/960] TRAIN loss:  0.997\n",
      "[epoch 3 Iteration 346/960] TRAIN loss:  0.966\n",
      "[epoch 3 Iteration 347/960] TRAIN loss:  1.180\n",
      "[epoch 3 Iteration 348/960] TRAIN loss:  0.876\n",
      "[epoch 3 Iteration 349/960] TRAIN loss:  1.037\n",
      "[epoch 3 Iteration 350/960] TRAIN loss:  0.867\n",
      "[epoch 3 Iteration 351/960] TRAIN loss:  1.320\n",
      "[epoch 3 Iteration 352/960] TRAIN loss:  1.188\n",
      "[epoch 3 Iteration 353/960] TRAIN loss:  1.435\n",
      "[epoch 3 Iteration 354/960] TRAIN loss:  0.795\n",
      "[epoch 3 Iteration 355/960] TRAIN loss:  0.812\n",
      "[epoch 3 Iteration 356/960] TRAIN loss:  0.984\n",
      "[epoch 3 Iteration 357/960] TRAIN loss:  0.948\n",
      "[epoch 3 Iteration 358/960] TRAIN loss:  0.957\n",
      "[epoch 3 Iteration 359/960] TRAIN loss:  1.229\n",
      "[epoch 3 Iteration 360/960] TRAIN loss:  1.014\n",
      "[epoch 3 Iteration 361/960] TRAIN loss:  1.223\n",
      "[epoch 3 Iteration 362/960] TRAIN loss:  1.112\n",
      "[epoch 3 Iteration 363/960] TRAIN loss:  1.183\n",
      "[epoch 3 Iteration 364/960] TRAIN loss:  0.876\n",
      "[epoch 3 Iteration 365/960] TRAIN loss:  1.088\n",
      "[epoch 3 Iteration 366/960] TRAIN loss:  1.044\n",
      "[epoch 3 Iteration 367/960] TRAIN loss:  0.843\n",
      "[epoch 3 Iteration 368/960] TRAIN loss:  1.417\n",
      "[epoch 3 Iteration 369/960] TRAIN loss:  1.167\n",
      "[epoch 3 Iteration 370/960] TRAIN loss:  1.007\n",
      "[epoch 3 Iteration 371/960] TRAIN loss:  1.016\n",
      "[epoch 3 Iteration 372/960] TRAIN loss:  1.203\n",
      "[epoch 3 Iteration 373/960] TRAIN loss:  1.278\n",
      "[epoch 3 Iteration 374/960] TRAIN loss:  1.207\n",
      "[epoch 3 Iteration 375/960] TRAIN loss:  0.973\n",
      "[epoch 3 Iteration 376/960] TRAIN loss:  0.941\n",
      "[epoch 3 Iteration 377/960] TRAIN loss:  1.149\n",
      "[epoch 3 Iteration 378/960] TRAIN loss:  1.132\n",
      "[epoch 3 Iteration 379/960] TRAIN loss:  0.953\n",
      "[epoch 3 Iteration 380/960] TRAIN loss:  0.947\n",
      "[epoch 3 Iteration 381/960] TRAIN loss:  0.912\n",
      "[epoch 3 Iteration 382/960] TRAIN loss:  1.038\n",
      "[epoch 3 Iteration 383/960] TRAIN loss:  1.104\n",
      "[epoch 3 Iteration 384/960] TRAIN loss:  0.973\n",
      "[epoch 3 Iteration 385/960] TRAIN loss:  1.157\n",
      "[epoch 3 Iteration 386/960] TRAIN loss:  1.258\n",
      "[epoch 3 Iteration 387/960] TRAIN loss:  0.888\n",
      "[epoch 3 Iteration 388/960] TRAIN loss:  0.975\n",
      "[epoch 3 Iteration 389/960] TRAIN loss:  1.178\n",
      "[epoch 3 Iteration 390/960] TRAIN loss:  1.195\n",
      "[epoch 3 Iteration 391/960] TRAIN loss:  1.256\n",
      "[epoch 3 Iteration 392/960] TRAIN loss:  1.108\n",
      "[epoch 3 Iteration 393/960] TRAIN loss:  1.268\n",
      "[epoch 3 Iteration 394/960] TRAIN loss:  1.041\n",
      "[epoch 3 Iteration 395/960] TRAIN loss:  1.255\n",
      "[epoch 3 Iteration 396/960] TRAIN loss:  0.985\n",
      "[epoch 3 Iteration 397/960] TRAIN loss:  1.027\n",
      "[epoch 3 Iteration 398/960] TRAIN loss:  1.058\n",
      "[epoch 3 Iteration 399/960] TRAIN loss:  1.019\n",
      "[epoch 3 Iteration 400/960] TRAIN loss:  1.109\n",
      "[epoch 3 Iteration 401/960] TRAIN loss:  1.010\n",
      "[epoch 3 Iteration 402/960] TRAIN loss:  1.127\n",
      "[epoch 3 Iteration 403/960] TRAIN loss:  1.113\n",
      "[epoch 3 Iteration 404/960] TRAIN loss:  1.052\n",
      "[epoch 3 Iteration 405/960] TRAIN loss:  0.993\n",
      "[epoch 3 Iteration 406/960] TRAIN loss:  1.033\n",
      "[epoch 3 Iteration 407/960] TRAIN loss:  1.097\n",
      "[epoch 3 Iteration 408/960] TRAIN loss:  0.979\n",
      "[epoch 3 Iteration 409/960] TRAIN loss:  1.237\n",
      "[epoch 3 Iteration 410/960] TRAIN loss:  1.051\n",
      "[epoch 3 Iteration 411/960] TRAIN loss:  0.913\n",
      "[epoch 3 Iteration 412/960] TRAIN loss:  1.056\n",
      "[epoch 3 Iteration 413/960] TRAIN loss:  1.223\n",
      "[epoch 3 Iteration 414/960] TRAIN loss:  0.748\n",
      "[epoch 3 Iteration 415/960] TRAIN loss:  1.121\n",
      "[epoch 3 Iteration 416/960] TRAIN loss:  0.866\n",
      "[epoch 3 Iteration 417/960] TRAIN loss:  1.135\n",
      "[epoch 3 Iteration 418/960] TRAIN loss:  0.939\n",
      "[epoch 3 Iteration 419/960] TRAIN loss:  0.998\n",
      "[epoch 3 Iteration 420/960] TRAIN loss:  0.847\n",
      "[epoch 3 Iteration 421/960] TRAIN loss:  1.025\n",
      "[epoch 3 Iteration 422/960] TRAIN loss:  1.257\n",
      "[epoch 3 Iteration 423/960] TRAIN loss:  1.041\n",
      "[epoch 3 Iteration 424/960] TRAIN loss:  0.788\n",
      "[epoch 3 Iteration 425/960] TRAIN loss:  1.224\n",
      "[epoch 3 Iteration 426/960] TRAIN loss:  0.907\n",
      "[epoch 3 Iteration 427/960] TRAIN loss:  0.905\n",
      "[epoch 3 Iteration 428/960] TRAIN loss:  1.277\n",
      "[epoch 3 Iteration 429/960] TRAIN loss:  1.153\n",
      "[epoch 3 Iteration 430/960] TRAIN loss:  1.239\n",
      "[epoch 3 Iteration 431/960] TRAIN loss:  1.040\n",
      "[epoch 3 Iteration 432/960] TRAIN loss:  1.035\n",
      "[epoch 3 Iteration 433/960] TRAIN loss:  0.722\n",
      "[epoch 3 Iteration 434/960] TRAIN loss:  1.017\n",
      "[epoch 3 Iteration 435/960] TRAIN loss:  1.141\n",
      "[epoch 3 Iteration 436/960] TRAIN loss:  1.355\n",
      "[epoch 3 Iteration 437/960] TRAIN loss:  0.911\n",
      "[epoch 3 Iteration 438/960] TRAIN loss:  1.192\n",
      "[epoch 3 Iteration 439/960] TRAIN loss:  1.119\n",
      "[epoch 3 Iteration 440/960] TRAIN loss:  0.952\n",
      "[epoch 3 Iteration 441/960] TRAIN loss:  1.094\n",
      "[epoch 3 Iteration 442/960] TRAIN loss:  1.281\n",
      "[epoch 3 Iteration 443/960] TRAIN loss:  1.167\n",
      "[epoch 3 Iteration 444/960] TRAIN loss:  1.021\n",
      "[epoch 3 Iteration 445/960] TRAIN loss:  1.128\n",
      "[epoch 3 Iteration 446/960] TRAIN loss:  1.352\n",
      "[epoch 3 Iteration 447/960] TRAIN loss:  1.007\n",
      "[epoch 3 Iteration 448/960] TRAIN loss:  1.132\n",
      "[epoch 3 Iteration 449/960] TRAIN loss:  1.090\n",
      "[epoch 3 Iteration 450/960] TRAIN loss:  1.225\n",
      "[epoch 3 Iteration 451/960] TRAIN loss:  0.993\n",
      "[epoch 3 Iteration 452/960] TRAIN loss:  1.285\n",
      "[epoch 3 Iteration 453/960] TRAIN loss:  0.900\n",
      "[epoch 3 Iteration 454/960] TRAIN loss:  0.972\n",
      "[epoch 3 Iteration 455/960] TRAIN loss:  1.075\n",
      "[epoch 3 Iteration 456/960] TRAIN loss:  1.141\n",
      "[epoch 3 Iteration 457/960] TRAIN loss:  1.250\n",
      "[epoch 3 Iteration 458/960] TRAIN loss:  1.318\n",
      "[epoch 3 Iteration 459/960] TRAIN loss:  1.313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3 Iteration 460/960] TRAIN loss:  0.882\n",
      "[epoch 3 Iteration 461/960] TRAIN loss:  0.923\n",
      "[epoch 3 Iteration 462/960] TRAIN loss:  0.998\n",
      "[epoch 3 Iteration 463/960] TRAIN loss:  1.014\n",
      "[epoch 3 Iteration 464/960] TRAIN loss:  1.090\n",
      "[epoch 3 Iteration 465/960] TRAIN loss:  1.033\n",
      "[epoch 3 Iteration 466/960] TRAIN loss:  1.143\n",
      "[epoch 3 Iteration 467/960] TRAIN loss:  1.035\n",
      "[epoch 3 Iteration 468/960] TRAIN loss:  0.866\n",
      "[epoch 3 Iteration 469/960] TRAIN loss:  1.035\n",
      "[epoch 3 Iteration 470/960] TRAIN loss:  0.966\n",
      "[epoch 3 Iteration 471/960] TRAIN loss:  1.076\n",
      "[epoch 3 Iteration 472/960] TRAIN loss:  1.158\n",
      "[epoch 3 Iteration 473/960] TRAIN loss:  1.091\n",
      "[epoch 3 Iteration 474/960] TRAIN loss:  1.112\n",
      "[epoch 3 Iteration 475/960] TRAIN loss:  1.275\n",
      "[epoch 3 Iteration 476/960] TRAIN loss:  0.876\n",
      "[epoch 3 Iteration 477/960] TRAIN loss:  1.144\n",
      "[epoch 3 Iteration 478/960] TRAIN loss:  1.164\n",
      "[epoch 3 Iteration 479/960] TRAIN loss:  1.070\n",
      "[epoch 3 Iteration 480/960] TRAIN loss:  0.857\n",
      "[epoch 3 Iteration 481/960] TRAIN loss:  0.881\n",
      "[epoch 3 Iteration 482/960] TRAIN loss:  1.124\n",
      "[epoch 3 Iteration 483/960] TRAIN loss:  1.214\n",
      "[epoch 3 Iteration 484/960] TRAIN loss:  1.013\n",
      "[epoch 3 Iteration 485/960] TRAIN loss:  1.090\n",
      "[epoch 3 Iteration 486/960] TRAIN loss:  1.105\n",
      "[epoch 3 Iteration 487/960] TRAIN loss:  0.941\n",
      "[epoch 3 Iteration 488/960] TRAIN loss:  1.220\n",
      "[epoch 3 Iteration 489/960] TRAIN loss:  0.874\n",
      "[epoch 3 Iteration 490/960] TRAIN loss:  0.912\n",
      "[epoch 3 Iteration 491/960] TRAIN loss:  0.926\n",
      "[epoch 3 Iteration 492/960] TRAIN loss:  1.023\n",
      "[epoch 3 Iteration 493/960] TRAIN loss:  1.093\n",
      "[epoch 3 Iteration 494/960] TRAIN loss:  1.054\n",
      "[epoch 3 Iteration 495/960] TRAIN loss:  1.013\n",
      "[epoch 3 Iteration 496/960] TRAIN loss:  1.542\n",
      "[epoch 3 Iteration 497/960] TRAIN loss:  1.090\n",
      "[epoch 3 Iteration 498/960] TRAIN loss:  1.073\n",
      "[epoch 3 Iteration 499/960] TRAIN loss:  1.059\n",
      "[epoch 3 Iteration 500/960] TRAIN loss:  1.321\n",
      "[epoch 3 Iteration 501/960] TRAIN loss:  1.068\n",
      "[epoch 3 Iteration 502/960] TRAIN loss:  1.168\n",
      "[epoch 3 Iteration 503/960] TRAIN loss:  0.913\n",
      "[epoch 3 Iteration 504/960] TRAIN loss:  0.982\n",
      "[epoch 3 Iteration 505/960] TRAIN loss:  1.062\n",
      "[epoch 3 Iteration 506/960] TRAIN loss:  0.939\n",
      "[epoch 3 Iteration 507/960] TRAIN loss:  1.240\n",
      "[epoch 3 Iteration 508/960] TRAIN loss:  1.129\n",
      "[epoch 3 Iteration 509/960] TRAIN loss:  0.892\n",
      "[epoch 3 Iteration 510/960] TRAIN loss:  0.962\n",
      "[epoch 3 Iteration 511/960] TRAIN loss:  1.017\n",
      "[epoch 3 Iteration 512/960] TRAIN loss:  1.033\n",
      "[epoch 3 Iteration 513/960] TRAIN loss:  1.165\n",
      "[epoch 3 Iteration 514/960] TRAIN loss:  1.394\n",
      "[epoch 3 Iteration 515/960] TRAIN loss:  0.861\n",
      "[epoch 3 Iteration 516/960] TRAIN loss:  1.189\n",
      "[epoch 3 Iteration 517/960] TRAIN loss:  1.277\n",
      "[epoch 3 Iteration 518/960] TRAIN loss:  0.952\n",
      "[epoch 3 Iteration 519/960] TRAIN loss:  0.823\n",
      "[epoch 3 Iteration 520/960] TRAIN loss:  0.853\n",
      "[epoch 3 Iteration 521/960] TRAIN loss:  0.799\n",
      "[epoch 3 Iteration 522/960] TRAIN loss:  1.110\n",
      "[epoch 3 Iteration 523/960] TRAIN loss:  0.962\n",
      "[epoch 3 Iteration 524/960] TRAIN loss:  1.074\n",
      "[epoch 3 Iteration 525/960] TRAIN loss:  1.050\n",
      "[epoch 3 Iteration 526/960] TRAIN loss:  0.973\n",
      "[epoch 3 Iteration 527/960] TRAIN loss:  1.247\n",
      "[epoch 3 Iteration 528/960] TRAIN loss:  0.874\n",
      "[epoch 3 Iteration 529/960] TRAIN loss:  0.857\n",
      "[epoch 3 Iteration 530/960] TRAIN loss:  0.911\n",
      "[epoch 3 Iteration 531/960] TRAIN loss:  1.424\n",
      "[epoch 3 Iteration 532/960] TRAIN loss:  1.072\n",
      "[epoch 3 Iteration 533/960] TRAIN loss:  1.013\n",
      "[epoch 3 Iteration 534/960] TRAIN loss:  1.034\n",
      "[epoch 3 Iteration 535/960] TRAIN loss:  1.022\n",
      "[epoch 3 Iteration 536/960] TRAIN loss:  1.101\n",
      "[epoch 3 Iteration 537/960] TRAIN loss:  1.153\n",
      "[epoch 3 Iteration 538/960] TRAIN loss:  0.924\n",
      "[epoch 3 Iteration 539/960] TRAIN loss:  1.079\n",
      "[epoch 3 Iteration 540/960] TRAIN loss:  0.844\n",
      "[epoch 3 Iteration 541/960] TRAIN loss:  1.194\n",
      "[epoch 3 Iteration 542/960] TRAIN loss:  0.937\n",
      "[epoch 3 Iteration 543/960] TRAIN loss:  0.855\n",
      "[epoch 3 Iteration 544/960] TRAIN loss:  1.040\n",
      "[epoch 3 Iteration 545/960] TRAIN loss:  1.206\n",
      "[epoch 3 Iteration 546/960] TRAIN loss:  1.055\n",
      "[epoch 3 Iteration 547/960] TRAIN loss:  1.126\n",
      "[epoch 3 Iteration 548/960] TRAIN loss:  1.235\n",
      "[epoch 3 Iteration 549/960] TRAIN loss:  1.172\n",
      "[epoch 3 Iteration 550/960] TRAIN loss:  0.837\n",
      "[epoch 3 Iteration 551/960] TRAIN loss:  1.159\n",
      "[epoch 3 Iteration 552/960] TRAIN loss:  1.143\n",
      "[epoch 3 Iteration 553/960] TRAIN loss:  1.453\n",
      "[epoch 3 Iteration 554/960] TRAIN loss:  1.036\n",
      "[epoch 3 Iteration 555/960] TRAIN loss:  1.308\n",
      "[epoch 3 Iteration 556/960] TRAIN loss:  0.896\n",
      "[epoch 3 Iteration 557/960] TRAIN loss:  0.780\n",
      "[epoch 3 Iteration 558/960] TRAIN loss:  0.910\n",
      "[epoch 3 Iteration 559/960] TRAIN loss:  1.140\n",
      "[epoch 3 Iteration 560/960] TRAIN loss:  1.072\n",
      "[epoch 3 Iteration 561/960] TRAIN loss:  0.753\n",
      "[epoch 3 Iteration 562/960] TRAIN loss:  1.494\n",
      "[epoch 3 Iteration 563/960] TRAIN loss:  0.946\n",
      "[epoch 3 Iteration 564/960] TRAIN loss:  1.147\n",
      "[epoch 3 Iteration 565/960] TRAIN loss:  1.066\n",
      "[epoch 3 Iteration 566/960] TRAIN loss:  1.094\n",
      "[epoch 3 Iteration 567/960] TRAIN loss:  1.016\n",
      "[epoch 3 Iteration 568/960] TRAIN loss:  1.280\n",
      "[epoch 3 Iteration 569/960] TRAIN loss:  0.807\n",
      "[epoch 3 Iteration 570/960] TRAIN loss:  0.938\n",
      "[epoch 3 Iteration 571/960] TRAIN loss:  0.951\n",
      "[epoch 3 Iteration 572/960] TRAIN loss:  1.221\n",
      "[epoch 3 Iteration 573/960] TRAIN loss:  1.120\n",
      "[epoch 3 Iteration 574/960] TRAIN loss:  1.139\n",
      "[epoch 3 Iteration 575/960] TRAIN loss:  0.940\n",
      "[epoch 3 Iteration 576/960] TRAIN loss:  1.108\n",
      "[epoch 3 Iteration 577/960] TRAIN loss:  1.336\n",
      "[epoch 3 Iteration 578/960] TRAIN loss:  1.237\n",
      "[epoch 3 Iteration 579/960] TRAIN loss:  0.993\n",
      "[epoch 3 Iteration 580/960] TRAIN loss:  1.327\n",
      "[epoch 3 Iteration 581/960] TRAIN loss:  1.084\n",
      "[epoch 3 Iteration 582/960] TRAIN loss:  1.119\n",
      "[epoch 3 Iteration 583/960] TRAIN loss:  1.104\n",
      "[epoch 3 Iteration 584/960] TRAIN loss:  0.967\n",
      "[epoch 3 Iteration 585/960] TRAIN loss:  1.143\n",
      "[epoch 3 Iteration 586/960] TRAIN loss:  0.991\n",
      "[epoch 3 Iteration 587/960] TRAIN loss:  1.479\n",
      "[epoch 3 Iteration 588/960] TRAIN loss:  1.412\n",
      "[epoch 3 Iteration 589/960] TRAIN loss:  1.172\n",
      "[epoch 3 Iteration 590/960] TRAIN loss:  0.748\n",
      "[epoch 3 Iteration 591/960] TRAIN loss:  1.037\n",
      "[epoch 3 Iteration 592/960] TRAIN loss:  0.981\n",
      "[epoch 3 Iteration 593/960] TRAIN loss:  0.935\n",
      "[epoch 3 Iteration 594/960] TRAIN loss:  1.221\n",
      "[epoch 3 Iteration 595/960] TRAIN loss:  1.090\n",
      "[epoch 3 Iteration 596/960] TRAIN loss:  1.012\n",
      "[epoch 3 Iteration 597/960] TRAIN loss:  0.905\n",
      "[epoch 3 Iteration 598/960] TRAIN loss:  0.902\n",
      "[epoch 3 Iteration 599/960] TRAIN loss:  1.052\n",
      "[epoch 3 Iteration 600/960] TRAIN loss:  0.996\n",
      "[epoch 3 Iteration 601/960] TRAIN loss:  1.072\n",
      "[epoch 3 Iteration 602/960] TRAIN loss:  1.017\n",
      "[epoch 3 Iteration 603/960] TRAIN loss:  1.027\n",
      "[epoch 3 Iteration 604/960] TRAIN loss:  1.153\n",
      "[epoch 3 Iteration 605/960] TRAIN loss:  1.187\n",
      "[epoch 3 Iteration 606/960] TRAIN loss:  0.997\n",
      "[epoch 3 Iteration 607/960] TRAIN loss:  0.912\n",
      "[epoch 3 Iteration 608/960] TRAIN loss:  1.104\n",
      "[epoch 3 Iteration 609/960] TRAIN loss:  0.964\n",
      "[epoch 3 Iteration 610/960] TRAIN loss:  0.963\n",
      "[epoch 3 Iteration 611/960] TRAIN loss:  0.991\n",
      "[epoch 3 Iteration 612/960] TRAIN loss:  1.053\n",
      "[epoch 3 Iteration 613/960] TRAIN loss:  1.072\n",
      "[epoch 3 Iteration 614/960] TRAIN loss:  1.094\n",
      "[epoch 3 Iteration 615/960] TRAIN loss:  0.950\n",
      "[epoch 3 Iteration 616/960] TRAIN loss:  1.099\n",
      "[epoch 3 Iteration 617/960] TRAIN loss:  1.009\n",
      "[epoch 3 Iteration 618/960] TRAIN loss:  0.840\n",
      "[epoch 3 Iteration 619/960] TRAIN loss:  1.237\n",
      "[epoch 3 Iteration 620/960] TRAIN loss:  1.251\n",
      "[epoch 3 Iteration 621/960] TRAIN loss:  1.069\n",
      "[epoch 3 Iteration 622/960] TRAIN loss:  1.407\n",
      "[epoch 3 Iteration 623/960] TRAIN loss:  1.091\n",
      "[epoch 3 Iteration 624/960] TRAIN loss:  1.288\n",
      "[epoch 3 Iteration 625/960] TRAIN loss:  1.118\n",
      "[epoch 3 Iteration 626/960] TRAIN loss:  1.106\n",
      "[epoch 3 Iteration 627/960] TRAIN loss:  1.190\n",
      "[epoch 3 Iteration 628/960] TRAIN loss:  1.247\n",
      "[epoch 3 Iteration 629/960] TRAIN loss:  1.008\n",
      "[epoch 3 Iteration 630/960] TRAIN loss:  0.875\n",
      "[epoch 3 Iteration 631/960] TRAIN loss:  1.070\n",
      "[epoch 3 Iteration 632/960] TRAIN loss:  0.921\n",
      "[epoch 3 Iteration 633/960] TRAIN loss:  1.091\n",
      "[epoch 3 Iteration 634/960] TRAIN loss:  1.144\n",
      "[epoch 3 Iteration 635/960] TRAIN loss:  1.112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3 Iteration 636/960] TRAIN loss:  1.019\n",
      "[epoch 3 Iteration 637/960] TRAIN loss:  0.892\n",
      "[epoch 3 Iteration 638/960] TRAIN loss:  1.045\n",
      "[epoch 3 Iteration 639/960] TRAIN loss:  1.024\n",
      "[epoch 3 Iteration 640/960] TRAIN loss:  0.935\n",
      "[epoch 3 Iteration 641/960] TRAIN loss:  1.239\n",
      "[epoch 3 Iteration 642/960] TRAIN loss:  1.026\n",
      "[epoch 3 Iteration 643/960] TRAIN loss:  1.075\n",
      "[epoch 3 Iteration 644/960] TRAIN loss:  1.529\n",
      "[epoch 3 Iteration 645/960] TRAIN loss:  1.222\n",
      "[epoch 3 Iteration 646/960] TRAIN loss:  1.149\n",
      "[epoch 3 Iteration 647/960] TRAIN loss:  1.328\n",
      "[epoch 3 Iteration 648/960] TRAIN loss:  1.209\n",
      "[epoch 3 Iteration 649/960] TRAIN loss:  1.152\n",
      "[epoch 3 Iteration 650/960] TRAIN loss:  1.064\n",
      "[epoch 3 Iteration 651/960] TRAIN loss:  0.887\n",
      "[epoch 3 Iteration 652/960] TRAIN loss:  1.308\n",
      "[epoch 3 Iteration 653/960] TRAIN loss:  1.263\n",
      "[epoch 3 Iteration 654/960] TRAIN loss:  0.997\n",
      "[epoch 3 Iteration 655/960] TRAIN loss:  1.209\n",
      "[epoch 3 Iteration 656/960] TRAIN loss:  1.154\n",
      "[epoch 3 Iteration 657/960] TRAIN loss:  1.169\n",
      "[epoch 3 Iteration 658/960] TRAIN loss:  1.170\n",
      "[epoch 3 Iteration 659/960] TRAIN loss:  1.296\n",
      "[epoch 3 Iteration 660/960] TRAIN loss:  1.077\n",
      "[epoch 3 Iteration 661/960] TRAIN loss:  1.298\n",
      "[epoch 3 Iteration 662/960] TRAIN loss:  1.132\n",
      "[epoch 3 Iteration 663/960] TRAIN loss:  1.261\n",
      "[epoch 3 Iteration 664/960] TRAIN loss:  1.087\n",
      "[epoch 3 Iteration 665/960] TRAIN loss:  1.009\n",
      "[epoch 3 Iteration 666/960] TRAIN loss:  0.960\n",
      "[epoch 3 Iteration 667/960] TRAIN loss:  1.115\n",
      "[epoch 3 Iteration 668/960] TRAIN loss:  1.015\n",
      "[epoch 3 Iteration 669/960] TRAIN loss:  0.882\n",
      "[epoch 3 Iteration 670/960] TRAIN loss:  1.133\n",
      "[epoch 3 Iteration 671/960] TRAIN loss:  0.807\n",
      "[epoch 3 Iteration 672/960] TRAIN loss:  0.947\n",
      "[epoch 3 Iteration 673/960] TRAIN loss:  1.115\n",
      "[epoch 3 Iteration 674/960] TRAIN loss:  1.034\n",
      "[epoch 3 Iteration 675/960] TRAIN loss:  1.032\n",
      "[epoch 3 Iteration 676/960] TRAIN loss:  1.087\n",
      "[epoch 3 Iteration 677/960] TRAIN loss:  1.487\n",
      "[epoch 3 Iteration 678/960] TRAIN loss:  0.935\n",
      "[epoch 3 Iteration 679/960] TRAIN loss:  1.054\n",
      "[epoch 3 Iteration 680/960] TRAIN loss:  0.859\n",
      "[epoch 3 Iteration 681/960] TRAIN loss:  1.086\n",
      "[epoch 3 Iteration 682/960] TRAIN loss:  1.501\n",
      "[epoch 3 Iteration 683/960] TRAIN loss:  0.962\n",
      "[epoch 3 Iteration 684/960] TRAIN loss:  1.238\n",
      "[epoch 3 Iteration 685/960] TRAIN loss:  1.072\n",
      "[epoch 3 Iteration 686/960] TRAIN loss:  0.883\n",
      "[epoch 3 Iteration 687/960] TRAIN loss:  1.127\n",
      "[epoch 3 Iteration 688/960] TRAIN loss:  1.279\n",
      "[epoch 3 Iteration 689/960] TRAIN loss:  0.877\n",
      "[epoch 3 Iteration 690/960] TRAIN loss:  1.122\n",
      "[epoch 3 Iteration 691/960] TRAIN loss:  1.183\n",
      "[epoch 3 Iteration 692/960] TRAIN loss:  1.161\n",
      "[epoch 3 Iteration 693/960] TRAIN loss:  1.134\n",
      "[epoch 3 Iteration 694/960] TRAIN loss:  1.448\n",
      "[epoch 3 Iteration 695/960] TRAIN loss:  1.128\n",
      "[epoch 3 Iteration 696/960] TRAIN loss:  1.276\n",
      "[epoch 3 Iteration 697/960] TRAIN loss:  1.144\n",
      "[epoch 3 Iteration 698/960] TRAIN loss:  1.032\n",
      "[epoch 3 Iteration 699/960] TRAIN loss:  1.161\n",
      "[epoch 3 Iteration 700/960] TRAIN loss:  0.975\n",
      "[epoch 3 Iteration 701/960] TRAIN loss:  1.063\n",
      "[epoch 3 Iteration 702/960] TRAIN loss:  1.093\n",
      "[epoch 3 Iteration 703/960] TRAIN loss:  0.810\n",
      "[epoch 3 Iteration 704/960] TRAIN loss:  0.986\n",
      "[epoch 3 Iteration 705/960] TRAIN loss:  1.203\n",
      "[epoch 3 Iteration 706/960] TRAIN loss:  1.167\n",
      "[epoch 3 Iteration 707/960] TRAIN loss:  1.283\n",
      "[epoch 3 Iteration 708/960] TRAIN loss:  1.020\n",
      "[epoch 3 Iteration 709/960] TRAIN loss:  1.228\n",
      "[epoch 3 Iteration 710/960] TRAIN loss:  1.050\n",
      "[epoch 3 Iteration 711/960] TRAIN loss:  1.235\n",
      "[epoch 3 Iteration 712/960] TRAIN loss:  1.186\n",
      "[epoch 3 Iteration 713/960] TRAIN loss:  0.943\n",
      "[epoch 3 Iteration 714/960] TRAIN loss:  1.095\n",
      "[epoch 3 Iteration 715/960] TRAIN loss:  1.300\n",
      "[epoch 3 Iteration 716/960] TRAIN loss:  1.152\n",
      "[epoch 3 Iteration 717/960] TRAIN loss:  0.889\n",
      "[epoch 3 Iteration 718/960] TRAIN loss:  1.023\n",
      "[epoch 3 Iteration 719/960] TRAIN loss:  0.954\n",
      "[epoch 3 Iteration 720/960] TRAIN loss:  0.936\n",
      "[epoch 3 Iteration 721/960] TRAIN loss:  1.242\n",
      "[epoch 3 Iteration 722/960] TRAIN loss:  0.933\n",
      "[epoch 3 Iteration 723/960] TRAIN loss:  0.929\n",
      "[epoch 3 Iteration 724/960] TRAIN loss:  1.173\n",
      "[epoch 3 Iteration 725/960] TRAIN loss:  0.970\n",
      "[epoch 3 Iteration 726/960] TRAIN loss:  1.175\n",
      "[epoch 3 Iteration 727/960] TRAIN loss:  0.959\n",
      "[epoch 3 Iteration 728/960] TRAIN loss:  1.305\n",
      "[epoch 3 Iteration 729/960] TRAIN loss:  1.053\n",
      "[epoch 3 Iteration 730/960] TRAIN loss:  1.040\n",
      "[epoch 3 Iteration 731/960] TRAIN loss:  0.938\n",
      "[epoch 3 Iteration 732/960] TRAIN loss:  1.082\n",
      "[epoch 3 Iteration 733/960] TRAIN loss:  1.020\n",
      "[epoch 3 Iteration 734/960] TRAIN loss:  1.266\n",
      "[epoch 3 Iteration 735/960] TRAIN loss:  0.700\n",
      "[epoch 3 Iteration 736/960] TRAIN loss:  1.008\n",
      "[epoch 3 Iteration 737/960] TRAIN loss:  1.201\n",
      "[epoch 3 Iteration 738/960] TRAIN loss:  1.110\n",
      "[epoch 3 Iteration 739/960] TRAIN loss:  1.018\n",
      "[epoch 3 Iteration 740/960] TRAIN loss:  1.150\n",
      "[epoch 3 Iteration 741/960] TRAIN loss:  1.362\n",
      "[epoch 3 Iteration 742/960] TRAIN loss:  1.045\n",
      "[epoch 3 Iteration 743/960] TRAIN loss:  0.991\n",
      "[epoch 3 Iteration 744/960] TRAIN loss:  1.046\n",
      "[epoch 3 Iteration 745/960] TRAIN loss:  0.905\n",
      "[epoch 3 Iteration 746/960] TRAIN loss:  0.941\n",
      "[epoch 3 Iteration 747/960] TRAIN loss:  0.803\n",
      "[epoch 3 Iteration 748/960] TRAIN loss:  1.170\n",
      "[epoch 3 Iteration 749/960] TRAIN loss:  1.054\n",
      "[epoch 3 Iteration 750/960] TRAIN loss:  0.953\n",
      "[epoch 3 Iteration 751/960] TRAIN loss:  1.262\n",
      "[epoch 3 Iteration 752/960] TRAIN loss:  0.998\n",
      "[epoch 3 Iteration 753/960] TRAIN loss:  0.954\n",
      "[epoch 3 Iteration 754/960] TRAIN loss:  0.893\n",
      "[epoch 3 Iteration 755/960] TRAIN loss:  1.109\n",
      "[epoch 3 Iteration 756/960] TRAIN loss:  1.228\n",
      "[epoch 3 Iteration 757/960] TRAIN loss:  1.525\n",
      "[epoch 3 Iteration 758/960] TRAIN loss:  0.860\n",
      "[epoch 3 Iteration 759/960] TRAIN loss:  0.831\n",
      "[epoch 3 Iteration 760/960] TRAIN loss:  1.094\n",
      "[epoch 3 Iteration 761/960] TRAIN loss:  0.804\n",
      "[epoch 3 Iteration 762/960] TRAIN loss:  0.787\n",
      "[epoch 3 Iteration 763/960] TRAIN loss:  1.228\n",
      "[epoch 3 Iteration 764/960] TRAIN loss:  0.820\n",
      "[epoch 3 Iteration 765/960] TRAIN loss:  0.803\n",
      "[epoch 3 Iteration 766/960] TRAIN loss:  1.017\n",
      "[epoch 3 Iteration 767/960] TRAIN loss:  1.004\n",
      "[epoch 3 Iteration 768/960] TRAIN loss:  0.867\n",
      "[epoch 3 Iteration 769/960] TRAIN loss:  0.927\n",
      "[epoch 3 Iteration 770/960] TRAIN loss:  1.206\n",
      "[epoch 3 Iteration 771/960] TRAIN loss:  0.901\n",
      "[epoch 3 Iteration 772/960] TRAIN loss:  1.139\n",
      "[epoch 3 Iteration 773/960] TRAIN loss:  0.992\n",
      "[epoch 3 Iteration 774/960] TRAIN loss:  1.006\n",
      "[epoch 3 Iteration 775/960] TRAIN loss:  0.876\n",
      "[epoch 3 Iteration 776/960] TRAIN loss:  0.943\n",
      "[epoch 3 Iteration 777/960] TRAIN loss:  1.013\n",
      "[epoch 3 Iteration 778/960] TRAIN loss:  1.237\n",
      "[epoch 3 Iteration 779/960] TRAIN loss:  1.061\n",
      "[epoch 3 Iteration 780/960] TRAIN loss:  1.142\n",
      "[epoch 3 Iteration 781/960] TRAIN loss:  1.070\n",
      "[epoch 3 Iteration 782/960] TRAIN loss:  1.030\n",
      "[epoch 3 Iteration 783/960] TRAIN loss:  1.111\n",
      "[epoch 3 Iteration 784/960] TRAIN loss:  0.983\n",
      "[epoch 3 Iteration 785/960] TRAIN loss:  1.228\n",
      "[epoch 3 Iteration 786/960] TRAIN loss:  0.873\n",
      "[epoch 3 Iteration 787/960] TRAIN loss:  0.740\n",
      "[epoch 3 Iteration 788/960] TRAIN loss:  1.048\n",
      "[epoch 3 Iteration 789/960] TRAIN loss:  1.181\n",
      "[epoch 3 Iteration 790/960] TRAIN loss:  0.936\n",
      "[epoch 3 Iteration 791/960] TRAIN loss:  1.084\n",
      "[epoch 3 Iteration 792/960] TRAIN loss:  1.253\n",
      "[epoch 3 Iteration 793/960] TRAIN loss:  1.227\n",
      "[epoch 3 Iteration 794/960] TRAIN loss:  1.198\n",
      "[epoch 3 Iteration 795/960] TRAIN loss:  1.143\n",
      "[epoch 3 Iteration 796/960] TRAIN loss:  1.116\n",
      "[epoch 3 Iteration 797/960] TRAIN loss:  1.165\n",
      "[epoch 3 Iteration 798/960] TRAIN loss:  0.901\n",
      "[epoch 3 Iteration 799/960] TRAIN loss:  1.169\n",
      "[epoch 3 Iteration 800/960] TRAIN loss:  1.139\n",
      "[epoch 3 Iteration 801/960] TRAIN loss:  0.983\n",
      "[epoch 3 Iteration 802/960] TRAIN loss:  1.291\n",
      "[epoch 3 Iteration 803/960] TRAIN loss:  1.194\n",
      "[epoch 3 Iteration 804/960] TRAIN loss:  1.082\n",
      "[epoch 3 Iteration 805/960] TRAIN loss:  1.469\n",
      "[epoch 3 Iteration 806/960] TRAIN loss:  1.008\n",
      "[epoch 3 Iteration 807/960] TRAIN loss:  1.124\n",
      "[epoch 3 Iteration 808/960] TRAIN loss:  1.236\n",
      "[epoch 3 Iteration 809/960] TRAIN loss:  1.076\n",
      "[epoch 3 Iteration 810/960] TRAIN loss:  1.024\n",
      "[epoch 3 Iteration 811/960] TRAIN loss:  0.925\n",
      "[epoch 3 Iteration 812/960] TRAIN loss:  1.132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3 Iteration 813/960] TRAIN loss:  1.036\n",
      "[epoch 3 Iteration 814/960] TRAIN loss:  1.055\n",
      "[epoch 3 Iteration 815/960] TRAIN loss:  1.279\n",
      "[epoch 3 Iteration 816/960] TRAIN loss:  1.274\n",
      "[epoch 3 Iteration 817/960] TRAIN loss:  0.952\n",
      "[epoch 3 Iteration 818/960] TRAIN loss:  1.264\n",
      "[epoch 3 Iteration 819/960] TRAIN loss:  0.974\n",
      "[epoch 3 Iteration 820/960] TRAIN loss:  1.288\n",
      "[epoch 3 Iteration 821/960] TRAIN loss:  1.077\n",
      "[epoch 3 Iteration 822/960] TRAIN loss:  0.878\n",
      "[epoch 3 Iteration 823/960] TRAIN loss:  1.137\n",
      "[epoch 3 Iteration 824/960] TRAIN loss:  1.142\n",
      "[epoch 3 Iteration 825/960] TRAIN loss:  1.099\n",
      "[epoch 3 Iteration 826/960] TRAIN loss:  0.973\n",
      "[epoch 3 Iteration 827/960] TRAIN loss:  1.054\n",
      "[epoch 3 Iteration 828/960] TRAIN loss:  1.295\n",
      "[epoch 3 Iteration 829/960] TRAIN loss:  1.337\n",
      "[epoch 3 Iteration 830/960] TRAIN loss:  0.905\n",
      "[epoch 3 Iteration 831/960] TRAIN loss:  1.011\n",
      "[epoch 3 Iteration 832/960] TRAIN loss:  0.933\n",
      "[epoch 3 Iteration 833/960] TRAIN loss:  0.960\n",
      "[epoch 3 Iteration 834/960] TRAIN loss:  0.789\n",
      "[epoch 3 Iteration 835/960] TRAIN loss:  0.636\n",
      "[epoch 3 Iteration 836/960] TRAIN loss:  1.139\n",
      "[epoch 3 Iteration 837/960] TRAIN loss:  1.014\n",
      "[epoch 3 Iteration 838/960] TRAIN loss:  1.002\n",
      "[epoch 3 Iteration 839/960] TRAIN loss:  1.006\n",
      "[epoch 3 Iteration 840/960] TRAIN loss:  1.012\n",
      "[epoch 3 Iteration 841/960] TRAIN loss:  1.018\n",
      "[epoch 3 Iteration 842/960] TRAIN loss:  0.835\n",
      "[epoch 3 Iteration 843/960] TRAIN loss:  0.822\n",
      "[epoch 3 Iteration 844/960] TRAIN loss:  1.093\n",
      "[epoch 3 Iteration 845/960] TRAIN loss:  0.760\n",
      "[epoch 3 Iteration 846/960] TRAIN loss:  1.295\n",
      "[epoch 3 Iteration 847/960] TRAIN loss:  1.344\n",
      "[epoch 3 Iteration 848/960] TRAIN loss:  1.397\n",
      "[epoch 3 Iteration 849/960] TRAIN loss:  0.927\n",
      "[epoch 3 Iteration 850/960] TRAIN loss:  1.025\n",
      "[epoch 3 Iteration 851/960] TRAIN loss:  0.985\n",
      "[epoch 3 Iteration 852/960] TRAIN loss:  0.748\n",
      "[epoch 3 Iteration 853/960] TRAIN loss:  0.853\n",
      "[epoch 3 Iteration 854/960] TRAIN loss:  0.954\n",
      "[epoch 3 Iteration 855/960] TRAIN loss:  0.962\n",
      "[epoch 3 Iteration 856/960] TRAIN loss:  1.280\n",
      "[epoch 3 Iteration 857/960] TRAIN loss:  1.011\n",
      "[epoch 3 Iteration 858/960] TRAIN loss:  0.948\n",
      "[epoch 3 Iteration 859/960] TRAIN loss:  1.194\n",
      "[epoch 3 Iteration 860/960] TRAIN loss:  0.942\n",
      "[epoch 3 Iteration 861/960] TRAIN loss:  1.077\n",
      "[epoch 3 Iteration 862/960] TRAIN loss:  1.120\n",
      "[epoch 3 Iteration 863/960] TRAIN loss:  0.785\n",
      "[epoch 3 Iteration 864/960] TRAIN loss:  0.918\n",
      "[epoch 3 Iteration 865/960] TRAIN loss:  1.125\n",
      "[epoch 3 Iteration 866/960] TRAIN loss:  0.949\n",
      "[epoch 3 Iteration 867/960] TRAIN loss:  1.016\n",
      "[epoch 3 Iteration 868/960] TRAIN loss:  1.186\n",
      "[epoch 3 Iteration 869/960] TRAIN loss:  1.179\n",
      "[epoch 3 Iteration 870/960] TRAIN loss:  1.184\n",
      "[epoch 3 Iteration 871/960] TRAIN loss:  0.898\n",
      "[epoch 3 Iteration 872/960] TRAIN loss:  1.054\n",
      "[epoch 3 Iteration 873/960] TRAIN loss:  0.979\n",
      "[epoch 3 Iteration 874/960] TRAIN loss:  1.123\n",
      "[epoch 3 Iteration 875/960] TRAIN loss:  1.144\n",
      "[epoch 3 Iteration 876/960] TRAIN loss:  1.038\n",
      "[epoch 3 Iteration 877/960] TRAIN loss:  0.879\n",
      "[epoch 3 Iteration 878/960] TRAIN loss:  1.110\n",
      "[epoch 3 Iteration 879/960] TRAIN loss:  0.915\n",
      "[epoch 3 Iteration 880/960] TRAIN loss:  1.088\n",
      "[epoch 3 Iteration 881/960] TRAIN loss:  1.004\n",
      "[epoch 3 Iteration 882/960] TRAIN loss:  0.979\n",
      "[epoch 3 Iteration 883/960] TRAIN loss:  0.942\n",
      "[epoch 3 Iteration 884/960] TRAIN loss:  1.112\n",
      "[epoch 3 Iteration 885/960] TRAIN loss:  1.019\n",
      "[epoch 3 Iteration 886/960] TRAIN loss:  1.292\n",
      "[epoch 3 Iteration 887/960] TRAIN loss:  1.091\n",
      "[epoch 3 Iteration 888/960] TRAIN loss:  1.178\n",
      "[epoch 3 Iteration 889/960] TRAIN loss:  1.229\n",
      "[epoch 3 Iteration 890/960] TRAIN loss:  0.992\n",
      "[epoch 3 Iteration 891/960] TRAIN loss:  1.074\n",
      "[epoch 3 Iteration 892/960] TRAIN loss:  1.105\n",
      "[epoch 3 Iteration 893/960] TRAIN loss:  1.094\n",
      "[epoch 3 Iteration 894/960] TRAIN loss:  1.149\n",
      "[epoch 3 Iteration 895/960] TRAIN loss:  1.200\n",
      "[epoch 3 Iteration 896/960] TRAIN loss:  1.066\n",
      "[epoch 3 Iteration 897/960] TRAIN loss:  0.959\n",
      "[epoch 3 Iteration 898/960] TRAIN loss:  1.202\n",
      "[epoch 3 Iteration 899/960] TRAIN loss:  0.942\n",
      "[epoch 3 Iteration 900/960] TRAIN loss:  0.927\n",
      "[epoch 3 Iteration 901/960] TRAIN loss:  1.437\n",
      "[epoch 3 Iteration 902/960] TRAIN loss:  1.182\n",
      "[epoch 3 Iteration 903/960] TRAIN loss:  1.250\n",
      "[epoch 3 Iteration 904/960] TRAIN loss:  1.134\n",
      "[epoch 3 Iteration 905/960] TRAIN loss:  0.920\n",
      "[epoch 3 Iteration 906/960] TRAIN loss:  1.156\n",
      "[epoch 3 Iteration 907/960] TRAIN loss:  1.016\n",
      "[epoch 3 Iteration 908/960] TRAIN loss:  0.991\n",
      "[epoch 3 Iteration 909/960] TRAIN loss:  0.936\n",
      "[epoch 3 Iteration 910/960] TRAIN loss:  0.929\n",
      "[epoch 3 Iteration 911/960] TRAIN loss:  0.954\n",
      "[epoch 3 Iteration 912/960] TRAIN loss:  1.031\n",
      "[epoch 3 Iteration 913/960] TRAIN loss:  0.743\n",
      "[epoch 3 Iteration 914/960] TRAIN loss:  1.147\n",
      "[epoch 3 Iteration 915/960] TRAIN loss:  0.872\n",
      "[epoch 3 Iteration 916/960] TRAIN loss:  0.907\n",
      "[epoch 3 Iteration 917/960] TRAIN loss:  1.160\n",
      "[epoch 3 Iteration 918/960] TRAIN loss:  1.075\n",
      "[epoch 3 Iteration 919/960] TRAIN loss:  1.130\n",
      "[epoch 3 Iteration 920/960] TRAIN loss:  1.325\n",
      "[epoch 3 Iteration 921/960] TRAIN loss:  1.290\n",
      "[epoch 3 Iteration 922/960] TRAIN loss:  1.152\n",
      "[epoch 3 Iteration 923/960] TRAIN loss:  0.902\n",
      "[epoch 3 Iteration 924/960] TRAIN loss:  1.004\n",
      "[epoch 3 Iteration 925/960] TRAIN loss:  1.015\n",
      "[epoch 3 Iteration 926/960] TRAIN loss:  1.482\n",
      "[epoch 3 Iteration 927/960] TRAIN loss:  1.019\n",
      "[epoch 3 Iteration 928/960] TRAIN loss:  1.174\n",
      "[epoch 3 Iteration 929/960] TRAIN loss:  0.945\n",
      "[epoch 3 Iteration 930/960] TRAIN loss:  0.968\n",
      "[epoch 3 Iteration 931/960] TRAIN loss:  0.911\n",
      "[epoch 3 Iteration 932/960] TRAIN loss:  1.150\n",
      "[epoch 3 Iteration 933/960] TRAIN loss:  1.336\n",
      "[epoch 3 Iteration 934/960] TRAIN loss:  1.034\n",
      "[epoch 3 Iteration 935/960] TRAIN loss:  1.165\n",
      "[epoch 3 Iteration 936/960] TRAIN loss:  1.259\n",
      "[epoch 3 Iteration 937/960] TRAIN loss:  1.143\n",
      "[epoch 3 Iteration 938/960] TRAIN loss:  0.974\n",
      "[epoch 3 Iteration 939/960] TRAIN loss:  0.890\n",
      "[epoch 3 Iteration 940/960] TRAIN loss:  1.143\n",
      "[epoch 3 Iteration 941/960] TRAIN loss:  0.969\n",
      "[epoch 3 Iteration 942/960] TRAIN loss:  1.224\n",
      "[epoch 3 Iteration 943/960] TRAIN loss:  0.917\n",
      "[epoch 3 Iteration 944/960] TRAIN loss:  1.168\n",
      "[epoch 3 Iteration 945/960] TRAIN loss:  1.112\n",
      "[epoch 3 Iteration 946/960] TRAIN loss:  1.018\n",
      "[epoch 3 Iteration 947/960] TRAIN loss:  1.234\n",
      "[epoch 3 Iteration 948/960] TRAIN loss:  1.216\n",
      "[epoch 3 Iteration 949/960] TRAIN loss:  1.004\n",
      "[epoch 3 Iteration 950/960] TRAIN loss:  1.125\n",
      "[epoch 3 Iteration 951/960] TRAIN loss:  1.077\n",
      "[epoch 3 Iteration 952/960] TRAIN loss:  1.168\n",
      "[epoch 3 Iteration 953/960] TRAIN loss:  0.915\n",
      "[epoch 3 Iteration 954/960] TRAIN loss:  1.163\n",
      "[epoch 3 Iteration 955/960] TRAIN loss:  1.231\n",
      "[epoch 3 Iteration 956/960] TRAIN loss:  0.897\n",
      "[epoch 3 Iteration 957/960] TRAIN loss:  1.204\n",
      "[epoch 3 Iteration 958/960] TRAIN loss:  0.859\n",
      "[epoch 3 Iteration 959/960] TRAIN loss:  1.111\n",
      "[epoch 3/15] TRAIN acc/loss:  0.621/1.111\n",
      "[epoch 3/15] VAL acc/loss:  0.580/0.709\n",
      "[epoch 4 Iteration 0/960] TRAIN loss:  0.828\n",
      "[epoch 4 Iteration 1/960] TRAIN loss:  0.967\n",
      "[epoch 4 Iteration 2/960] TRAIN loss:  0.943\n",
      "[epoch 4 Iteration 3/960] TRAIN loss:  1.097\n",
      "[epoch 4 Iteration 4/960] TRAIN loss:  1.096\n",
      "[epoch 4 Iteration 5/960] TRAIN loss:  0.806\n",
      "[epoch 4 Iteration 6/960] TRAIN loss:  0.889\n",
      "[epoch 4 Iteration 7/960] TRAIN loss:  1.038\n",
      "[epoch 4 Iteration 8/960] TRAIN loss:  0.776\n",
      "[epoch 4 Iteration 9/960] TRAIN loss:  0.841\n",
      "[epoch 4 Iteration 10/960] TRAIN loss:  1.124\n",
      "[epoch 4 Iteration 11/960] TRAIN loss:  0.902\n",
      "[epoch 4 Iteration 12/960] TRAIN loss:  1.079\n",
      "[epoch 4 Iteration 13/960] TRAIN loss:  0.910\n",
      "[epoch 4 Iteration 14/960] TRAIN loss:  0.995\n",
      "[epoch 4 Iteration 15/960] TRAIN loss:  1.194\n",
      "[epoch 4 Iteration 16/960] TRAIN loss:  1.130\n",
      "[epoch 4 Iteration 17/960] TRAIN loss:  1.059\n",
      "[epoch 4 Iteration 18/960] TRAIN loss:  0.763\n",
      "[epoch 4 Iteration 19/960] TRAIN loss:  0.836\n",
      "[epoch 4 Iteration 20/960] TRAIN loss:  0.946\n",
      "[epoch 4 Iteration 21/960] TRAIN loss:  1.022\n",
      "[epoch 4 Iteration 22/960] TRAIN loss:  1.510\n",
      "[epoch 4 Iteration 23/960] TRAIN loss:  1.110\n",
      "[epoch 4 Iteration 24/960] TRAIN loss:  0.981\n",
      "[epoch 4 Iteration 25/960] TRAIN loss:  1.185\n",
      "[epoch 4 Iteration 26/960] TRAIN loss:  1.329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4 Iteration 27/960] TRAIN loss:  1.064\n",
      "[epoch 4 Iteration 28/960] TRAIN loss:  0.683\n",
      "[epoch 4 Iteration 29/960] TRAIN loss:  0.941\n",
      "[epoch 4 Iteration 30/960] TRAIN loss:  1.148\n",
      "[epoch 4 Iteration 31/960] TRAIN loss:  0.798\n",
      "[epoch 4 Iteration 32/960] TRAIN loss:  0.877\n",
      "[epoch 4 Iteration 33/960] TRAIN loss:  1.057\n",
      "[epoch 4 Iteration 34/960] TRAIN loss:  1.134\n",
      "[epoch 4 Iteration 35/960] TRAIN loss:  1.006\n",
      "[epoch 4 Iteration 36/960] TRAIN loss:  0.855\n",
      "[epoch 4 Iteration 37/960] TRAIN loss:  1.118\n",
      "[epoch 4 Iteration 38/960] TRAIN loss:  0.985\n",
      "[epoch 4 Iteration 39/960] TRAIN loss:  0.919\n",
      "[epoch 4 Iteration 40/960] TRAIN loss:  1.012\n",
      "[epoch 4 Iteration 41/960] TRAIN loss:  1.019\n",
      "[epoch 4 Iteration 42/960] TRAIN loss:  0.830\n",
      "[epoch 4 Iteration 43/960] TRAIN loss:  1.221\n",
      "[epoch 4 Iteration 44/960] TRAIN loss:  0.992\n",
      "[epoch 4 Iteration 45/960] TRAIN loss:  1.019\n",
      "[epoch 4 Iteration 46/960] TRAIN loss:  0.948\n",
      "[epoch 4 Iteration 47/960] TRAIN loss:  1.031\n",
      "[epoch 4 Iteration 48/960] TRAIN loss:  1.089\n",
      "[epoch 4 Iteration 49/960] TRAIN loss:  1.017\n",
      "[epoch 4 Iteration 50/960] TRAIN loss:  1.175\n",
      "[epoch 4 Iteration 51/960] TRAIN loss:  0.973\n",
      "[epoch 4 Iteration 52/960] TRAIN loss:  0.724\n",
      "[epoch 4 Iteration 53/960] TRAIN loss:  1.001\n",
      "[epoch 4 Iteration 54/960] TRAIN loss:  1.060\n",
      "[epoch 4 Iteration 55/960] TRAIN loss:  1.001\n",
      "[epoch 4 Iteration 56/960] TRAIN loss:  0.910\n",
      "[epoch 4 Iteration 57/960] TRAIN loss:  1.143\n",
      "[epoch 4 Iteration 58/960] TRAIN loss:  0.880\n",
      "[epoch 4 Iteration 59/960] TRAIN loss:  0.882\n",
      "[epoch 4 Iteration 60/960] TRAIN loss:  1.199\n",
      "[epoch 4 Iteration 61/960] TRAIN loss:  1.029\n",
      "[epoch 4 Iteration 62/960] TRAIN loss:  0.883\n",
      "[epoch 4 Iteration 63/960] TRAIN loss:  1.029\n",
      "[epoch 4 Iteration 64/960] TRAIN loss:  1.084\n",
      "[epoch 4 Iteration 65/960] TRAIN loss:  1.029\n",
      "[epoch 4 Iteration 66/960] TRAIN loss:  1.000\n",
      "[epoch 4 Iteration 67/960] TRAIN loss:  1.258\n",
      "[epoch 4 Iteration 68/960] TRAIN loss:  1.005\n",
      "[epoch 4 Iteration 69/960] TRAIN loss:  0.684\n",
      "[epoch 4 Iteration 70/960] TRAIN loss:  1.198\n",
      "[epoch 4 Iteration 71/960] TRAIN loss:  0.954\n",
      "[epoch 4 Iteration 72/960] TRAIN loss:  1.121\n",
      "[epoch 4 Iteration 73/960] TRAIN loss:  1.174\n",
      "[epoch 4 Iteration 74/960] TRAIN loss:  0.909\n",
      "[epoch 4 Iteration 75/960] TRAIN loss:  1.029\n",
      "[epoch 4 Iteration 76/960] TRAIN loss:  0.915\n",
      "[epoch 4 Iteration 77/960] TRAIN loss:  1.084\n",
      "[epoch 4 Iteration 78/960] TRAIN loss:  1.205\n",
      "[epoch 4 Iteration 79/960] TRAIN loss:  0.784\n",
      "[epoch 4 Iteration 80/960] TRAIN loss:  1.170\n",
      "[epoch 4 Iteration 81/960] TRAIN loss:  0.954\n",
      "[epoch 4 Iteration 82/960] TRAIN loss:  1.049\n",
      "[epoch 4 Iteration 83/960] TRAIN loss:  1.141\n",
      "[epoch 4 Iteration 84/960] TRAIN loss:  1.503\n",
      "[epoch 4 Iteration 85/960] TRAIN loss:  1.137\n",
      "[epoch 4 Iteration 86/960] TRAIN loss:  0.960\n",
      "[epoch 4 Iteration 87/960] TRAIN loss:  1.083\n",
      "[epoch 4 Iteration 88/960] TRAIN loss:  0.939\n",
      "[epoch 4 Iteration 89/960] TRAIN loss:  1.009\n",
      "[epoch 4 Iteration 90/960] TRAIN loss:  0.836\n",
      "[epoch 4 Iteration 91/960] TRAIN loss:  0.647\n",
      "[epoch 4 Iteration 92/960] TRAIN loss:  1.057\n",
      "[epoch 4 Iteration 93/960] TRAIN loss:  1.014\n",
      "[epoch 4 Iteration 94/960] TRAIN loss:  1.077\n",
      "[epoch 4 Iteration 95/960] TRAIN loss:  1.101\n",
      "[epoch 4 Iteration 96/960] TRAIN loss:  0.951\n",
      "[epoch 4 Iteration 97/960] TRAIN loss:  0.905\n",
      "[epoch 4 Iteration 98/960] TRAIN loss:  0.933\n",
      "[epoch 4 Iteration 99/960] TRAIN loss:  0.776\n",
      "[epoch 4 Iteration 100/960] TRAIN loss:  0.960\n",
      "[epoch 4 Iteration 101/960] TRAIN loss:  0.772\n",
      "[epoch 4 Iteration 102/960] TRAIN loss:  0.798\n",
      "[epoch 4 Iteration 103/960] TRAIN loss:  0.940\n",
      "[epoch 4 Iteration 104/960] TRAIN loss:  1.034\n",
      "[epoch 4 Iteration 105/960] TRAIN loss:  0.944\n",
      "[epoch 4 Iteration 106/960] TRAIN loss:  1.056\n",
      "[epoch 4 Iteration 107/960] TRAIN loss:  0.959\n",
      "[epoch 4 Iteration 108/960] TRAIN loss:  1.017\n",
      "[epoch 4 Iteration 109/960] TRAIN loss:  0.990\n",
      "[epoch 4 Iteration 110/960] TRAIN loss:  0.871\n",
      "[epoch 4 Iteration 111/960] TRAIN loss:  0.612\n",
      "[epoch 4 Iteration 112/960] TRAIN loss:  0.875\n",
      "[epoch 4 Iteration 113/960] TRAIN loss:  1.165\n",
      "[epoch 4 Iteration 114/960] TRAIN loss:  1.092\n",
      "[epoch 4 Iteration 115/960] TRAIN loss:  0.922\n",
      "[epoch 4 Iteration 116/960] TRAIN loss:  0.760\n",
      "[epoch 4 Iteration 117/960] TRAIN loss:  0.866\n",
      "[epoch 4 Iteration 118/960] TRAIN loss:  0.985\n",
      "[epoch 4 Iteration 119/960] TRAIN loss:  0.925\n",
      "[epoch 4 Iteration 120/960] TRAIN loss:  1.215\n",
      "[epoch 4 Iteration 121/960] TRAIN loss:  0.935\n",
      "[epoch 4 Iteration 122/960] TRAIN loss:  1.254\n",
      "[epoch 4 Iteration 123/960] TRAIN loss:  0.950\n",
      "[epoch 4 Iteration 124/960] TRAIN loss:  1.244\n",
      "[epoch 4 Iteration 125/960] TRAIN loss:  1.016\n",
      "[epoch 4 Iteration 126/960] TRAIN loss:  0.867\n",
      "[epoch 4 Iteration 127/960] TRAIN loss:  0.839\n",
      "[epoch 4 Iteration 128/960] TRAIN loss:  1.025\n",
      "[epoch 4 Iteration 129/960] TRAIN loss:  1.008\n",
      "[epoch 4 Iteration 130/960] TRAIN loss:  1.066\n",
      "[epoch 4 Iteration 131/960] TRAIN loss:  1.082\n",
      "[epoch 4 Iteration 132/960] TRAIN loss:  0.895\n",
      "[epoch 4 Iteration 133/960] TRAIN loss:  0.881\n",
      "[epoch 4 Iteration 134/960] TRAIN loss:  1.008\n",
      "[epoch 4 Iteration 135/960] TRAIN loss:  1.153\n",
      "[epoch 4 Iteration 136/960] TRAIN loss:  0.972\n",
      "[epoch 4 Iteration 137/960] TRAIN loss:  1.196\n",
      "[epoch 4 Iteration 138/960] TRAIN loss:  0.916\n",
      "[epoch 4 Iteration 139/960] TRAIN loss:  1.205\n",
      "[epoch 4 Iteration 140/960] TRAIN loss:  0.874\n",
      "[epoch 4 Iteration 141/960] TRAIN loss:  0.925\n",
      "[epoch 4 Iteration 142/960] TRAIN loss:  0.924\n",
      "[epoch 4 Iteration 143/960] TRAIN loss:  0.898\n",
      "[epoch 4 Iteration 144/960] TRAIN loss:  1.125\n",
      "[epoch 4 Iteration 145/960] TRAIN loss:  1.047\n",
      "[epoch 4 Iteration 146/960] TRAIN loss:  0.877\n",
      "[epoch 4 Iteration 147/960] TRAIN loss:  1.071\n",
      "[epoch 4 Iteration 148/960] TRAIN loss:  1.082\n",
      "[epoch 4 Iteration 149/960] TRAIN loss:  1.169\n",
      "[epoch 4 Iteration 150/960] TRAIN loss:  0.926\n",
      "[epoch 4 Iteration 151/960] TRAIN loss:  0.959\n",
      "[epoch 4 Iteration 152/960] TRAIN loss:  1.020\n",
      "[epoch 4 Iteration 153/960] TRAIN loss:  0.835\n",
      "[epoch 4 Iteration 154/960] TRAIN loss:  0.919\n",
      "[epoch 4 Iteration 155/960] TRAIN loss:  0.985\n",
      "[epoch 4 Iteration 156/960] TRAIN loss:  0.978\n",
      "[epoch 4 Iteration 157/960] TRAIN loss:  0.911\n",
      "[epoch 4 Iteration 158/960] TRAIN loss:  1.150\n",
      "[epoch 4 Iteration 159/960] TRAIN loss:  0.963\n",
      "[epoch 4 Iteration 160/960] TRAIN loss:  0.972\n",
      "[epoch 4 Iteration 161/960] TRAIN loss:  1.147\n",
      "[epoch 4 Iteration 162/960] TRAIN loss:  0.852\n",
      "[epoch 4 Iteration 163/960] TRAIN loss:  0.670\n",
      "[epoch 4 Iteration 164/960] TRAIN loss:  0.900\n",
      "[epoch 4 Iteration 165/960] TRAIN loss:  1.276\n",
      "[epoch 4 Iteration 166/960] TRAIN loss:  1.349\n",
      "[epoch 4 Iteration 167/960] TRAIN loss:  0.924\n",
      "[epoch 4 Iteration 168/960] TRAIN loss:  1.160\n",
      "[epoch 4 Iteration 169/960] TRAIN loss:  0.919\n",
      "[epoch 4 Iteration 170/960] TRAIN loss:  0.915\n",
      "[epoch 4 Iteration 171/960] TRAIN loss:  1.160\n",
      "[epoch 4 Iteration 172/960] TRAIN loss:  1.280\n",
      "[epoch 4 Iteration 173/960] TRAIN loss:  0.931\n",
      "[epoch 4 Iteration 174/960] TRAIN loss:  1.248\n",
      "[epoch 4 Iteration 175/960] TRAIN loss:  1.123\n",
      "[epoch 4 Iteration 176/960] TRAIN loss:  0.864\n",
      "[epoch 4 Iteration 177/960] TRAIN loss:  1.058\n",
      "[epoch 4 Iteration 178/960] TRAIN loss:  0.918\n",
      "[epoch 4 Iteration 179/960] TRAIN loss:  1.017\n",
      "[epoch 4 Iteration 180/960] TRAIN loss:  1.043\n",
      "[epoch 4 Iteration 181/960] TRAIN loss:  1.103\n",
      "[epoch 4 Iteration 182/960] TRAIN loss:  0.775\n",
      "[epoch 4 Iteration 183/960] TRAIN loss:  1.076\n",
      "[epoch 4 Iteration 184/960] TRAIN loss:  0.898\n",
      "[epoch 4 Iteration 185/960] TRAIN loss:  0.961\n",
      "[epoch 4 Iteration 186/960] TRAIN loss:  1.045\n",
      "[epoch 4 Iteration 187/960] TRAIN loss:  0.854\n",
      "[epoch 4 Iteration 188/960] TRAIN loss:  0.902\n",
      "[epoch 4 Iteration 189/960] TRAIN loss:  0.982\n",
      "[epoch 4 Iteration 190/960] TRAIN loss:  0.929\n",
      "[epoch 4 Iteration 191/960] TRAIN loss:  1.229\n",
      "[epoch 4 Iteration 192/960] TRAIN loss:  1.187\n",
      "[epoch 4 Iteration 193/960] TRAIN loss:  1.121\n",
      "[epoch 4 Iteration 194/960] TRAIN loss:  1.109\n",
      "[epoch 4 Iteration 195/960] TRAIN loss:  0.795\n",
      "[epoch 4 Iteration 196/960] TRAIN loss:  1.063\n",
      "[epoch 4 Iteration 197/960] TRAIN loss:  1.131\n",
      "[epoch 4 Iteration 198/960] TRAIN loss:  0.963\n",
      "[epoch 4 Iteration 199/960] TRAIN loss:  0.962\n",
      "[epoch 4 Iteration 200/960] TRAIN loss:  0.954\n",
      "[epoch 4 Iteration 201/960] TRAIN loss:  1.245\n",
      "[epoch 4 Iteration 202/960] TRAIN loss:  1.000\n",
      "[epoch 4 Iteration 203/960] TRAIN loss:  1.018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4 Iteration 204/960] TRAIN loss:  0.900\n",
      "[epoch 4 Iteration 205/960] TRAIN loss:  1.077\n",
      "[epoch 4 Iteration 206/960] TRAIN loss:  1.093\n",
      "[epoch 4 Iteration 207/960] TRAIN loss:  0.988\n",
      "[epoch 4 Iteration 208/960] TRAIN loss:  0.786\n",
      "[epoch 4 Iteration 209/960] TRAIN loss:  1.345\n",
      "[epoch 4 Iteration 210/960] TRAIN loss:  1.304\n",
      "[epoch 4 Iteration 211/960] TRAIN loss:  0.892\n",
      "[epoch 4 Iteration 212/960] TRAIN loss:  1.182\n",
      "[epoch 4 Iteration 213/960] TRAIN loss:  0.960\n",
      "[epoch 4 Iteration 214/960] TRAIN loss:  1.098\n",
      "[epoch 4 Iteration 215/960] TRAIN loss:  1.068\n",
      "[epoch 4 Iteration 216/960] TRAIN loss:  1.125\n",
      "[epoch 4 Iteration 217/960] TRAIN loss:  1.110\n",
      "[epoch 4 Iteration 218/960] TRAIN loss:  1.269\n",
      "[epoch 4 Iteration 219/960] TRAIN loss:  1.028\n",
      "[epoch 4 Iteration 220/960] TRAIN loss:  1.113\n",
      "[epoch 4 Iteration 221/960] TRAIN loss:  0.790\n",
      "[epoch 4 Iteration 222/960] TRAIN loss:  1.040\n",
      "[epoch 4 Iteration 223/960] TRAIN loss:  1.110\n",
      "[epoch 4 Iteration 224/960] TRAIN loss:  1.222\n",
      "[epoch 4 Iteration 225/960] TRAIN loss:  1.036\n",
      "[epoch 4 Iteration 226/960] TRAIN loss:  1.007\n",
      "[epoch 4 Iteration 227/960] TRAIN loss:  1.334\n",
      "[epoch 4 Iteration 228/960] TRAIN loss:  0.937\n",
      "[epoch 4 Iteration 229/960] TRAIN loss:  1.153\n",
      "[epoch 4 Iteration 230/960] TRAIN loss:  1.037\n",
      "[epoch 4 Iteration 231/960] TRAIN loss:  0.888\n",
      "[epoch 4 Iteration 232/960] TRAIN loss:  1.107\n",
      "[epoch 4 Iteration 233/960] TRAIN loss:  1.101\n",
      "[epoch 4 Iteration 234/960] TRAIN loss:  0.998\n",
      "[epoch 4 Iteration 235/960] TRAIN loss:  0.832\n",
      "[epoch 4 Iteration 236/960] TRAIN loss:  1.104\n",
      "[epoch 4 Iteration 237/960] TRAIN loss:  1.441\n",
      "[epoch 4 Iteration 238/960] TRAIN loss:  0.785\n",
      "[epoch 4 Iteration 239/960] TRAIN loss:  1.117\n",
      "[epoch 4 Iteration 240/960] TRAIN loss:  1.018\n",
      "[epoch 4 Iteration 241/960] TRAIN loss:  0.960\n",
      "[epoch 4 Iteration 242/960] TRAIN loss:  0.805\n",
      "[epoch 4 Iteration 243/960] TRAIN loss:  1.086\n",
      "[epoch 4 Iteration 244/960] TRAIN loss:  0.938\n",
      "[epoch 4 Iteration 245/960] TRAIN loss:  1.217\n",
      "[epoch 4 Iteration 246/960] TRAIN loss:  0.762\n",
      "[epoch 4 Iteration 247/960] TRAIN loss:  1.065\n",
      "[epoch 4 Iteration 248/960] TRAIN loss:  1.039\n",
      "[epoch 4 Iteration 249/960] TRAIN loss:  1.000\n",
      "[epoch 4 Iteration 250/960] TRAIN loss:  1.189\n",
      "[epoch 4 Iteration 251/960] TRAIN loss:  0.984\n",
      "[epoch 4 Iteration 252/960] TRAIN loss:  0.844\n",
      "[epoch 4 Iteration 253/960] TRAIN loss:  0.823\n",
      "[epoch 4 Iteration 254/960] TRAIN loss:  0.979\n",
      "[epoch 4 Iteration 255/960] TRAIN loss:  0.810\n",
      "[epoch 4 Iteration 256/960] TRAIN loss:  0.988\n",
      "[epoch 4 Iteration 257/960] TRAIN loss:  1.059\n",
      "[epoch 4 Iteration 258/960] TRAIN loss:  1.002\n",
      "[epoch 4 Iteration 259/960] TRAIN loss:  1.090\n",
      "[epoch 4 Iteration 260/960] TRAIN loss:  0.777\n",
      "[epoch 4 Iteration 261/960] TRAIN loss:  0.710\n",
      "[epoch 4 Iteration 262/960] TRAIN loss:  1.027\n",
      "[epoch 4 Iteration 263/960] TRAIN loss:  0.661\n",
      "[epoch 4 Iteration 264/960] TRAIN loss:  0.933\n",
      "[epoch 4 Iteration 265/960] TRAIN loss:  1.077\n",
      "[epoch 4 Iteration 266/960] TRAIN loss:  1.029\n",
      "[epoch 4 Iteration 267/960] TRAIN loss:  0.823\n",
      "[epoch 4 Iteration 268/960] TRAIN loss:  1.441\n",
      "[epoch 4 Iteration 269/960] TRAIN loss:  0.874\n",
      "[epoch 4 Iteration 270/960] TRAIN loss:  1.043\n",
      "[epoch 4 Iteration 271/960] TRAIN loss:  1.011\n",
      "[epoch 4 Iteration 272/960] TRAIN loss:  0.960\n",
      "[epoch 4 Iteration 273/960] TRAIN loss:  0.832\n",
      "[epoch 4 Iteration 274/960] TRAIN loss:  1.193\n",
      "[epoch 4 Iteration 275/960] TRAIN loss:  1.027\n",
      "[epoch 4 Iteration 276/960] TRAIN loss:  1.160\n",
      "[epoch 4 Iteration 277/960] TRAIN loss:  0.868\n",
      "[epoch 4 Iteration 278/960] TRAIN loss:  1.083\n",
      "[epoch 4 Iteration 279/960] TRAIN loss:  0.966\n",
      "[epoch 4 Iteration 280/960] TRAIN loss:  0.926\n",
      "[epoch 4 Iteration 281/960] TRAIN loss:  1.212\n",
      "[epoch 4 Iteration 282/960] TRAIN loss:  0.916\n",
      "[epoch 4 Iteration 283/960] TRAIN loss:  0.765\n",
      "[epoch 4 Iteration 284/960] TRAIN loss:  0.907\n",
      "[epoch 4 Iteration 285/960] TRAIN loss:  0.901\n",
      "[epoch 4 Iteration 286/960] TRAIN loss:  1.442\n",
      "[epoch 4 Iteration 287/960] TRAIN loss:  0.885\n",
      "[epoch 4 Iteration 288/960] TRAIN loss:  1.051\n",
      "[epoch 4 Iteration 289/960] TRAIN loss:  1.104\n",
      "[epoch 4 Iteration 290/960] TRAIN loss:  0.784\n",
      "[epoch 4 Iteration 291/960] TRAIN loss:  1.010\n",
      "[epoch 4 Iteration 292/960] TRAIN loss:  1.028\n",
      "[epoch 4 Iteration 293/960] TRAIN loss:  0.946\n",
      "[epoch 4 Iteration 294/960] TRAIN loss:  0.986\n",
      "[epoch 4 Iteration 295/960] TRAIN loss:  0.820\n",
      "[epoch 4 Iteration 296/960] TRAIN loss:  1.019\n",
      "[epoch 4 Iteration 297/960] TRAIN loss:  0.834\n",
      "[epoch 4 Iteration 298/960] TRAIN loss:  0.859\n",
      "[epoch 4 Iteration 299/960] TRAIN loss:  0.924\n",
      "[epoch 4 Iteration 300/960] TRAIN loss:  1.013\n",
      "[epoch 4 Iteration 301/960] TRAIN loss:  0.958\n",
      "[epoch 4 Iteration 302/960] TRAIN loss:  1.042\n",
      "[epoch 4 Iteration 303/960] TRAIN loss:  0.895\n",
      "[epoch 4 Iteration 304/960] TRAIN loss:  1.087\n",
      "[epoch 4 Iteration 305/960] TRAIN loss:  1.186\n",
      "[epoch 4 Iteration 306/960] TRAIN loss:  0.871\n",
      "[epoch 4 Iteration 307/960] TRAIN loss:  0.942\n",
      "[epoch 4 Iteration 308/960] TRAIN loss:  0.999\n",
      "[epoch 4 Iteration 309/960] TRAIN loss:  0.998\n",
      "[epoch 4 Iteration 310/960] TRAIN loss:  1.095\n",
      "[epoch 4 Iteration 311/960] TRAIN loss:  0.838\n",
      "[epoch 4 Iteration 312/960] TRAIN loss:  1.145\n",
      "[epoch 4 Iteration 313/960] TRAIN loss:  1.029\n",
      "[epoch 4 Iteration 314/960] TRAIN loss:  1.265\n",
      "[epoch 4 Iteration 315/960] TRAIN loss:  1.007\n",
      "[epoch 4 Iteration 316/960] TRAIN loss:  0.837\n",
      "[epoch 4 Iteration 317/960] TRAIN loss:  1.138\n",
      "[epoch 4 Iteration 318/960] TRAIN loss:  1.429\n",
      "[epoch 4 Iteration 319/960] TRAIN loss:  0.971\n",
      "[epoch 4 Iteration 320/960] TRAIN loss:  0.926\n",
      "[epoch 4 Iteration 321/960] TRAIN loss:  0.668\n",
      "[epoch 4 Iteration 322/960] TRAIN loss:  0.952\n",
      "[epoch 4 Iteration 323/960] TRAIN loss:  0.826\n",
      "[epoch 4 Iteration 324/960] TRAIN loss:  0.940\n",
      "[epoch 4 Iteration 325/960] TRAIN loss:  0.958\n",
      "[epoch 4 Iteration 326/960] TRAIN loss:  1.027\n",
      "[epoch 4 Iteration 327/960] TRAIN loss:  0.867\n",
      "[epoch 4 Iteration 328/960] TRAIN loss:  0.856\n",
      "[epoch 4 Iteration 329/960] TRAIN loss:  1.037\n",
      "[epoch 4 Iteration 330/960] TRAIN loss:  1.037\n",
      "[epoch 4 Iteration 331/960] TRAIN loss:  1.132\n",
      "[epoch 4 Iteration 332/960] TRAIN loss:  0.869\n",
      "[epoch 4 Iteration 333/960] TRAIN loss:  1.113\n",
      "[epoch 4 Iteration 334/960] TRAIN loss:  0.889\n",
      "[epoch 4 Iteration 335/960] TRAIN loss:  1.124\n",
      "[epoch 4 Iteration 336/960] TRAIN loss:  0.936\n",
      "[epoch 4 Iteration 337/960] TRAIN loss:  0.838\n",
      "[epoch 4 Iteration 338/960] TRAIN loss:  0.892\n",
      "[epoch 4 Iteration 339/960] TRAIN loss:  0.885\n",
      "[epoch 4 Iteration 340/960] TRAIN loss:  0.910\n",
      "[epoch 4 Iteration 341/960] TRAIN loss:  1.132\n",
      "[epoch 4 Iteration 342/960] TRAIN loss:  0.921\n",
      "[epoch 4 Iteration 343/960] TRAIN loss:  1.313\n",
      "[epoch 4 Iteration 344/960] TRAIN loss:  1.072\n",
      "[epoch 4 Iteration 345/960] TRAIN loss:  1.043\n",
      "[epoch 4 Iteration 346/960] TRAIN loss:  1.028\n",
      "[epoch 4 Iteration 347/960] TRAIN loss:  0.751\n",
      "[epoch 4 Iteration 348/960] TRAIN loss:  1.003\n",
      "[epoch 4 Iteration 349/960] TRAIN loss:  1.171\n",
      "[epoch 4 Iteration 350/960] TRAIN loss:  1.003\n",
      "[epoch 4 Iteration 351/960] TRAIN loss:  1.455\n",
      "[epoch 4 Iteration 352/960] TRAIN loss:  1.226\n",
      "[epoch 4 Iteration 353/960] TRAIN loss:  1.456\n",
      "[epoch 4 Iteration 354/960] TRAIN loss:  1.095\n",
      "[epoch 4 Iteration 355/960] TRAIN loss:  1.244\n",
      "[epoch 4 Iteration 356/960] TRAIN loss:  0.782\n",
      "[epoch 4 Iteration 357/960] TRAIN loss:  1.067\n",
      "[epoch 4 Iteration 358/960] TRAIN loss:  0.829\n",
      "[epoch 4 Iteration 359/960] TRAIN loss:  0.785\n",
      "[epoch 4 Iteration 360/960] TRAIN loss:  1.145\n",
      "[epoch 4 Iteration 361/960] TRAIN loss:  1.046\n",
      "[epoch 4 Iteration 362/960] TRAIN loss:  1.138\n",
      "[epoch 4 Iteration 363/960] TRAIN loss:  1.046\n",
      "[epoch 4 Iteration 364/960] TRAIN loss:  0.991\n",
      "[epoch 4 Iteration 365/960] TRAIN loss:  1.391\n",
      "[epoch 4 Iteration 366/960] TRAIN loss:  0.968\n",
      "[epoch 4 Iteration 367/960] TRAIN loss:  0.961\n",
      "[epoch 4 Iteration 368/960] TRAIN loss:  1.195\n",
      "[epoch 4 Iteration 369/960] TRAIN loss:  1.281\n",
      "[epoch 4 Iteration 370/960] TRAIN loss:  1.168\n",
      "[epoch 4 Iteration 371/960] TRAIN loss:  0.861\n",
      "[epoch 4 Iteration 372/960] TRAIN loss:  1.228\n",
      "[epoch 4 Iteration 373/960] TRAIN loss:  1.264\n",
      "[epoch 4 Iteration 374/960] TRAIN loss:  1.063\n",
      "[epoch 4 Iteration 375/960] TRAIN loss:  0.884\n",
      "[epoch 4 Iteration 376/960] TRAIN loss:  0.830\n",
      "[epoch 4 Iteration 377/960] TRAIN loss:  1.303\n",
      "[epoch 4 Iteration 378/960] TRAIN loss:  0.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4 Iteration 379/960] TRAIN loss:  1.154\n",
      "[epoch 4 Iteration 380/960] TRAIN loss:  1.041\n",
      "[epoch 4 Iteration 381/960] TRAIN loss:  1.037\n",
      "[epoch 4 Iteration 382/960] TRAIN loss:  0.833\n",
      "[epoch 4 Iteration 383/960] TRAIN loss:  0.978\n",
      "[epoch 4 Iteration 384/960] TRAIN loss:  1.160\n",
      "[epoch 4 Iteration 385/960] TRAIN loss:  1.221\n",
      "[epoch 4 Iteration 386/960] TRAIN loss:  1.050\n",
      "[epoch 4 Iteration 387/960] TRAIN loss:  0.864\n",
      "[epoch 4 Iteration 388/960] TRAIN loss:  1.157\n",
      "[epoch 4 Iteration 389/960] TRAIN loss:  1.181\n",
      "[epoch 4 Iteration 390/960] TRAIN loss:  0.877\n",
      "[epoch 4 Iteration 391/960] TRAIN loss:  0.849\n",
      "[epoch 4 Iteration 392/960] TRAIN loss:  0.986\n",
      "[epoch 4 Iteration 393/960] TRAIN loss:  1.004\n",
      "[epoch 4 Iteration 394/960] TRAIN loss:  0.840\n",
      "[epoch 4 Iteration 395/960] TRAIN loss:  0.797\n",
      "[epoch 4 Iteration 396/960] TRAIN loss:  0.951\n",
      "[epoch 4 Iteration 397/960] TRAIN loss:  1.109\n",
      "[epoch 4 Iteration 398/960] TRAIN loss:  0.939\n",
      "[epoch 4 Iteration 399/960] TRAIN loss:  1.032\n",
      "[epoch 4 Iteration 400/960] TRAIN loss:  1.010\n",
      "[epoch 4 Iteration 401/960] TRAIN loss:  0.883\n",
      "[epoch 4 Iteration 402/960] TRAIN loss:  0.772\n",
      "[epoch 4 Iteration 403/960] TRAIN loss:  0.920\n",
      "[epoch 4 Iteration 404/960] TRAIN loss:  0.813\n",
      "[epoch 4 Iteration 405/960] TRAIN loss:  0.847\n",
      "[epoch 4 Iteration 406/960] TRAIN loss:  0.922\n",
      "[epoch 4 Iteration 407/960] TRAIN loss:  1.106\n",
      "[epoch 4 Iteration 408/960] TRAIN loss:  0.838\n",
      "[epoch 4 Iteration 409/960] TRAIN loss:  1.005\n",
      "[epoch 4 Iteration 410/960] TRAIN loss:  1.032\n",
      "[epoch 4 Iteration 411/960] TRAIN loss:  0.822\n",
      "[epoch 4 Iteration 412/960] TRAIN loss:  0.919\n",
      "[epoch 4 Iteration 413/960] TRAIN loss:  1.166\n",
      "[epoch 4 Iteration 414/960] TRAIN loss:  1.052\n",
      "[epoch 4 Iteration 415/960] TRAIN loss:  0.889\n",
      "[epoch 4 Iteration 416/960] TRAIN loss:  1.035\n",
      "[epoch 4 Iteration 417/960] TRAIN loss:  0.793\n",
      "[epoch 4 Iteration 418/960] TRAIN loss:  1.018\n",
      "[epoch 4 Iteration 419/960] TRAIN loss:  0.934\n",
      "[epoch 4 Iteration 420/960] TRAIN loss:  0.926\n",
      "[epoch 4 Iteration 421/960] TRAIN loss:  1.190\n",
      "[epoch 4 Iteration 422/960] TRAIN loss:  0.835\n",
      "[epoch 4 Iteration 423/960] TRAIN loss:  0.815\n",
      "[epoch 4 Iteration 424/960] TRAIN loss:  0.981\n",
      "[epoch 4 Iteration 425/960] TRAIN loss:  1.065\n",
      "[epoch 4 Iteration 426/960] TRAIN loss:  1.283\n",
      "[epoch 4 Iteration 427/960] TRAIN loss:  0.777\n",
      "[epoch 4 Iteration 428/960] TRAIN loss:  0.951\n",
      "[epoch 4 Iteration 429/960] TRAIN loss:  0.716\n",
      "[epoch 4 Iteration 430/960] TRAIN loss:  0.995\n",
      "[epoch 4 Iteration 431/960] TRAIN loss:  1.031\n",
      "[epoch 4 Iteration 432/960] TRAIN loss:  0.890\n",
      "[epoch 4 Iteration 433/960] TRAIN loss:  1.125\n",
      "[epoch 4 Iteration 434/960] TRAIN loss:  1.349\n",
      "[epoch 4 Iteration 435/960] TRAIN loss:  0.836\n",
      "[epoch 4 Iteration 436/960] TRAIN loss:  1.273\n",
      "[epoch 4 Iteration 437/960] TRAIN loss:  1.178\n",
      "[epoch 4 Iteration 438/960] TRAIN loss:  1.053\n",
      "[epoch 4 Iteration 439/960] TRAIN loss:  1.045\n",
      "[epoch 4 Iteration 440/960] TRAIN loss:  1.256\n",
      "[epoch 4 Iteration 441/960] TRAIN loss:  1.255\n",
      "[epoch 4 Iteration 442/960] TRAIN loss:  0.876\n",
      "[epoch 4 Iteration 443/960] TRAIN loss:  0.903\n",
      "[epoch 4 Iteration 444/960] TRAIN loss:  0.924\n",
      "[epoch 4 Iteration 445/960] TRAIN loss:  1.155\n",
      "[epoch 4 Iteration 446/960] TRAIN loss:  0.840\n",
      "[epoch 4 Iteration 447/960] TRAIN loss:  0.804\n",
      "[epoch 4 Iteration 448/960] TRAIN loss:  0.944\n",
      "[epoch 4 Iteration 449/960] TRAIN loss:  1.058\n",
      "[epoch 4 Iteration 450/960] TRAIN loss:  0.948\n",
      "[epoch 4 Iteration 451/960] TRAIN loss:  0.986\n",
      "[epoch 4 Iteration 452/960] TRAIN loss:  1.069\n",
      "[epoch 4 Iteration 453/960] TRAIN loss:  1.065\n",
      "[epoch 4 Iteration 454/960] TRAIN loss:  0.860\n",
      "[epoch 4 Iteration 455/960] TRAIN loss:  1.140\n",
      "[epoch 4 Iteration 456/960] TRAIN loss:  0.790\n",
      "[epoch 4 Iteration 457/960] TRAIN loss:  0.828\n",
      "[epoch 4 Iteration 458/960] TRAIN loss:  0.874\n",
      "[epoch 4 Iteration 459/960] TRAIN loss:  0.930\n",
      "[epoch 4 Iteration 460/960] TRAIN loss:  1.060\n",
      "[epoch 4 Iteration 461/960] TRAIN loss:  0.987\n",
      "[epoch 4 Iteration 462/960] TRAIN loss:  1.104\n",
      "[epoch 4 Iteration 463/960] TRAIN loss:  0.767\n",
      "[epoch 4 Iteration 464/960] TRAIN loss:  0.744\n",
      "[epoch 4 Iteration 465/960] TRAIN loss:  0.942\n",
      "[epoch 4 Iteration 466/960] TRAIN loss:  1.267\n",
      "[epoch 4 Iteration 467/960] TRAIN loss:  0.927\n",
      "[epoch 4 Iteration 468/960] TRAIN loss:  1.080\n",
      "[epoch 4 Iteration 469/960] TRAIN loss:  0.863\n",
      "[epoch 4 Iteration 470/960] TRAIN loss:  0.992\n",
      "[epoch 4 Iteration 471/960] TRAIN loss:  0.944\n",
      "[epoch 4 Iteration 472/960] TRAIN loss:  0.984\n",
      "[epoch 4 Iteration 473/960] TRAIN loss:  1.125\n",
      "[epoch 4 Iteration 474/960] TRAIN loss:  0.948\n",
      "[epoch 4 Iteration 475/960] TRAIN loss:  1.070\n",
      "[epoch 4 Iteration 476/960] TRAIN loss:  1.115\n",
      "[epoch 4 Iteration 477/960] TRAIN loss:  0.960\n",
      "[epoch 4 Iteration 478/960] TRAIN loss:  0.911\n",
      "[epoch 4 Iteration 479/960] TRAIN loss:  0.873\n",
      "[epoch 4 Iteration 480/960] TRAIN loss:  0.958\n",
      "[epoch 4 Iteration 481/960] TRAIN loss:  0.918\n",
      "[epoch 4 Iteration 482/960] TRAIN loss:  0.997\n",
      "[epoch 4 Iteration 483/960] TRAIN loss:  0.817\n",
      "[epoch 4 Iteration 484/960] TRAIN loss:  0.925\n",
      "[epoch 4 Iteration 485/960] TRAIN loss:  1.045\n",
      "[epoch 4 Iteration 486/960] TRAIN loss:  1.217\n",
      "[epoch 4 Iteration 487/960] TRAIN loss:  1.152\n",
      "[epoch 4 Iteration 488/960] TRAIN loss:  1.001\n",
      "[epoch 4 Iteration 489/960] TRAIN loss:  1.099\n",
      "[epoch 4 Iteration 490/960] TRAIN loss:  0.707\n",
      "[epoch 4 Iteration 491/960] TRAIN loss:  0.971\n",
      "[epoch 4 Iteration 492/960] TRAIN loss:  1.142\n",
      "[epoch 4 Iteration 493/960] TRAIN loss:  1.015\n",
      "[epoch 4 Iteration 494/960] TRAIN loss:  0.929\n",
      "[epoch 4 Iteration 495/960] TRAIN loss:  1.092\n",
      "[epoch 4 Iteration 496/960] TRAIN loss:  0.817\n",
      "[epoch 4 Iteration 497/960] TRAIN loss:  0.969\n",
      "[epoch 4 Iteration 498/960] TRAIN loss:  1.112\n",
      "[epoch 4 Iteration 499/960] TRAIN loss:  1.108\n",
      "[epoch 4 Iteration 500/960] TRAIN loss:  0.932\n",
      "[epoch 4 Iteration 501/960] TRAIN loss:  1.205\n",
      "[epoch 4 Iteration 502/960] TRAIN loss:  0.871\n",
      "[epoch 4 Iteration 503/960] TRAIN loss:  0.931\n",
      "[epoch 4 Iteration 504/960] TRAIN loss:  1.138\n",
      "[epoch 4 Iteration 505/960] TRAIN loss:  0.887\n",
      "[epoch 4 Iteration 506/960] TRAIN loss:  1.080\n",
      "[epoch 4 Iteration 507/960] TRAIN loss:  1.047\n",
      "[epoch 4 Iteration 508/960] TRAIN loss:  1.158\n",
      "[epoch 4 Iteration 509/960] TRAIN loss:  1.230\n",
      "[epoch 4 Iteration 510/960] TRAIN loss:  1.073\n",
      "[epoch 4 Iteration 511/960] TRAIN loss:  1.095\n",
      "[epoch 4 Iteration 512/960] TRAIN loss:  0.958\n",
      "[epoch 4 Iteration 513/960] TRAIN loss:  1.039\n",
      "[epoch 4 Iteration 514/960] TRAIN loss:  1.021\n",
      "[epoch 4 Iteration 515/960] TRAIN loss:  1.023\n",
      "[epoch 4 Iteration 516/960] TRAIN loss:  0.795\n",
      "[epoch 4 Iteration 517/960] TRAIN loss:  1.003\n",
      "[epoch 4 Iteration 518/960] TRAIN loss:  0.903\n",
      "[epoch 4 Iteration 519/960] TRAIN loss:  1.048\n",
      "[epoch 4 Iteration 520/960] TRAIN loss:  0.945\n",
      "[epoch 4 Iteration 521/960] TRAIN loss:  1.122\n",
      "[epoch 4 Iteration 522/960] TRAIN loss:  1.223\n",
      "[epoch 4 Iteration 523/960] TRAIN loss:  0.640\n",
      "[epoch 4 Iteration 524/960] TRAIN loss:  1.101\n",
      "[epoch 4 Iteration 525/960] TRAIN loss:  1.113\n",
      "[epoch 4 Iteration 526/960] TRAIN loss:  0.960\n",
      "[epoch 4 Iteration 527/960] TRAIN loss:  0.895\n",
      "[epoch 4 Iteration 528/960] TRAIN loss:  0.909\n",
      "[epoch 4 Iteration 529/960] TRAIN loss:  0.840\n",
      "[epoch 4 Iteration 530/960] TRAIN loss:  0.932\n",
      "[epoch 4 Iteration 531/960] TRAIN loss:  1.048\n",
      "[epoch 4 Iteration 532/960] TRAIN loss:  0.872\n",
      "[epoch 4 Iteration 533/960] TRAIN loss:  1.124\n",
      "[epoch 4 Iteration 534/960] TRAIN loss:  0.693\n",
      "[epoch 4 Iteration 535/960] TRAIN loss:  1.001\n",
      "[epoch 4 Iteration 536/960] TRAIN loss:  1.053\n",
      "[epoch 4 Iteration 537/960] TRAIN loss:  0.857\n",
      "[epoch 4 Iteration 538/960] TRAIN loss:  1.027\n",
      "[epoch 4 Iteration 539/960] TRAIN loss:  0.989\n",
      "[epoch 4 Iteration 540/960] TRAIN loss:  0.935\n",
      "[epoch 4 Iteration 541/960] TRAIN loss:  1.011\n",
      "[epoch 4 Iteration 542/960] TRAIN loss:  0.989\n",
      "[epoch 4 Iteration 543/960] TRAIN loss:  0.781\n",
      "[epoch 4 Iteration 544/960] TRAIN loss:  1.049\n",
      "[epoch 4 Iteration 545/960] TRAIN loss:  0.866\n",
      "[epoch 4 Iteration 546/960] TRAIN loss:  1.243\n",
      "[epoch 4 Iteration 547/960] TRAIN loss:  0.761\n",
      "[epoch 4 Iteration 548/960] TRAIN loss:  0.990\n",
      "[epoch 4 Iteration 549/960] TRAIN loss:  1.034\n",
      "[epoch 4 Iteration 550/960] TRAIN loss:  1.142\n",
      "[epoch 4 Iteration 551/960] TRAIN loss:  0.961\n",
      "[epoch 4 Iteration 552/960] TRAIN loss:  0.987\n",
      "[epoch 4 Iteration 553/960] TRAIN loss:  0.881\n",
      "[epoch 4 Iteration 554/960] TRAIN loss:  1.054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4 Iteration 555/960] TRAIN loss:  0.871\n",
      "[epoch 4 Iteration 556/960] TRAIN loss:  0.701\n",
      "[epoch 4 Iteration 557/960] TRAIN loss:  1.128\n",
      "[epoch 4 Iteration 558/960] TRAIN loss:  1.302\n",
      "[epoch 4 Iteration 559/960] TRAIN loss:  1.087\n",
      "[epoch 4 Iteration 560/960] TRAIN loss:  1.248\n",
      "[epoch 4 Iteration 561/960] TRAIN loss:  0.890\n",
      "[epoch 4 Iteration 562/960] TRAIN loss:  0.793\n",
      "[epoch 4 Iteration 563/960] TRAIN loss:  1.107\n",
      "[epoch 4 Iteration 564/960] TRAIN loss:  0.963\n",
      "[epoch 4 Iteration 565/960] TRAIN loss:  0.901\n",
      "[epoch 4 Iteration 566/960] TRAIN loss:  1.170\n",
      "[epoch 4 Iteration 567/960] TRAIN loss:  0.932\n",
      "[epoch 4 Iteration 568/960] TRAIN loss:  1.363\n",
      "[epoch 4 Iteration 569/960] TRAIN loss:  1.168\n",
      "[epoch 4 Iteration 570/960] TRAIN loss:  0.737\n",
      "[epoch 4 Iteration 571/960] TRAIN loss:  0.960\n",
      "[epoch 4 Iteration 572/960] TRAIN loss:  0.927\n",
      "[epoch 4 Iteration 573/960] TRAIN loss:  1.114\n",
      "[epoch 4 Iteration 574/960] TRAIN loss:  0.889\n",
      "[epoch 4 Iteration 575/960] TRAIN loss:  1.182\n",
      "[epoch 4 Iteration 576/960] TRAIN loss:  1.024\n",
      "[epoch 4 Iteration 577/960] TRAIN loss:  0.977\n",
      "[epoch 4 Iteration 578/960] TRAIN loss:  0.830\n",
      "[epoch 4 Iteration 579/960] TRAIN loss:  0.990\n",
      "[epoch 4 Iteration 580/960] TRAIN loss:  1.047\n",
      "[epoch 4 Iteration 581/960] TRAIN loss:  1.114\n",
      "[epoch 4 Iteration 582/960] TRAIN loss:  0.984\n",
      "[epoch 4 Iteration 583/960] TRAIN loss:  0.850\n",
      "[epoch 4 Iteration 584/960] TRAIN loss:  1.108\n",
      "[epoch 4 Iteration 585/960] TRAIN loss:  0.966\n",
      "[epoch 4 Iteration 586/960] TRAIN loss:  1.106\n",
      "[epoch 4 Iteration 587/960] TRAIN loss:  0.997\n",
      "[epoch 4 Iteration 588/960] TRAIN loss:  1.028\n",
      "[epoch 4 Iteration 589/960] TRAIN loss:  1.203\n",
      "[epoch 4 Iteration 590/960] TRAIN loss:  0.982\n",
      "[epoch 4 Iteration 591/960] TRAIN loss:  0.907\n",
      "[epoch 4 Iteration 592/960] TRAIN loss:  0.990\n",
      "[epoch 4 Iteration 593/960] TRAIN loss:  0.989\n",
      "[epoch 4 Iteration 594/960] TRAIN loss:  1.157\n",
      "[epoch 4 Iteration 595/960] TRAIN loss:  0.803\n",
      "[epoch 4 Iteration 596/960] TRAIN loss:  1.161\n",
      "[epoch 4 Iteration 597/960] TRAIN loss:  0.880\n",
      "[epoch 4 Iteration 598/960] TRAIN loss:  1.080\n",
      "[epoch 4 Iteration 599/960] TRAIN loss:  1.051\n",
      "[epoch 4 Iteration 600/960] TRAIN loss:  0.905\n",
      "[epoch 4 Iteration 601/960] TRAIN loss:  0.986\n",
      "[epoch 4 Iteration 602/960] TRAIN loss:  0.934\n",
      "[epoch 4 Iteration 603/960] TRAIN loss:  0.949\n",
      "[epoch 4 Iteration 604/960] TRAIN loss:  0.842\n",
      "[epoch 4 Iteration 605/960] TRAIN loss:  0.888\n",
      "[epoch 4 Iteration 606/960] TRAIN loss:  1.159\n",
      "[epoch 4 Iteration 607/960] TRAIN loss:  0.960\n",
      "[epoch 4 Iteration 608/960] TRAIN loss:  0.896\n",
      "[epoch 4 Iteration 609/960] TRAIN loss:  0.848\n",
      "[epoch 4 Iteration 610/960] TRAIN loss:  0.972\n",
      "[epoch 4 Iteration 611/960] TRAIN loss:  1.150\n",
      "[epoch 4 Iteration 612/960] TRAIN loss:  0.902\n",
      "[epoch 4 Iteration 613/960] TRAIN loss:  0.842\n",
      "[epoch 4 Iteration 614/960] TRAIN loss:  1.118\n",
      "[epoch 4 Iteration 615/960] TRAIN loss:  1.125\n",
      "[epoch 4 Iteration 616/960] TRAIN loss:  0.933\n",
      "[epoch 4 Iteration 617/960] TRAIN loss:  1.032\n",
      "[epoch 4 Iteration 618/960] TRAIN loss:  0.649\n",
      "[epoch 4 Iteration 619/960] TRAIN loss:  0.923\n",
      "[epoch 4 Iteration 620/960] TRAIN loss:  1.121\n",
      "[epoch 4 Iteration 621/960] TRAIN loss:  0.969\n",
      "[epoch 4 Iteration 622/960] TRAIN loss:  0.889\n",
      "[epoch 4 Iteration 623/960] TRAIN loss:  1.314\n",
      "[epoch 4 Iteration 624/960] TRAIN loss:  1.092\n",
      "[epoch 4 Iteration 625/960] TRAIN loss:  1.193\n",
      "[epoch 4 Iteration 626/960] TRAIN loss:  1.172\n",
      "[epoch 4 Iteration 627/960] TRAIN loss:  1.062\n",
      "[epoch 4 Iteration 628/960] TRAIN loss:  1.091\n",
      "[epoch 4 Iteration 629/960] TRAIN loss:  0.914\n",
      "[epoch 4 Iteration 630/960] TRAIN loss:  1.028\n",
      "[epoch 4 Iteration 631/960] TRAIN loss:  1.065\n",
      "[epoch 4 Iteration 632/960] TRAIN loss:  1.036\n",
      "[epoch 4 Iteration 633/960] TRAIN loss:  0.912\n",
      "[epoch 4 Iteration 634/960] TRAIN loss:  0.668\n",
      "[epoch 4 Iteration 635/960] TRAIN loss:  0.867\n",
      "[epoch 4 Iteration 636/960] TRAIN loss:  0.904\n",
      "[epoch 4 Iteration 637/960] TRAIN loss:  1.078\n",
      "[epoch 4 Iteration 638/960] TRAIN loss:  0.817\n",
      "[epoch 4 Iteration 639/960] TRAIN loss:  0.883\n",
      "[epoch 4 Iteration 640/960] TRAIN loss:  0.932\n",
      "[epoch 4 Iteration 641/960] TRAIN loss:  1.073\n",
      "[epoch 4 Iteration 642/960] TRAIN loss:  1.198\n",
      "[epoch 4 Iteration 643/960] TRAIN loss:  1.128\n",
      "[epoch 4 Iteration 644/960] TRAIN loss:  0.989\n",
      "[epoch 4 Iteration 645/960] TRAIN loss:  0.860\n",
      "[epoch 4 Iteration 646/960] TRAIN loss:  1.156\n",
      "[epoch 4 Iteration 647/960] TRAIN loss:  0.932\n",
      "[epoch 4 Iteration 648/960] TRAIN loss:  0.969\n",
      "[epoch 4 Iteration 649/960] TRAIN loss:  1.140\n",
      "[epoch 4 Iteration 650/960] TRAIN loss:  1.067\n",
      "[epoch 4 Iteration 651/960] TRAIN loss:  1.020\n",
      "[epoch 4 Iteration 652/960] TRAIN loss:  1.222\n",
      "[epoch 4 Iteration 653/960] TRAIN loss:  1.066\n",
      "[epoch 4 Iteration 654/960] TRAIN loss:  0.736\n",
      "[epoch 4 Iteration 655/960] TRAIN loss:  0.858\n",
      "[epoch 4 Iteration 656/960] TRAIN loss:  1.074\n",
      "[epoch 4 Iteration 657/960] TRAIN loss:  0.939\n",
      "[epoch 4 Iteration 658/960] TRAIN loss:  1.056\n",
      "[epoch 4 Iteration 659/960] TRAIN loss:  0.876\n",
      "[epoch 4 Iteration 660/960] TRAIN loss:  0.988\n",
      "[epoch 4 Iteration 661/960] TRAIN loss:  0.853\n",
      "[epoch 4 Iteration 662/960] TRAIN loss:  1.065\n",
      "[epoch 4 Iteration 663/960] TRAIN loss:  1.188\n",
      "[epoch 4 Iteration 664/960] TRAIN loss:  1.142\n",
      "[epoch 4 Iteration 665/960] TRAIN loss:  1.039\n",
      "[epoch 4 Iteration 666/960] TRAIN loss:  0.902\n",
      "[epoch 4 Iteration 667/960] TRAIN loss:  0.892\n",
      "[epoch 4 Iteration 668/960] TRAIN loss:  1.037\n",
      "[epoch 4 Iteration 669/960] TRAIN loss:  0.869\n",
      "[epoch 4 Iteration 670/960] TRAIN loss:  0.801\n",
      "[epoch 4 Iteration 671/960] TRAIN loss:  0.724\n",
      "[epoch 4 Iteration 672/960] TRAIN loss:  0.812\n",
      "[epoch 4 Iteration 673/960] TRAIN loss:  1.057\n",
      "[epoch 4 Iteration 674/960] TRAIN loss:  0.739\n",
      "[epoch 4 Iteration 675/960] TRAIN loss:  1.134\n",
      "[epoch 4 Iteration 676/960] TRAIN loss:  1.056\n",
      "[epoch 4 Iteration 677/960] TRAIN loss:  0.945\n",
      "[epoch 4 Iteration 678/960] TRAIN loss:  0.710\n",
      "[epoch 4 Iteration 679/960] TRAIN loss:  0.695\n",
      "[epoch 4 Iteration 680/960] TRAIN loss:  0.699\n",
      "[epoch 4 Iteration 681/960] TRAIN loss:  0.985\n",
      "[epoch 4 Iteration 682/960] TRAIN loss:  0.790\n",
      "[epoch 4 Iteration 683/960] TRAIN loss:  1.045\n",
      "[epoch 4 Iteration 684/960] TRAIN loss:  0.763\n",
      "[epoch 4 Iteration 685/960] TRAIN loss:  0.671\n",
      "[epoch 4 Iteration 686/960] TRAIN loss:  1.419\n",
      "[epoch 4 Iteration 687/960] TRAIN loss:  1.201\n",
      "[epoch 4 Iteration 688/960] TRAIN loss:  1.002\n",
      "[epoch 4 Iteration 689/960] TRAIN loss:  1.005\n",
      "[epoch 4 Iteration 690/960] TRAIN loss:  0.982\n",
      "[epoch 4 Iteration 691/960] TRAIN loss:  0.974\n",
      "[epoch 4 Iteration 692/960] TRAIN loss:  0.917\n",
      "[epoch 4 Iteration 693/960] TRAIN loss:  0.914\n",
      "[epoch 4 Iteration 694/960] TRAIN loss:  0.921\n",
      "[epoch 4 Iteration 695/960] TRAIN loss:  0.710\n",
      "[epoch 4 Iteration 696/960] TRAIN loss:  0.867\n",
      "[epoch 4 Iteration 697/960] TRAIN loss:  0.806\n",
      "[epoch 4 Iteration 698/960] TRAIN loss:  0.726\n",
      "[epoch 4 Iteration 699/960] TRAIN loss:  1.268\n",
      "[epoch 4 Iteration 700/960] TRAIN loss:  1.128\n",
      "[epoch 4 Iteration 701/960] TRAIN loss:  0.910\n",
      "[epoch 4 Iteration 702/960] TRAIN loss:  1.283\n",
      "[epoch 4 Iteration 703/960] TRAIN loss:  1.222\n",
      "[epoch 4 Iteration 704/960] TRAIN loss:  1.022\n",
      "[epoch 4 Iteration 705/960] TRAIN loss:  0.809\n",
      "[epoch 4 Iteration 706/960] TRAIN loss:  0.810\n",
      "[epoch 4 Iteration 707/960] TRAIN loss:  1.044\n",
      "[epoch 4 Iteration 708/960] TRAIN loss:  1.036\n",
      "[epoch 4 Iteration 709/960] TRAIN loss:  0.729\n",
      "[epoch 4 Iteration 710/960] TRAIN loss:  0.745\n",
      "[epoch 4 Iteration 711/960] TRAIN loss:  0.985\n",
      "[epoch 4 Iteration 712/960] TRAIN loss:  1.083\n",
      "[epoch 4 Iteration 713/960] TRAIN loss:  0.718\n",
      "[epoch 4 Iteration 714/960] TRAIN loss:  0.802\n",
      "[epoch 4 Iteration 715/960] TRAIN loss:  0.888\n",
      "[epoch 4 Iteration 716/960] TRAIN loss:  0.989\n",
      "[epoch 4 Iteration 717/960] TRAIN loss:  1.135\n",
      "[epoch 4 Iteration 718/960] TRAIN loss:  1.010\n",
      "[epoch 4 Iteration 719/960] TRAIN loss:  1.051\n",
      "[epoch 4 Iteration 720/960] TRAIN loss:  1.269\n",
      "[epoch 4 Iteration 721/960] TRAIN loss:  0.988\n",
      "[epoch 4 Iteration 722/960] TRAIN loss:  0.928\n",
      "[epoch 4 Iteration 723/960] TRAIN loss:  1.448\n",
      "[epoch 4 Iteration 724/960] TRAIN loss:  0.841\n",
      "[epoch 4 Iteration 725/960] TRAIN loss:  0.992\n",
      "[epoch 4 Iteration 726/960] TRAIN loss:  1.078\n",
      "[epoch 4 Iteration 727/960] TRAIN loss:  1.038\n",
      "[epoch 4 Iteration 728/960] TRAIN loss:  1.149\n",
      "[epoch 4 Iteration 729/960] TRAIN loss:  1.123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4 Iteration 730/960] TRAIN loss:  1.349\n",
      "[epoch 4 Iteration 731/960] TRAIN loss:  0.923\n",
      "[epoch 4 Iteration 732/960] TRAIN loss:  1.037\n",
      "[epoch 4 Iteration 733/960] TRAIN loss:  0.852\n",
      "[epoch 4 Iteration 734/960] TRAIN loss:  0.782\n",
      "[epoch 4 Iteration 735/960] TRAIN loss:  1.060\n",
      "[epoch 4 Iteration 736/960] TRAIN loss:  0.804\n",
      "[epoch 4 Iteration 737/960] TRAIN loss:  0.966\n",
      "[epoch 4 Iteration 738/960] TRAIN loss:  1.063\n",
      "[epoch 4 Iteration 739/960] TRAIN loss:  1.039\n",
      "[epoch 4 Iteration 740/960] TRAIN loss:  1.032\n",
      "[epoch 4 Iteration 741/960] TRAIN loss:  1.438\n",
      "[epoch 4 Iteration 742/960] TRAIN loss:  1.210\n",
      "[epoch 4 Iteration 743/960] TRAIN loss:  1.073\n",
      "[epoch 4 Iteration 744/960] TRAIN loss:  0.990\n",
      "[epoch 4 Iteration 745/960] TRAIN loss:  1.053\n",
      "[epoch 4 Iteration 746/960] TRAIN loss:  0.782\n",
      "[epoch 4 Iteration 747/960] TRAIN loss:  1.078\n",
      "[epoch 4 Iteration 748/960] TRAIN loss:  1.095\n",
      "[epoch 4 Iteration 749/960] TRAIN loss:  0.738\n",
      "[epoch 4 Iteration 750/960] TRAIN loss:  0.950\n",
      "[epoch 4 Iteration 751/960] TRAIN loss:  0.832\n",
      "[epoch 4 Iteration 752/960] TRAIN loss:  0.972\n",
      "[epoch 4 Iteration 753/960] TRAIN loss:  1.286\n",
      "[epoch 4 Iteration 754/960] TRAIN loss:  1.080\n",
      "[epoch 4 Iteration 755/960] TRAIN loss:  0.712\n",
      "[epoch 4 Iteration 756/960] TRAIN loss:  0.888\n",
      "[epoch 4 Iteration 757/960] TRAIN loss:  1.189\n",
      "[epoch 4 Iteration 758/960] TRAIN loss:  0.882\n",
      "[epoch 4 Iteration 759/960] TRAIN loss:  0.691\n",
      "[epoch 4 Iteration 760/960] TRAIN loss:  0.872\n",
      "[epoch 4 Iteration 761/960] TRAIN loss:  0.901\n",
      "[epoch 4 Iteration 762/960] TRAIN loss:  1.061\n",
      "[epoch 4 Iteration 763/960] TRAIN loss:  1.143\n",
      "[epoch 4 Iteration 764/960] TRAIN loss:  0.944\n",
      "[epoch 4 Iteration 765/960] TRAIN loss:  0.905\n",
      "[epoch 4 Iteration 766/960] TRAIN loss:  1.100\n",
      "[epoch 4 Iteration 767/960] TRAIN loss:  0.820\n",
      "[epoch 4 Iteration 768/960] TRAIN loss:  0.622\n",
      "[epoch 4 Iteration 769/960] TRAIN loss:  1.013\n",
      "[epoch 4 Iteration 770/960] TRAIN loss:  1.402\n",
      "[epoch 4 Iteration 771/960] TRAIN loss:  0.964\n",
      "[epoch 4 Iteration 772/960] TRAIN loss:  1.022\n",
      "[epoch 4 Iteration 773/960] TRAIN loss:  1.498\n",
      "[epoch 4 Iteration 774/960] TRAIN loss:  0.798\n",
      "[epoch 4 Iteration 775/960] TRAIN loss:  0.823\n",
      "[epoch 4 Iteration 776/960] TRAIN loss:  1.063\n",
      "[epoch 4 Iteration 777/960] TRAIN loss:  0.873\n",
      "[epoch 4 Iteration 778/960] TRAIN loss:  1.207\n",
      "[epoch 4 Iteration 779/960] TRAIN loss:  0.928\n",
      "[epoch 4 Iteration 780/960] TRAIN loss:  0.864\n",
      "[epoch 4 Iteration 781/960] TRAIN loss:  0.765\n",
      "[epoch 4 Iteration 782/960] TRAIN loss:  0.993\n",
      "[epoch 4 Iteration 783/960] TRAIN loss:  1.212\n",
      "[epoch 4 Iteration 784/960] TRAIN loss:  0.849\n",
      "[epoch 4 Iteration 785/960] TRAIN loss:  1.065\n",
      "[epoch 4 Iteration 786/960] TRAIN loss:  0.790\n",
      "[epoch 4 Iteration 787/960] TRAIN loss:  1.216\n",
      "[epoch 4 Iteration 788/960] TRAIN loss:  0.858\n",
      "[epoch 4 Iteration 789/960] TRAIN loss:  0.979\n",
      "[epoch 4 Iteration 790/960] TRAIN loss:  1.156\n",
      "[epoch 4 Iteration 791/960] TRAIN loss:  1.107\n",
      "[epoch 4 Iteration 792/960] TRAIN loss:  0.837\n",
      "[epoch 4 Iteration 793/960] TRAIN loss:  1.044\n",
      "[epoch 4 Iteration 794/960] TRAIN loss:  0.997\n",
      "[epoch 4 Iteration 795/960] TRAIN loss:  1.105\n",
      "[epoch 4 Iteration 796/960] TRAIN loss:  0.895\n",
      "[epoch 4 Iteration 797/960] TRAIN loss:  0.909\n",
      "[epoch 4 Iteration 798/960] TRAIN loss:  0.913\n",
      "[epoch 4 Iteration 799/960] TRAIN loss:  1.249\n",
      "[epoch 4 Iteration 800/960] TRAIN loss:  1.417\n",
      "[epoch 4 Iteration 801/960] TRAIN loss:  1.151\n",
      "[epoch 4 Iteration 802/960] TRAIN loss:  1.075\n",
      "[epoch 4 Iteration 803/960] TRAIN loss:  0.795\n",
      "[epoch 4 Iteration 804/960] TRAIN loss:  0.962\n",
      "[epoch 4 Iteration 805/960] TRAIN loss:  1.052\n",
      "[epoch 4 Iteration 806/960] TRAIN loss:  1.000\n",
      "[epoch 4 Iteration 807/960] TRAIN loss:  0.990\n",
      "[epoch 4 Iteration 808/960] TRAIN loss:  0.972\n",
      "[epoch 4 Iteration 809/960] TRAIN loss:  1.204\n",
      "[epoch 4 Iteration 810/960] TRAIN loss:  0.988\n",
      "[epoch 4 Iteration 811/960] TRAIN loss:  1.010\n",
      "[epoch 4 Iteration 812/960] TRAIN loss:  1.197\n",
      "[epoch 4 Iteration 813/960] TRAIN loss:  1.148\n",
      "[epoch 4 Iteration 814/960] TRAIN loss:  0.882\n",
      "[epoch 4 Iteration 815/960] TRAIN loss:  0.877\n",
      "[epoch 4 Iteration 816/960] TRAIN loss:  0.948\n",
      "[epoch 4 Iteration 817/960] TRAIN loss:  1.103\n",
      "[epoch 4 Iteration 818/960] TRAIN loss:  1.080\n",
      "[epoch 4 Iteration 819/960] TRAIN loss:  1.117\n",
      "[epoch 4 Iteration 820/960] TRAIN loss:  1.036\n",
      "[epoch 4 Iteration 821/960] TRAIN loss:  0.951\n",
      "[epoch 4 Iteration 822/960] TRAIN loss:  1.112\n",
      "[epoch 4 Iteration 823/960] TRAIN loss:  1.078\n",
      "[epoch 4 Iteration 824/960] TRAIN loss:  0.731\n",
      "[epoch 4 Iteration 825/960] TRAIN loss:  0.887\n",
      "[epoch 4 Iteration 826/960] TRAIN loss:  1.106\n",
      "[epoch 4 Iteration 827/960] TRAIN loss:  1.349\n",
      "[epoch 4 Iteration 828/960] TRAIN loss:  0.885\n",
      "[epoch 4 Iteration 829/960] TRAIN loss:  1.136\n",
      "[epoch 4 Iteration 830/960] TRAIN loss:  0.948\n",
      "[epoch 4 Iteration 831/960] TRAIN loss:  0.817\n",
      "[epoch 4 Iteration 832/960] TRAIN loss:  0.918\n",
      "[epoch 4 Iteration 833/960] TRAIN loss:  0.994\n",
      "[epoch 4 Iteration 834/960] TRAIN loss:  1.183\n",
      "[epoch 4 Iteration 835/960] TRAIN loss:  0.902\n",
      "[epoch 4 Iteration 836/960] TRAIN loss:  0.801\n",
      "[epoch 4 Iteration 837/960] TRAIN loss:  0.805\n",
      "[epoch 4 Iteration 838/960] TRAIN loss:  1.142\n",
      "[epoch 4 Iteration 839/960] TRAIN loss:  1.138\n",
      "[epoch 4 Iteration 840/960] TRAIN loss:  0.934\n",
      "[epoch 4 Iteration 841/960] TRAIN loss:  1.211\n",
      "[epoch 4 Iteration 842/960] TRAIN loss:  1.162\n",
      "[epoch 4 Iteration 843/960] TRAIN loss:  0.796\n",
      "[epoch 4 Iteration 844/960] TRAIN loss:  1.001\n",
      "[epoch 4 Iteration 845/960] TRAIN loss:  0.764\n",
      "[epoch 4 Iteration 846/960] TRAIN loss:  1.085\n",
      "[epoch 4 Iteration 847/960] TRAIN loss:  0.936\n",
      "[epoch 4 Iteration 848/960] TRAIN loss:  1.180\n",
      "[epoch 4 Iteration 849/960] TRAIN loss:  1.299\n",
      "[epoch 4 Iteration 850/960] TRAIN loss:  0.889\n",
      "[epoch 4 Iteration 851/960] TRAIN loss:  1.229\n",
      "[epoch 4 Iteration 852/960] TRAIN loss:  0.982\n",
      "[epoch 4 Iteration 853/960] TRAIN loss:  0.968\n",
      "[epoch 4 Iteration 854/960] TRAIN loss:  1.071\n",
      "[epoch 4 Iteration 855/960] TRAIN loss:  0.763\n",
      "[epoch 4 Iteration 856/960] TRAIN loss:  0.873\n",
      "[epoch 4 Iteration 857/960] TRAIN loss:  1.040\n",
      "[epoch 4 Iteration 858/960] TRAIN loss:  1.125\n",
      "[epoch 4 Iteration 859/960] TRAIN loss:  1.327\n",
      "[epoch 4 Iteration 860/960] TRAIN loss:  1.052\n",
      "[epoch 4 Iteration 861/960] TRAIN loss:  1.312\n",
      "[epoch 4 Iteration 862/960] TRAIN loss:  0.906\n",
      "[epoch 4 Iteration 863/960] TRAIN loss:  0.995\n",
      "[epoch 4 Iteration 864/960] TRAIN loss:  0.943\n",
      "[epoch 4 Iteration 865/960] TRAIN loss:  1.415\n",
      "[epoch 4 Iteration 866/960] TRAIN loss:  0.754\n",
      "[epoch 4 Iteration 867/960] TRAIN loss:  0.792\n",
      "[epoch 4 Iteration 868/960] TRAIN loss:  1.198\n",
      "[epoch 4 Iteration 869/960] TRAIN loss:  0.758\n",
      "[epoch 4 Iteration 870/960] TRAIN loss:  1.105\n",
      "[epoch 4 Iteration 871/960] TRAIN loss:  0.913\n",
      "[epoch 4 Iteration 872/960] TRAIN loss:  1.202\n",
      "[epoch 4 Iteration 873/960] TRAIN loss:  1.229\n",
      "[epoch 4 Iteration 874/960] TRAIN loss:  1.230\n",
      "[epoch 4 Iteration 875/960] TRAIN loss:  0.947\n",
      "[epoch 4 Iteration 876/960] TRAIN loss:  1.033\n",
      "[epoch 4 Iteration 877/960] TRAIN loss:  0.777\n",
      "[epoch 4 Iteration 878/960] TRAIN loss:  0.982\n",
      "[epoch 4 Iteration 879/960] TRAIN loss:  1.049\n",
      "[epoch 4 Iteration 880/960] TRAIN loss:  1.200\n",
      "[epoch 4 Iteration 881/960] TRAIN loss:  1.214\n",
      "[epoch 4 Iteration 882/960] TRAIN loss:  1.051\n",
      "[epoch 4 Iteration 883/960] TRAIN loss:  1.062\n",
      "[epoch 4 Iteration 884/960] TRAIN loss:  1.042\n",
      "[epoch 4 Iteration 885/960] TRAIN loss:  0.859\n",
      "[epoch 4 Iteration 886/960] TRAIN loss:  1.214\n",
      "[epoch 4 Iteration 887/960] TRAIN loss:  0.700\n",
      "[epoch 4 Iteration 888/960] TRAIN loss:  0.774\n",
      "[epoch 4 Iteration 889/960] TRAIN loss:  0.874\n",
      "[epoch 4 Iteration 890/960] TRAIN loss:  0.966\n",
      "[epoch 4 Iteration 891/960] TRAIN loss:  0.868\n",
      "[epoch 4 Iteration 892/960] TRAIN loss:  1.028\n",
      "[epoch 4 Iteration 893/960] TRAIN loss:  1.335\n",
      "[epoch 4 Iteration 894/960] TRAIN loss:  0.945\n",
      "[epoch 4 Iteration 895/960] TRAIN loss:  0.838\n",
      "[epoch 4 Iteration 896/960] TRAIN loss:  0.867\n",
      "[epoch 4 Iteration 897/960] TRAIN loss:  0.985\n",
      "[epoch 4 Iteration 898/960] TRAIN loss:  1.361\n",
      "[epoch 4 Iteration 899/960] TRAIN loss:  0.957\n",
      "[epoch 4 Iteration 900/960] TRAIN loss:  0.876\n",
      "[epoch 4 Iteration 901/960] TRAIN loss:  1.124\n",
      "[epoch 4 Iteration 902/960] TRAIN loss:  0.858\n",
      "[epoch 4 Iteration 903/960] TRAIN loss:  0.864\n",
      "[epoch 4 Iteration 904/960] TRAIN loss:  0.836\n",
      "[epoch 4 Iteration 905/960] TRAIN loss:  0.848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4 Iteration 906/960] TRAIN loss:  1.027\n",
      "[epoch 4 Iteration 907/960] TRAIN loss:  1.096\n",
      "[epoch 4 Iteration 908/960] TRAIN loss:  0.966\n",
      "[epoch 4 Iteration 909/960] TRAIN loss:  0.880\n",
      "[epoch 4 Iteration 910/960] TRAIN loss:  1.199\n",
      "[epoch 4 Iteration 911/960] TRAIN loss:  1.142\n",
      "[epoch 4 Iteration 912/960] TRAIN loss:  0.878\n",
      "[epoch 4 Iteration 913/960] TRAIN loss:  0.978\n",
      "[epoch 4 Iteration 914/960] TRAIN loss:  1.013\n",
      "[epoch 4 Iteration 915/960] TRAIN loss:  1.066\n",
      "[epoch 4 Iteration 916/960] TRAIN loss:  1.202\n",
      "[epoch 4 Iteration 917/960] TRAIN loss:  1.099\n",
      "[epoch 4 Iteration 918/960] TRAIN loss:  0.816\n",
      "[epoch 4 Iteration 919/960] TRAIN loss:  1.035\n",
      "[epoch 4 Iteration 920/960] TRAIN loss:  0.825\n",
      "[epoch 4 Iteration 921/960] TRAIN loss:  1.097\n",
      "[epoch 4 Iteration 922/960] TRAIN loss:  0.907\n",
      "[epoch 4 Iteration 923/960] TRAIN loss:  1.313\n",
      "[epoch 4 Iteration 924/960] TRAIN loss:  1.220\n",
      "[epoch 4 Iteration 925/960] TRAIN loss:  1.279\n",
      "[epoch 4 Iteration 926/960] TRAIN loss:  1.105\n",
      "[epoch 4 Iteration 927/960] TRAIN loss:  1.067\n",
      "[epoch 4 Iteration 928/960] TRAIN loss:  0.766\n",
      "[epoch 4 Iteration 929/960] TRAIN loss:  0.981\n",
      "[epoch 4 Iteration 930/960] TRAIN loss:  0.923\n",
      "[epoch 4 Iteration 931/960] TRAIN loss:  1.143\n",
      "[epoch 4 Iteration 932/960] TRAIN loss:  1.532\n",
      "[epoch 4 Iteration 933/960] TRAIN loss:  0.881\n",
      "[epoch 4 Iteration 934/960] TRAIN loss:  1.078\n",
      "[epoch 4 Iteration 935/960] TRAIN loss:  0.932\n",
      "[epoch 4 Iteration 936/960] TRAIN loss:  0.883\n",
      "[epoch 4 Iteration 937/960] TRAIN loss:  0.859\n",
      "[epoch 4 Iteration 938/960] TRAIN loss:  1.063\n",
      "[epoch 4 Iteration 939/960] TRAIN loss:  1.088\n",
      "[epoch 4 Iteration 940/960] TRAIN loss:  0.804\n",
      "[epoch 4 Iteration 941/960] TRAIN loss:  0.762\n",
      "[epoch 4 Iteration 942/960] TRAIN loss:  0.965\n",
      "[epoch 4 Iteration 943/960] TRAIN loss:  1.021\n",
      "[epoch 4 Iteration 944/960] TRAIN loss:  0.801\n",
      "[epoch 4 Iteration 945/960] TRAIN loss:  0.946\n",
      "[epoch 4 Iteration 946/960] TRAIN loss:  1.252\n",
      "[epoch 4 Iteration 947/960] TRAIN loss:  1.031\n",
      "[epoch 4 Iteration 948/960] TRAIN loss:  0.836\n",
      "[epoch 4 Iteration 949/960] TRAIN loss:  0.788\n",
      "[epoch 4 Iteration 950/960] TRAIN loss:  0.936\n",
      "[epoch 4 Iteration 951/960] TRAIN loss:  1.175\n",
      "[epoch 4 Iteration 952/960] TRAIN loss:  0.906\n",
      "[epoch 4 Iteration 953/960] TRAIN loss:  0.817\n",
      "[epoch 4 Iteration 954/960] TRAIN loss:  0.909\n",
      "[epoch 4 Iteration 955/960] TRAIN loss:  0.834\n",
      "[epoch 4 Iteration 956/960] TRAIN loss:  0.790\n",
      "[epoch 4 Iteration 957/960] TRAIN loss:  0.722\n",
      "[epoch 4 Iteration 958/960] TRAIN loss:  1.068\n",
      "[epoch 4 Iteration 959/960] TRAIN loss:  1.131\n",
      "[epoch 4/15] TRAIN acc/loss:  0.646/1.131\n",
      "[epoch 4/15] VAL acc/loss:  0.629/0.611\n",
      "[epoch 5 Iteration 0/960] TRAIN loss:  0.857\n",
      "[epoch 5 Iteration 1/960] TRAIN loss:  1.002\n",
      "[epoch 5 Iteration 2/960] TRAIN loss:  1.015\n",
      "[epoch 5 Iteration 3/960] TRAIN loss:  0.717\n",
      "[epoch 5 Iteration 4/960] TRAIN loss:  0.849\n",
      "[epoch 5 Iteration 5/960] TRAIN loss:  0.862\n",
      "[epoch 5 Iteration 6/960] TRAIN loss:  1.282\n",
      "[epoch 5 Iteration 7/960] TRAIN loss:  0.880\n",
      "[epoch 5 Iteration 8/960] TRAIN loss:  1.225\n",
      "[epoch 5 Iteration 9/960] TRAIN loss:  0.933\n",
      "[epoch 5 Iteration 10/960] TRAIN loss:  0.884\n",
      "[epoch 5 Iteration 11/960] TRAIN loss:  0.941\n",
      "[epoch 5 Iteration 12/960] TRAIN loss:  0.838\n",
      "[epoch 5 Iteration 13/960] TRAIN loss:  0.991\n",
      "[epoch 5 Iteration 14/960] TRAIN loss:  0.758\n",
      "[epoch 5 Iteration 15/960] TRAIN loss:  0.958\n",
      "[epoch 5 Iteration 16/960] TRAIN loss:  0.800\n",
      "[epoch 5 Iteration 17/960] TRAIN loss:  0.729\n",
      "[epoch 5 Iteration 18/960] TRAIN loss:  0.730\n",
      "[epoch 5 Iteration 19/960] TRAIN loss:  1.086\n",
      "[epoch 5 Iteration 20/960] TRAIN loss:  0.759\n",
      "[epoch 5 Iteration 21/960] TRAIN loss:  0.785\n",
      "[epoch 5 Iteration 22/960] TRAIN loss:  0.866\n",
      "[epoch 5 Iteration 23/960] TRAIN loss:  0.809\n",
      "[epoch 5 Iteration 24/960] TRAIN loss:  0.897\n",
      "[epoch 5 Iteration 25/960] TRAIN loss:  0.882\n",
      "[epoch 5 Iteration 26/960] TRAIN loss:  0.972\n",
      "[epoch 5 Iteration 27/960] TRAIN loss:  1.095\n",
      "[epoch 5 Iteration 28/960] TRAIN loss:  0.742\n",
      "[epoch 5 Iteration 29/960] TRAIN loss:  0.831\n",
      "[epoch 5 Iteration 30/960] TRAIN loss:  0.994\n",
      "[epoch 5 Iteration 31/960] TRAIN loss:  1.013\n",
      "[epoch 5 Iteration 32/960] TRAIN loss:  0.923\n",
      "[epoch 5 Iteration 33/960] TRAIN loss:  0.995\n",
      "[epoch 5 Iteration 34/960] TRAIN loss:  0.877\n",
      "[epoch 5 Iteration 35/960] TRAIN loss:  0.966\n",
      "[epoch 5 Iteration 36/960] TRAIN loss:  0.888\n",
      "[epoch 5 Iteration 37/960] TRAIN loss:  1.003\n",
      "[epoch 5 Iteration 38/960] TRAIN loss:  0.624\n",
      "[epoch 5 Iteration 39/960] TRAIN loss:  1.016\n",
      "[epoch 5 Iteration 40/960] TRAIN loss:  0.896\n",
      "[epoch 5 Iteration 41/960] TRAIN loss:  0.852\n",
      "[epoch 5 Iteration 42/960] TRAIN loss:  1.227\n",
      "[epoch 5 Iteration 43/960] TRAIN loss:  0.930\n",
      "[epoch 5 Iteration 44/960] TRAIN loss:  0.994\n",
      "[epoch 5 Iteration 45/960] TRAIN loss:  0.814\n",
      "[epoch 5 Iteration 46/960] TRAIN loss:  0.908\n",
      "[epoch 5 Iteration 47/960] TRAIN loss:  1.071\n",
      "[epoch 5 Iteration 48/960] TRAIN loss:  0.714\n",
      "[epoch 5 Iteration 49/960] TRAIN loss:  0.931\n",
      "[epoch 5 Iteration 50/960] TRAIN loss:  0.781\n",
      "[epoch 5 Iteration 51/960] TRAIN loss:  0.942\n",
      "[epoch 5 Iteration 52/960] TRAIN loss:  1.151\n",
      "[epoch 5 Iteration 53/960] TRAIN loss:  0.964\n",
      "[epoch 5 Iteration 54/960] TRAIN loss:  1.225\n",
      "[epoch 5 Iteration 55/960] TRAIN loss:  0.997\n",
      "[epoch 5 Iteration 56/960] TRAIN loss:  0.865\n",
      "[epoch 5 Iteration 57/960] TRAIN loss:  0.883\n",
      "[epoch 5 Iteration 58/960] TRAIN loss:  0.931\n",
      "[epoch 5 Iteration 59/960] TRAIN loss:  0.996\n",
      "[epoch 5 Iteration 60/960] TRAIN loss:  0.890\n",
      "[epoch 5 Iteration 61/960] TRAIN loss:  0.886\n",
      "[epoch 5 Iteration 62/960] TRAIN loss:  0.870\n",
      "[epoch 5 Iteration 63/960] TRAIN loss:  1.086\n",
      "[epoch 5 Iteration 64/960] TRAIN loss:  1.033\n",
      "[epoch 5 Iteration 65/960] TRAIN loss:  0.928\n",
      "[epoch 5 Iteration 66/960] TRAIN loss:  1.255\n",
      "[epoch 5 Iteration 67/960] TRAIN loss:  0.657\n",
      "[epoch 5 Iteration 68/960] TRAIN loss:  0.966\n",
      "[epoch 5 Iteration 69/960] TRAIN loss:  0.853\n",
      "[epoch 5 Iteration 70/960] TRAIN loss:  0.847\n",
      "[epoch 5 Iteration 71/960] TRAIN loss:  0.990\n",
      "[epoch 5 Iteration 72/960] TRAIN loss:  0.784\n",
      "[epoch 5 Iteration 73/960] TRAIN loss:  1.151\n",
      "[epoch 5 Iteration 74/960] TRAIN loss:  0.960\n",
      "[epoch 5 Iteration 75/960] TRAIN loss:  0.641\n",
      "[epoch 5 Iteration 76/960] TRAIN loss:  1.135\n",
      "[epoch 5 Iteration 77/960] TRAIN loss:  0.867\n",
      "[epoch 5 Iteration 78/960] TRAIN loss:  0.993\n",
      "[epoch 5 Iteration 79/960] TRAIN loss:  0.953\n",
      "[epoch 5 Iteration 80/960] TRAIN loss:  1.160\n",
      "[epoch 5 Iteration 81/960] TRAIN loss:  1.130\n",
      "[epoch 5 Iteration 82/960] TRAIN loss:  0.915\n",
      "[epoch 5 Iteration 83/960] TRAIN loss:  0.754\n",
      "[epoch 5 Iteration 84/960] TRAIN loss:  0.907\n",
      "[epoch 5 Iteration 85/960] TRAIN loss:  0.877\n",
      "[epoch 5 Iteration 86/960] TRAIN loss:  1.147\n",
      "[epoch 5 Iteration 87/960] TRAIN loss:  0.883\n",
      "[epoch 5 Iteration 88/960] TRAIN loss:  0.833\n",
      "[epoch 5 Iteration 89/960] TRAIN loss:  1.035\n",
      "[epoch 5 Iteration 90/960] TRAIN loss:  1.021\n",
      "[epoch 5 Iteration 91/960] TRAIN loss:  0.860\n",
      "[epoch 5 Iteration 92/960] TRAIN loss:  0.764\n",
      "[epoch 5 Iteration 93/960] TRAIN loss:  0.979\n",
      "[epoch 5 Iteration 94/960] TRAIN loss:  0.851\n",
      "[epoch 5 Iteration 95/960] TRAIN loss:  0.836\n",
      "[epoch 5 Iteration 96/960] TRAIN loss:  0.857\n",
      "[epoch 5 Iteration 97/960] TRAIN loss:  1.099\n",
      "[epoch 5 Iteration 98/960] TRAIN loss:  0.994\n",
      "[epoch 5 Iteration 99/960] TRAIN loss:  0.846\n",
      "[epoch 5 Iteration 100/960] TRAIN loss:  0.797\n",
      "[epoch 5 Iteration 101/960] TRAIN loss:  0.757\n",
      "[epoch 5 Iteration 102/960] TRAIN loss:  0.832\n",
      "[epoch 5 Iteration 103/960] TRAIN loss:  0.913\n",
      "[epoch 5 Iteration 104/960] TRAIN loss:  1.057\n",
      "[epoch 5 Iteration 105/960] TRAIN loss:  1.117\n",
      "[epoch 5 Iteration 106/960] TRAIN loss:  1.144\n",
      "[epoch 5 Iteration 107/960] TRAIN loss:  0.828\n",
      "[epoch 5 Iteration 108/960] TRAIN loss:  0.885\n",
      "[epoch 5 Iteration 109/960] TRAIN loss:  1.076\n",
      "[epoch 5 Iteration 110/960] TRAIN loss:  1.059\n",
      "[epoch 5 Iteration 111/960] TRAIN loss:  1.154\n",
      "[epoch 5 Iteration 112/960] TRAIN loss:  0.848\n",
      "[epoch 5 Iteration 113/960] TRAIN loss:  1.039\n",
      "[epoch 5 Iteration 114/960] TRAIN loss:  1.010\n",
      "[epoch 5 Iteration 115/960] TRAIN loss:  0.761\n",
      "[epoch 5 Iteration 116/960] TRAIN loss:  0.784\n",
      "[epoch 5 Iteration 117/960] TRAIN loss:  0.663\n",
      "[epoch 5 Iteration 118/960] TRAIN loss:  0.926\n",
      "[epoch 5 Iteration 119/960] TRAIN loss:  1.013\n",
      "[epoch 5 Iteration 120/960] TRAIN loss:  0.959\n",
      "[epoch 5 Iteration 121/960] TRAIN loss:  0.894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5 Iteration 122/960] TRAIN loss:  0.913\n",
      "[epoch 5 Iteration 123/960] TRAIN loss:  1.041\n",
      "[epoch 5 Iteration 124/960] TRAIN loss:  0.773\n",
      "[epoch 5 Iteration 125/960] TRAIN loss:  1.011\n",
      "[epoch 5 Iteration 126/960] TRAIN loss:  0.861\n",
      "[epoch 5 Iteration 127/960] TRAIN loss:  1.055\n",
      "[epoch 5 Iteration 128/960] TRAIN loss:  1.208\n",
      "[epoch 5 Iteration 129/960] TRAIN loss:  0.912\n",
      "[epoch 5 Iteration 130/960] TRAIN loss:  0.899\n",
      "[epoch 5 Iteration 131/960] TRAIN loss:  1.189\n",
      "[epoch 5 Iteration 132/960] TRAIN loss:  0.847\n",
      "[epoch 5 Iteration 133/960] TRAIN loss:  1.145\n",
      "[epoch 5 Iteration 134/960] TRAIN loss:  0.797\n",
      "[epoch 5 Iteration 135/960] TRAIN loss:  0.855\n",
      "[epoch 5 Iteration 136/960] TRAIN loss:  0.958\n",
      "[epoch 5 Iteration 137/960] TRAIN loss:  0.720\n",
      "[epoch 5 Iteration 138/960] TRAIN loss:  1.469\n",
      "[epoch 5 Iteration 139/960] TRAIN loss:  0.943\n",
      "[epoch 5 Iteration 140/960] TRAIN loss:  0.741\n",
      "[epoch 5 Iteration 141/960] TRAIN loss:  1.288\n",
      "[epoch 5 Iteration 142/960] TRAIN loss:  0.934\n",
      "[epoch 5 Iteration 143/960] TRAIN loss:  0.795\n",
      "[epoch 5 Iteration 144/960] TRAIN loss:  0.921\n",
      "[epoch 5 Iteration 145/960] TRAIN loss:  1.010\n",
      "[epoch 5 Iteration 146/960] TRAIN loss:  0.856\n",
      "[epoch 5 Iteration 147/960] TRAIN loss:  0.890\n",
      "[epoch 5 Iteration 148/960] TRAIN loss:  1.076\n",
      "[epoch 5 Iteration 149/960] TRAIN loss:  0.976\n",
      "[epoch 5 Iteration 150/960] TRAIN loss:  0.883\n",
      "[epoch 5 Iteration 151/960] TRAIN loss:  1.007\n",
      "[epoch 5 Iteration 152/960] TRAIN loss:  0.804\n",
      "[epoch 5 Iteration 153/960] TRAIN loss:  0.813\n",
      "[epoch 5 Iteration 154/960] TRAIN loss:  0.914\n",
      "[epoch 5 Iteration 155/960] TRAIN loss:  0.977\n",
      "[epoch 5 Iteration 156/960] TRAIN loss:  0.732\n",
      "[epoch 5 Iteration 157/960] TRAIN loss:  0.940\n",
      "[epoch 5 Iteration 158/960] TRAIN loss:  0.850\n",
      "[epoch 5 Iteration 159/960] TRAIN loss:  0.732\n",
      "[epoch 5 Iteration 160/960] TRAIN loss:  0.828\n",
      "[epoch 5 Iteration 161/960] TRAIN loss:  0.921\n",
      "[epoch 5 Iteration 162/960] TRAIN loss:  0.981\n",
      "[epoch 5 Iteration 163/960] TRAIN loss:  0.926\n",
      "[epoch 5 Iteration 164/960] TRAIN loss:  0.914\n",
      "[epoch 5 Iteration 165/960] TRAIN loss:  1.046\n",
      "[epoch 5 Iteration 166/960] TRAIN loss:  0.796\n",
      "[epoch 5 Iteration 167/960] TRAIN loss:  1.169\n",
      "[epoch 5 Iteration 168/960] TRAIN loss:  0.776\n",
      "[epoch 5 Iteration 169/960] TRAIN loss:  0.753\n",
      "[epoch 5 Iteration 170/960] TRAIN loss:  1.005\n",
      "[epoch 5 Iteration 171/960] TRAIN loss:  0.819\n",
      "[epoch 5 Iteration 172/960] TRAIN loss:  0.787\n",
      "[epoch 5 Iteration 173/960] TRAIN loss:  0.774\n",
      "[epoch 5 Iteration 174/960] TRAIN loss:  0.954\n",
      "[epoch 5 Iteration 175/960] TRAIN loss:  1.075\n",
      "[epoch 5 Iteration 176/960] TRAIN loss:  0.904\n",
      "[epoch 5 Iteration 177/960] TRAIN loss:  0.960\n",
      "[epoch 5 Iteration 178/960] TRAIN loss:  1.132\n",
      "[epoch 5 Iteration 179/960] TRAIN loss:  0.953\n",
      "[epoch 5 Iteration 180/960] TRAIN loss:  0.978\n",
      "[epoch 5 Iteration 181/960] TRAIN loss:  0.782\n",
      "[epoch 5 Iteration 182/960] TRAIN loss:  0.802\n",
      "[epoch 5 Iteration 183/960] TRAIN loss:  0.937\n",
      "[epoch 5 Iteration 184/960] TRAIN loss:  1.079\n",
      "[epoch 5 Iteration 185/960] TRAIN loss:  0.727\n",
      "[epoch 5 Iteration 186/960] TRAIN loss:  1.078\n",
      "[epoch 5 Iteration 187/960] TRAIN loss:  0.690\n",
      "[epoch 5 Iteration 188/960] TRAIN loss:  0.879\n",
      "[epoch 5 Iteration 189/960] TRAIN loss:  0.995\n",
      "[epoch 5 Iteration 190/960] TRAIN loss:  0.999\n",
      "[epoch 5 Iteration 191/960] TRAIN loss:  0.806\n",
      "[epoch 5 Iteration 192/960] TRAIN loss:  0.839\n",
      "[epoch 5 Iteration 193/960] TRAIN loss:  1.260\n",
      "[epoch 5 Iteration 194/960] TRAIN loss:  0.843\n",
      "[epoch 5 Iteration 195/960] TRAIN loss:  0.996\n",
      "[epoch 5 Iteration 196/960] TRAIN loss:  1.097\n",
      "[epoch 5 Iteration 197/960] TRAIN loss:  0.961\n",
      "[epoch 5 Iteration 198/960] TRAIN loss:  1.127\n",
      "[epoch 5 Iteration 199/960] TRAIN loss:  1.032\n",
      "[epoch 5 Iteration 200/960] TRAIN loss:  0.832\n",
      "[epoch 5 Iteration 201/960] TRAIN loss:  0.917\n",
      "[epoch 5 Iteration 202/960] TRAIN loss:  0.917\n",
      "[epoch 5 Iteration 203/960] TRAIN loss:  0.843\n",
      "[epoch 5 Iteration 204/960] TRAIN loss:  1.113\n",
      "[epoch 5 Iteration 205/960] TRAIN loss:  0.648\n",
      "[epoch 5 Iteration 206/960] TRAIN loss:  0.942\n",
      "[epoch 5 Iteration 207/960] TRAIN loss:  1.036\n",
      "[epoch 5 Iteration 208/960] TRAIN loss:  0.716\n",
      "[epoch 5 Iteration 209/960] TRAIN loss:  1.122\n",
      "[epoch 5 Iteration 210/960] TRAIN loss:  0.738\n",
      "[epoch 5 Iteration 211/960] TRAIN loss:  0.791\n",
      "[epoch 5 Iteration 212/960] TRAIN loss:  1.062\n",
      "[epoch 5 Iteration 213/960] TRAIN loss:  0.946\n",
      "[epoch 5 Iteration 214/960] TRAIN loss:  0.870\n",
      "[epoch 5 Iteration 215/960] TRAIN loss:  1.032\n",
      "[epoch 5 Iteration 216/960] TRAIN loss:  0.758\n",
      "[epoch 5 Iteration 217/960] TRAIN loss:  0.958\n",
      "[epoch 5 Iteration 218/960] TRAIN loss:  0.736\n",
      "[epoch 5 Iteration 219/960] TRAIN loss:  0.883\n",
      "[epoch 5 Iteration 220/960] TRAIN loss:  0.752\n",
      "[epoch 5 Iteration 221/960] TRAIN loss:  1.127\n",
      "[epoch 5 Iteration 222/960] TRAIN loss:  1.045\n",
      "[epoch 5 Iteration 223/960] TRAIN loss:  0.938\n",
      "[epoch 5 Iteration 224/960] TRAIN loss:  0.688\n",
      "[epoch 5 Iteration 225/960] TRAIN loss:  0.722\n",
      "[epoch 5 Iteration 226/960] TRAIN loss:  1.062\n",
      "[epoch 5 Iteration 227/960] TRAIN loss:  0.767\n",
      "[epoch 5 Iteration 228/960] TRAIN loss:  0.961\n",
      "[epoch 5 Iteration 229/960] TRAIN loss:  0.914\n",
      "[epoch 5 Iteration 230/960] TRAIN loss:  0.716\n",
      "[epoch 5 Iteration 231/960] TRAIN loss:  1.134\n",
      "[epoch 5 Iteration 232/960] TRAIN loss:  0.831\n",
      "[epoch 5 Iteration 233/960] TRAIN loss:  0.899\n",
      "[epoch 5 Iteration 234/960] TRAIN loss:  1.027\n",
      "[epoch 5 Iteration 235/960] TRAIN loss:  0.683\n",
      "[epoch 5 Iteration 236/960] TRAIN loss:  0.817\n",
      "[epoch 5 Iteration 237/960] TRAIN loss:  0.790\n",
      "[epoch 5 Iteration 238/960] TRAIN loss:  0.570\n",
      "[epoch 5 Iteration 239/960] TRAIN loss:  0.773\n",
      "[epoch 5 Iteration 240/960] TRAIN loss:  1.092\n",
      "[epoch 5 Iteration 241/960] TRAIN loss:  0.976\n",
      "[epoch 5 Iteration 242/960] TRAIN loss:  0.984\n",
      "[epoch 5 Iteration 243/960] TRAIN loss:  0.956\n",
      "[epoch 5 Iteration 244/960] TRAIN loss:  0.848\n",
      "[epoch 5 Iteration 245/960] TRAIN loss:  0.657\n",
      "[epoch 5 Iteration 246/960] TRAIN loss:  1.347\n",
      "[epoch 5 Iteration 247/960] TRAIN loss:  0.884\n",
      "[epoch 5 Iteration 248/960] TRAIN loss:  0.835\n",
      "[epoch 5 Iteration 249/960] TRAIN loss:  0.625\n",
      "[epoch 5 Iteration 250/960] TRAIN loss:  0.750\n",
      "[epoch 5 Iteration 251/960] TRAIN loss:  1.093\n",
      "[epoch 5 Iteration 252/960] TRAIN loss:  1.063\n",
      "[epoch 5 Iteration 253/960] TRAIN loss:  1.149\n",
      "[epoch 5 Iteration 254/960] TRAIN loss:  0.971\n",
      "[epoch 5 Iteration 255/960] TRAIN loss:  0.741\n",
      "[epoch 5 Iteration 256/960] TRAIN loss:  0.908\n",
      "[epoch 5 Iteration 257/960] TRAIN loss:  0.831\n",
      "[epoch 5 Iteration 258/960] TRAIN loss:  0.786\n",
      "[epoch 5 Iteration 259/960] TRAIN loss:  1.079\n",
      "[epoch 5 Iteration 260/960] TRAIN loss:  0.870\n",
      "[epoch 5 Iteration 261/960] TRAIN loss:  1.041\n",
      "[epoch 5 Iteration 262/960] TRAIN loss:  1.211\n",
      "[epoch 5 Iteration 263/960] TRAIN loss:  0.900\n",
      "[epoch 5 Iteration 264/960] TRAIN loss:  0.967\n",
      "[epoch 5 Iteration 265/960] TRAIN loss:  0.799\n",
      "[epoch 5 Iteration 266/960] TRAIN loss:  1.037\n",
      "[epoch 5 Iteration 267/960] TRAIN loss:  1.216\n",
      "[epoch 5 Iteration 268/960] TRAIN loss:  0.912\n",
      "[epoch 5 Iteration 269/960] TRAIN loss:  0.819\n",
      "[epoch 5 Iteration 270/960] TRAIN loss:  0.748\n",
      "[epoch 5 Iteration 271/960] TRAIN loss:  0.974\n",
      "[epoch 5 Iteration 272/960] TRAIN loss:  0.915\n",
      "[epoch 5 Iteration 273/960] TRAIN loss:  0.923\n",
      "[epoch 5 Iteration 274/960] TRAIN loss:  0.607\n",
      "[epoch 5 Iteration 275/960] TRAIN loss:  0.661\n",
      "[epoch 5 Iteration 276/960] TRAIN loss:  0.817\n",
      "[epoch 5 Iteration 277/960] TRAIN loss:  0.840\n",
      "[epoch 5 Iteration 278/960] TRAIN loss:  1.106\n",
      "[epoch 5 Iteration 279/960] TRAIN loss:  0.933\n",
      "[epoch 5 Iteration 280/960] TRAIN loss:  1.108\n",
      "[epoch 5 Iteration 281/960] TRAIN loss:  1.123\n",
      "[epoch 5 Iteration 282/960] TRAIN loss:  0.895\n",
      "[epoch 5 Iteration 283/960] TRAIN loss:  1.175\n",
      "[epoch 5 Iteration 284/960] TRAIN loss:  0.787\n",
      "[epoch 5 Iteration 285/960] TRAIN loss:  1.044\n",
      "[epoch 5 Iteration 286/960] TRAIN loss:  0.831\n",
      "[epoch 5 Iteration 287/960] TRAIN loss:  0.923\n",
      "[epoch 5 Iteration 288/960] TRAIN loss:  1.047\n",
      "[epoch 5 Iteration 289/960] TRAIN loss:  0.832\n",
      "[epoch 5 Iteration 290/960] TRAIN loss:  1.052\n",
      "[epoch 5 Iteration 291/960] TRAIN loss:  1.207\n",
      "[epoch 5 Iteration 292/960] TRAIN loss:  0.938\n",
      "[epoch 5 Iteration 293/960] TRAIN loss:  1.185\n",
      "[epoch 5 Iteration 294/960] TRAIN loss:  1.239\n",
      "[epoch 5 Iteration 295/960] TRAIN loss:  0.928\n",
      "[epoch 5 Iteration 296/960] TRAIN loss:  0.917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5 Iteration 297/960] TRAIN loss:  0.891\n",
      "[epoch 5 Iteration 298/960] TRAIN loss:  1.088\n",
      "[epoch 5 Iteration 299/960] TRAIN loss:  0.656\n",
      "[epoch 5 Iteration 300/960] TRAIN loss:  0.852\n",
      "[epoch 5 Iteration 301/960] TRAIN loss:  0.836\n",
      "[epoch 5 Iteration 302/960] TRAIN loss:  0.794\n",
      "[epoch 5 Iteration 303/960] TRAIN loss:  0.741\n",
      "[epoch 5 Iteration 304/960] TRAIN loss:  1.135\n",
      "[epoch 5 Iteration 305/960] TRAIN loss:  0.878\n",
      "[epoch 5 Iteration 306/960] TRAIN loss:  1.461\n",
      "[epoch 5 Iteration 307/960] TRAIN loss:  1.095\n",
      "[epoch 5 Iteration 308/960] TRAIN loss:  1.021\n",
      "[epoch 5 Iteration 309/960] TRAIN loss:  0.945\n",
      "[epoch 5 Iteration 310/960] TRAIN loss:  0.769\n",
      "[epoch 5 Iteration 311/960] TRAIN loss:  0.875\n",
      "[epoch 5 Iteration 312/960] TRAIN loss:  0.673\n",
      "[epoch 5 Iteration 313/960] TRAIN loss:  0.769\n",
      "[epoch 5 Iteration 314/960] TRAIN loss:  1.142\n",
      "[epoch 5 Iteration 315/960] TRAIN loss:  0.881\n",
      "[epoch 5 Iteration 316/960] TRAIN loss:  0.783\n",
      "[epoch 5 Iteration 317/960] TRAIN loss:  1.019\n",
      "[epoch 5 Iteration 318/960] TRAIN loss:  1.038\n",
      "[epoch 5 Iteration 319/960] TRAIN loss:  1.139\n",
      "[epoch 5 Iteration 320/960] TRAIN loss:  0.869\n",
      "[epoch 5 Iteration 321/960] TRAIN loss:  1.215\n",
      "[epoch 5 Iteration 322/960] TRAIN loss:  1.199\n",
      "[epoch 5 Iteration 323/960] TRAIN loss:  1.096\n",
      "[epoch 5 Iteration 324/960] TRAIN loss:  0.920\n",
      "[epoch 5 Iteration 325/960] TRAIN loss:  0.748\n",
      "[epoch 5 Iteration 326/960] TRAIN loss:  1.039\n",
      "[epoch 5 Iteration 327/960] TRAIN loss:  0.790\n",
      "[epoch 5 Iteration 328/960] TRAIN loss:  0.788\n",
      "[epoch 5 Iteration 329/960] TRAIN loss:  1.103\n",
      "[epoch 5 Iteration 330/960] TRAIN loss:  1.034\n",
      "[epoch 5 Iteration 331/960] TRAIN loss:  1.105\n",
      "[epoch 5 Iteration 332/960] TRAIN loss:  1.136\n",
      "[epoch 5 Iteration 333/960] TRAIN loss:  0.619\n",
      "[epoch 5 Iteration 334/960] TRAIN loss:  0.935\n",
      "[epoch 5 Iteration 335/960] TRAIN loss:  0.765\n",
      "[epoch 5 Iteration 336/960] TRAIN loss:  0.751\n",
      "[epoch 5 Iteration 337/960] TRAIN loss:  1.224\n",
      "[epoch 5 Iteration 338/960] TRAIN loss:  0.957\n",
      "[epoch 5 Iteration 339/960] TRAIN loss:  0.991\n",
      "[epoch 5 Iteration 340/960] TRAIN loss:  0.872\n",
      "[epoch 5 Iteration 341/960] TRAIN loss:  0.821\n",
      "[epoch 5 Iteration 342/960] TRAIN loss:  0.954\n",
      "[epoch 5 Iteration 343/960] TRAIN loss:  0.987\n",
      "[epoch 5 Iteration 344/960] TRAIN loss:  0.823\n",
      "[epoch 5 Iteration 345/960] TRAIN loss:  0.868\n",
      "[epoch 5 Iteration 346/960] TRAIN loss:  1.042\n",
      "[epoch 5 Iteration 347/960] TRAIN loss:  0.805\n",
      "[epoch 5 Iteration 348/960] TRAIN loss:  0.894\n",
      "[epoch 5 Iteration 349/960] TRAIN loss:  0.952\n",
      "[epoch 5 Iteration 350/960] TRAIN loss:  1.078\n",
      "[epoch 5 Iteration 351/960] TRAIN loss:  1.092\n",
      "[epoch 5 Iteration 352/960] TRAIN loss:  0.718\n",
      "[epoch 5 Iteration 353/960] TRAIN loss:  1.336\n",
      "[epoch 5 Iteration 354/960] TRAIN loss:  1.056\n",
      "[epoch 5 Iteration 355/960] TRAIN loss:  1.058\n",
      "[epoch 5 Iteration 356/960] TRAIN loss:  0.841\n",
      "[epoch 5 Iteration 357/960] TRAIN loss:  0.927\n",
      "[epoch 5 Iteration 358/960] TRAIN loss:  0.884\n",
      "[epoch 5 Iteration 359/960] TRAIN loss:  0.827\n",
      "[epoch 5 Iteration 360/960] TRAIN loss:  1.141\n",
      "[epoch 5 Iteration 361/960] TRAIN loss:  0.868\n",
      "[epoch 5 Iteration 362/960] TRAIN loss:  1.105\n",
      "[epoch 5 Iteration 363/960] TRAIN loss:  1.030\n",
      "[epoch 5 Iteration 364/960] TRAIN loss:  1.018\n",
      "[epoch 5 Iteration 365/960] TRAIN loss:  1.175\n",
      "[epoch 5 Iteration 366/960] TRAIN loss:  1.322\n",
      "[epoch 5 Iteration 367/960] TRAIN loss:  0.883\n",
      "[epoch 5 Iteration 368/960] TRAIN loss:  1.136\n",
      "[epoch 5 Iteration 369/960] TRAIN loss:  1.006\n",
      "[epoch 5 Iteration 370/960] TRAIN loss:  0.675\n",
      "[epoch 5 Iteration 371/960] TRAIN loss:  1.079\n",
      "[epoch 5 Iteration 372/960] TRAIN loss:  0.986\n",
      "[epoch 5 Iteration 373/960] TRAIN loss:  1.132\n",
      "[epoch 5 Iteration 374/960] TRAIN loss:  0.951\n",
      "[epoch 5 Iteration 375/960] TRAIN loss:  1.051\n",
      "[epoch 5 Iteration 376/960] TRAIN loss:  0.892\n",
      "[epoch 5 Iteration 377/960] TRAIN loss:  0.875\n",
      "[epoch 5 Iteration 378/960] TRAIN loss:  0.788\n",
      "[epoch 5 Iteration 379/960] TRAIN loss:  1.090\n",
      "[epoch 5 Iteration 380/960] TRAIN loss:  0.873\n",
      "[epoch 5 Iteration 381/960] TRAIN loss:  0.765\n",
      "[epoch 5 Iteration 382/960] TRAIN loss:  1.112\n",
      "[epoch 5 Iteration 383/960] TRAIN loss:  0.819\n",
      "[epoch 5 Iteration 384/960] TRAIN loss:  1.075\n",
      "[epoch 5 Iteration 385/960] TRAIN loss:  0.855\n",
      "[epoch 5 Iteration 386/960] TRAIN loss:  1.008\n",
      "[epoch 5 Iteration 387/960] TRAIN loss:  1.092\n",
      "[epoch 5 Iteration 388/960] TRAIN loss:  0.905\n",
      "[epoch 5 Iteration 389/960] TRAIN loss:  1.053\n",
      "[epoch 5 Iteration 390/960] TRAIN loss:  1.160\n",
      "[epoch 5 Iteration 391/960] TRAIN loss:  0.694\n",
      "[epoch 5 Iteration 392/960] TRAIN loss:  0.891\n",
      "[epoch 5 Iteration 393/960] TRAIN loss:  0.972\n",
      "[epoch 5 Iteration 394/960] TRAIN loss:  0.916\n",
      "[epoch 5 Iteration 395/960] TRAIN loss:  1.167\n",
      "[epoch 5 Iteration 396/960] TRAIN loss:  0.736\n",
      "[epoch 5 Iteration 397/960] TRAIN loss:  0.940\n",
      "[epoch 5 Iteration 398/960] TRAIN loss:  0.808\n",
      "[epoch 5 Iteration 399/960] TRAIN loss:  1.102\n",
      "[epoch 5 Iteration 400/960] TRAIN loss:  0.788\n",
      "[epoch 5 Iteration 401/960] TRAIN loss:  0.963\n",
      "[epoch 5 Iteration 402/960] TRAIN loss:  0.725\n",
      "[epoch 5 Iteration 403/960] TRAIN loss:  0.889\n",
      "[epoch 5 Iteration 404/960] TRAIN loss:  0.881\n",
      "[epoch 5 Iteration 405/960] TRAIN loss:  0.653\n",
      "[epoch 5 Iteration 406/960] TRAIN loss:  0.965\n",
      "[epoch 5 Iteration 407/960] TRAIN loss:  0.853\n",
      "[epoch 5 Iteration 408/960] TRAIN loss:  0.887\n",
      "[epoch 5 Iteration 409/960] TRAIN loss:  1.371\n",
      "[epoch 5 Iteration 410/960] TRAIN loss:  0.874\n",
      "[epoch 5 Iteration 411/960] TRAIN loss:  0.770\n",
      "[epoch 5 Iteration 412/960] TRAIN loss:  0.870\n",
      "[epoch 5 Iteration 413/960] TRAIN loss:  1.005\n",
      "[epoch 5 Iteration 414/960] TRAIN loss:  0.850\n",
      "[epoch 5 Iteration 415/960] TRAIN loss:  0.947\n",
      "[epoch 5 Iteration 416/960] TRAIN loss:  1.006\n",
      "[epoch 5 Iteration 417/960] TRAIN loss:  0.755\n",
      "[epoch 5 Iteration 418/960] TRAIN loss:  0.891\n",
      "[epoch 5 Iteration 419/960] TRAIN loss:  1.335\n",
      "[epoch 5 Iteration 420/960] TRAIN loss:  1.108\n",
      "[epoch 5 Iteration 421/960] TRAIN loss:  0.795\n",
      "[epoch 5 Iteration 422/960] TRAIN loss:  1.005\n",
      "[epoch 5 Iteration 423/960] TRAIN loss:  1.088\n",
      "[epoch 5 Iteration 424/960] TRAIN loss:  0.894\n",
      "[epoch 5 Iteration 425/960] TRAIN loss:  0.739\n",
      "[epoch 5 Iteration 426/960] TRAIN loss:  0.946\n",
      "[epoch 5 Iteration 427/960] TRAIN loss:  0.630\n",
      "[epoch 5 Iteration 428/960] TRAIN loss:  0.857\n",
      "[epoch 5 Iteration 429/960] TRAIN loss:  1.143\n",
      "[epoch 5 Iteration 430/960] TRAIN loss:  0.872\n",
      "[epoch 5 Iteration 431/960] TRAIN loss:  1.108\n",
      "[epoch 5 Iteration 432/960] TRAIN loss:  0.776\n",
      "[epoch 5 Iteration 433/960] TRAIN loss:  0.926\n",
      "[epoch 5 Iteration 434/960] TRAIN loss:  1.101\n",
      "[epoch 5 Iteration 435/960] TRAIN loss:  1.135\n",
      "[epoch 5 Iteration 436/960] TRAIN loss:  0.992\n",
      "[epoch 5 Iteration 437/960] TRAIN loss:  0.995\n",
      "[epoch 5 Iteration 438/960] TRAIN loss:  1.345\n",
      "[epoch 5 Iteration 439/960] TRAIN loss:  0.766\n",
      "[epoch 5 Iteration 440/960] TRAIN loss:  1.010\n",
      "[epoch 5 Iteration 441/960] TRAIN loss:  1.086\n",
      "[epoch 5 Iteration 442/960] TRAIN loss:  1.405\n",
      "[epoch 5 Iteration 443/960] TRAIN loss:  0.854\n",
      "[epoch 5 Iteration 444/960] TRAIN loss:  1.107\n",
      "[epoch 5 Iteration 445/960] TRAIN loss:  1.219\n",
      "[epoch 5 Iteration 446/960] TRAIN loss:  1.056\n",
      "[epoch 5 Iteration 447/960] TRAIN loss:  0.944\n",
      "[epoch 5 Iteration 448/960] TRAIN loss:  0.823\n",
      "[epoch 5 Iteration 449/960] TRAIN loss:  1.271\n",
      "[epoch 5 Iteration 450/960] TRAIN loss:  0.819\n",
      "[epoch 5 Iteration 451/960] TRAIN loss:  1.092\n",
      "[epoch 5 Iteration 452/960] TRAIN loss:  1.031\n",
      "[epoch 5 Iteration 453/960] TRAIN loss:  0.810\n",
      "[epoch 5 Iteration 454/960] TRAIN loss:  0.939\n",
      "[epoch 5 Iteration 455/960] TRAIN loss:  1.011\n",
      "[epoch 5 Iteration 456/960] TRAIN loss:  0.921\n",
      "[epoch 5 Iteration 457/960] TRAIN loss:  0.896\n",
      "[epoch 5 Iteration 458/960] TRAIN loss:  1.044\n",
      "[epoch 5 Iteration 459/960] TRAIN loss:  1.250\n",
      "[epoch 5 Iteration 460/960] TRAIN loss:  0.903\n",
      "[epoch 5 Iteration 461/960] TRAIN loss:  0.783\n",
      "[epoch 5 Iteration 462/960] TRAIN loss:  1.002\n",
      "[epoch 5 Iteration 463/960] TRAIN loss:  0.942\n",
      "[epoch 5 Iteration 464/960] TRAIN loss:  0.964\n",
      "[epoch 5 Iteration 465/960] TRAIN loss:  0.935\n",
      "[epoch 5 Iteration 466/960] TRAIN loss:  1.052\n",
      "[epoch 5 Iteration 467/960] TRAIN loss:  0.892\n",
      "[epoch 5 Iteration 468/960] TRAIN loss:  0.883\n",
      "[epoch 5 Iteration 469/960] TRAIN loss:  0.973\n",
      "[epoch 5 Iteration 470/960] TRAIN loss:  1.088\n",
      "[epoch 5 Iteration 471/960] TRAIN loss:  0.944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5 Iteration 472/960] TRAIN loss:  0.758\n",
      "[epoch 5 Iteration 473/960] TRAIN loss:  0.912\n",
      "[epoch 5 Iteration 474/960] TRAIN loss:  0.806\n",
      "[epoch 5 Iteration 475/960] TRAIN loss:  1.122\n",
      "[epoch 5 Iteration 476/960] TRAIN loss:  0.941\n",
      "[epoch 5 Iteration 477/960] TRAIN loss:  0.914\n",
      "[epoch 5 Iteration 478/960] TRAIN loss:  1.139\n",
      "[epoch 5 Iteration 479/960] TRAIN loss:  0.836\n",
      "[epoch 5 Iteration 480/960] TRAIN loss:  0.982\n",
      "[epoch 5 Iteration 481/960] TRAIN loss:  1.137\n",
      "[epoch 5 Iteration 482/960] TRAIN loss:  1.107\n",
      "[epoch 5 Iteration 483/960] TRAIN loss:  0.703\n",
      "[epoch 5 Iteration 484/960] TRAIN loss:  1.078\n",
      "[epoch 5 Iteration 485/960] TRAIN loss:  1.004\n",
      "[epoch 5 Iteration 486/960] TRAIN loss:  1.072\n",
      "[epoch 5 Iteration 487/960] TRAIN loss:  0.952\n",
      "[epoch 5 Iteration 488/960] TRAIN loss:  1.091\n",
      "[epoch 5 Iteration 489/960] TRAIN loss:  1.042\n",
      "[epoch 5 Iteration 490/960] TRAIN loss:  1.120\n",
      "[epoch 5 Iteration 491/960] TRAIN loss:  1.075\n",
      "[epoch 5 Iteration 492/960] TRAIN loss:  0.897\n",
      "[epoch 5 Iteration 493/960] TRAIN loss:  0.879\n",
      "[epoch 5 Iteration 494/960] TRAIN loss:  0.863\n",
      "[epoch 5 Iteration 495/960] TRAIN loss:  0.900\n",
      "[epoch 5 Iteration 496/960] TRAIN loss:  1.246\n",
      "[epoch 5 Iteration 497/960] TRAIN loss:  0.992\n",
      "[epoch 5 Iteration 498/960] TRAIN loss:  1.388\n",
      "[epoch 5 Iteration 499/960] TRAIN loss:  0.970\n",
      "[epoch 5 Iteration 500/960] TRAIN loss:  0.780\n",
      "[epoch 5 Iteration 501/960] TRAIN loss:  0.751\n",
      "[epoch 5 Iteration 502/960] TRAIN loss:  0.843\n",
      "[epoch 5 Iteration 503/960] TRAIN loss:  0.873\n",
      "[epoch 5 Iteration 504/960] TRAIN loss:  0.917\n",
      "[epoch 5 Iteration 505/960] TRAIN loss:  0.928\n",
      "[epoch 5 Iteration 506/960] TRAIN loss:  1.363\n",
      "[epoch 5 Iteration 507/960] TRAIN loss:  1.096\n",
      "[epoch 5 Iteration 508/960] TRAIN loss:  0.989\n",
      "[epoch 5 Iteration 509/960] TRAIN loss:  0.813\n",
      "[epoch 5 Iteration 510/960] TRAIN loss:  1.094\n",
      "[epoch 5 Iteration 511/960] TRAIN loss:  1.257\n",
      "[epoch 5 Iteration 512/960] TRAIN loss:  0.761\n",
      "[epoch 5 Iteration 513/960] TRAIN loss:  1.008\n",
      "[epoch 5 Iteration 514/960] TRAIN loss:  0.845\n",
      "[epoch 5 Iteration 515/960] TRAIN loss:  1.065\n",
      "[epoch 5 Iteration 516/960] TRAIN loss:  0.923\n",
      "[epoch 5 Iteration 517/960] TRAIN loss:  0.819\n",
      "[epoch 5 Iteration 518/960] TRAIN loss:  1.307\n",
      "[epoch 5 Iteration 519/960] TRAIN loss:  1.132\n",
      "[epoch 5 Iteration 520/960] TRAIN loss:  1.065\n",
      "[epoch 5 Iteration 521/960] TRAIN loss:  0.961\n",
      "[epoch 5 Iteration 522/960] TRAIN loss:  0.812\n",
      "[epoch 5 Iteration 523/960] TRAIN loss:  0.879\n",
      "[epoch 5 Iteration 524/960] TRAIN loss:  0.925\n",
      "[epoch 5 Iteration 525/960] TRAIN loss:  1.022\n",
      "[epoch 5 Iteration 526/960] TRAIN loss:  1.043\n",
      "[epoch 5 Iteration 527/960] TRAIN loss:  0.762\n",
      "[epoch 5 Iteration 528/960] TRAIN loss:  1.032\n",
      "[epoch 5 Iteration 529/960] TRAIN loss:  0.838\n",
      "[epoch 5 Iteration 530/960] TRAIN loss:  0.970\n",
      "[epoch 5 Iteration 531/960] TRAIN loss:  1.162\n",
      "[epoch 5 Iteration 532/960] TRAIN loss:  1.074\n",
      "[epoch 5 Iteration 533/960] TRAIN loss:  0.965\n",
      "[epoch 5 Iteration 534/960] TRAIN loss:  1.071\n",
      "[epoch 5 Iteration 535/960] TRAIN loss:  0.964\n",
      "[epoch 5 Iteration 536/960] TRAIN loss:  0.848\n",
      "[epoch 5 Iteration 537/960] TRAIN loss:  1.061\n",
      "[epoch 5 Iteration 538/960] TRAIN loss:  1.227\n",
      "[epoch 5 Iteration 539/960] TRAIN loss:  0.878\n",
      "[epoch 5 Iteration 540/960] TRAIN loss:  0.840\n",
      "[epoch 5 Iteration 541/960] TRAIN loss:  0.945\n",
      "[epoch 5 Iteration 542/960] TRAIN loss:  0.886\n",
      "[epoch 5 Iteration 543/960] TRAIN loss:  0.835\n",
      "[epoch 5 Iteration 544/960] TRAIN loss:  0.953\n",
      "[epoch 5 Iteration 545/960] TRAIN loss:  0.872\n",
      "[epoch 5 Iteration 546/960] TRAIN loss:  0.825\n",
      "[epoch 5 Iteration 547/960] TRAIN loss:  0.898\n",
      "[epoch 5 Iteration 548/960] TRAIN loss:  0.958\n",
      "[epoch 5 Iteration 549/960] TRAIN loss:  0.836\n",
      "[epoch 5 Iteration 550/960] TRAIN loss:  1.165\n",
      "[epoch 5 Iteration 551/960] TRAIN loss:  0.940\n",
      "[epoch 5 Iteration 552/960] TRAIN loss:  0.670\n",
      "[epoch 5 Iteration 553/960] TRAIN loss:  1.113\n",
      "[epoch 5 Iteration 554/960] TRAIN loss:  0.718\n",
      "[epoch 5 Iteration 555/960] TRAIN loss:  1.193\n",
      "[epoch 5 Iteration 556/960] TRAIN loss:  1.007\n",
      "[epoch 5 Iteration 557/960] TRAIN loss:  0.870\n",
      "[epoch 5 Iteration 558/960] TRAIN loss:  1.068\n",
      "[epoch 5 Iteration 559/960] TRAIN loss:  1.078\n",
      "[epoch 5 Iteration 560/960] TRAIN loss:  1.242\n",
      "[epoch 5 Iteration 561/960] TRAIN loss:  1.198\n",
      "[epoch 5 Iteration 562/960] TRAIN loss:  0.825\n",
      "[epoch 5 Iteration 563/960] TRAIN loss:  0.990\n",
      "[epoch 5 Iteration 564/960] TRAIN loss:  0.923\n",
      "[epoch 5 Iteration 565/960] TRAIN loss:  1.045\n",
      "[epoch 5 Iteration 566/960] TRAIN loss:  0.859\n",
      "[epoch 5 Iteration 567/960] TRAIN loss:  0.922\n",
      "[epoch 5 Iteration 568/960] TRAIN loss:  1.022\n",
      "[epoch 5 Iteration 569/960] TRAIN loss:  1.066\n",
      "[epoch 5 Iteration 570/960] TRAIN loss:  0.899\n",
      "[epoch 5 Iteration 571/960] TRAIN loss:  1.209\n",
      "[epoch 5 Iteration 572/960] TRAIN loss:  0.849\n",
      "[epoch 5 Iteration 573/960] TRAIN loss:  0.916\n",
      "[epoch 5 Iteration 574/960] TRAIN loss:  0.833\n",
      "[epoch 5 Iteration 575/960] TRAIN loss:  0.886\n",
      "[epoch 5 Iteration 576/960] TRAIN loss:  0.790\n",
      "[epoch 5 Iteration 577/960] TRAIN loss:  1.116\n",
      "[epoch 5 Iteration 578/960] TRAIN loss:  0.823\n",
      "[epoch 5 Iteration 579/960] TRAIN loss:  1.077\n",
      "[epoch 5 Iteration 580/960] TRAIN loss:  0.884\n",
      "[epoch 5 Iteration 581/960] TRAIN loss:  1.097\n",
      "[epoch 5 Iteration 582/960] TRAIN loss:  0.887\n",
      "[epoch 5 Iteration 583/960] TRAIN loss:  0.831\n",
      "[epoch 5 Iteration 584/960] TRAIN loss:  1.390\n",
      "[epoch 5 Iteration 585/960] TRAIN loss:  0.994\n",
      "[epoch 5 Iteration 586/960] TRAIN loss:  0.995\n",
      "[epoch 5 Iteration 587/960] TRAIN loss:  0.913\n",
      "[epoch 5 Iteration 588/960] TRAIN loss:  1.154\n",
      "[epoch 5 Iteration 589/960] TRAIN loss:  0.735\n",
      "[epoch 5 Iteration 590/960] TRAIN loss:  0.811\n",
      "[epoch 5 Iteration 591/960] TRAIN loss:  1.045\n",
      "[epoch 5 Iteration 592/960] TRAIN loss:  1.090\n",
      "[epoch 5 Iteration 593/960] TRAIN loss:  1.122\n",
      "[epoch 5 Iteration 594/960] TRAIN loss:  0.983\n",
      "[epoch 5 Iteration 595/960] TRAIN loss:  0.916\n",
      "[epoch 5 Iteration 596/960] TRAIN loss:  1.197\n",
      "[epoch 5 Iteration 597/960] TRAIN loss:  1.065\n",
      "[epoch 5 Iteration 598/960] TRAIN loss:  0.724\n",
      "[epoch 5 Iteration 599/960] TRAIN loss:  0.756\n",
      "[epoch 5 Iteration 600/960] TRAIN loss:  1.096\n",
      "[epoch 5 Iteration 601/960] TRAIN loss:  1.219\n",
      "[epoch 5 Iteration 602/960] TRAIN loss:  0.951\n",
      "[epoch 5 Iteration 603/960] TRAIN loss:  0.777\n",
      "[epoch 5 Iteration 604/960] TRAIN loss:  0.911\n",
      "[epoch 5 Iteration 605/960] TRAIN loss:  0.616\n",
      "[epoch 5 Iteration 606/960] TRAIN loss:  0.607\n",
      "[epoch 5 Iteration 607/960] TRAIN loss:  0.808\n",
      "[epoch 5 Iteration 608/960] TRAIN loss:  0.747\n",
      "[epoch 5 Iteration 609/960] TRAIN loss:  1.253\n",
      "[epoch 5 Iteration 610/960] TRAIN loss:  0.931\n",
      "[epoch 5 Iteration 611/960] TRAIN loss:  0.750\n",
      "[epoch 5 Iteration 612/960] TRAIN loss:  0.912\n",
      "[epoch 5 Iteration 613/960] TRAIN loss:  0.953\n",
      "[epoch 5 Iteration 614/960] TRAIN loss:  0.998\n",
      "[epoch 5 Iteration 615/960] TRAIN loss:  0.827\n",
      "[epoch 5 Iteration 616/960] TRAIN loss:  0.779\n",
      "[epoch 5 Iteration 617/960] TRAIN loss:  0.698\n",
      "[epoch 5 Iteration 618/960] TRAIN loss:  0.870\n",
      "[epoch 5 Iteration 619/960] TRAIN loss:  1.041\n",
      "[epoch 5 Iteration 620/960] TRAIN loss:  0.778\n",
      "[epoch 5 Iteration 621/960] TRAIN loss:  0.733\n",
      "[epoch 5 Iteration 622/960] TRAIN loss:  0.822\n",
      "[epoch 5 Iteration 623/960] TRAIN loss:  1.061\n",
      "[epoch 5 Iteration 624/960] TRAIN loss:  0.875\n",
      "[epoch 5 Iteration 625/960] TRAIN loss:  1.089\n",
      "[epoch 5 Iteration 626/960] TRAIN loss:  1.078\n",
      "[epoch 5 Iteration 627/960] TRAIN loss:  1.155\n",
      "[epoch 5 Iteration 628/960] TRAIN loss:  0.962\n",
      "[epoch 5 Iteration 629/960] TRAIN loss:  1.233\n",
      "[epoch 5 Iteration 630/960] TRAIN loss:  1.006\n",
      "[epoch 5 Iteration 631/960] TRAIN loss:  0.870\n",
      "[epoch 5 Iteration 632/960] TRAIN loss:  0.940\n",
      "[epoch 5 Iteration 633/960] TRAIN loss:  0.889\n",
      "[epoch 5 Iteration 634/960] TRAIN loss:  0.817\n",
      "[epoch 5 Iteration 635/960] TRAIN loss:  1.034\n",
      "[epoch 5 Iteration 636/960] TRAIN loss:  0.918\n",
      "[epoch 5 Iteration 637/960] TRAIN loss:  0.796\n",
      "[epoch 5 Iteration 638/960] TRAIN loss:  0.915\n",
      "[epoch 5 Iteration 639/960] TRAIN loss:  0.807\n",
      "[epoch 5 Iteration 640/960] TRAIN loss:  1.192\n",
      "[epoch 5 Iteration 641/960] TRAIN loss:  0.867\n",
      "[epoch 5 Iteration 642/960] TRAIN loss:  0.864\n",
      "[epoch 5 Iteration 643/960] TRAIN loss:  0.978\n",
      "[epoch 5 Iteration 644/960] TRAIN loss:  0.675\n",
      "[epoch 5 Iteration 645/960] TRAIN loss:  0.585\n",
      "[epoch 5 Iteration 646/960] TRAIN loss:  1.247\n",
      "[epoch 5 Iteration 647/960] TRAIN loss:  0.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5 Iteration 648/960] TRAIN loss:  0.800\n",
      "[epoch 5 Iteration 649/960] TRAIN loss:  0.668\n",
      "[epoch 5 Iteration 650/960] TRAIN loss:  1.020\n",
      "[epoch 5 Iteration 651/960] TRAIN loss:  1.130\n",
      "[epoch 5 Iteration 652/960] TRAIN loss:  0.846\n",
      "[epoch 5 Iteration 653/960] TRAIN loss:  0.799\n",
      "[epoch 5 Iteration 654/960] TRAIN loss:  0.929\n",
      "[epoch 5 Iteration 655/960] TRAIN loss:  0.729\n",
      "[epoch 5 Iteration 656/960] TRAIN loss:  1.194\n",
      "[epoch 5 Iteration 657/960] TRAIN loss:  0.889\n",
      "[epoch 5 Iteration 658/960] TRAIN loss:  0.872\n",
      "[epoch 5 Iteration 659/960] TRAIN loss:  0.800\n",
      "[epoch 5 Iteration 660/960] TRAIN loss:  0.758\n",
      "[epoch 5 Iteration 661/960] TRAIN loss:  0.876\n",
      "[epoch 5 Iteration 662/960] TRAIN loss:  0.918\n",
      "[epoch 5 Iteration 663/960] TRAIN loss:  0.847\n",
      "[epoch 5 Iteration 664/960] TRAIN loss:  1.230\n",
      "[epoch 5 Iteration 665/960] TRAIN loss:  0.960\n",
      "[epoch 5 Iteration 666/960] TRAIN loss:  0.761\n",
      "[epoch 5 Iteration 667/960] TRAIN loss:  0.775\n",
      "[epoch 5 Iteration 668/960] TRAIN loss:  0.887\n",
      "[epoch 5 Iteration 669/960] TRAIN loss:  0.914\n",
      "[epoch 5 Iteration 670/960] TRAIN loss:  0.763\n",
      "[epoch 5 Iteration 671/960] TRAIN loss:  0.950\n",
      "[epoch 5 Iteration 672/960] TRAIN loss:  1.008\n",
      "[epoch 5 Iteration 673/960] TRAIN loss:  1.071\n",
      "[epoch 5 Iteration 674/960] TRAIN loss:  0.695\n",
      "[epoch 5 Iteration 675/960] TRAIN loss:  0.888\n",
      "[epoch 5 Iteration 676/960] TRAIN loss:  0.966\n",
      "[epoch 5 Iteration 677/960] TRAIN loss:  0.928\n",
      "[epoch 5 Iteration 678/960] TRAIN loss:  0.808\n",
      "[epoch 5 Iteration 679/960] TRAIN loss:  0.804\n",
      "[epoch 5 Iteration 680/960] TRAIN loss:  0.846\n",
      "[epoch 5 Iteration 681/960] TRAIN loss:  1.023\n",
      "[epoch 5 Iteration 682/960] TRAIN loss:  0.881\n",
      "[epoch 5 Iteration 683/960] TRAIN loss:  0.952\n",
      "[epoch 5 Iteration 684/960] TRAIN loss:  0.842\n",
      "[epoch 5 Iteration 685/960] TRAIN loss:  1.029\n",
      "[epoch 5 Iteration 686/960] TRAIN loss:  1.097\n",
      "[epoch 5 Iteration 687/960] TRAIN loss:  0.948\n",
      "[epoch 5 Iteration 688/960] TRAIN loss:  0.805\n",
      "[epoch 5 Iteration 689/960] TRAIN loss:  0.890\n",
      "[epoch 5 Iteration 690/960] TRAIN loss:  0.905\n",
      "[epoch 5 Iteration 691/960] TRAIN loss:  0.950\n",
      "[epoch 5 Iteration 692/960] TRAIN loss:  1.045\n",
      "[epoch 5 Iteration 693/960] TRAIN loss:  0.973\n",
      "[epoch 5 Iteration 694/960] TRAIN loss:  0.962\n",
      "[epoch 5 Iteration 695/960] TRAIN loss:  0.962\n",
      "[epoch 5 Iteration 696/960] TRAIN loss:  0.940\n",
      "[epoch 5 Iteration 697/960] TRAIN loss:  1.212\n",
      "[epoch 5 Iteration 698/960] TRAIN loss:  0.953\n",
      "[epoch 5 Iteration 699/960] TRAIN loss:  0.907\n",
      "[epoch 5 Iteration 700/960] TRAIN loss:  0.753\n",
      "[epoch 5 Iteration 701/960] TRAIN loss:  1.030\n",
      "[epoch 5 Iteration 702/960] TRAIN loss:  1.133\n",
      "[epoch 5 Iteration 703/960] TRAIN loss:  0.965\n",
      "[epoch 5 Iteration 704/960] TRAIN loss:  1.023\n",
      "[epoch 5 Iteration 705/960] TRAIN loss:  1.095\n",
      "[epoch 5 Iteration 706/960] TRAIN loss:  0.767\n",
      "[epoch 5 Iteration 707/960] TRAIN loss:  0.948\n",
      "[epoch 5 Iteration 708/960] TRAIN loss:  0.852\n",
      "[epoch 5 Iteration 709/960] TRAIN loss:  1.166\n",
      "[epoch 5 Iteration 710/960] TRAIN loss:  0.689\n",
      "[epoch 5 Iteration 711/960] TRAIN loss:  0.877\n",
      "[epoch 5 Iteration 712/960] TRAIN loss:  1.120\n",
      "[epoch 5 Iteration 713/960] TRAIN loss:  1.147\n",
      "[epoch 5 Iteration 714/960] TRAIN loss:  1.073\n",
      "[epoch 5 Iteration 715/960] TRAIN loss:  0.886\n",
      "[epoch 5 Iteration 716/960] TRAIN loss:  1.036\n",
      "[epoch 5 Iteration 717/960] TRAIN loss:  1.051\n",
      "[epoch 5 Iteration 718/960] TRAIN loss:  0.993\n",
      "[epoch 5 Iteration 719/960] TRAIN loss:  0.744\n",
      "[epoch 5 Iteration 720/960] TRAIN loss:  0.945\n",
      "[epoch 5 Iteration 721/960] TRAIN loss:  0.988\n",
      "[epoch 5 Iteration 722/960] TRAIN loss:  0.915\n",
      "[epoch 5 Iteration 723/960] TRAIN loss:  1.141\n",
      "[epoch 5 Iteration 724/960] TRAIN loss:  1.136\n",
      "[epoch 5 Iteration 725/960] TRAIN loss:  0.820\n",
      "[epoch 5 Iteration 726/960] TRAIN loss:  0.880\n",
      "[epoch 5 Iteration 727/960] TRAIN loss:  1.091\n",
      "[epoch 5 Iteration 728/960] TRAIN loss:  0.820\n",
      "[epoch 5 Iteration 729/960] TRAIN loss:  1.318\n",
      "[epoch 5 Iteration 730/960] TRAIN loss:  0.843\n",
      "[epoch 5 Iteration 731/960] TRAIN loss:  0.872\n",
      "[epoch 5 Iteration 732/960] TRAIN loss:  1.035\n",
      "[epoch 5 Iteration 733/960] TRAIN loss:  0.894\n",
      "[epoch 5 Iteration 734/960] TRAIN loss:  0.887\n",
      "[epoch 5 Iteration 735/960] TRAIN loss:  0.994\n",
      "[epoch 5 Iteration 736/960] TRAIN loss:  0.752\n",
      "[epoch 5 Iteration 737/960] TRAIN loss:  1.289\n",
      "[epoch 5 Iteration 738/960] TRAIN loss:  0.814\n",
      "[epoch 5 Iteration 739/960] TRAIN loss:  1.241\n",
      "[epoch 5 Iteration 740/960] TRAIN loss:  0.866\n",
      "[epoch 5 Iteration 741/960] TRAIN loss:  0.912\n",
      "[epoch 5 Iteration 742/960] TRAIN loss:  0.876\n",
      "[epoch 5 Iteration 743/960] TRAIN loss:  0.799\n",
      "[epoch 5 Iteration 744/960] TRAIN loss:  0.720\n",
      "[epoch 5 Iteration 745/960] TRAIN loss:  0.784\n",
      "[epoch 5 Iteration 746/960] TRAIN loss:  1.153\n",
      "[epoch 5 Iteration 747/960] TRAIN loss:  1.102\n",
      "[epoch 5 Iteration 748/960] TRAIN loss:  0.913\n",
      "[epoch 5 Iteration 749/960] TRAIN loss:  0.818\n",
      "[epoch 5 Iteration 750/960] TRAIN loss:  0.930\n",
      "[epoch 5 Iteration 751/960] TRAIN loss:  0.980\n",
      "[epoch 5 Iteration 752/960] TRAIN loss:  0.965\n",
      "[epoch 5 Iteration 753/960] TRAIN loss:  0.958\n",
      "[epoch 5 Iteration 754/960] TRAIN loss:  0.969\n",
      "[epoch 5 Iteration 755/960] TRAIN loss:  0.746\n",
      "[epoch 5 Iteration 756/960] TRAIN loss:  0.780\n",
      "[epoch 5 Iteration 757/960] TRAIN loss:  0.914\n",
      "[epoch 5 Iteration 758/960] TRAIN loss:  0.748\n",
      "[epoch 5 Iteration 759/960] TRAIN loss:  1.090\n",
      "[epoch 5 Iteration 760/960] TRAIN loss:  0.962\n",
      "[epoch 5 Iteration 761/960] TRAIN loss:  0.681\n",
      "[epoch 5 Iteration 762/960] TRAIN loss:  0.690\n",
      "[epoch 5 Iteration 763/960] TRAIN loss:  0.788\n",
      "[epoch 5 Iteration 764/960] TRAIN loss:  0.718\n",
      "[epoch 5 Iteration 765/960] TRAIN loss:  1.292\n",
      "[epoch 5 Iteration 766/960] TRAIN loss:  1.133\n",
      "[epoch 5 Iteration 767/960] TRAIN loss:  0.941\n",
      "[epoch 5 Iteration 768/960] TRAIN loss:  0.864\n",
      "[epoch 5 Iteration 769/960] TRAIN loss:  1.009\n",
      "[epoch 5 Iteration 770/960] TRAIN loss:  0.891\n",
      "[epoch 5 Iteration 771/960] TRAIN loss:  1.222\n",
      "[epoch 5 Iteration 772/960] TRAIN loss:  1.119\n",
      "[epoch 5 Iteration 773/960] TRAIN loss:  0.902\n",
      "[epoch 5 Iteration 774/960] TRAIN loss:  1.014\n",
      "[epoch 5 Iteration 775/960] TRAIN loss:  0.972\n",
      "[epoch 5 Iteration 776/960] TRAIN loss:  1.157\n",
      "[epoch 5 Iteration 777/960] TRAIN loss:  0.824\n",
      "[epoch 5 Iteration 778/960] TRAIN loss:  0.826\n",
      "[epoch 5 Iteration 779/960] TRAIN loss:  1.177\n",
      "[epoch 5 Iteration 780/960] TRAIN loss:  0.796\n",
      "[epoch 5 Iteration 781/960] TRAIN loss:  0.932\n",
      "[epoch 5 Iteration 782/960] TRAIN loss:  1.102\n",
      "[epoch 5 Iteration 783/960] TRAIN loss:  1.040\n",
      "[epoch 5 Iteration 784/960] TRAIN loss:  1.269\n",
      "[epoch 5 Iteration 785/960] TRAIN loss:  0.780\n",
      "[epoch 5 Iteration 786/960] TRAIN loss:  0.905\n",
      "[epoch 5 Iteration 787/960] TRAIN loss:  1.078\n",
      "[epoch 5 Iteration 788/960] TRAIN loss:  0.856\n",
      "[epoch 5 Iteration 789/960] TRAIN loss:  0.983\n",
      "[epoch 5 Iteration 790/960] TRAIN loss:  0.928\n",
      "[epoch 5 Iteration 791/960] TRAIN loss:  0.813\n",
      "[epoch 5 Iteration 792/960] TRAIN loss:  1.189\n",
      "[epoch 5 Iteration 793/960] TRAIN loss:  0.901\n",
      "[epoch 5 Iteration 794/960] TRAIN loss:  0.828\n",
      "[epoch 5 Iteration 795/960] TRAIN loss:  1.074\n",
      "[epoch 5 Iteration 796/960] TRAIN loss:  1.104\n",
      "[epoch 5 Iteration 797/960] TRAIN loss:  0.653\n",
      "[epoch 5 Iteration 798/960] TRAIN loss:  0.815\n",
      "[epoch 5 Iteration 799/960] TRAIN loss:  0.996\n",
      "[epoch 5 Iteration 800/960] TRAIN loss:  1.046\n",
      "[epoch 5 Iteration 801/960] TRAIN loss:  0.957\n",
      "[epoch 5 Iteration 802/960] TRAIN loss:  0.966\n",
      "[epoch 5 Iteration 803/960] TRAIN loss:  0.620\n",
      "[epoch 5 Iteration 804/960] TRAIN loss:  1.082\n",
      "[epoch 5 Iteration 805/960] TRAIN loss:  1.115\n",
      "[epoch 5 Iteration 806/960] TRAIN loss:  0.746\n",
      "[epoch 5 Iteration 807/960] TRAIN loss:  0.924\n",
      "[epoch 5 Iteration 808/960] TRAIN loss:  0.877\n",
      "[epoch 5 Iteration 809/960] TRAIN loss:  1.136\n",
      "[epoch 5 Iteration 810/960] TRAIN loss:  1.095\n",
      "[epoch 5 Iteration 811/960] TRAIN loss:  1.082\n",
      "[epoch 5 Iteration 812/960] TRAIN loss:  0.943\n",
      "[epoch 5 Iteration 813/960] TRAIN loss:  1.090\n",
      "[epoch 5 Iteration 814/960] TRAIN loss:  1.125\n",
      "[epoch 5 Iteration 815/960] TRAIN loss:  0.951\n",
      "[epoch 5 Iteration 816/960] TRAIN loss:  0.822\n",
      "[epoch 5 Iteration 817/960] TRAIN loss:  1.059\n",
      "[epoch 5 Iteration 818/960] TRAIN loss:  0.959\n",
      "[epoch 5 Iteration 819/960] TRAIN loss:  0.816\n",
      "[epoch 5 Iteration 820/960] TRAIN loss:  0.902\n",
      "[epoch 5 Iteration 821/960] TRAIN loss:  1.198\n",
      "[epoch 5 Iteration 822/960] TRAIN loss:  0.912\n",
      "[epoch 5 Iteration 823/960] TRAIN loss:  0.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5 Iteration 824/960] TRAIN loss:  0.915\n",
      "[epoch 5 Iteration 825/960] TRAIN loss:  0.560\n",
      "[epoch 5 Iteration 826/960] TRAIN loss:  1.008\n",
      "[epoch 5 Iteration 827/960] TRAIN loss:  0.944\n",
      "[epoch 5 Iteration 828/960] TRAIN loss:  0.967\n",
      "[epoch 5 Iteration 829/960] TRAIN loss:  0.901\n",
      "[epoch 5 Iteration 830/960] TRAIN loss:  0.811\n",
      "[epoch 5 Iteration 831/960] TRAIN loss:  1.060\n",
      "[epoch 5 Iteration 832/960] TRAIN loss:  0.974\n",
      "[epoch 5 Iteration 833/960] TRAIN loss:  0.688\n",
      "[epoch 5 Iteration 834/960] TRAIN loss:  0.991\n",
      "[epoch 5 Iteration 835/960] TRAIN loss:  0.924\n",
      "[epoch 5 Iteration 836/960] TRAIN loss:  0.931\n",
      "[epoch 5 Iteration 837/960] TRAIN loss:  1.122\n",
      "[epoch 5 Iteration 838/960] TRAIN loss:  0.851\n",
      "[epoch 5 Iteration 839/960] TRAIN loss:  0.881\n",
      "[epoch 5 Iteration 840/960] TRAIN loss:  1.104\n",
      "[epoch 5 Iteration 841/960] TRAIN loss:  1.057\n",
      "[epoch 5 Iteration 842/960] TRAIN loss:  0.952\n",
      "[epoch 5 Iteration 843/960] TRAIN loss:  0.936\n",
      "[epoch 5 Iteration 844/960] TRAIN loss:  1.030\n",
      "[epoch 5 Iteration 845/960] TRAIN loss:  0.769\n",
      "[epoch 5 Iteration 846/960] TRAIN loss:  1.109\n",
      "[epoch 5 Iteration 847/960] TRAIN loss:  0.879\n",
      "[epoch 5 Iteration 848/960] TRAIN loss:  0.842\n",
      "[epoch 5 Iteration 849/960] TRAIN loss:  0.905\n",
      "[epoch 5 Iteration 850/960] TRAIN loss:  0.874\n",
      "[epoch 5 Iteration 851/960] TRAIN loss:  0.906\n",
      "[epoch 5 Iteration 852/960] TRAIN loss:  0.974\n",
      "[epoch 5 Iteration 853/960] TRAIN loss:  1.037\n",
      "[epoch 5 Iteration 854/960] TRAIN loss:  0.681\n",
      "[epoch 5 Iteration 855/960] TRAIN loss:  0.897\n",
      "[epoch 5 Iteration 856/960] TRAIN loss:  1.091\n",
      "[epoch 5 Iteration 857/960] TRAIN loss:  0.717\n",
      "[epoch 5 Iteration 858/960] TRAIN loss:  0.889\n",
      "[epoch 5 Iteration 859/960] TRAIN loss:  1.033\n",
      "[epoch 5 Iteration 860/960] TRAIN loss:  0.756\n",
      "[epoch 5 Iteration 861/960] TRAIN loss:  0.915\n",
      "[epoch 5 Iteration 862/960] TRAIN loss:  1.110\n",
      "[epoch 5 Iteration 863/960] TRAIN loss:  1.085\n",
      "[epoch 5 Iteration 864/960] TRAIN loss:  0.903\n",
      "[epoch 5 Iteration 865/960] TRAIN loss:  1.203\n",
      "[epoch 5 Iteration 866/960] TRAIN loss:  0.920\n",
      "[epoch 5 Iteration 867/960] TRAIN loss:  1.216\n",
      "[epoch 5 Iteration 868/960] TRAIN loss:  0.799\n",
      "[epoch 5 Iteration 869/960] TRAIN loss:  0.792\n",
      "[epoch 5 Iteration 870/960] TRAIN loss:  1.130\n",
      "[epoch 5 Iteration 871/960] TRAIN loss:  0.852\n",
      "[epoch 5 Iteration 872/960] TRAIN loss:  0.983\n",
      "[epoch 5 Iteration 873/960] TRAIN loss:  0.763\n",
      "[epoch 5 Iteration 874/960] TRAIN loss:  1.142\n",
      "[epoch 5 Iteration 875/960] TRAIN loss:  0.913\n",
      "[epoch 5 Iteration 876/960] TRAIN loss:  0.977\n",
      "[epoch 5 Iteration 877/960] TRAIN loss:  0.785\n",
      "[epoch 5 Iteration 878/960] TRAIN loss:  0.911\n",
      "[epoch 5 Iteration 879/960] TRAIN loss:  1.110\n",
      "[epoch 5 Iteration 880/960] TRAIN loss:  0.897\n",
      "[epoch 5 Iteration 881/960] TRAIN loss:  0.977\n",
      "[epoch 5 Iteration 882/960] TRAIN loss:  0.941\n",
      "[epoch 5 Iteration 883/960] TRAIN loss:  0.847\n",
      "[epoch 5 Iteration 884/960] TRAIN loss:  0.843\n",
      "[epoch 5 Iteration 885/960] TRAIN loss:  0.691\n",
      "[epoch 5 Iteration 886/960] TRAIN loss:  1.185\n",
      "[epoch 5 Iteration 887/960] TRAIN loss:  0.895\n",
      "[epoch 5 Iteration 888/960] TRAIN loss:  0.914\n",
      "[epoch 5 Iteration 889/960] TRAIN loss:  0.854\n",
      "[epoch 5 Iteration 890/960] TRAIN loss:  1.045\n",
      "[epoch 5 Iteration 891/960] TRAIN loss:  0.820\n",
      "[epoch 5 Iteration 892/960] TRAIN loss:  0.874\n",
      "[epoch 5 Iteration 893/960] TRAIN loss:  0.715\n",
      "[epoch 5 Iteration 894/960] TRAIN loss:  0.993\n",
      "[epoch 5 Iteration 895/960] TRAIN loss:  0.822\n",
      "[epoch 5 Iteration 896/960] TRAIN loss:  0.817\n",
      "[epoch 5 Iteration 897/960] TRAIN loss:  0.713\n",
      "[epoch 5 Iteration 898/960] TRAIN loss:  0.926\n",
      "[epoch 5 Iteration 899/960] TRAIN loss:  0.839\n",
      "[epoch 5 Iteration 900/960] TRAIN loss:  0.951\n",
      "[epoch 5 Iteration 901/960] TRAIN loss:  1.157\n",
      "[epoch 5 Iteration 902/960] TRAIN loss:  1.014\n",
      "[epoch 5 Iteration 903/960] TRAIN loss:  0.884\n",
      "[epoch 5 Iteration 904/960] TRAIN loss:  0.781\n",
      "[epoch 5 Iteration 905/960] TRAIN loss:  0.945\n",
      "[epoch 5 Iteration 906/960] TRAIN loss:  1.092\n",
      "[epoch 5 Iteration 907/960] TRAIN loss:  0.746\n",
      "[epoch 5 Iteration 908/960] TRAIN loss:  0.930\n",
      "[epoch 5 Iteration 909/960] TRAIN loss:  1.151\n",
      "[epoch 5 Iteration 910/960] TRAIN loss:  1.097\n",
      "[epoch 5 Iteration 911/960] TRAIN loss:  0.858\n",
      "[epoch 5 Iteration 912/960] TRAIN loss:  1.039\n",
      "[epoch 5 Iteration 913/960] TRAIN loss:  1.114\n",
      "[epoch 5 Iteration 914/960] TRAIN loss:  1.166\n",
      "[epoch 5 Iteration 915/960] TRAIN loss:  1.039\n",
      "[epoch 5 Iteration 916/960] TRAIN loss:  0.669\n",
      "[epoch 5 Iteration 917/960] TRAIN loss:  0.979\n",
      "[epoch 5 Iteration 918/960] TRAIN loss:  0.997\n",
      "[epoch 5 Iteration 919/960] TRAIN loss:  1.163\n",
      "[epoch 5 Iteration 920/960] TRAIN loss:  0.938\n",
      "[epoch 5 Iteration 921/960] TRAIN loss:  0.909\n",
      "[epoch 5 Iteration 922/960] TRAIN loss:  0.757\n",
      "[epoch 5 Iteration 923/960] TRAIN loss:  0.774\n",
      "[epoch 5 Iteration 924/960] TRAIN loss:  0.740\n",
      "[epoch 5 Iteration 925/960] TRAIN loss:  0.832\n",
      "[epoch 5 Iteration 926/960] TRAIN loss:  0.899\n",
      "[epoch 5 Iteration 927/960] TRAIN loss:  1.087\n",
      "[epoch 5 Iteration 928/960] TRAIN loss:  0.951\n",
      "[epoch 5 Iteration 929/960] TRAIN loss:  0.900\n",
      "[epoch 5 Iteration 930/960] TRAIN loss:  1.172\n",
      "[epoch 5 Iteration 931/960] TRAIN loss:  0.863\n",
      "[epoch 5 Iteration 932/960] TRAIN loss:  0.485\n",
      "[epoch 5 Iteration 933/960] TRAIN loss:  0.921\n",
      "[epoch 5 Iteration 934/960] TRAIN loss:  0.621\n",
      "[epoch 5 Iteration 935/960] TRAIN loss:  0.861\n",
      "[epoch 5 Iteration 936/960] TRAIN loss:  0.904\n",
      "[epoch 5 Iteration 937/960] TRAIN loss:  0.921\n",
      "[epoch 5 Iteration 938/960] TRAIN loss:  0.760\n",
      "[epoch 5 Iteration 939/960] TRAIN loss:  0.761\n",
      "[epoch 5 Iteration 940/960] TRAIN loss:  0.852\n",
      "[epoch 5 Iteration 941/960] TRAIN loss:  0.984\n",
      "[epoch 5 Iteration 942/960] TRAIN loss:  0.818\n",
      "[epoch 5 Iteration 943/960] TRAIN loss:  1.239\n",
      "[epoch 5 Iteration 944/960] TRAIN loss:  0.897\n",
      "[epoch 5 Iteration 945/960] TRAIN loss:  0.659\n",
      "[epoch 5 Iteration 946/960] TRAIN loss:  0.877\n",
      "[epoch 5 Iteration 947/960] TRAIN loss:  1.035\n",
      "[epoch 5 Iteration 948/960] TRAIN loss:  0.953\n",
      "[epoch 5 Iteration 949/960] TRAIN loss:  0.987\n",
      "[epoch 5 Iteration 950/960] TRAIN loss:  0.662\n",
      "[epoch 5 Iteration 951/960] TRAIN loss:  0.733\n",
      "[epoch 5 Iteration 952/960] TRAIN loss:  0.812\n",
      "[epoch 5 Iteration 953/960] TRAIN loss:  0.543\n",
      "[epoch 5 Iteration 954/960] TRAIN loss:  0.943\n",
      "[epoch 5 Iteration 955/960] TRAIN loss:  0.814\n",
      "[epoch 5 Iteration 956/960] TRAIN loss:  0.805\n",
      "[epoch 5 Iteration 957/960] TRAIN loss:  0.682\n",
      "[epoch 5 Iteration 958/960] TRAIN loss:  1.117\n",
      "[epoch 5 Iteration 959/960] TRAIN loss:  0.559\n",
      "[epoch 5/15] TRAIN acc/loss:  0.668/0.559\n",
      "[epoch 5/15] VAL acc/loss:  0.634/0.511\n",
      "[epoch 6 Iteration 0/960] TRAIN loss:  0.811\n",
      "[epoch 6 Iteration 1/960] TRAIN loss:  0.964\n",
      "[epoch 6 Iteration 2/960] TRAIN loss:  0.984\n",
      "[epoch 6 Iteration 3/960] TRAIN loss:  0.886\n",
      "[epoch 6 Iteration 4/960] TRAIN loss:  0.942\n",
      "[epoch 6 Iteration 5/960] TRAIN loss:  0.811\n",
      "[epoch 6 Iteration 6/960] TRAIN loss:  0.681\n",
      "[epoch 6 Iteration 7/960] TRAIN loss:  0.751\n",
      "[epoch 6 Iteration 8/960] TRAIN loss:  0.766\n",
      "[epoch 6 Iteration 9/960] TRAIN loss:  0.864\n",
      "[epoch 6 Iteration 10/960] TRAIN loss:  0.845\n",
      "[epoch 6 Iteration 11/960] TRAIN loss:  0.727\n",
      "[epoch 6 Iteration 12/960] TRAIN loss:  0.892\n",
      "[epoch 6 Iteration 13/960] TRAIN loss:  0.865\n",
      "[epoch 6 Iteration 14/960] TRAIN loss:  0.869\n",
      "[epoch 6 Iteration 15/960] TRAIN loss:  0.604\n",
      "[epoch 6 Iteration 16/960] TRAIN loss:  0.617\n",
      "[epoch 6 Iteration 17/960] TRAIN loss:  1.180\n",
      "[epoch 6 Iteration 18/960] TRAIN loss:  0.896\n",
      "[epoch 6 Iteration 19/960] TRAIN loss:  0.725\n",
      "[epoch 6 Iteration 20/960] TRAIN loss:  0.681\n",
      "[epoch 6 Iteration 21/960] TRAIN loss:  0.795\n",
      "[epoch 6 Iteration 22/960] TRAIN loss:  1.073\n",
      "[epoch 6 Iteration 23/960] TRAIN loss:  1.139\n",
      "[epoch 6 Iteration 24/960] TRAIN loss:  0.942\n",
      "[epoch 6 Iteration 25/960] TRAIN loss:  0.896\n",
      "[epoch 6 Iteration 26/960] TRAIN loss:  0.764\n",
      "[epoch 6 Iteration 27/960] TRAIN loss:  0.984\n",
      "[epoch 6 Iteration 28/960] TRAIN loss:  0.690\n",
      "[epoch 6 Iteration 29/960] TRAIN loss:  0.736\n",
      "[epoch 6 Iteration 30/960] TRAIN loss:  0.772\n",
      "[epoch 6 Iteration 31/960] TRAIN loss:  1.176\n",
      "[epoch 6 Iteration 32/960] TRAIN loss:  0.790\n",
      "[epoch 6 Iteration 33/960] TRAIN loss:  0.776\n",
      "[epoch 6 Iteration 34/960] TRAIN loss:  0.734\n",
      "[epoch 6 Iteration 35/960] TRAIN loss:  1.173\n",
      "[epoch 6 Iteration 36/960] TRAIN loss:  0.753\n",
      "[epoch 6 Iteration 37/960] TRAIN loss:  0.805\n",
      "[epoch 6 Iteration 38/960] TRAIN loss:  0.808\n",
      "[epoch 6 Iteration 39/960] TRAIN loss:  0.787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6 Iteration 40/960] TRAIN loss:  0.854\n",
      "[epoch 6 Iteration 41/960] TRAIN loss:  0.686\n",
      "[epoch 6 Iteration 42/960] TRAIN loss:  0.785\n",
      "[epoch 6 Iteration 43/960] TRAIN loss:  0.931\n",
      "[epoch 6 Iteration 44/960] TRAIN loss:  0.697\n",
      "[epoch 6 Iteration 45/960] TRAIN loss:  0.596\n",
      "[epoch 6 Iteration 46/960] TRAIN loss:  0.857\n",
      "[epoch 6 Iteration 47/960] TRAIN loss:  0.720\n",
      "[epoch 6 Iteration 48/960] TRAIN loss:  0.647\n",
      "[epoch 6 Iteration 49/960] TRAIN loss:  0.840\n",
      "[epoch 6 Iteration 50/960] TRAIN loss:  0.992\n",
      "[epoch 6 Iteration 51/960] TRAIN loss:  0.967\n",
      "[epoch 6 Iteration 52/960] TRAIN loss:  1.064\n",
      "[epoch 6 Iteration 53/960] TRAIN loss:  0.641\n",
      "[epoch 6 Iteration 54/960] TRAIN loss:  1.025\n",
      "[epoch 6 Iteration 55/960] TRAIN loss:  0.941\n",
      "[epoch 6 Iteration 56/960] TRAIN loss:  0.837\n",
      "[epoch 6 Iteration 57/960] TRAIN loss:  0.705\n",
      "[epoch 6 Iteration 58/960] TRAIN loss:  0.803\n",
      "[epoch 6 Iteration 59/960] TRAIN loss:  0.817\n",
      "[epoch 6 Iteration 60/960] TRAIN loss:  0.895\n",
      "[epoch 6 Iteration 61/960] TRAIN loss:  0.793\n",
      "[epoch 6 Iteration 62/960] TRAIN loss:  1.017\n",
      "[epoch 6 Iteration 63/960] TRAIN loss:  0.930\n",
      "[epoch 6 Iteration 64/960] TRAIN loss:  0.924\n",
      "[epoch 6 Iteration 65/960] TRAIN loss:  1.072\n",
      "[epoch 6 Iteration 66/960] TRAIN loss:  0.822\n",
      "[epoch 6 Iteration 67/960] TRAIN loss:  0.713\n",
      "[epoch 6 Iteration 68/960] TRAIN loss:  0.685\n",
      "[epoch 6 Iteration 69/960] TRAIN loss:  0.812\n",
      "[epoch 6 Iteration 70/960] TRAIN loss:  1.133\n",
      "[epoch 6 Iteration 71/960] TRAIN loss:  0.771\n",
      "[epoch 6 Iteration 72/960] TRAIN loss:  0.988\n",
      "[epoch 6 Iteration 73/960] TRAIN loss:  0.987\n",
      "[epoch 6 Iteration 74/960] TRAIN loss:  0.664\n",
      "[epoch 6 Iteration 75/960] TRAIN loss:  0.637\n",
      "[epoch 6 Iteration 76/960] TRAIN loss:  0.745\n",
      "[epoch 6 Iteration 77/960] TRAIN loss:  1.019\n",
      "[epoch 6 Iteration 78/960] TRAIN loss:  1.054\n",
      "[epoch 6 Iteration 79/960] TRAIN loss:  0.689\n",
      "[epoch 6 Iteration 80/960] TRAIN loss:  0.895\n",
      "[epoch 6 Iteration 81/960] TRAIN loss:  0.593\n",
      "[epoch 6 Iteration 82/960] TRAIN loss:  1.033\n",
      "[epoch 6 Iteration 83/960] TRAIN loss:  0.737\n",
      "[epoch 6 Iteration 84/960] TRAIN loss:  1.078\n",
      "[epoch 6 Iteration 85/960] TRAIN loss:  0.559\n",
      "[epoch 6 Iteration 86/960] TRAIN loss:  0.684\n",
      "[epoch 6 Iteration 87/960] TRAIN loss:  0.798\n",
      "[epoch 6 Iteration 88/960] TRAIN loss:  1.020\n",
      "[epoch 6 Iteration 89/960] TRAIN loss:  1.011\n",
      "[epoch 6 Iteration 90/960] TRAIN loss:  0.966\n",
      "[epoch 6 Iteration 91/960] TRAIN loss:  0.879\n",
      "[epoch 6 Iteration 92/960] TRAIN loss:  0.791\n",
      "[epoch 6 Iteration 93/960] TRAIN loss:  0.878\n",
      "[epoch 6 Iteration 94/960] TRAIN loss:  0.710\n",
      "[epoch 6 Iteration 95/960] TRAIN loss:  0.921\n",
      "[epoch 6 Iteration 96/960] TRAIN loss:  0.881\n",
      "[epoch 6 Iteration 97/960] TRAIN loss:  0.917\n",
      "[epoch 6 Iteration 98/960] TRAIN loss:  0.911\n",
      "[epoch 6 Iteration 99/960] TRAIN loss:  1.193\n",
      "[epoch 6 Iteration 100/960] TRAIN loss:  0.922\n",
      "[epoch 6 Iteration 101/960] TRAIN loss:  0.864\n",
      "[epoch 6 Iteration 102/960] TRAIN loss:  0.611\n",
      "[epoch 6 Iteration 103/960] TRAIN loss:  0.720\n",
      "[epoch 6 Iteration 104/960] TRAIN loss:  0.765\n",
      "[epoch 6 Iteration 105/960] TRAIN loss:  0.858\n",
      "[epoch 6 Iteration 106/960] TRAIN loss:  0.940\n",
      "[epoch 6 Iteration 107/960] TRAIN loss:  0.832\n",
      "[epoch 6 Iteration 108/960] TRAIN loss:  1.031\n",
      "[epoch 6 Iteration 109/960] TRAIN loss:  1.043\n",
      "[epoch 6 Iteration 110/960] TRAIN loss:  0.576\n",
      "[epoch 6 Iteration 111/960] TRAIN loss:  0.628\n",
      "[epoch 6 Iteration 112/960] TRAIN loss:  0.669\n",
      "[epoch 6 Iteration 113/960] TRAIN loss:  1.058\n",
      "[epoch 6 Iteration 114/960] TRAIN loss:  1.144\n",
      "[epoch 6 Iteration 115/960] TRAIN loss:  1.175\n",
      "[epoch 6 Iteration 116/960] TRAIN loss:  0.888\n",
      "[epoch 6 Iteration 117/960] TRAIN loss:  0.772\n",
      "[epoch 6 Iteration 118/960] TRAIN loss:  0.848\n",
      "[epoch 6 Iteration 119/960] TRAIN loss:  0.916\n",
      "[epoch 6 Iteration 120/960] TRAIN loss:  0.763\n",
      "[epoch 6 Iteration 121/960] TRAIN loss:  0.870\n",
      "[epoch 6 Iteration 122/960] TRAIN loss:  0.938\n",
      "[epoch 6 Iteration 123/960] TRAIN loss:  0.814\n",
      "[epoch 6 Iteration 124/960] TRAIN loss:  0.888\n",
      "[epoch 6 Iteration 125/960] TRAIN loss:  0.873\n",
      "[epoch 6 Iteration 126/960] TRAIN loss:  0.610\n",
      "[epoch 6 Iteration 127/960] TRAIN loss:  0.636\n",
      "[epoch 6 Iteration 128/960] TRAIN loss:  0.769\n",
      "[epoch 6 Iteration 129/960] TRAIN loss:  0.799\n",
      "[epoch 6 Iteration 130/960] TRAIN loss:  0.750\n",
      "[epoch 6 Iteration 131/960] TRAIN loss:  0.788\n",
      "[epoch 6 Iteration 132/960] TRAIN loss:  0.813\n",
      "[epoch 6 Iteration 133/960] TRAIN loss:  0.624\n",
      "[epoch 6 Iteration 134/960] TRAIN loss:  1.099\n",
      "[epoch 6 Iteration 135/960] TRAIN loss:  0.959\n",
      "[epoch 6 Iteration 136/960] TRAIN loss:  0.742\n",
      "[epoch 6 Iteration 137/960] TRAIN loss:  0.727\n",
      "[epoch 6 Iteration 138/960] TRAIN loss:  0.766\n",
      "[epoch 6 Iteration 139/960] TRAIN loss:  1.035\n",
      "[epoch 6 Iteration 140/960] TRAIN loss:  0.960\n",
      "[epoch 6 Iteration 141/960] TRAIN loss:  0.775\n",
      "[epoch 6 Iteration 142/960] TRAIN loss:  0.647\n",
      "[epoch 6 Iteration 143/960] TRAIN loss:  0.880\n",
      "[epoch 6 Iteration 144/960] TRAIN loss:  0.847\n",
      "[epoch 6 Iteration 145/960] TRAIN loss:  0.664\n",
      "[epoch 6 Iteration 146/960] TRAIN loss:  0.690\n",
      "[epoch 6 Iteration 147/960] TRAIN loss:  0.686\n",
      "[epoch 6 Iteration 148/960] TRAIN loss:  0.774\n",
      "[epoch 6 Iteration 149/960] TRAIN loss:  0.668\n",
      "[epoch 6 Iteration 150/960] TRAIN loss:  1.114\n",
      "[epoch 6 Iteration 151/960] TRAIN loss:  0.763\n",
      "[epoch 6 Iteration 152/960] TRAIN loss:  0.779\n",
      "[epoch 6 Iteration 153/960] TRAIN loss:  0.866\n",
      "[epoch 6 Iteration 154/960] TRAIN loss:  0.882\n",
      "[epoch 6 Iteration 155/960] TRAIN loss:  0.816\n",
      "[epoch 6 Iteration 156/960] TRAIN loss:  0.906\n",
      "[epoch 6 Iteration 157/960] TRAIN loss:  0.854\n",
      "[epoch 6 Iteration 158/960] TRAIN loss:  0.838\n",
      "[epoch 6 Iteration 159/960] TRAIN loss:  0.735\n",
      "[epoch 6 Iteration 160/960] TRAIN loss:  0.702\n",
      "[epoch 6 Iteration 161/960] TRAIN loss:  0.753\n",
      "[epoch 6 Iteration 162/960] TRAIN loss:  0.726\n",
      "[epoch 6 Iteration 163/960] TRAIN loss:  0.606\n",
      "[epoch 6 Iteration 164/960] TRAIN loss:  1.089\n",
      "[epoch 6 Iteration 165/960] TRAIN loss:  0.952\n",
      "[epoch 6 Iteration 166/960] TRAIN loss:  1.099\n",
      "[epoch 6 Iteration 167/960] TRAIN loss:  1.100\n",
      "[epoch 6 Iteration 168/960] TRAIN loss:  0.790\n",
      "[epoch 6 Iteration 169/960] TRAIN loss:  1.072\n",
      "[epoch 6 Iteration 170/960] TRAIN loss:  0.816\n",
      "[epoch 6 Iteration 171/960] TRAIN loss:  0.970\n",
      "[epoch 6 Iteration 172/960] TRAIN loss:  0.983\n",
      "[epoch 6 Iteration 173/960] TRAIN loss:  1.105\n",
      "[epoch 6 Iteration 174/960] TRAIN loss:  0.816\n",
      "[epoch 6 Iteration 175/960] TRAIN loss:  0.921\n",
      "[epoch 6 Iteration 176/960] TRAIN loss:  0.798\n",
      "[epoch 6 Iteration 177/960] TRAIN loss:  0.699\n",
      "[epoch 6 Iteration 178/960] TRAIN loss:  0.767\n",
      "[epoch 6 Iteration 179/960] TRAIN loss:  1.244\n",
      "[epoch 6 Iteration 180/960] TRAIN loss:  1.226\n",
      "[epoch 6 Iteration 181/960] TRAIN loss:  1.068\n",
      "[epoch 6 Iteration 182/960] TRAIN loss:  0.910\n",
      "[epoch 6 Iteration 183/960] TRAIN loss:  0.837\n",
      "[epoch 6 Iteration 184/960] TRAIN loss:  1.007\n",
      "[epoch 6 Iteration 185/960] TRAIN loss:  0.904\n",
      "[epoch 6 Iteration 186/960] TRAIN loss:  1.035\n",
      "[epoch 6 Iteration 187/960] TRAIN loss:  0.991\n",
      "[epoch 6 Iteration 188/960] TRAIN loss:  0.783\n",
      "[epoch 6 Iteration 189/960] TRAIN loss:  0.956\n",
      "[epoch 6 Iteration 190/960] TRAIN loss:  0.869\n",
      "[epoch 6 Iteration 191/960] TRAIN loss:  0.999\n",
      "[epoch 6 Iteration 192/960] TRAIN loss:  0.661\n",
      "[epoch 6 Iteration 193/960] TRAIN loss:  0.774\n",
      "[epoch 6 Iteration 194/960] TRAIN loss:  0.935\n",
      "[epoch 6 Iteration 195/960] TRAIN loss:  0.960\n",
      "[epoch 6 Iteration 196/960] TRAIN loss:  0.790\n",
      "[epoch 6 Iteration 197/960] TRAIN loss:  0.811\n",
      "[epoch 6 Iteration 198/960] TRAIN loss:  0.838\n",
      "[epoch 6 Iteration 199/960] TRAIN loss:  0.909\n",
      "[epoch 6 Iteration 200/960] TRAIN loss:  0.847\n",
      "[epoch 6 Iteration 201/960] TRAIN loss:  1.028\n",
      "[epoch 6 Iteration 202/960] TRAIN loss:  0.765\n",
      "[epoch 6 Iteration 203/960] TRAIN loss:  1.003\n",
      "[epoch 6 Iteration 204/960] TRAIN loss:  0.621\n",
      "[epoch 6 Iteration 205/960] TRAIN loss:  0.963\n",
      "[epoch 6 Iteration 206/960] TRAIN loss:  0.825\n",
      "[epoch 6 Iteration 207/960] TRAIN loss:  0.913\n",
      "[epoch 6 Iteration 208/960] TRAIN loss:  1.212\n",
      "[epoch 6 Iteration 209/960] TRAIN loss:  0.983\n",
      "[epoch 6 Iteration 210/960] TRAIN loss:  0.750\n",
      "[epoch 6 Iteration 211/960] TRAIN loss:  0.886\n",
      "[epoch 6 Iteration 212/960] TRAIN loss:  0.964\n",
      "[epoch 6 Iteration 213/960] TRAIN loss:  0.956\n",
      "[epoch 6 Iteration 214/960] TRAIN loss:  1.050\n",
      "[epoch 6 Iteration 215/960] TRAIN loss:  0.918\n",
      "[epoch 6 Iteration 216/960] TRAIN loss:  1.003\n",
      "[epoch 6 Iteration 217/960] TRAIN loss:  0.886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6 Iteration 218/960] TRAIN loss:  1.102\n",
      "[epoch 6 Iteration 219/960] TRAIN loss:  0.610\n",
      "[epoch 6 Iteration 220/960] TRAIN loss:  0.737\n",
      "[epoch 6 Iteration 221/960] TRAIN loss:  0.903\n",
      "[epoch 6 Iteration 222/960] TRAIN loss:  1.072\n",
      "[epoch 6 Iteration 223/960] TRAIN loss:  0.740\n",
      "[epoch 6 Iteration 224/960] TRAIN loss:  0.926\n",
      "[epoch 6 Iteration 225/960] TRAIN loss:  0.899\n",
      "[epoch 6 Iteration 226/960] TRAIN loss:  0.714\n",
      "[epoch 6 Iteration 227/960] TRAIN loss:  0.930\n",
      "[epoch 6 Iteration 228/960] TRAIN loss:  1.186\n",
      "[epoch 6 Iteration 229/960] TRAIN loss:  0.763\n",
      "[epoch 6 Iteration 230/960] TRAIN loss:  0.939\n",
      "[epoch 6 Iteration 231/960] TRAIN loss:  0.930\n",
      "[epoch 6 Iteration 232/960] TRAIN loss:  0.747\n",
      "[epoch 6 Iteration 233/960] TRAIN loss:  1.012\n",
      "[epoch 6 Iteration 234/960] TRAIN loss:  0.612\n",
      "[epoch 6 Iteration 235/960] TRAIN loss:  1.388\n",
      "[epoch 6 Iteration 236/960] TRAIN loss:  1.032\n",
      "[epoch 6 Iteration 237/960] TRAIN loss:  1.007\n",
      "[epoch 6 Iteration 238/960] TRAIN loss:  0.758\n",
      "[epoch 6 Iteration 239/960] TRAIN loss:  0.816\n",
      "[epoch 6 Iteration 240/960] TRAIN loss:  0.792\n",
      "[epoch 6 Iteration 241/960] TRAIN loss:  1.004\n",
      "[epoch 6 Iteration 242/960] TRAIN loss:  0.868\n",
      "[epoch 6 Iteration 243/960] TRAIN loss:  1.089\n",
      "[epoch 6 Iteration 244/960] TRAIN loss:  1.054\n",
      "[epoch 6 Iteration 245/960] TRAIN loss:  1.308\n",
      "[epoch 6 Iteration 246/960] TRAIN loss:  1.304\n",
      "[epoch 6 Iteration 247/960] TRAIN loss:  0.850\n",
      "[epoch 6 Iteration 248/960] TRAIN loss:  1.105\n",
      "[epoch 6 Iteration 249/960] TRAIN loss:  0.944\n",
      "[epoch 6 Iteration 250/960] TRAIN loss:  0.913\n",
      "[epoch 6 Iteration 251/960] TRAIN loss:  0.711\n",
      "[epoch 6 Iteration 252/960] TRAIN loss:  0.698\n",
      "[epoch 6 Iteration 253/960] TRAIN loss:  0.809\n",
      "[epoch 6 Iteration 254/960] TRAIN loss:  0.946\n",
      "[epoch 6 Iteration 255/960] TRAIN loss:  0.895\n",
      "[epoch 6 Iteration 256/960] TRAIN loss:  0.746\n",
      "[epoch 6 Iteration 257/960] TRAIN loss:  0.840\n",
      "[epoch 6 Iteration 258/960] TRAIN loss:  0.822\n",
      "[epoch 6 Iteration 259/960] TRAIN loss:  0.759\n",
      "[epoch 6 Iteration 260/960] TRAIN loss:  0.886\n",
      "[epoch 6 Iteration 261/960] TRAIN loss:  0.996\n",
      "[epoch 6 Iteration 262/960] TRAIN loss:  1.017\n",
      "[epoch 6 Iteration 263/960] TRAIN loss:  0.825\n",
      "[epoch 6 Iteration 264/960] TRAIN loss:  0.893\n",
      "[epoch 6 Iteration 265/960] TRAIN loss:  0.913\n",
      "[epoch 6 Iteration 266/960] TRAIN loss:  1.205\n",
      "[epoch 6 Iteration 267/960] TRAIN loss:  0.818\n",
      "[epoch 6 Iteration 268/960] TRAIN loss:  0.655\n",
      "[epoch 6 Iteration 269/960] TRAIN loss:  0.794\n",
      "[epoch 6 Iteration 270/960] TRAIN loss:  1.250\n",
      "[epoch 6 Iteration 271/960] TRAIN loss:  1.127\n",
      "[epoch 6 Iteration 272/960] TRAIN loss:  0.649\n",
      "[epoch 6 Iteration 273/960] TRAIN loss:  0.683\n",
      "[epoch 6 Iteration 274/960] TRAIN loss:  0.712\n",
      "[epoch 6 Iteration 275/960] TRAIN loss:  0.644\n",
      "[epoch 6 Iteration 276/960] TRAIN loss:  0.889\n",
      "[epoch 6 Iteration 277/960] TRAIN loss:  1.133\n",
      "[epoch 6 Iteration 278/960] TRAIN loss:  0.931\n",
      "[epoch 6 Iteration 279/960] TRAIN loss:  1.132\n",
      "[epoch 6 Iteration 280/960] TRAIN loss:  0.861\n",
      "[epoch 6 Iteration 281/960] TRAIN loss:  1.048\n",
      "[epoch 6 Iteration 282/960] TRAIN loss:  0.734\n",
      "[epoch 6 Iteration 283/960] TRAIN loss:  0.939\n",
      "[epoch 6 Iteration 284/960] TRAIN loss:  0.880\n",
      "[epoch 6 Iteration 285/960] TRAIN loss:  0.949\n",
      "[epoch 6 Iteration 286/960] TRAIN loss:  0.700\n",
      "[epoch 6 Iteration 287/960] TRAIN loss:  0.863\n",
      "[epoch 6 Iteration 288/960] TRAIN loss:  0.926\n",
      "[epoch 6 Iteration 289/960] TRAIN loss:  1.043\n",
      "[epoch 6 Iteration 290/960] TRAIN loss:  1.000\n",
      "[epoch 6 Iteration 291/960] TRAIN loss:  0.922\n",
      "[epoch 6 Iteration 292/960] TRAIN loss:  1.168\n",
      "[epoch 6 Iteration 293/960] TRAIN loss:  0.730\n",
      "[epoch 6 Iteration 294/960] TRAIN loss:  0.971\n",
      "[epoch 6 Iteration 295/960] TRAIN loss:  0.949\n",
      "[epoch 6 Iteration 296/960] TRAIN loss:  0.870\n",
      "[epoch 6 Iteration 297/960] TRAIN loss:  0.679\n",
      "[epoch 6 Iteration 298/960] TRAIN loss:  0.680\n",
      "[epoch 6 Iteration 299/960] TRAIN loss:  0.876\n",
      "[epoch 6 Iteration 300/960] TRAIN loss:  0.720\n",
      "[epoch 6 Iteration 301/960] TRAIN loss:  0.872\n",
      "[epoch 6 Iteration 302/960] TRAIN loss:  0.984\n",
      "[epoch 6 Iteration 303/960] TRAIN loss:  0.977\n",
      "[epoch 6 Iteration 304/960] TRAIN loss:  0.841\n",
      "[epoch 6 Iteration 305/960] TRAIN loss:  0.677\n",
      "[epoch 6 Iteration 306/960] TRAIN loss:  0.762\n",
      "[epoch 6 Iteration 307/960] TRAIN loss:  0.894\n",
      "[epoch 6 Iteration 308/960] TRAIN loss:  0.905\n",
      "[epoch 6 Iteration 309/960] TRAIN loss:  0.898\n",
      "[epoch 6 Iteration 310/960] TRAIN loss:  0.715\n",
      "[epoch 6 Iteration 311/960] TRAIN loss:  0.711\n",
      "[epoch 6 Iteration 312/960] TRAIN loss:  0.767\n",
      "[epoch 6 Iteration 313/960] TRAIN loss:  0.857\n",
      "[epoch 6 Iteration 314/960] TRAIN loss:  0.902\n",
      "[epoch 6 Iteration 315/960] TRAIN loss:  0.855\n",
      "[epoch 6 Iteration 316/960] TRAIN loss:  1.039\n",
      "[epoch 6 Iteration 317/960] TRAIN loss:  0.767\n",
      "[epoch 6 Iteration 318/960] TRAIN loss:  0.722\n",
      "[epoch 6 Iteration 319/960] TRAIN loss:  0.739\n",
      "[epoch 6 Iteration 320/960] TRAIN loss:  0.828\n",
      "[epoch 6 Iteration 321/960] TRAIN loss:  0.696\n",
      "[epoch 6 Iteration 322/960] TRAIN loss:  0.767\n",
      "[epoch 6 Iteration 323/960] TRAIN loss:  1.003\n",
      "[epoch 6 Iteration 324/960] TRAIN loss:  0.896\n",
      "[epoch 6 Iteration 325/960] TRAIN loss:  1.005\n",
      "[epoch 6 Iteration 326/960] TRAIN loss:  0.944\n",
      "[epoch 6 Iteration 327/960] TRAIN loss:  1.058\n",
      "[epoch 6 Iteration 328/960] TRAIN loss:  0.894\n",
      "[epoch 6 Iteration 329/960] TRAIN loss:  0.953\n",
      "[epoch 6 Iteration 330/960] TRAIN loss:  0.919\n",
      "[epoch 6 Iteration 331/960] TRAIN loss:  0.844\n",
      "[epoch 6 Iteration 332/960] TRAIN loss:  1.001\n",
      "[epoch 6 Iteration 333/960] TRAIN loss:  1.061\n",
      "[epoch 6 Iteration 334/960] TRAIN loss:  0.754\n",
      "[epoch 6 Iteration 335/960] TRAIN loss:  1.081\n",
      "[epoch 6 Iteration 336/960] TRAIN loss:  1.041\n",
      "[epoch 6 Iteration 337/960] TRAIN loss:  0.852\n",
      "[epoch 6 Iteration 338/960] TRAIN loss:  0.904\n",
      "[epoch 6 Iteration 339/960] TRAIN loss:  1.091\n",
      "[epoch 6 Iteration 340/960] TRAIN loss:  0.846\n",
      "[epoch 6 Iteration 341/960] TRAIN loss:  0.778\n",
      "[epoch 6 Iteration 342/960] TRAIN loss:  0.687\n",
      "[epoch 6 Iteration 343/960] TRAIN loss:  0.908\n",
      "[epoch 6 Iteration 344/960] TRAIN loss:  0.787\n",
      "[epoch 6 Iteration 345/960] TRAIN loss:  0.963\n",
      "[epoch 6 Iteration 346/960] TRAIN loss:  1.028\n",
      "[epoch 6 Iteration 347/960] TRAIN loss:  0.804\n",
      "[epoch 6 Iteration 348/960] TRAIN loss:  0.783\n",
      "[epoch 6 Iteration 349/960] TRAIN loss:  1.062\n",
      "[epoch 6 Iteration 350/960] TRAIN loss:  0.875\n",
      "[epoch 6 Iteration 351/960] TRAIN loss:  0.912\n",
      "[epoch 6 Iteration 352/960] TRAIN loss:  1.306\n",
      "[epoch 6 Iteration 353/960] TRAIN loss:  1.080\n",
      "[epoch 6 Iteration 354/960] TRAIN loss:  0.698\n",
      "[epoch 6 Iteration 355/960] TRAIN loss:  0.922\n",
      "[epoch 6 Iteration 356/960] TRAIN loss:  1.172\n",
      "[epoch 6 Iteration 357/960] TRAIN loss:  0.858\n",
      "[epoch 6 Iteration 358/960] TRAIN loss:  1.042\n",
      "[epoch 6 Iteration 359/960] TRAIN loss:  0.843\n",
      "[epoch 6 Iteration 360/960] TRAIN loss:  0.934\n",
      "[epoch 6 Iteration 361/960] TRAIN loss:  0.687\n",
      "[epoch 6 Iteration 362/960] TRAIN loss:  0.879\n",
      "[epoch 6 Iteration 363/960] TRAIN loss:  0.870\n",
      "[epoch 6 Iteration 364/960] TRAIN loss:  0.780\n",
      "[epoch 6 Iteration 365/960] TRAIN loss:  1.225\n",
      "[epoch 6 Iteration 366/960] TRAIN loss:  0.913\n",
      "[epoch 6 Iteration 367/960] TRAIN loss:  0.920\n",
      "[epoch 6 Iteration 368/960] TRAIN loss:  0.783\n",
      "[epoch 6 Iteration 369/960] TRAIN loss:  0.772\n",
      "[epoch 6 Iteration 370/960] TRAIN loss:  0.825\n",
      "[epoch 6 Iteration 371/960] TRAIN loss:  0.811\n",
      "[epoch 6 Iteration 372/960] TRAIN loss:  0.881\n",
      "[epoch 6 Iteration 373/960] TRAIN loss:  0.969\n",
      "[epoch 6 Iteration 374/960] TRAIN loss:  0.922\n",
      "[epoch 6 Iteration 375/960] TRAIN loss:  0.943\n",
      "[epoch 6 Iteration 376/960] TRAIN loss:  0.744\n",
      "[epoch 6 Iteration 377/960] TRAIN loss:  0.780\n",
      "[epoch 6 Iteration 378/960] TRAIN loss:  0.954\n",
      "[epoch 6 Iteration 379/960] TRAIN loss:  1.165\n",
      "[epoch 6 Iteration 380/960] TRAIN loss:  0.617\n",
      "[epoch 6 Iteration 381/960] TRAIN loss:  1.271\n",
      "[epoch 6 Iteration 382/960] TRAIN loss:  0.788\n",
      "[epoch 6 Iteration 383/960] TRAIN loss:  1.052\n",
      "[epoch 6 Iteration 384/960] TRAIN loss:  1.212\n",
      "[epoch 6 Iteration 385/960] TRAIN loss:  1.058\n",
      "[epoch 6 Iteration 386/960] TRAIN loss:  1.066\n",
      "[epoch 6 Iteration 387/960] TRAIN loss:  0.794\n",
      "[epoch 6 Iteration 388/960] TRAIN loss:  0.541\n",
      "[epoch 6 Iteration 389/960] TRAIN loss:  0.959\n",
      "[epoch 6 Iteration 390/960] TRAIN loss:  0.914\n",
      "[epoch 6 Iteration 391/960] TRAIN loss:  0.708\n",
      "[epoch 6 Iteration 392/960] TRAIN loss:  0.937\n",
      "[epoch 6 Iteration 393/960] TRAIN loss:  0.726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6 Iteration 394/960] TRAIN loss:  1.027\n",
      "[epoch 6 Iteration 395/960] TRAIN loss:  0.721\n",
      "[epoch 6 Iteration 396/960] TRAIN loss:  0.577\n",
      "[epoch 6 Iteration 397/960] TRAIN loss:  0.898\n",
      "[epoch 6 Iteration 398/960] TRAIN loss:  1.110\n",
      "[epoch 6 Iteration 399/960] TRAIN loss:  0.710\n",
      "[epoch 6 Iteration 400/960] TRAIN loss:  0.696\n",
      "[epoch 6 Iteration 401/960] TRAIN loss:  0.857\n",
      "[epoch 6 Iteration 402/960] TRAIN loss:  1.266\n",
      "[epoch 6 Iteration 403/960] TRAIN loss:  0.820\n",
      "[epoch 6 Iteration 404/960] TRAIN loss:  0.945\n",
      "[epoch 6 Iteration 405/960] TRAIN loss:  1.034\n",
      "[epoch 6 Iteration 406/960] TRAIN loss:  0.859\n",
      "[epoch 6 Iteration 407/960] TRAIN loss:  0.631\n",
      "[epoch 6 Iteration 408/960] TRAIN loss:  1.003\n",
      "[epoch 6 Iteration 409/960] TRAIN loss:  0.902\n",
      "[epoch 6 Iteration 410/960] TRAIN loss:  0.849\n",
      "[epoch 6 Iteration 411/960] TRAIN loss:  1.163\n",
      "[epoch 6 Iteration 412/960] TRAIN loss:  0.660\n",
      "[epoch 6 Iteration 413/960] TRAIN loss:  0.936\n",
      "[epoch 6 Iteration 414/960] TRAIN loss:  0.611\n",
      "[epoch 6 Iteration 415/960] TRAIN loss:  1.109\n",
      "[epoch 6 Iteration 416/960] TRAIN loss:  1.048\n",
      "[epoch 6 Iteration 417/960] TRAIN loss:  1.040\n",
      "[epoch 6 Iteration 418/960] TRAIN loss:  0.874\n",
      "[epoch 6 Iteration 419/960] TRAIN loss:  0.803\n",
      "[epoch 6 Iteration 420/960] TRAIN loss:  1.090\n",
      "[epoch 6 Iteration 421/960] TRAIN loss:  0.893\n",
      "[epoch 6 Iteration 422/960] TRAIN loss:  1.064\n",
      "[epoch 6 Iteration 423/960] TRAIN loss:  0.740\n",
      "[epoch 6 Iteration 424/960] TRAIN loss:  0.907\n",
      "[epoch 6 Iteration 425/960] TRAIN loss:  0.711\n",
      "[epoch 6 Iteration 426/960] TRAIN loss:  0.707\n",
      "[epoch 6 Iteration 427/960] TRAIN loss:  0.975\n",
      "[epoch 6 Iteration 428/960] TRAIN loss:  0.826\n",
      "[epoch 6 Iteration 429/960] TRAIN loss:  0.813\n",
      "[epoch 6 Iteration 430/960] TRAIN loss:  0.805\n",
      "[epoch 6 Iteration 431/960] TRAIN loss:  1.079\n",
      "[epoch 6 Iteration 432/960] TRAIN loss:  0.881\n",
      "[epoch 6 Iteration 433/960] TRAIN loss:  0.771\n",
      "[epoch 6 Iteration 434/960] TRAIN loss:  0.619\n",
      "[epoch 6 Iteration 435/960] TRAIN loss:  1.076\n",
      "[epoch 6 Iteration 436/960] TRAIN loss:  0.834\n",
      "[epoch 6 Iteration 437/960] TRAIN loss:  0.868\n",
      "[epoch 6 Iteration 438/960] TRAIN loss:  0.971\n",
      "[epoch 6 Iteration 439/960] TRAIN loss:  0.871\n",
      "[epoch 6 Iteration 440/960] TRAIN loss:  0.850\n",
      "[epoch 6 Iteration 441/960] TRAIN loss:  0.938\n",
      "[epoch 6 Iteration 442/960] TRAIN loss:  0.833\n",
      "[epoch 6 Iteration 443/960] TRAIN loss:  0.829\n",
      "[epoch 6 Iteration 444/960] TRAIN loss:  0.713\n",
      "[epoch 6 Iteration 445/960] TRAIN loss:  0.902\n",
      "[epoch 6 Iteration 446/960] TRAIN loss:  0.786\n",
      "[epoch 6 Iteration 447/960] TRAIN loss:  0.807\n",
      "[epoch 6 Iteration 448/960] TRAIN loss:  0.892\n",
      "[epoch 6 Iteration 449/960] TRAIN loss:  0.910\n",
      "[epoch 6 Iteration 450/960] TRAIN loss:  0.827\n",
      "[epoch 6 Iteration 451/960] TRAIN loss:  0.916\n",
      "[epoch 6 Iteration 452/960] TRAIN loss:  1.022\n",
      "[epoch 6 Iteration 453/960] TRAIN loss:  0.954\n",
      "[epoch 6 Iteration 454/960] TRAIN loss:  1.030\n",
      "[epoch 6 Iteration 455/960] TRAIN loss:  0.669\n",
      "[epoch 6 Iteration 456/960] TRAIN loss:  1.170\n",
      "[epoch 6 Iteration 457/960] TRAIN loss:  0.743\n",
      "[epoch 6 Iteration 458/960] TRAIN loss:  0.899\n",
      "[epoch 6 Iteration 459/960] TRAIN loss:  0.812\n",
      "[epoch 6 Iteration 460/960] TRAIN loss:  0.515\n",
      "[epoch 6 Iteration 461/960] TRAIN loss:  0.750\n",
      "[epoch 6 Iteration 462/960] TRAIN loss:  0.679\n",
      "[epoch 6 Iteration 463/960] TRAIN loss:  0.926\n",
      "[epoch 6 Iteration 464/960] TRAIN loss:  1.349\n",
      "[epoch 6 Iteration 465/960] TRAIN loss:  0.836\n",
      "[epoch 6 Iteration 466/960] TRAIN loss:  0.904\n",
      "[epoch 6 Iteration 467/960] TRAIN loss:  0.949\n",
      "[epoch 6 Iteration 468/960] TRAIN loss:  0.755\n",
      "[epoch 6 Iteration 469/960] TRAIN loss:  0.959\n",
      "[epoch 6 Iteration 470/960] TRAIN loss:  0.718\n",
      "[epoch 6 Iteration 471/960] TRAIN loss:  0.929\n",
      "[epoch 6 Iteration 472/960] TRAIN loss:  0.842\n",
      "[epoch 6 Iteration 473/960] TRAIN loss:  0.878\n",
      "[epoch 6 Iteration 474/960] TRAIN loss:  0.884\n",
      "[epoch 6 Iteration 475/960] TRAIN loss:  1.004\n",
      "[epoch 6 Iteration 476/960] TRAIN loss:  1.131\n",
      "[epoch 6 Iteration 477/960] TRAIN loss:  1.022\n",
      "[epoch 6 Iteration 478/960] TRAIN loss:  1.044\n",
      "[epoch 6 Iteration 479/960] TRAIN loss:  0.781\n",
      "[epoch 6 Iteration 480/960] TRAIN loss:  0.808\n",
      "[epoch 6 Iteration 481/960] TRAIN loss:  0.605\n",
      "[epoch 6 Iteration 482/960] TRAIN loss:  0.919\n",
      "[epoch 6 Iteration 483/960] TRAIN loss:  0.916\n",
      "[epoch 6 Iteration 484/960] TRAIN loss:  0.900\n",
      "[epoch 6 Iteration 485/960] TRAIN loss:  0.795\n",
      "[epoch 6 Iteration 486/960] TRAIN loss:  1.019\n",
      "[epoch 6 Iteration 487/960] TRAIN loss:  0.969\n",
      "[epoch 6 Iteration 488/960] TRAIN loss:  0.749\n",
      "[epoch 6 Iteration 489/960] TRAIN loss:  0.809\n",
      "[epoch 6 Iteration 490/960] TRAIN loss:  1.150\n",
      "[epoch 6 Iteration 491/960] TRAIN loss:  0.743\n",
      "[epoch 6 Iteration 492/960] TRAIN loss:  1.013\n",
      "[epoch 6 Iteration 493/960] TRAIN loss:  0.965\n",
      "[epoch 6 Iteration 494/960] TRAIN loss:  0.825\n",
      "[epoch 6 Iteration 495/960] TRAIN loss:  0.901\n",
      "[epoch 6 Iteration 496/960] TRAIN loss:  0.876\n",
      "[epoch 6 Iteration 497/960] TRAIN loss:  0.882\n",
      "[epoch 6 Iteration 498/960] TRAIN loss:  0.833\n",
      "[epoch 6 Iteration 499/960] TRAIN loss:  1.048\n",
      "[epoch 6 Iteration 500/960] TRAIN loss:  1.047\n",
      "[epoch 6 Iteration 501/960] TRAIN loss:  0.694\n",
      "[epoch 6 Iteration 502/960] TRAIN loss:  0.902\n",
      "[epoch 6 Iteration 503/960] TRAIN loss:  1.061\n",
      "[epoch 6 Iteration 504/960] TRAIN loss:  0.751\n",
      "[epoch 6 Iteration 505/960] TRAIN loss:  0.912\n",
      "[epoch 6 Iteration 506/960] TRAIN loss:  1.060\n",
      "[epoch 6 Iteration 507/960] TRAIN loss:  0.814\n",
      "[epoch 6 Iteration 508/960] TRAIN loss:  1.129\n",
      "[epoch 6 Iteration 509/960] TRAIN loss:  0.950\n",
      "[epoch 6 Iteration 510/960] TRAIN loss:  1.075\n",
      "[epoch 6 Iteration 511/960] TRAIN loss:  0.764\n",
      "[epoch 6 Iteration 512/960] TRAIN loss:  1.051\n",
      "[epoch 6 Iteration 513/960] TRAIN loss:  0.852\n",
      "[epoch 6 Iteration 514/960] TRAIN loss:  1.140\n",
      "[epoch 6 Iteration 515/960] TRAIN loss:  0.968\n",
      "[epoch 6 Iteration 516/960] TRAIN loss:  1.002\n",
      "[epoch 6 Iteration 517/960] TRAIN loss:  0.676\n",
      "[epoch 6 Iteration 518/960] TRAIN loss:  0.765\n",
      "[epoch 6 Iteration 519/960] TRAIN loss:  1.163\n",
      "[epoch 6 Iteration 520/960] TRAIN loss:  0.851\n",
      "[epoch 6 Iteration 521/960] TRAIN loss:  0.872\n",
      "[epoch 6 Iteration 522/960] TRAIN loss:  0.767\n",
      "[epoch 6 Iteration 523/960] TRAIN loss:  1.304\n",
      "[epoch 6 Iteration 524/960] TRAIN loss:  0.907\n",
      "[epoch 6 Iteration 525/960] TRAIN loss:  0.742\n",
      "[epoch 6 Iteration 526/960] TRAIN loss:  0.920\n",
      "[epoch 6 Iteration 527/960] TRAIN loss:  0.770\n",
      "[epoch 6 Iteration 528/960] TRAIN loss:  0.742\n",
      "[epoch 6 Iteration 529/960] TRAIN loss:  0.906\n",
      "[epoch 6 Iteration 530/960] TRAIN loss:  0.678\n",
      "[epoch 6 Iteration 531/960] TRAIN loss:  1.174\n",
      "[epoch 6 Iteration 532/960] TRAIN loss:  0.582\n",
      "[epoch 6 Iteration 533/960] TRAIN loss:  1.026\n",
      "[epoch 6 Iteration 534/960] TRAIN loss:  0.986\n",
      "[epoch 6 Iteration 535/960] TRAIN loss:  0.957\n",
      "[epoch 6 Iteration 536/960] TRAIN loss:  0.800\n",
      "[epoch 6 Iteration 537/960] TRAIN loss:  0.791\n",
      "[epoch 6 Iteration 538/960] TRAIN loss:  0.852\n",
      "[epoch 6 Iteration 539/960] TRAIN loss:  0.799\n",
      "[epoch 6 Iteration 540/960] TRAIN loss:  1.160\n",
      "[epoch 6 Iteration 541/960] TRAIN loss:  1.022\n",
      "[epoch 6 Iteration 542/960] TRAIN loss:  0.885\n",
      "[epoch 6 Iteration 543/960] TRAIN loss:  0.839\n",
      "[epoch 6 Iteration 544/960] TRAIN loss:  0.758\n",
      "[epoch 6 Iteration 545/960] TRAIN loss:  0.875\n",
      "[epoch 6 Iteration 546/960] TRAIN loss:  0.893\n",
      "[epoch 6 Iteration 547/960] TRAIN loss:  0.756\n",
      "[epoch 6 Iteration 548/960] TRAIN loss:  0.800\n",
      "[epoch 6 Iteration 549/960] TRAIN loss:  0.841\n",
      "[epoch 6 Iteration 550/960] TRAIN loss:  0.788\n",
      "[epoch 6 Iteration 551/960] TRAIN loss:  1.042\n",
      "[epoch 6 Iteration 552/960] TRAIN loss:  0.856\n",
      "[epoch 6 Iteration 553/960] TRAIN loss:  1.157\n",
      "[epoch 6 Iteration 554/960] TRAIN loss:  0.827\n",
      "[epoch 6 Iteration 555/960] TRAIN loss:  1.003\n",
      "[epoch 6 Iteration 556/960] TRAIN loss:  0.849\n",
      "[epoch 6 Iteration 557/960] TRAIN loss:  0.671\n",
      "[epoch 6 Iteration 558/960] TRAIN loss:  0.693\n",
      "[epoch 6 Iteration 559/960] TRAIN loss:  0.822\n",
      "[epoch 6 Iteration 560/960] TRAIN loss:  0.876\n",
      "[epoch 6 Iteration 561/960] TRAIN loss:  0.770\n",
      "[epoch 6 Iteration 562/960] TRAIN loss:  1.053\n",
      "[epoch 6 Iteration 563/960] TRAIN loss:  0.940\n",
      "[epoch 6 Iteration 564/960] TRAIN loss:  0.494\n",
      "[epoch 6 Iteration 565/960] TRAIN loss:  0.829\n",
      "[epoch 6 Iteration 566/960] TRAIN loss:  0.809\n",
      "[epoch 6 Iteration 567/960] TRAIN loss:  0.969\n",
      "[epoch 6 Iteration 568/960] TRAIN loss:  0.890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6 Iteration 569/960] TRAIN loss:  0.903\n",
      "[epoch 6 Iteration 570/960] TRAIN loss:  0.906\n",
      "[epoch 6 Iteration 571/960] TRAIN loss:  0.742\n",
      "[epoch 6 Iteration 572/960] TRAIN loss:  0.817\n",
      "[epoch 6 Iteration 573/960] TRAIN loss:  0.975\n",
      "[epoch 6 Iteration 574/960] TRAIN loss:  1.027\n",
      "[epoch 6 Iteration 575/960] TRAIN loss:  0.857\n",
      "[epoch 6 Iteration 576/960] TRAIN loss:  0.585\n",
      "[epoch 6 Iteration 577/960] TRAIN loss:  0.952\n",
      "[epoch 6 Iteration 578/960] TRAIN loss:  0.709\n",
      "[epoch 6 Iteration 579/960] TRAIN loss:  0.971\n",
      "[epoch 6 Iteration 580/960] TRAIN loss:  1.157\n",
      "[epoch 6 Iteration 581/960] TRAIN loss:  0.982\n",
      "[epoch 6 Iteration 582/960] TRAIN loss:  0.832\n",
      "[epoch 6 Iteration 583/960] TRAIN loss:  0.968\n",
      "[epoch 6 Iteration 584/960] TRAIN loss:  0.716\n",
      "[epoch 6 Iteration 585/960] TRAIN loss:  0.759\n",
      "[epoch 6 Iteration 586/960] TRAIN loss:  1.017\n",
      "[epoch 6 Iteration 587/960] TRAIN loss:  0.658\n",
      "[epoch 6 Iteration 588/960] TRAIN loss:  0.733\n",
      "[epoch 6 Iteration 589/960] TRAIN loss:  0.690\n",
      "[epoch 6 Iteration 590/960] TRAIN loss:  1.008\n",
      "[epoch 6 Iteration 591/960] TRAIN loss:  0.923\n",
      "[epoch 6 Iteration 592/960] TRAIN loss:  0.839\n",
      "[epoch 6 Iteration 593/960] TRAIN loss:  0.757\n",
      "[epoch 6 Iteration 594/960] TRAIN loss:  0.613\n",
      "[epoch 6 Iteration 595/960] TRAIN loss:  1.037\n",
      "[epoch 6 Iteration 596/960] TRAIN loss:  0.914\n",
      "[epoch 6 Iteration 597/960] TRAIN loss:  1.016\n",
      "[epoch 6 Iteration 598/960] TRAIN loss:  1.047\n",
      "[epoch 6 Iteration 599/960] TRAIN loss:  0.703\n",
      "[epoch 6 Iteration 600/960] TRAIN loss:  0.703\n",
      "[epoch 6 Iteration 601/960] TRAIN loss:  0.770\n",
      "[epoch 6 Iteration 602/960] TRAIN loss:  0.846\n",
      "[epoch 6 Iteration 603/960] TRAIN loss:  0.924\n",
      "[epoch 6 Iteration 604/960] TRAIN loss:  0.969\n",
      "[epoch 6 Iteration 605/960] TRAIN loss:  0.775\n",
      "[epoch 6 Iteration 606/960] TRAIN loss:  0.950\n",
      "[epoch 6 Iteration 607/960] TRAIN loss:  1.043\n",
      "[epoch 6 Iteration 608/960] TRAIN loss:  0.770\n",
      "[epoch 6 Iteration 609/960] TRAIN loss:  0.900\n",
      "[epoch 6 Iteration 610/960] TRAIN loss:  0.864\n",
      "[epoch 6 Iteration 611/960] TRAIN loss:  0.962\n",
      "[epoch 6 Iteration 612/960] TRAIN loss:  0.776\n",
      "[epoch 6 Iteration 613/960] TRAIN loss:  0.881\n",
      "[epoch 6 Iteration 614/960] TRAIN loss:  0.850\n",
      "[epoch 6 Iteration 615/960] TRAIN loss:  0.807\n",
      "[epoch 6 Iteration 616/960] TRAIN loss:  0.888\n",
      "[epoch 6 Iteration 617/960] TRAIN loss:  0.781\n",
      "[epoch 6 Iteration 618/960] TRAIN loss:  0.775\n",
      "[epoch 6 Iteration 619/960] TRAIN loss:  0.883\n",
      "[epoch 6 Iteration 620/960] TRAIN loss:  1.039\n",
      "[epoch 6 Iteration 621/960] TRAIN loss:  0.695\n",
      "[epoch 6 Iteration 622/960] TRAIN loss:  1.024\n",
      "[epoch 6 Iteration 623/960] TRAIN loss:  0.457\n",
      "[epoch 6 Iteration 624/960] TRAIN loss:  0.807\n",
      "[epoch 6 Iteration 625/960] TRAIN loss:  0.795\n",
      "[epoch 6 Iteration 626/960] TRAIN loss:  1.034\n",
      "[epoch 6 Iteration 627/960] TRAIN loss:  0.826\n",
      "[epoch 6 Iteration 628/960] TRAIN loss:  0.886\n",
      "[epoch 6 Iteration 629/960] TRAIN loss:  0.789\n",
      "[epoch 6 Iteration 630/960] TRAIN loss:  0.816\n",
      "[epoch 6 Iteration 631/960] TRAIN loss:  0.844\n",
      "[epoch 6 Iteration 632/960] TRAIN loss:  0.819\n",
      "[epoch 6 Iteration 633/960] TRAIN loss:  0.872\n",
      "[epoch 6 Iteration 634/960] TRAIN loss:  1.250\n",
      "[epoch 6 Iteration 635/960] TRAIN loss:  0.694\n",
      "[epoch 6 Iteration 636/960] TRAIN loss:  1.067\n",
      "[epoch 6 Iteration 637/960] TRAIN loss:  0.741\n",
      "[epoch 6 Iteration 638/960] TRAIN loss:  0.695\n",
      "[epoch 6 Iteration 639/960] TRAIN loss:  0.902\n",
      "[epoch 6 Iteration 640/960] TRAIN loss:  0.729\n",
      "[epoch 6 Iteration 641/960] TRAIN loss:  0.783\n",
      "[epoch 6 Iteration 642/960] TRAIN loss:  0.911\n",
      "[epoch 6 Iteration 643/960] TRAIN loss:  0.704\n",
      "[epoch 6 Iteration 644/960] TRAIN loss:  0.739\n",
      "[epoch 6 Iteration 645/960] TRAIN loss:  1.114\n",
      "[epoch 6 Iteration 646/960] TRAIN loss:  0.728\n",
      "[epoch 6 Iteration 647/960] TRAIN loss:  0.845\n",
      "[epoch 6 Iteration 648/960] TRAIN loss:  0.869\n",
      "[epoch 6 Iteration 649/960] TRAIN loss:  1.341\n",
      "[epoch 6 Iteration 650/960] TRAIN loss:  0.700\n",
      "[epoch 6 Iteration 651/960] TRAIN loss:  0.948\n",
      "[epoch 6 Iteration 652/960] TRAIN loss:  0.884\n",
      "[epoch 6 Iteration 653/960] TRAIN loss:  1.086\n",
      "[epoch 6 Iteration 654/960] TRAIN loss:  1.148\n",
      "[epoch 6 Iteration 655/960] TRAIN loss:  0.713\n",
      "[epoch 6 Iteration 656/960] TRAIN loss:  0.589\n",
      "[epoch 6 Iteration 657/960] TRAIN loss:  0.791\n",
      "[epoch 6 Iteration 658/960] TRAIN loss:  0.959\n",
      "[epoch 6 Iteration 659/960] TRAIN loss:  0.835\n",
      "[epoch 6 Iteration 660/960] TRAIN loss:  0.847\n",
      "[epoch 6 Iteration 661/960] TRAIN loss:  1.331\n",
      "[epoch 6 Iteration 662/960] TRAIN loss:  0.873\n",
      "[epoch 6 Iteration 663/960] TRAIN loss:  0.509\n",
      "[epoch 6 Iteration 664/960] TRAIN loss:  0.595\n",
      "[epoch 6 Iteration 665/960] TRAIN loss:  1.003\n",
      "[epoch 6 Iteration 666/960] TRAIN loss:  0.654\n",
      "[epoch 6 Iteration 667/960] TRAIN loss:  0.622\n",
      "[epoch 6 Iteration 668/960] TRAIN loss:  0.898\n",
      "[epoch 6 Iteration 669/960] TRAIN loss:  1.106\n",
      "[epoch 6 Iteration 670/960] TRAIN loss:  1.037\n",
      "[epoch 6 Iteration 671/960] TRAIN loss:  1.172\n",
      "[epoch 6 Iteration 672/960] TRAIN loss:  0.737\n",
      "[epoch 6 Iteration 673/960] TRAIN loss:  0.865\n",
      "[epoch 6 Iteration 674/960] TRAIN loss:  0.876\n",
      "[epoch 6 Iteration 675/960] TRAIN loss:  0.833\n",
      "[epoch 6 Iteration 676/960] TRAIN loss:  0.880\n",
      "[epoch 6 Iteration 677/960] TRAIN loss:  0.899\n",
      "[epoch 6 Iteration 678/960] TRAIN loss:  0.829\n",
      "[epoch 6 Iteration 679/960] TRAIN loss:  0.659\n",
      "[epoch 6 Iteration 680/960] TRAIN loss:  1.062\n",
      "[epoch 6 Iteration 681/960] TRAIN loss:  0.761\n",
      "[epoch 6 Iteration 682/960] TRAIN loss:  0.662\n",
      "[epoch 6 Iteration 683/960] TRAIN loss:  1.227\n",
      "[epoch 6 Iteration 684/960] TRAIN loss:  0.931\n",
      "[epoch 6 Iteration 685/960] TRAIN loss:  0.999\n",
      "[epoch 6 Iteration 686/960] TRAIN loss:  0.997\n",
      "[epoch 6 Iteration 687/960] TRAIN loss:  0.983\n",
      "[epoch 6 Iteration 688/960] TRAIN loss:  1.036\n",
      "[epoch 6 Iteration 689/960] TRAIN loss:  0.908\n",
      "[epoch 6 Iteration 690/960] TRAIN loss:  0.656\n",
      "[epoch 6 Iteration 691/960] TRAIN loss:  0.983\n",
      "[epoch 6 Iteration 692/960] TRAIN loss:  0.580\n",
      "[epoch 6 Iteration 693/960] TRAIN loss:  0.954\n",
      "[epoch 6 Iteration 694/960] TRAIN loss:  1.197\n",
      "[epoch 6 Iteration 695/960] TRAIN loss:  0.995\n",
      "[epoch 6 Iteration 696/960] TRAIN loss:  0.725\n",
      "[epoch 6 Iteration 697/960] TRAIN loss:  0.751\n",
      "[epoch 6 Iteration 698/960] TRAIN loss:  0.800\n",
      "[epoch 6 Iteration 699/960] TRAIN loss:  0.637\n",
      "[epoch 6 Iteration 700/960] TRAIN loss:  0.796\n",
      "[epoch 6 Iteration 701/960] TRAIN loss:  1.134\n",
      "[epoch 6 Iteration 702/960] TRAIN loss:  1.132\n",
      "[epoch 6 Iteration 703/960] TRAIN loss:  0.878\n",
      "[epoch 6 Iteration 704/960] TRAIN loss:  0.878\n",
      "[epoch 6 Iteration 705/960] TRAIN loss:  0.794\n",
      "[epoch 6 Iteration 706/960] TRAIN loss:  1.155\n",
      "[epoch 6 Iteration 707/960] TRAIN loss:  0.781\n",
      "[epoch 6 Iteration 708/960] TRAIN loss:  0.867\n",
      "[epoch 6 Iteration 709/960] TRAIN loss:  0.887\n",
      "[epoch 6 Iteration 710/960] TRAIN loss:  0.913\n",
      "[epoch 6 Iteration 711/960] TRAIN loss:  0.769\n",
      "[epoch 6 Iteration 712/960] TRAIN loss:  1.057\n",
      "[epoch 6 Iteration 713/960] TRAIN loss:  0.977\n",
      "[epoch 6 Iteration 714/960] TRAIN loss:  0.919\n",
      "[epoch 6 Iteration 715/960] TRAIN loss:  0.852\n",
      "[epoch 6 Iteration 716/960] TRAIN loss:  0.711\n",
      "[epoch 6 Iteration 717/960] TRAIN loss:  0.836\n",
      "[epoch 6 Iteration 718/960] TRAIN loss:  0.669\n",
      "[epoch 6 Iteration 719/960] TRAIN loss:  0.993\n",
      "[epoch 6 Iteration 720/960] TRAIN loss:  0.654\n",
      "[epoch 6 Iteration 721/960] TRAIN loss:  1.083\n",
      "[epoch 6 Iteration 722/960] TRAIN loss:  1.106\n",
      "[epoch 6 Iteration 723/960] TRAIN loss:  0.769\n",
      "[epoch 6 Iteration 724/960] TRAIN loss:  0.888\n",
      "[epoch 6 Iteration 725/960] TRAIN loss:  0.790\n",
      "[epoch 6 Iteration 726/960] TRAIN loss:  0.763\n",
      "[epoch 6 Iteration 727/960] TRAIN loss:  1.085\n",
      "[epoch 6 Iteration 728/960] TRAIN loss:  0.875\n",
      "[epoch 6 Iteration 729/960] TRAIN loss:  1.010\n",
      "[epoch 6 Iteration 730/960] TRAIN loss:  1.024\n",
      "[epoch 6 Iteration 731/960] TRAIN loss:  0.705\n",
      "[epoch 6 Iteration 732/960] TRAIN loss:  0.868\n",
      "[epoch 6 Iteration 733/960] TRAIN loss:  0.894\n",
      "[epoch 6 Iteration 734/960] TRAIN loss:  0.583\n",
      "[epoch 6 Iteration 735/960] TRAIN loss:  0.626\n",
      "[epoch 6 Iteration 736/960] TRAIN loss:  0.903\n",
      "[epoch 6 Iteration 737/960] TRAIN loss:  0.588\n",
      "[epoch 6 Iteration 738/960] TRAIN loss:  0.664\n",
      "[epoch 6 Iteration 739/960] TRAIN loss:  0.897\n",
      "[epoch 6 Iteration 740/960] TRAIN loss:  1.053\n",
      "[epoch 6 Iteration 741/960] TRAIN loss:  0.947\n",
      "[epoch 6 Iteration 742/960] TRAIN loss:  1.104\n",
      "[epoch 6 Iteration 743/960] TRAIN loss:  0.830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6 Iteration 744/960] TRAIN loss:  1.072\n",
      "[epoch 6 Iteration 745/960] TRAIN loss:  1.283\n",
      "[epoch 6 Iteration 746/960] TRAIN loss:  0.864\n",
      "[epoch 6 Iteration 747/960] TRAIN loss:  0.759\n",
      "[epoch 6 Iteration 748/960] TRAIN loss:  0.744\n",
      "[epoch 6 Iteration 749/960] TRAIN loss:  0.961\n",
      "[epoch 6 Iteration 750/960] TRAIN loss:  0.954\n",
      "[epoch 6 Iteration 751/960] TRAIN loss:  0.908\n",
      "[epoch 6 Iteration 752/960] TRAIN loss:  0.714\n",
      "[epoch 6 Iteration 753/960] TRAIN loss:  0.744\n",
      "[epoch 6 Iteration 754/960] TRAIN loss:  1.105\n",
      "[epoch 6 Iteration 755/960] TRAIN loss:  0.840\n",
      "[epoch 6 Iteration 756/960] TRAIN loss:  0.766\n",
      "[epoch 6 Iteration 757/960] TRAIN loss:  0.740\n",
      "[epoch 6 Iteration 758/960] TRAIN loss:  1.209\n",
      "[epoch 6 Iteration 759/960] TRAIN loss:  1.076\n",
      "[epoch 6 Iteration 760/960] TRAIN loss:  0.703\n",
      "[epoch 6 Iteration 761/960] TRAIN loss:  0.966\n",
      "[epoch 6 Iteration 762/960] TRAIN loss:  1.089\n",
      "[epoch 6 Iteration 763/960] TRAIN loss:  1.090\n",
      "[epoch 6 Iteration 764/960] TRAIN loss:  1.033\n",
      "[epoch 6 Iteration 765/960] TRAIN loss:  0.911\n",
      "[epoch 6 Iteration 766/960] TRAIN loss:  1.052\n",
      "[epoch 6 Iteration 767/960] TRAIN loss:  0.968\n",
      "[epoch 6 Iteration 768/960] TRAIN loss:  0.811\n",
      "[epoch 6 Iteration 769/960] TRAIN loss:  0.776\n",
      "[epoch 6 Iteration 770/960] TRAIN loss:  0.847\n",
      "[epoch 6 Iteration 771/960] TRAIN loss:  0.994\n",
      "[epoch 6 Iteration 772/960] TRAIN loss:  0.931\n",
      "[epoch 6 Iteration 773/960] TRAIN loss:  0.836\n",
      "[epoch 6 Iteration 774/960] TRAIN loss:  0.993\n",
      "[epoch 6 Iteration 775/960] TRAIN loss:  1.069\n",
      "[epoch 6 Iteration 776/960] TRAIN loss:  0.989\n",
      "[epoch 6 Iteration 777/960] TRAIN loss:  0.782\n",
      "[epoch 6 Iteration 778/960] TRAIN loss:  0.944\n",
      "[epoch 6 Iteration 779/960] TRAIN loss:  1.141\n",
      "[epoch 6 Iteration 780/960] TRAIN loss:  0.616\n",
      "[epoch 6 Iteration 781/960] TRAIN loss:  1.103\n",
      "[epoch 6 Iteration 782/960] TRAIN loss:  0.731\n",
      "[epoch 6 Iteration 783/960] TRAIN loss:  1.115\n",
      "[epoch 6 Iteration 784/960] TRAIN loss:  0.622\n",
      "[epoch 6 Iteration 785/960] TRAIN loss:  0.744\n",
      "[epoch 6 Iteration 786/960] TRAIN loss:  0.934\n",
      "[epoch 6 Iteration 787/960] TRAIN loss:  0.739\n",
      "[epoch 6 Iteration 788/960] TRAIN loss:  1.112\n",
      "[epoch 6 Iteration 789/960] TRAIN loss:  0.804\n",
      "[epoch 6 Iteration 790/960] TRAIN loss:  1.035\n",
      "[epoch 6 Iteration 791/960] TRAIN loss:  0.633\n",
      "[epoch 6 Iteration 792/960] TRAIN loss:  0.770\n",
      "[epoch 6 Iteration 793/960] TRAIN loss:  1.186\n",
      "[epoch 6 Iteration 794/960] TRAIN loss:  0.804\n",
      "[epoch 6 Iteration 795/960] TRAIN loss:  0.926\n",
      "[epoch 6 Iteration 796/960] TRAIN loss:  0.761\n",
      "[epoch 6 Iteration 797/960] TRAIN loss:  1.200\n",
      "[epoch 6 Iteration 798/960] TRAIN loss:  0.993\n",
      "[epoch 6 Iteration 799/960] TRAIN loss:  0.866\n",
      "[epoch 6 Iteration 800/960] TRAIN loss:  0.936\n",
      "[epoch 6 Iteration 801/960] TRAIN loss:  0.991\n",
      "[epoch 6 Iteration 802/960] TRAIN loss:  1.047\n",
      "[epoch 6 Iteration 803/960] TRAIN loss:  0.866\n",
      "[epoch 6 Iteration 804/960] TRAIN loss:  0.912\n",
      "[epoch 6 Iteration 805/960] TRAIN loss:  0.953\n",
      "[epoch 6 Iteration 806/960] TRAIN loss:  0.681\n",
      "[epoch 6 Iteration 807/960] TRAIN loss:  0.973\n",
      "[epoch 6 Iteration 808/960] TRAIN loss:  0.764\n",
      "[epoch 6 Iteration 809/960] TRAIN loss:  0.850\n",
      "[epoch 6 Iteration 810/960] TRAIN loss:  1.038\n",
      "[epoch 6 Iteration 811/960] TRAIN loss:  1.001\n",
      "[epoch 6 Iteration 812/960] TRAIN loss:  0.951\n",
      "[epoch 6 Iteration 813/960] TRAIN loss:  0.814\n",
      "[epoch 6 Iteration 814/960] TRAIN loss:  0.816\n",
      "[epoch 6 Iteration 815/960] TRAIN loss:  0.926\n",
      "[epoch 6 Iteration 816/960] TRAIN loss:  0.655\n",
      "[epoch 6 Iteration 817/960] TRAIN loss:  0.739\n",
      "[epoch 6 Iteration 818/960] TRAIN loss:  0.801\n",
      "[epoch 6 Iteration 819/960] TRAIN loss:  0.940\n",
      "[epoch 6 Iteration 820/960] TRAIN loss:  0.773\n",
      "[epoch 6 Iteration 821/960] TRAIN loss:  1.130\n",
      "[epoch 6 Iteration 822/960] TRAIN loss:  0.857\n",
      "[epoch 6 Iteration 823/960] TRAIN loss:  0.854\n",
      "[epoch 6 Iteration 824/960] TRAIN loss:  0.951\n",
      "[epoch 6 Iteration 825/960] TRAIN loss:  0.945\n",
      "[epoch 6 Iteration 826/960] TRAIN loss:  1.063\n",
      "[epoch 6 Iteration 827/960] TRAIN loss:  1.119\n",
      "[epoch 6 Iteration 828/960] TRAIN loss:  0.773\n",
      "[epoch 6 Iteration 829/960] TRAIN loss:  0.663\n",
      "[epoch 6 Iteration 830/960] TRAIN loss:  0.736\n",
      "[epoch 6 Iteration 831/960] TRAIN loss:  0.929\n",
      "[epoch 6 Iteration 832/960] TRAIN loss:  0.808\n",
      "[epoch 6 Iteration 833/960] TRAIN loss:  0.837\n",
      "[epoch 6 Iteration 834/960] TRAIN loss:  1.170\n",
      "[epoch 6 Iteration 835/960] TRAIN loss:  0.928\n",
      "[epoch 6 Iteration 836/960] TRAIN loss:  0.911\n",
      "[epoch 6 Iteration 837/960] TRAIN loss:  0.851\n",
      "[epoch 6 Iteration 838/960] TRAIN loss:  1.276\n",
      "[epoch 6 Iteration 839/960] TRAIN loss:  1.030\n",
      "[epoch 6 Iteration 840/960] TRAIN loss:  0.898\n",
      "[epoch 6 Iteration 841/960] TRAIN loss:  1.033\n",
      "[epoch 6 Iteration 842/960] TRAIN loss:  1.086\n",
      "[epoch 6 Iteration 843/960] TRAIN loss:  1.369\n",
      "[epoch 6 Iteration 844/960] TRAIN loss:  0.768\n",
      "[epoch 6 Iteration 845/960] TRAIN loss:  0.881\n",
      "[epoch 6 Iteration 846/960] TRAIN loss:  1.117\n",
      "[epoch 6 Iteration 847/960] TRAIN loss:  0.847\n",
      "[epoch 6 Iteration 848/960] TRAIN loss:  0.746\n",
      "[epoch 6 Iteration 849/960] TRAIN loss:  0.877\n",
      "[epoch 6 Iteration 850/960] TRAIN loss:  1.008\n",
      "[epoch 6 Iteration 851/960] TRAIN loss:  0.734\n",
      "[epoch 6 Iteration 852/960] TRAIN loss:  0.889\n",
      "[epoch 6 Iteration 853/960] TRAIN loss:  1.050\n",
      "[epoch 6 Iteration 854/960] TRAIN loss:  0.673\n",
      "[epoch 6 Iteration 855/960] TRAIN loss:  1.036\n",
      "[epoch 6 Iteration 856/960] TRAIN loss:  1.002\n",
      "[epoch 6 Iteration 857/960] TRAIN loss:  0.759\n",
      "[epoch 6 Iteration 858/960] TRAIN loss:  0.807\n",
      "[epoch 6 Iteration 859/960] TRAIN loss:  0.851\n",
      "[epoch 6 Iteration 860/960] TRAIN loss:  0.857\n",
      "[epoch 6 Iteration 861/960] TRAIN loss:  0.780\n",
      "[epoch 6 Iteration 862/960] TRAIN loss:  0.817\n",
      "[epoch 6 Iteration 863/960] TRAIN loss:  1.034\n",
      "[epoch 6 Iteration 864/960] TRAIN loss:  1.045\n",
      "[epoch 6 Iteration 865/960] TRAIN loss:  0.666\n",
      "[epoch 6 Iteration 866/960] TRAIN loss:  1.001\n",
      "[epoch 6 Iteration 867/960] TRAIN loss:  0.842\n",
      "[epoch 6 Iteration 868/960] TRAIN loss:  0.909\n",
      "[epoch 6 Iteration 869/960] TRAIN loss:  0.970\n",
      "[epoch 6 Iteration 870/960] TRAIN loss:  1.197\n",
      "[epoch 6 Iteration 871/960] TRAIN loss:  0.663\n",
      "[epoch 6 Iteration 872/960] TRAIN loss:  1.056\n",
      "[epoch 6 Iteration 873/960] TRAIN loss:  1.025\n",
      "[epoch 6 Iteration 874/960] TRAIN loss:  0.793\n",
      "[epoch 6 Iteration 875/960] TRAIN loss:  0.881\n",
      "[epoch 6 Iteration 876/960] TRAIN loss:  0.689\n",
      "[epoch 6 Iteration 877/960] TRAIN loss:  0.825\n",
      "[epoch 6 Iteration 878/960] TRAIN loss:  1.030\n",
      "[epoch 6 Iteration 879/960] TRAIN loss:  0.833\n",
      "[epoch 6 Iteration 880/960] TRAIN loss:  1.190\n",
      "[epoch 6 Iteration 881/960] TRAIN loss:  1.021\n",
      "[epoch 6 Iteration 882/960] TRAIN loss:  0.930\n",
      "[epoch 6 Iteration 883/960] TRAIN loss:  0.972\n",
      "[epoch 6 Iteration 884/960] TRAIN loss:  1.005\n",
      "[epoch 6 Iteration 885/960] TRAIN loss:  0.867\n",
      "[epoch 6 Iteration 886/960] TRAIN loss:  0.853\n",
      "[epoch 6 Iteration 887/960] TRAIN loss:  0.790\n",
      "[epoch 6 Iteration 888/960] TRAIN loss:  0.764\n",
      "[epoch 6 Iteration 889/960] TRAIN loss:  0.950\n",
      "[epoch 6 Iteration 890/960] TRAIN loss:  0.978\n",
      "[epoch 6 Iteration 891/960] TRAIN loss:  1.053\n",
      "[epoch 6 Iteration 892/960] TRAIN loss:  0.806\n",
      "[epoch 6 Iteration 893/960] TRAIN loss:  0.807\n",
      "[epoch 6 Iteration 894/960] TRAIN loss:  0.817\n",
      "[epoch 6 Iteration 895/960] TRAIN loss:  0.612\n",
      "[epoch 6 Iteration 896/960] TRAIN loss:  0.760\n",
      "[epoch 6 Iteration 897/960] TRAIN loss:  0.877\n",
      "[epoch 6 Iteration 898/960] TRAIN loss:  1.009\n",
      "[epoch 6 Iteration 899/960] TRAIN loss:  0.839\n",
      "[epoch 6 Iteration 900/960] TRAIN loss:  0.814\n",
      "[epoch 6 Iteration 901/960] TRAIN loss:  0.725\n",
      "[epoch 6 Iteration 902/960] TRAIN loss:  0.792\n",
      "[epoch 6 Iteration 903/960] TRAIN loss:  0.897\n",
      "[epoch 6 Iteration 904/960] TRAIN loss:  0.763\n",
      "[epoch 6 Iteration 905/960] TRAIN loss:  1.136\n",
      "[epoch 6 Iteration 906/960] TRAIN loss:  0.958\n",
      "[epoch 6 Iteration 907/960] TRAIN loss:  1.165\n",
      "[epoch 6 Iteration 908/960] TRAIN loss:  0.783\n",
      "[epoch 6 Iteration 909/960] TRAIN loss:  0.990\n",
      "[epoch 6 Iteration 910/960] TRAIN loss:  0.626\n",
      "[epoch 6 Iteration 911/960] TRAIN loss:  0.794\n",
      "[epoch 6 Iteration 912/960] TRAIN loss:  1.030\n",
      "[epoch 6 Iteration 913/960] TRAIN loss:  0.979\n",
      "[epoch 6 Iteration 914/960] TRAIN loss:  0.518\n",
      "[epoch 6 Iteration 915/960] TRAIN loss:  0.815\n",
      "[epoch 6 Iteration 916/960] TRAIN loss:  0.798\n",
      "[epoch 6 Iteration 917/960] TRAIN loss:  1.090\n",
      "[epoch 6 Iteration 918/960] TRAIN loss:  0.740\n",
      "[epoch 6 Iteration 919/960] TRAIN loss:  0.912\n",
      "[epoch 6 Iteration 920/960] TRAIN loss:  1.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6 Iteration 921/960] TRAIN loss:  0.678\n",
      "[epoch 6 Iteration 922/960] TRAIN loss:  0.830\n",
      "[epoch 6 Iteration 923/960] TRAIN loss:  0.777\n",
      "[epoch 6 Iteration 924/960] TRAIN loss:  0.869\n",
      "[epoch 6 Iteration 925/960] TRAIN loss:  0.891\n",
      "[epoch 6 Iteration 926/960] TRAIN loss:  0.988\n",
      "[epoch 6 Iteration 927/960] TRAIN loss:  0.960\n",
      "[epoch 6 Iteration 928/960] TRAIN loss:  0.915\n",
      "[epoch 6 Iteration 929/960] TRAIN loss:  0.737\n",
      "[epoch 6 Iteration 930/960] TRAIN loss:  1.022\n",
      "[epoch 6 Iteration 931/960] TRAIN loss:  1.278\n",
      "[epoch 6 Iteration 932/960] TRAIN loss:  0.868\n",
      "[epoch 6 Iteration 933/960] TRAIN loss:  1.114\n",
      "[epoch 6 Iteration 934/960] TRAIN loss:  0.830\n",
      "[epoch 6 Iteration 935/960] TRAIN loss:  0.986\n",
      "[epoch 6 Iteration 936/960] TRAIN loss:  0.802\n",
      "[epoch 6 Iteration 937/960] TRAIN loss:  0.878\n",
      "[epoch 6 Iteration 938/960] TRAIN loss:  0.953\n",
      "[epoch 6 Iteration 939/960] TRAIN loss:  0.830\n",
      "[epoch 6 Iteration 940/960] TRAIN loss:  1.027\n",
      "[epoch 6 Iteration 941/960] TRAIN loss:  0.784\n",
      "[epoch 6 Iteration 942/960] TRAIN loss:  0.744\n",
      "[epoch 6 Iteration 943/960] TRAIN loss:  0.729\n",
      "[epoch 6 Iteration 944/960] TRAIN loss:  1.025\n",
      "[epoch 6 Iteration 945/960] TRAIN loss:  1.036\n",
      "[epoch 6 Iteration 946/960] TRAIN loss:  0.841\n",
      "[epoch 6 Iteration 947/960] TRAIN loss:  0.898\n",
      "[epoch 6 Iteration 948/960] TRAIN loss:  0.687\n",
      "[epoch 6 Iteration 949/960] TRAIN loss:  0.854\n",
      "[epoch 6 Iteration 950/960] TRAIN loss:  0.980\n",
      "[epoch 6 Iteration 951/960] TRAIN loss:  0.859\n",
      "[epoch 6 Iteration 952/960] TRAIN loss:  0.623\n",
      "[epoch 6 Iteration 953/960] TRAIN loss:  0.976\n",
      "[epoch 6 Iteration 954/960] TRAIN loss:  0.860\n",
      "[epoch 6 Iteration 955/960] TRAIN loss:  0.999\n",
      "[epoch 6 Iteration 956/960] TRAIN loss:  0.999\n",
      "[epoch 6 Iteration 957/960] TRAIN loss:  0.904\n",
      "[epoch 6 Iteration 958/960] TRAIN loss:  0.931\n",
      "[epoch 6 Iteration 959/960] TRAIN loss:  0.779\n",
      "[epoch 6/15] TRAIN acc/loss:  0.687/0.779\n",
      "[epoch 6/15] VAL acc/loss:  0.640/0.579\n",
      "[epoch 7 Iteration 0/960] TRAIN loss:  0.927\n",
      "[epoch 7 Iteration 1/960] TRAIN loss:  1.037\n",
      "[epoch 7 Iteration 2/960] TRAIN loss:  0.813\n",
      "[epoch 7 Iteration 3/960] TRAIN loss:  0.711\n",
      "[epoch 7 Iteration 4/960] TRAIN loss:  0.821\n",
      "[epoch 7 Iteration 5/960] TRAIN loss:  0.803\n",
      "[epoch 7 Iteration 6/960] TRAIN loss:  0.813\n",
      "[epoch 7 Iteration 7/960] TRAIN loss:  0.746\n",
      "[epoch 7 Iteration 8/960] TRAIN loss:  0.714\n",
      "[epoch 7 Iteration 9/960] TRAIN loss:  0.877\n",
      "[epoch 7 Iteration 10/960] TRAIN loss:  0.869\n",
      "[epoch 7 Iteration 11/960] TRAIN loss:  0.852\n",
      "[epoch 7 Iteration 12/960] TRAIN loss:  0.856\n",
      "[epoch 7 Iteration 13/960] TRAIN loss:  1.123\n",
      "[epoch 7 Iteration 14/960] TRAIN loss:  0.928\n",
      "[epoch 7 Iteration 15/960] TRAIN loss:  0.838\n",
      "[epoch 7 Iteration 16/960] TRAIN loss:  1.074\n",
      "[epoch 7 Iteration 17/960] TRAIN loss:  0.754\n",
      "[epoch 7 Iteration 18/960] TRAIN loss:  0.765\n",
      "[epoch 7 Iteration 19/960] TRAIN loss:  0.724\n",
      "[epoch 7 Iteration 20/960] TRAIN loss:  0.653\n",
      "[epoch 7 Iteration 21/960] TRAIN loss:  0.874\n",
      "[epoch 7 Iteration 22/960] TRAIN loss:  1.003\n",
      "[epoch 7 Iteration 23/960] TRAIN loss:  0.938\n",
      "[epoch 7 Iteration 24/960] TRAIN loss:  0.858\n",
      "[epoch 7 Iteration 25/960] TRAIN loss:  1.138\n",
      "[epoch 7 Iteration 26/960] TRAIN loss:  0.469\n",
      "[epoch 7 Iteration 27/960] TRAIN loss:  0.918\n",
      "[epoch 7 Iteration 28/960] TRAIN loss:  0.701\n",
      "[epoch 7 Iteration 29/960] TRAIN loss:  0.780\n",
      "[epoch 7 Iteration 30/960] TRAIN loss:  0.789\n",
      "[epoch 7 Iteration 31/960] TRAIN loss:  0.712\n",
      "[epoch 7 Iteration 32/960] TRAIN loss:  0.709\n",
      "[epoch 7 Iteration 33/960] TRAIN loss:  0.748\n",
      "[epoch 7 Iteration 34/960] TRAIN loss:  1.172\n",
      "[epoch 7 Iteration 35/960] TRAIN loss:  0.639\n",
      "[epoch 7 Iteration 36/960] TRAIN loss:  0.872\n",
      "[epoch 7 Iteration 37/960] TRAIN loss:  0.736\n",
      "[epoch 7 Iteration 38/960] TRAIN loss:  0.487\n",
      "[epoch 7 Iteration 39/960] TRAIN loss:  1.084\n",
      "[epoch 7 Iteration 40/960] TRAIN loss:  0.788\n",
      "[epoch 7 Iteration 41/960] TRAIN loss:  0.935\n",
      "[epoch 7 Iteration 42/960] TRAIN loss:  0.678\n",
      "[epoch 7 Iteration 43/960] TRAIN loss:  0.782\n",
      "[epoch 7 Iteration 44/960] TRAIN loss:  0.475\n",
      "[epoch 7 Iteration 45/960] TRAIN loss:  0.833\n",
      "[epoch 7 Iteration 46/960] TRAIN loss:  0.818\n",
      "[epoch 7 Iteration 47/960] TRAIN loss:  0.829\n",
      "[epoch 7 Iteration 48/960] TRAIN loss:  0.727\n",
      "[epoch 7 Iteration 49/960] TRAIN loss:  0.731\n",
      "[epoch 7 Iteration 50/960] TRAIN loss:  0.615\n",
      "[epoch 7 Iteration 51/960] TRAIN loss:  0.760\n",
      "[epoch 7 Iteration 52/960] TRAIN loss:  0.861\n",
      "[epoch 7 Iteration 53/960] TRAIN loss:  0.738\n",
      "[epoch 7 Iteration 54/960] TRAIN loss:  0.900\n",
      "[epoch 7 Iteration 55/960] TRAIN loss:  0.709\n",
      "[epoch 7 Iteration 56/960] TRAIN loss:  1.175\n",
      "[epoch 7 Iteration 57/960] TRAIN loss:  0.579\n",
      "[epoch 7 Iteration 58/960] TRAIN loss:  0.788\n",
      "[epoch 7 Iteration 59/960] TRAIN loss:  1.051\n",
      "[epoch 7 Iteration 60/960] TRAIN loss:  0.653\n",
      "[epoch 7 Iteration 61/960] TRAIN loss:  0.786\n",
      "[epoch 7 Iteration 62/960] TRAIN loss:  0.980\n",
      "[epoch 7 Iteration 63/960] TRAIN loss:  0.956\n",
      "[epoch 7 Iteration 64/960] TRAIN loss:  0.900\n",
      "[epoch 7 Iteration 65/960] TRAIN loss:  0.695\n",
      "[epoch 7 Iteration 66/960] TRAIN loss:  0.961\n",
      "[epoch 7 Iteration 67/960] TRAIN loss:  0.942\n",
      "[epoch 7 Iteration 68/960] TRAIN loss:  1.145\n",
      "[epoch 7 Iteration 69/960] TRAIN loss:  0.693\n",
      "[epoch 7 Iteration 70/960] TRAIN loss:  0.817\n",
      "[epoch 7 Iteration 71/960] TRAIN loss:  0.699\n",
      "[epoch 7 Iteration 72/960] TRAIN loss:  0.623\n",
      "[epoch 7 Iteration 73/960] TRAIN loss:  0.899\n",
      "[epoch 7 Iteration 74/960] TRAIN loss:  0.641\n",
      "[epoch 7 Iteration 75/960] TRAIN loss:  0.790\n",
      "[epoch 7 Iteration 76/960] TRAIN loss:  0.772\n",
      "[epoch 7 Iteration 77/960] TRAIN loss:  0.830\n",
      "[epoch 7 Iteration 78/960] TRAIN loss:  0.758\n",
      "[epoch 7 Iteration 79/960] TRAIN loss:  0.709\n",
      "[epoch 7 Iteration 80/960] TRAIN loss:  0.677\n",
      "[epoch 7 Iteration 81/960] TRAIN loss:  1.268\n",
      "[epoch 7 Iteration 82/960] TRAIN loss:  0.760\n",
      "[epoch 7 Iteration 83/960] TRAIN loss:  0.656\n",
      "[epoch 7 Iteration 84/960] TRAIN loss:  0.988\n",
      "[epoch 7 Iteration 85/960] TRAIN loss:  1.001\n",
      "[epoch 7 Iteration 86/960] TRAIN loss:  0.960\n",
      "[epoch 7 Iteration 87/960] TRAIN loss:  0.880\n",
      "[epoch 7 Iteration 88/960] TRAIN loss:  0.781\n",
      "[epoch 7 Iteration 89/960] TRAIN loss:  0.891\n",
      "[epoch 7 Iteration 90/960] TRAIN loss:  0.714\n",
      "[epoch 7 Iteration 91/960] TRAIN loss:  0.646\n",
      "[epoch 7 Iteration 92/960] TRAIN loss:  0.955\n",
      "[epoch 7 Iteration 93/960] TRAIN loss:  0.818\n",
      "[epoch 7 Iteration 94/960] TRAIN loss:  0.755\n",
      "[epoch 7 Iteration 95/960] TRAIN loss:  0.874\n",
      "[epoch 7 Iteration 96/960] TRAIN loss:  0.772\n",
      "[epoch 7 Iteration 97/960] TRAIN loss:  0.655\n",
      "[epoch 7 Iteration 98/960] TRAIN loss:  0.743\n",
      "[epoch 7 Iteration 99/960] TRAIN loss:  0.713\n",
      "[epoch 7 Iteration 100/960] TRAIN loss:  0.763\n",
      "[epoch 7 Iteration 101/960] TRAIN loss:  0.873\n",
      "[epoch 7 Iteration 102/960] TRAIN loss:  1.034\n",
      "[epoch 7 Iteration 103/960] TRAIN loss:  0.899\n",
      "[epoch 7 Iteration 104/960] TRAIN loss:  0.678\n",
      "[epoch 7 Iteration 105/960] TRAIN loss:  0.920\n",
      "[epoch 7 Iteration 106/960] TRAIN loss:  0.705\n",
      "[epoch 7 Iteration 107/960] TRAIN loss:  0.691\n",
      "[epoch 7 Iteration 108/960] TRAIN loss:  0.848\n",
      "[epoch 7 Iteration 109/960] TRAIN loss:  0.809\n",
      "[epoch 7 Iteration 110/960] TRAIN loss:  0.833\n",
      "[epoch 7 Iteration 111/960] TRAIN loss:  0.804\n",
      "[epoch 7 Iteration 112/960] TRAIN loss:  0.777\n",
      "[epoch 7 Iteration 113/960] TRAIN loss:  0.917\n",
      "[epoch 7 Iteration 114/960] TRAIN loss:  0.841\n",
      "[epoch 7 Iteration 115/960] TRAIN loss:  0.680\n",
      "[epoch 7 Iteration 116/960] TRAIN loss:  0.832\n",
      "[epoch 7 Iteration 117/960] TRAIN loss:  0.773\n",
      "[epoch 7 Iteration 118/960] TRAIN loss:  0.840\n",
      "[epoch 7 Iteration 119/960] TRAIN loss:  0.852\n",
      "[epoch 7 Iteration 120/960] TRAIN loss:  0.712\n",
      "[epoch 7 Iteration 121/960] TRAIN loss:  0.709\n",
      "[epoch 7 Iteration 122/960] TRAIN loss:  0.599\n",
      "[epoch 7 Iteration 123/960] TRAIN loss:  0.934\n",
      "[epoch 7 Iteration 124/960] TRAIN loss:  0.768\n",
      "[epoch 7 Iteration 125/960] TRAIN loss:  0.782\n",
      "[epoch 7 Iteration 126/960] TRAIN loss:  0.763\n",
      "[epoch 7 Iteration 127/960] TRAIN loss:  1.029\n",
      "[epoch 7 Iteration 128/960] TRAIN loss:  0.772\n",
      "[epoch 7 Iteration 129/960] TRAIN loss:  0.766\n",
      "[epoch 7 Iteration 130/960] TRAIN loss:  0.758\n",
      "[epoch 7 Iteration 131/960] TRAIN loss:  1.020\n",
      "[epoch 7 Iteration 132/960] TRAIN loss:  0.777\n",
      "[epoch 7 Iteration 133/960] TRAIN loss:  0.696\n",
      "[epoch 7 Iteration 134/960] TRAIN loss:  0.762\n",
      "[epoch 7 Iteration 135/960] TRAIN loss:  0.988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7 Iteration 136/960] TRAIN loss:  0.879\n",
      "[epoch 7 Iteration 137/960] TRAIN loss:  1.015\n",
      "[epoch 7 Iteration 138/960] TRAIN loss:  0.581\n",
      "[epoch 7 Iteration 139/960] TRAIN loss:  0.845\n",
      "[epoch 7 Iteration 140/960] TRAIN loss:  0.859\n",
      "[epoch 7 Iteration 141/960] TRAIN loss:  0.713\n",
      "[epoch 7 Iteration 142/960] TRAIN loss:  0.558\n",
      "[epoch 7 Iteration 143/960] TRAIN loss:  0.923\n",
      "[epoch 7 Iteration 144/960] TRAIN loss:  0.602\n",
      "[epoch 7 Iteration 145/960] TRAIN loss:  0.728\n",
      "[epoch 7 Iteration 146/960] TRAIN loss:  0.636\n",
      "[epoch 7 Iteration 147/960] TRAIN loss:  0.679\n",
      "[epoch 7 Iteration 148/960] TRAIN loss:  1.027\n",
      "[epoch 7 Iteration 149/960] TRAIN loss:  1.067\n",
      "[epoch 7 Iteration 150/960] TRAIN loss:  0.997\n",
      "[epoch 7 Iteration 151/960] TRAIN loss:  0.810\n",
      "[epoch 7 Iteration 152/960] TRAIN loss:  0.775\n",
      "[epoch 7 Iteration 153/960] TRAIN loss:  0.813\n",
      "[epoch 7 Iteration 154/960] TRAIN loss:  0.635\n",
      "[epoch 7 Iteration 155/960] TRAIN loss:  0.846\n",
      "[epoch 7 Iteration 156/960] TRAIN loss:  1.043\n",
      "[epoch 7 Iteration 157/960] TRAIN loss:  0.971\n",
      "[epoch 7 Iteration 158/960] TRAIN loss:  0.860\n",
      "[epoch 7 Iteration 159/960] TRAIN loss:  0.690\n",
      "[epoch 7 Iteration 160/960] TRAIN loss:  0.723\n",
      "[epoch 7 Iteration 161/960] TRAIN loss:  0.845\n",
      "[epoch 7 Iteration 162/960] TRAIN loss:  0.786\n",
      "[epoch 7 Iteration 163/960] TRAIN loss:  1.006\n",
      "[epoch 7 Iteration 164/960] TRAIN loss:  0.690\n",
      "[epoch 7 Iteration 165/960] TRAIN loss:  1.009\n",
      "[epoch 7 Iteration 166/960] TRAIN loss:  0.702\n",
      "[epoch 7 Iteration 167/960] TRAIN loss:  0.924\n",
      "[epoch 7 Iteration 168/960] TRAIN loss:  0.616\n",
      "[epoch 7 Iteration 169/960] TRAIN loss:  0.679\n",
      "[epoch 7 Iteration 170/960] TRAIN loss:  0.892\n",
      "[epoch 7 Iteration 171/960] TRAIN loss:  0.888\n",
      "[epoch 7 Iteration 172/960] TRAIN loss:  0.832\n",
      "[epoch 7 Iteration 173/960] TRAIN loss:  0.875\n",
      "[epoch 7 Iteration 174/960] TRAIN loss:  0.597\n",
      "[epoch 7 Iteration 175/960] TRAIN loss:  0.566\n",
      "[epoch 7 Iteration 176/960] TRAIN loss:  0.978\n",
      "[epoch 7 Iteration 177/960] TRAIN loss:  0.982\n",
      "[epoch 7 Iteration 178/960] TRAIN loss:  0.472\n",
      "[epoch 7 Iteration 179/960] TRAIN loss:  0.561\n",
      "[epoch 7 Iteration 180/960] TRAIN loss:  0.692\n",
      "[epoch 7 Iteration 181/960] TRAIN loss:  1.012\n",
      "[epoch 7 Iteration 182/960] TRAIN loss:  0.905\n",
      "[epoch 7 Iteration 183/960] TRAIN loss:  0.832\n",
      "[epoch 7 Iteration 184/960] TRAIN loss:  0.778\n",
      "[epoch 7 Iteration 185/960] TRAIN loss:  0.683\n",
      "[epoch 7 Iteration 186/960] TRAIN loss:  0.958\n",
      "[epoch 7 Iteration 187/960] TRAIN loss:  0.752\n",
      "[epoch 7 Iteration 188/960] TRAIN loss:  0.596\n",
      "[epoch 7 Iteration 189/960] TRAIN loss:  0.744\n",
      "[epoch 7 Iteration 190/960] TRAIN loss:  0.667\n",
      "[epoch 7 Iteration 191/960] TRAIN loss:  0.883\n",
      "[epoch 7 Iteration 192/960] TRAIN loss:  0.923\n",
      "[epoch 7 Iteration 193/960] TRAIN loss:  0.907\n",
      "[epoch 7 Iteration 194/960] TRAIN loss:  0.721\n",
      "[epoch 7 Iteration 195/960] TRAIN loss:  0.704\n",
      "[epoch 7 Iteration 196/960] TRAIN loss:  0.877\n",
      "[epoch 7 Iteration 197/960] TRAIN loss:  0.647\n",
      "[epoch 7 Iteration 198/960] TRAIN loss:  1.073\n",
      "[epoch 7 Iteration 199/960] TRAIN loss:  0.828\n",
      "[epoch 7 Iteration 200/960] TRAIN loss:  0.760\n",
      "[epoch 7 Iteration 201/960] TRAIN loss:  0.639\n",
      "[epoch 7 Iteration 202/960] TRAIN loss:  0.904\n",
      "[epoch 7 Iteration 203/960] TRAIN loss:  0.963\n",
      "[epoch 7 Iteration 204/960] TRAIN loss:  0.836\n",
      "[epoch 7 Iteration 205/960] TRAIN loss:  0.670\n",
      "[epoch 7 Iteration 206/960] TRAIN loss:  0.918\n",
      "[epoch 7 Iteration 207/960] TRAIN loss:  0.925\n",
      "[epoch 7 Iteration 208/960] TRAIN loss:  0.954\n",
      "[epoch 7 Iteration 209/960] TRAIN loss:  0.845\n",
      "[epoch 7 Iteration 210/960] TRAIN loss:  0.858\n",
      "[epoch 7 Iteration 211/960] TRAIN loss:  0.842\n",
      "[epoch 7 Iteration 212/960] TRAIN loss:  0.905\n",
      "[epoch 7 Iteration 213/960] TRAIN loss:  0.676\n",
      "[epoch 7 Iteration 214/960] TRAIN loss:  1.277\n",
      "[epoch 7 Iteration 215/960] TRAIN loss:  0.804\n",
      "[epoch 7 Iteration 216/960] TRAIN loss:  0.833\n",
      "[epoch 7 Iteration 217/960] TRAIN loss:  0.666\n",
      "[epoch 7 Iteration 218/960] TRAIN loss:  0.748\n",
      "[epoch 7 Iteration 219/960] TRAIN loss:  0.790\n",
      "[epoch 7 Iteration 220/960] TRAIN loss:  0.878\n",
      "[epoch 7 Iteration 221/960] TRAIN loss:  0.910\n",
      "[epoch 7 Iteration 222/960] TRAIN loss:  0.737\n",
      "[epoch 7 Iteration 223/960] TRAIN loss:  0.588\n",
      "[epoch 7 Iteration 224/960] TRAIN loss:  0.891\n",
      "[epoch 7 Iteration 225/960] TRAIN loss:  0.761\n",
      "[epoch 7 Iteration 226/960] TRAIN loss:  1.036\n",
      "[epoch 7 Iteration 227/960] TRAIN loss:  0.837\n",
      "[epoch 7 Iteration 228/960] TRAIN loss:  0.761\n",
      "[epoch 7 Iteration 229/960] TRAIN loss:  0.771\n",
      "[epoch 7 Iteration 230/960] TRAIN loss:  0.815\n",
      "[epoch 7 Iteration 231/960] TRAIN loss:  1.054\n",
      "[epoch 7 Iteration 232/960] TRAIN loss:  0.690\n",
      "[epoch 7 Iteration 233/960] TRAIN loss:  0.709\n",
      "[epoch 7 Iteration 234/960] TRAIN loss:  0.780\n",
      "[epoch 7 Iteration 235/960] TRAIN loss:  0.961\n",
      "[epoch 7 Iteration 236/960] TRAIN loss:  1.099\n",
      "[epoch 7 Iteration 237/960] TRAIN loss:  0.396\n",
      "[epoch 7 Iteration 238/960] TRAIN loss:  0.857\n",
      "[epoch 7 Iteration 239/960] TRAIN loss:  0.831\n",
      "[epoch 7 Iteration 240/960] TRAIN loss:  0.701\n",
      "[epoch 7 Iteration 241/960] TRAIN loss:  1.103\n",
      "[epoch 7 Iteration 242/960] TRAIN loss:  0.974\n",
      "[epoch 7 Iteration 243/960] TRAIN loss:  0.774\n",
      "[epoch 7 Iteration 244/960] TRAIN loss:  0.821\n",
      "[epoch 7 Iteration 245/960] TRAIN loss:  0.788\n",
      "[epoch 7 Iteration 246/960] TRAIN loss:  1.042\n",
      "[epoch 7 Iteration 247/960] TRAIN loss:  0.575\n",
      "[epoch 7 Iteration 248/960] TRAIN loss:  0.689\n",
      "[epoch 7 Iteration 249/960] TRAIN loss:  0.672\n",
      "[epoch 7 Iteration 250/960] TRAIN loss:  0.868\n",
      "[epoch 7 Iteration 251/960] TRAIN loss:  0.998\n",
      "[epoch 7 Iteration 252/960] TRAIN loss:  0.622\n",
      "[epoch 7 Iteration 253/960] TRAIN loss:  0.802\n",
      "[epoch 7 Iteration 254/960] TRAIN loss:  0.893\n",
      "[epoch 7 Iteration 255/960] TRAIN loss:  0.967\n",
      "[epoch 7 Iteration 256/960] TRAIN loss:  0.924\n",
      "[epoch 7 Iteration 257/960] TRAIN loss:  1.033\n",
      "[epoch 7 Iteration 258/960] TRAIN loss:  1.102\n",
      "[epoch 7 Iteration 259/960] TRAIN loss:  0.669\n",
      "[epoch 7 Iteration 260/960] TRAIN loss:  1.088\n",
      "[epoch 7 Iteration 261/960] TRAIN loss:  0.701\n",
      "[epoch 7 Iteration 262/960] TRAIN loss:  0.771\n",
      "[epoch 7 Iteration 263/960] TRAIN loss:  0.969\n",
      "[epoch 7 Iteration 264/960] TRAIN loss:  0.911\n",
      "[epoch 7 Iteration 265/960] TRAIN loss:  0.721\n",
      "[epoch 7 Iteration 266/960] TRAIN loss:  0.910\n",
      "[epoch 7 Iteration 267/960] TRAIN loss:  0.845\n",
      "[epoch 7 Iteration 268/960] TRAIN loss:  0.845\n",
      "[epoch 7 Iteration 269/960] TRAIN loss:  0.769\n",
      "[epoch 7 Iteration 270/960] TRAIN loss:  0.846\n",
      "[epoch 7 Iteration 271/960] TRAIN loss:  0.771\n",
      "[epoch 7 Iteration 272/960] TRAIN loss:  0.863\n",
      "[epoch 7 Iteration 273/960] TRAIN loss:  0.845\n",
      "[epoch 7 Iteration 274/960] TRAIN loss:  0.540\n",
      "[epoch 7 Iteration 275/960] TRAIN loss:  0.875\n",
      "[epoch 7 Iteration 276/960] TRAIN loss:  0.627\n",
      "[epoch 7 Iteration 277/960] TRAIN loss:  0.929\n",
      "[epoch 7 Iteration 278/960] TRAIN loss:  0.693\n",
      "[epoch 7 Iteration 279/960] TRAIN loss:  0.554\n",
      "[epoch 7 Iteration 280/960] TRAIN loss:  0.771\n",
      "[epoch 7 Iteration 281/960] TRAIN loss:  1.047\n",
      "[epoch 7 Iteration 282/960] TRAIN loss:  0.612\n",
      "[epoch 7 Iteration 283/960] TRAIN loss:  0.761\n",
      "[epoch 7 Iteration 284/960] TRAIN loss:  0.774\n",
      "[epoch 7 Iteration 285/960] TRAIN loss:  0.749\n",
      "[epoch 7 Iteration 286/960] TRAIN loss:  0.915\n",
      "[epoch 7 Iteration 287/960] TRAIN loss:  1.145\n",
      "[epoch 7 Iteration 288/960] TRAIN loss:  0.963\n",
      "[epoch 7 Iteration 289/960] TRAIN loss:  0.874\n",
      "[epoch 7 Iteration 290/960] TRAIN loss:  0.804\n",
      "[epoch 7 Iteration 291/960] TRAIN loss:  0.914\n",
      "[epoch 7 Iteration 292/960] TRAIN loss:  1.068\n",
      "[epoch 7 Iteration 293/960] TRAIN loss:  0.829\n",
      "[epoch 7 Iteration 294/960] TRAIN loss:  1.185\n",
      "[epoch 7 Iteration 295/960] TRAIN loss:  0.884\n",
      "[epoch 7 Iteration 296/960] TRAIN loss:  0.777\n",
      "[epoch 7 Iteration 297/960] TRAIN loss:  1.014\n",
      "[epoch 7 Iteration 298/960] TRAIN loss:  0.871\n",
      "[epoch 7 Iteration 299/960] TRAIN loss:  1.128\n",
      "[epoch 7 Iteration 300/960] TRAIN loss:  0.895\n",
      "[epoch 7 Iteration 301/960] TRAIN loss:  0.730\n",
      "[epoch 7 Iteration 302/960] TRAIN loss:  0.918\n",
      "[epoch 7 Iteration 303/960] TRAIN loss:  0.971\n",
      "[epoch 7 Iteration 304/960] TRAIN loss:  0.964\n",
      "[epoch 7 Iteration 305/960] TRAIN loss:  1.049\n",
      "[epoch 7 Iteration 306/960] TRAIN loss:  1.024\n",
      "[epoch 7 Iteration 307/960] TRAIN loss:  0.894\n",
      "[epoch 7 Iteration 308/960] TRAIN loss:  0.762\n",
      "[epoch 7 Iteration 309/960] TRAIN loss:  0.568\n",
      "[epoch 7 Iteration 310/960] TRAIN loss:  1.015\n",
      "[epoch 7 Iteration 311/960] TRAIN loss:  0.970\n",
      "[epoch 7 Iteration 312/960] TRAIN loss:  0.627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7 Iteration 313/960] TRAIN loss:  0.762\n",
      "[epoch 7 Iteration 314/960] TRAIN loss:  0.740\n",
      "[epoch 7 Iteration 315/960] TRAIN loss:  0.995\n",
      "[epoch 7 Iteration 316/960] TRAIN loss:  0.804\n",
      "[epoch 7 Iteration 317/960] TRAIN loss:  0.701\n",
      "[epoch 7 Iteration 318/960] TRAIN loss:  0.801\n",
      "[epoch 7 Iteration 319/960] TRAIN loss:  0.700\n",
      "[epoch 7 Iteration 320/960] TRAIN loss:  0.878\n",
      "[epoch 7 Iteration 321/960] TRAIN loss:  0.818\n",
      "[epoch 7 Iteration 322/960] TRAIN loss:  0.831\n",
      "[epoch 7 Iteration 323/960] TRAIN loss:  0.973\n",
      "[epoch 7 Iteration 324/960] TRAIN loss:  1.180\n",
      "[epoch 7 Iteration 325/960] TRAIN loss:  0.756\n",
      "[epoch 7 Iteration 326/960] TRAIN loss:  1.129\n",
      "[epoch 7 Iteration 327/960] TRAIN loss:  1.023\n",
      "[epoch 7 Iteration 328/960] TRAIN loss:  0.770\n",
      "[epoch 7 Iteration 329/960] TRAIN loss:  0.649\n",
      "[epoch 7 Iteration 330/960] TRAIN loss:  0.930\n",
      "[epoch 7 Iteration 331/960] TRAIN loss:  1.037\n",
      "[epoch 7 Iteration 332/960] TRAIN loss:  0.691\n",
      "[epoch 7 Iteration 333/960] TRAIN loss:  0.658\n",
      "[epoch 7 Iteration 334/960] TRAIN loss:  0.886\n",
      "[epoch 7 Iteration 335/960] TRAIN loss:  0.832\n",
      "[epoch 7 Iteration 336/960] TRAIN loss:  1.139\n",
      "[epoch 7 Iteration 337/960] TRAIN loss:  1.015\n",
      "[epoch 7 Iteration 338/960] TRAIN loss:  0.894\n",
      "[epoch 7 Iteration 339/960] TRAIN loss:  0.837\n",
      "[epoch 7 Iteration 340/960] TRAIN loss:  0.711\n",
      "[epoch 7 Iteration 341/960] TRAIN loss:  0.716\n",
      "[epoch 7 Iteration 342/960] TRAIN loss:  0.721\n",
      "[epoch 7 Iteration 343/960] TRAIN loss:  0.707\n",
      "[epoch 7 Iteration 344/960] TRAIN loss:  1.184\n",
      "[epoch 7 Iteration 345/960] TRAIN loss:  1.125\n",
      "[epoch 7 Iteration 346/960] TRAIN loss:  0.658\n",
      "[epoch 7 Iteration 347/960] TRAIN loss:  0.656\n",
      "[epoch 7 Iteration 348/960] TRAIN loss:  0.883\n",
      "[epoch 7 Iteration 349/960] TRAIN loss:  1.018\n",
      "[epoch 7 Iteration 350/960] TRAIN loss:  0.737\n",
      "[epoch 7 Iteration 351/960] TRAIN loss:  0.827\n",
      "[epoch 7 Iteration 352/960] TRAIN loss:  0.825\n",
      "[epoch 7 Iteration 353/960] TRAIN loss:  0.895\n",
      "[epoch 7 Iteration 354/960] TRAIN loss:  0.872\n",
      "[epoch 7 Iteration 355/960] TRAIN loss:  0.967\n",
      "[epoch 7 Iteration 356/960] TRAIN loss:  0.762\n",
      "[epoch 7 Iteration 357/960] TRAIN loss:  0.781\n",
      "[epoch 7 Iteration 358/960] TRAIN loss:  0.827\n",
      "[epoch 7 Iteration 359/960] TRAIN loss:  0.671\n",
      "[epoch 7 Iteration 360/960] TRAIN loss:  0.856\n",
      "[epoch 7 Iteration 361/960] TRAIN loss:  0.549\n",
      "[epoch 7 Iteration 362/960] TRAIN loss:  0.938\n",
      "[epoch 7 Iteration 363/960] TRAIN loss:  1.117\n",
      "[epoch 7 Iteration 364/960] TRAIN loss:  0.813\n",
      "[epoch 7 Iteration 365/960] TRAIN loss:  0.919\n",
      "[epoch 7 Iteration 366/960] TRAIN loss:  0.730\n",
      "[epoch 7 Iteration 367/960] TRAIN loss:  0.727\n",
      "[epoch 7 Iteration 368/960] TRAIN loss:  0.823\n",
      "[epoch 7 Iteration 369/960] TRAIN loss:  0.929\n",
      "[epoch 7 Iteration 370/960] TRAIN loss:  0.672\n",
      "[epoch 7 Iteration 371/960] TRAIN loss:  0.977\n",
      "[epoch 7 Iteration 372/960] TRAIN loss:  0.795\n",
      "[epoch 7 Iteration 373/960] TRAIN loss:  0.506\n",
      "[epoch 7 Iteration 374/960] TRAIN loss:  0.767\n",
      "[epoch 7 Iteration 375/960] TRAIN loss:  1.228\n",
      "[epoch 7 Iteration 376/960] TRAIN loss:  0.933\n",
      "[epoch 7 Iteration 377/960] TRAIN loss:  0.614\n",
      "[epoch 7 Iteration 378/960] TRAIN loss:  0.541\n",
      "[epoch 7 Iteration 379/960] TRAIN loss:  0.610\n",
      "[epoch 7 Iteration 380/960] TRAIN loss:  0.927\n",
      "[epoch 7 Iteration 381/960] TRAIN loss:  1.068\n",
      "[epoch 7 Iteration 382/960] TRAIN loss:  0.952\n",
      "[epoch 7 Iteration 383/960] TRAIN loss:  0.824\n",
      "[epoch 7 Iteration 384/960] TRAIN loss:  0.661\n",
      "[epoch 7 Iteration 385/960] TRAIN loss:  0.701\n",
      "[epoch 7 Iteration 386/960] TRAIN loss:  0.819\n",
      "[epoch 7 Iteration 387/960] TRAIN loss:  1.028\n",
      "[epoch 7 Iteration 388/960] TRAIN loss:  0.685\n",
      "[epoch 7 Iteration 389/960] TRAIN loss:  0.937\n",
      "[epoch 7 Iteration 390/960] TRAIN loss:  0.913\n",
      "[epoch 7 Iteration 391/960] TRAIN loss:  0.805\n",
      "[epoch 7 Iteration 392/960] TRAIN loss:  0.858\n",
      "[epoch 7 Iteration 393/960] TRAIN loss:  0.787\n",
      "[epoch 7 Iteration 394/960] TRAIN loss:  1.021\n",
      "[epoch 7 Iteration 395/960] TRAIN loss:  0.789\n",
      "[epoch 7 Iteration 396/960] TRAIN loss:  0.778\n",
      "[epoch 7 Iteration 397/960] TRAIN loss:  0.748\n",
      "[epoch 7 Iteration 398/960] TRAIN loss:  0.762\n",
      "[epoch 7 Iteration 399/960] TRAIN loss:  0.615\n",
      "[epoch 7 Iteration 400/960] TRAIN loss:  0.981\n",
      "[epoch 7 Iteration 401/960] TRAIN loss:  0.495\n",
      "[epoch 7 Iteration 402/960] TRAIN loss:  0.669\n",
      "[epoch 7 Iteration 403/960] TRAIN loss:  0.792\n",
      "[epoch 7 Iteration 404/960] TRAIN loss:  0.771\n",
      "[epoch 7 Iteration 405/960] TRAIN loss:  0.923\n",
      "[epoch 7 Iteration 406/960] TRAIN loss:  0.661\n",
      "[epoch 7 Iteration 407/960] TRAIN loss:  0.810\n",
      "[epoch 7 Iteration 408/960] TRAIN loss:  0.991\n",
      "[epoch 7 Iteration 409/960] TRAIN loss:  0.930\n",
      "[epoch 7 Iteration 410/960] TRAIN loss:  1.026\n",
      "[epoch 7 Iteration 411/960] TRAIN loss:  0.839\n",
      "[epoch 7 Iteration 412/960] TRAIN loss:  0.784\n",
      "[epoch 7 Iteration 413/960] TRAIN loss:  0.822\n",
      "[epoch 7 Iteration 414/960] TRAIN loss:  0.769\n",
      "[epoch 7 Iteration 415/960] TRAIN loss:  0.839\n",
      "[epoch 7 Iteration 416/960] TRAIN loss:  0.876\n",
      "[epoch 7 Iteration 417/960] TRAIN loss:  0.780\n",
      "[epoch 7 Iteration 418/960] TRAIN loss:  1.157\n",
      "[epoch 7 Iteration 419/960] TRAIN loss:  0.793\n",
      "[epoch 7 Iteration 420/960] TRAIN loss:  0.745\n",
      "[epoch 7 Iteration 421/960] TRAIN loss:  0.639\n",
      "[epoch 7 Iteration 422/960] TRAIN loss:  0.792\n",
      "[epoch 7 Iteration 423/960] TRAIN loss:  0.996\n",
      "[epoch 7 Iteration 424/960] TRAIN loss:  0.872\n",
      "[epoch 7 Iteration 425/960] TRAIN loss:  0.732\n",
      "[epoch 7 Iteration 426/960] TRAIN loss:  0.983\n",
      "[epoch 7 Iteration 427/960] TRAIN loss:  0.916\n",
      "[epoch 7 Iteration 428/960] TRAIN loss:  1.062\n",
      "[epoch 7 Iteration 429/960] TRAIN loss:  0.897\n",
      "[epoch 7 Iteration 430/960] TRAIN loss:  0.720\n",
      "[epoch 7 Iteration 431/960] TRAIN loss:  0.860\n",
      "[epoch 7 Iteration 432/960] TRAIN loss:  0.695\n",
      "[epoch 7 Iteration 433/960] TRAIN loss:  0.956\n",
      "[epoch 7 Iteration 434/960] TRAIN loss:  1.109\n",
      "[epoch 7 Iteration 435/960] TRAIN loss:  0.622\n",
      "[epoch 7 Iteration 436/960] TRAIN loss:  0.642\n",
      "[epoch 7 Iteration 437/960] TRAIN loss:  0.955\n",
      "[epoch 7 Iteration 438/960] TRAIN loss:  0.954\n",
      "[epoch 7 Iteration 439/960] TRAIN loss:  0.712\n",
      "[epoch 7 Iteration 440/960] TRAIN loss:  0.904\n",
      "[epoch 7 Iteration 441/960] TRAIN loss:  0.828\n",
      "[epoch 7 Iteration 442/960] TRAIN loss:  0.824\n",
      "[epoch 7 Iteration 443/960] TRAIN loss:  0.837\n",
      "[epoch 7 Iteration 444/960] TRAIN loss:  0.566\n",
      "[epoch 7 Iteration 445/960] TRAIN loss:  0.926\n",
      "[epoch 7 Iteration 446/960] TRAIN loss:  0.569\n",
      "[epoch 7 Iteration 447/960] TRAIN loss:  0.761\n",
      "[epoch 7 Iteration 448/960] TRAIN loss:  0.680\n",
      "[epoch 7 Iteration 449/960] TRAIN loss:  0.628\n",
      "[epoch 7 Iteration 450/960] TRAIN loss:  0.722\n",
      "[epoch 7 Iteration 451/960] TRAIN loss:  0.616\n",
      "[epoch 7 Iteration 452/960] TRAIN loss:  0.731\n",
      "[epoch 7 Iteration 453/960] TRAIN loss:  0.708\n",
      "[epoch 7 Iteration 454/960] TRAIN loss:  0.699\n",
      "[epoch 7 Iteration 455/960] TRAIN loss:  0.861\n",
      "[epoch 7 Iteration 456/960] TRAIN loss:  0.891\n",
      "[epoch 7 Iteration 457/960] TRAIN loss:  0.732\n",
      "[epoch 7 Iteration 458/960] TRAIN loss:  1.057\n",
      "[epoch 7 Iteration 459/960] TRAIN loss:  0.674\n",
      "[epoch 7 Iteration 460/960] TRAIN loss:  0.866\n",
      "[epoch 7 Iteration 461/960] TRAIN loss:  0.778\n",
      "[epoch 7 Iteration 462/960] TRAIN loss:  0.839\n",
      "[epoch 7 Iteration 463/960] TRAIN loss:  0.873\n",
      "[epoch 7 Iteration 464/960] TRAIN loss:  0.708\n",
      "[epoch 7 Iteration 465/960] TRAIN loss:  0.628\n",
      "[epoch 7 Iteration 466/960] TRAIN loss:  0.911\n",
      "[epoch 7 Iteration 467/960] TRAIN loss:  0.597\n",
      "[epoch 7 Iteration 468/960] TRAIN loss:  1.066\n",
      "[epoch 7 Iteration 469/960] TRAIN loss:  0.862\n",
      "[epoch 7 Iteration 470/960] TRAIN loss:  0.998\n",
      "[epoch 7 Iteration 471/960] TRAIN loss:  0.526\n",
      "[epoch 7 Iteration 472/960] TRAIN loss:  0.652\n",
      "[epoch 7 Iteration 473/960] TRAIN loss:  0.836\n",
      "[epoch 7 Iteration 474/960] TRAIN loss:  0.818\n",
      "[epoch 7 Iteration 475/960] TRAIN loss:  0.738\n",
      "[epoch 7 Iteration 476/960] TRAIN loss:  0.546\n",
      "[epoch 7 Iteration 477/960] TRAIN loss:  0.862\n",
      "[epoch 7 Iteration 478/960] TRAIN loss:  0.776\n",
      "[epoch 7 Iteration 479/960] TRAIN loss:  0.842\n",
      "[epoch 7 Iteration 480/960] TRAIN loss:  0.682\n",
      "[epoch 7 Iteration 481/960] TRAIN loss:  0.791\n",
      "[epoch 7 Iteration 482/960] TRAIN loss:  0.633\n",
      "[epoch 7 Iteration 483/960] TRAIN loss:  0.945\n",
      "[epoch 7 Iteration 484/960] TRAIN loss:  0.675\n",
      "[epoch 7 Iteration 485/960] TRAIN loss:  1.127\n",
      "[epoch 7 Iteration 486/960] TRAIN loss:  0.901\n",
      "[epoch 7 Iteration 487/960] TRAIN loss:  1.085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7 Iteration 488/960] TRAIN loss:  0.614\n",
      "[epoch 7 Iteration 489/960] TRAIN loss:  0.713\n",
      "[epoch 7 Iteration 490/960] TRAIN loss:  0.942\n",
      "[epoch 7 Iteration 491/960] TRAIN loss:  0.808\n",
      "[epoch 7 Iteration 492/960] TRAIN loss:  0.919\n",
      "[epoch 7 Iteration 493/960] TRAIN loss:  0.739\n",
      "[epoch 7 Iteration 494/960] TRAIN loss:  0.983\n",
      "[epoch 7 Iteration 495/960] TRAIN loss:  0.779\n",
      "[epoch 7 Iteration 496/960] TRAIN loss:  0.714\n",
      "[epoch 7 Iteration 497/960] TRAIN loss:  0.895\n",
      "[epoch 7 Iteration 498/960] TRAIN loss:  1.134\n",
      "[epoch 7 Iteration 499/960] TRAIN loss:  0.817\n",
      "[epoch 7 Iteration 500/960] TRAIN loss:  0.955\n",
      "[epoch 7 Iteration 501/960] TRAIN loss:  0.596\n",
      "[epoch 7 Iteration 502/960] TRAIN loss:  0.690\n",
      "[epoch 7 Iteration 503/960] TRAIN loss:  1.299\n",
      "[epoch 7 Iteration 504/960] TRAIN loss:  0.778\n",
      "[epoch 7 Iteration 505/960] TRAIN loss:  1.071\n",
      "[epoch 7 Iteration 506/960] TRAIN loss:  1.001\n",
      "[epoch 7 Iteration 507/960] TRAIN loss:  0.934\n",
      "[epoch 7 Iteration 508/960] TRAIN loss:  0.962\n",
      "[epoch 7 Iteration 509/960] TRAIN loss:  0.915\n",
      "[epoch 7 Iteration 510/960] TRAIN loss:  0.655\n",
      "[epoch 7 Iteration 511/960] TRAIN loss:  0.900\n",
      "[epoch 7 Iteration 512/960] TRAIN loss:  0.855\n",
      "[epoch 7 Iteration 513/960] TRAIN loss:  0.846\n",
      "[epoch 7 Iteration 514/960] TRAIN loss:  0.652\n",
      "[epoch 7 Iteration 515/960] TRAIN loss:  0.986\n",
      "[epoch 7 Iteration 516/960] TRAIN loss:  0.927\n",
      "[epoch 7 Iteration 517/960] TRAIN loss:  0.983\n",
      "[epoch 7 Iteration 518/960] TRAIN loss:  0.690\n",
      "[epoch 7 Iteration 519/960] TRAIN loss:  0.777\n",
      "[epoch 7 Iteration 520/960] TRAIN loss:  0.908\n",
      "[epoch 7 Iteration 521/960] TRAIN loss:  1.175\n",
      "[epoch 7 Iteration 522/960] TRAIN loss:  0.712\n",
      "[epoch 7 Iteration 523/960] TRAIN loss:  0.741\n",
      "[epoch 7 Iteration 524/960] TRAIN loss:  0.902\n",
      "[epoch 7 Iteration 525/960] TRAIN loss:  0.868\n",
      "[epoch 7 Iteration 526/960] TRAIN loss:  0.925\n",
      "[epoch 7 Iteration 527/960] TRAIN loss:  0.853\n",
      "[epoch 7 Iteration 528/960] TRAIN loss:  0.740\n",
      "[epoch 7 Iteration 529/960] TRAIN loss:  0.663\n",
      "[epoch 7 Iteration 530/960] TRAIN loss:  0.732\n",
      "[epoch 7 Iteration 531/960] TRAIN loss:  0.766\n",
      "[epoch 7 Iteration 532/960] TRAIN loss:  1.131\n",
      "[epoch 7 Iteration 533/960] TRAIN loss:  0.842\n",
      "[epoch 7 Iteration 534/960] TRAIN loss:  0.886\n",
      "[epoch 7 Iteration 535/960] TRAIN loss:  0.677\n",
      "[epoch 7 Iteration 536/960] TRAIN loss:  0.869\n",
      "[epoch 7 Iteration 537/960] TRAIN loss:  0.945\n",
      "[epoch 7 Iteration 538/960] TRAIN loss:  1.190\n",
      "[epoch 7 Iteration 539/960] TRAIN loss:  1.015\n",
      "[epoch 7 Iteration 540/960] TRAIN loss:  0.891\n",
      "[epoch 7 Iteration 541/960] TRAIN loss:  0.942\n",
      "[epoch 7 Iteration 542/960] TRAIN loss:  1.008\n",
      "[epoch 7 Iteration 543/960] TRAIN loss:  0.742\n",
      "[epoch 7 Iteration 544/960] TRAIN loss:  1.045\n",
      "[epoch 7 Iteration 545/960] TRAIN loss:  0.740\n",
      "[epoch 7 Iteration 546/960] TRAIN loss:  0.847\n",
      "[epoch 7 Iteration 547/960] TRAIN loss:  1.337\n",
      "[epoch 7 Iteration 548/960] TRAIN loss:  0.796\n",
      "[epoch 7 Iteration 549/960] TRAIN loss:  0.831\n",
      "[epoch 7 Iteration 550/960] TRAIN loss:  0.851\n",
      "[epoch 7 Iteration 551/960] TRAIN loss:  0.838\n",
      "[epoch 7 Iteration 552/960] TRAIN loss:  0.811\n",
      "[epoch 7 Iteration 553/960] TRAIN loss:  1.048\n",
      "[epoch 7 Iteration 554/960] TRAIN loss:  1.144\n",
      "[epoch 7 Iteration 555/960] TRAIN loss:  0.972\n",
      "[epoch 7 Iteration 556/960] TRAIN loss:  0.853\n",
      "[epoch 7 Iteration 557/960] TRAIN loss:  0.714\n",
      "[epoch 7 Iteration 558/960] TRAIN loss:  0.777\n",
      "[epoch 7 Iteration 559/960] TRAIN loss:  0.829\n",
      "[epoch 7 Iteration 560/960] TRAIN loss:  1.152\n",
      "[epoch 7 Iteration 561/960] TRAIN loss:  1.086\n",
      "[epoch 7 Iteration 562/960] TRAIN loss:  0.827\n",
      "[epoch 7 Iteration 563/960] TRAIN loss:  0.745\n",
      "[epoch 7 Iteration 564/960] TRAIN loss:  1.146\n",
      "[epoch 7 Iteration 565/960] TRAIN loss:  0.737\n",
      "[epoch 7 Iteration 566/960] TRAIN loss:  0.733\n",
      "[epoch 7 Iteration 567/960] TRAIN loss:  0.666\n",
      "[epoch 7 Iteration 568/960] TRAIN loss:  0.796\n",
      "[epoch 7 Iteration 569/960] TRAIN loss:  0.966\n",
      "[epoch 7 Iteration 570/960] TRAIN loss:  0.850\n",
      "[epoch 7 Iteration 571/960] TRAIN loss:  0.877\n",
      "[epoch 7 Iteration 572/960] TRAIN loss:  1.121\n",
      "[epoch 7 Iteration 573/960] TRAIN loss:  0.690\n",
      "[epoch 7 Iteration 574/960] TRAIN loss:  1.013\n",
      "[epoch 7 Iteration 575/960] TRAIN loss:  0.784\n",
      "[epoch 7 Iteration 576/960] TRAIN loss:  0.752\n",
      "[epoch 7 Iteration 577/960] TRAIN loss:  0.807\n",
      "[epoch 7 Iteration 578/960] TRAIN loss:  0.918\n",
      "[epoch 7 Iteration 579/960] TRAIN loss:  0.995\n",
      "[epoch 7 Iteration 580/960] TRAIN loss:  0.780\n",
      "[epoch 7 Iteration 581/960] TRAIN loss:  0.805\n",
      "[epoch 7 Iteration 582/960] TRAIN loss:  0.889\n",
      "[epoch 7 Iteration 583/960] TRAIN loss:  0.786\n",
      "[epoch 7 Iteration 584/960] TRAIN loss:  0.901\n",
      "[epoch 7 Iteration 585/960] TRAIN loss:  0.846\n",
      "[epoch 7 Iteration 586/960] TRAIN loss:  0.652\n",
      "[epoch 7 Iteration 587/960] TRAIN loss:  0.646\n",
      "[epoch 7 Iteration 588/960] TRAIN loss:  0.931\n",
      "[epoch 7 Iteration 589/960] TRAIN loss:  0.913\n",
      "[epoch 7 Iteration 590/960] TRAIN loss:  0.817\n",
      "[epoch 7 Iteration 591/960] TRAIN loss:  0.724\n",
      "[epoch 7 Iteration 592/960] TRAIN loss:  0.715\n",
      "[epoch 7 Iteration 593/960] TRAIN loss:  0.729\n",
      "[epoch 7 Iteration 594/960] TRAIN loss:  0.866\n",
      "[epoch 7 Iteration 595/960] TRAIN loss:  0.816\n",
      "[epoch 7 Iteration 596/960] TRAIN loss:  0.862\n",
      "[epoch 7 Iteration 597/960] TRAIN loss:  1.092\n",
      "[epoch 7 Iteration 598/960] TRAIN loss:  0.724\n",
      "[epoch 7 Iteration 599/960] TRAIN loss:  1.076\n",
      "[epoch 7 Iteration 600/960] TRAIN loss:  0.622\n",
      "[epoch 7 Iteration 601/960] TRAIN loss:  1.114\n",
      "[epoch 7 Iteration 602/960] TRAIN loss:  0.907\n",
      "[epoch 7 Iteration 603/960] TRAIN loss:  1.030\n",
      "[epoch 7 Iteration 604/960] TRAIN loss:  0.956\n",
      "[epoch 7 Iteration 605/960] TRAIN loss:  0.650\n",
      "[epoch 7 Iteration 606/960] TRAIN loss:  0.782\n",
      "[epoch 7 Iteration 607/960] TRAIN loss:  0.772\n",
      "[epoch 7 Iteration 608/960] TRAIN loss:  0.740\n",
      "[epoch 7 Iteration 609/960] TRAIN loss:  0.734\n",
      "[epoch 7 Iteration 610/960] TRAIN loss:  0.831\n",
      "[epoch 7 Iteration 611/960] TRAIN loss:  0.813\n",
      "[epoch 7 Iteration 612/960] TRAIN loss:  1.003\n",
      "[epoch 7 Iteration 613/960] TRAIN loss:  0.659\n",
      "[epoch 7 Iteration 614/960] TRAIN loss:  0.868\n",
      "[epoch 7 Iteration 615/960] TRAIN loss:  0.644\n",
      "[epoch 7 Iteration 616/960] TRAIN loss:  0.861\n",
      "[epoch 7 Iteration 617/960] TRAIN loss:  0.733\n",
      "[epoch 7 Iteration 618/960] TRAIN loss:  0.935\n",
      "[epoch 7 Iteration 619/960] TRAIN loss:  0.820\n",
      "[epoch 7 Iteration 620/960] TRAIN loss:  0.793\n",
      "[epoch 7 Iteration 621/960] TRAIN loss:  0.685\n",
      "[epoch 7 Iteration 622/960] TRAIN loss:  0.912\n",
      "[epoch 7 Iteration 623/960] TRAIN loss:  0.849\n",
      "[epoch 7 Iteration 624/960] TRAIN loss:  0.951\n",
      "[epoch 7 Iteration 625/960] TRAIN loss:  0.931\n",
      "[epoch 7 Iteration 626/960] TRAIN loss:  1.038\n",
      "[epoch 7 Iteration 627/960] TRAIN loss:  0.929\n",
      "[epoch 7 Iteration 628/960] TRAIN loss:  0.842\n",
      "[epoch 7 Iteration 629/960] TRAIN loss:  1.097\n",
      "[epoch 7 Iteration 630/960] TRAIN loss:  1.006\n",
      "[epoch 7 Iteration 631/960] TRAIN loss:  0.658\n",
      "[epoch 7 Iteration 632/960] TRAIN loss:  0.975\n",
      "[epoch 7 Iteration 633/960] TRAIN loss:  0.728\n",
      "[epoch 7 Iteration 634/960] TRAIN loss:  0.738\n",
      "[epoch 7 Iteration 635/960] TRAIN loss:  0.748\n",
      "[epoch 7 Iteration 636/960] TRAIN loss:  0.927\n",
      "[epoch 7 Iteration 637/960] TRAIN loss:  0.837\n",
      "[epoch 7 Iteration 638/960] TRAIN loss:  0.673\n",
      "[epoch 7 Iteration 639/960] TRAIN loss:  0.922\n",
      "[epoch 7 Iteration 640/960] TRAIN loss:  0.878\n",
      "[epoch 7 Iteration 641/960] TRAIN loss:  0.561\n",
      "[epoch 7 Iteration 642/960] TRAIN loss:  0.665\n",
      "[epoch 7 Iteration 643/960] TRAIN loss:  0.775\n",
      "[epoch 7 Iteration 644/960] TRAIN loss:  0.817\n",
      "[epoch 7 Iteration 645/960] TRAIN loss:  0.985\n",
      "[epoch 7 Iteration 646/960] TRAIN loss:  0.857\n",
      "[epoch 7 Iteration 647/960] TRAIN loss:  0.898\n",
      "[epoch 7 Iteration 648/960] TRAIN loss:  0.847\n",
      "[epoch 7 Iteration 649/960] TRAIN loss:  0.772\n",
      "[epoch 7 Iteration 650/960] TRAIN loss:  0.710\n",
      "[epoch 7 Iteration 651/960] TRAIN loss:  0.782\n",
      "[epoch 7 Iteration 652/960] TRAIN loss:  0.930\n",
      "[epoch 7 Iteration 653/960] TRAIN loss:  0.850\n",
      "[epoch 7 Iteration 654/960] TRAIN loss:  0.981\n",
      "[epoch 7 Iteration 655/960] TRAIN loss:  0.903\n",
      "[epoch 7 Iteration 656/960] TRAIN loss:  0.928\n",
      "[epoch 7 Iteration 657/960] TRAIN loss:  0.931\n",
      "[epoch 7 Iteration 658/960] TRAIN loss:  1.097\n",
      "[epoch 7 Iteration 659/960] TRAIN loss:  0.882\n",
      "[epoch 7 Iteration 660/960] TRAIN loss:  0.776\n",
      "[epoch 7 Iteration 661/960] TRAIN loss:  0.864\n",
      "[epoch 7 Iteration 662/960] TRAIN loss:  0.833\n",
      "[epoch 7 Iteration 663/960] TRAIN loss:  0.905\n",
      "[epoch 7 Iteration 664/960] TRAIN loss:  0.790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7 Iteration 665/960] TRAIN loss:  0.781\n",
      "[epoch 7 Iteration 666/960] TRAIN loss:  0.687\n",
      "[epoch 7 Iteration 667/960] TRAIN loss:  0.900\n",
      "[epoch 7 Iteration 668/960] TRAIN loss:  0.941\n",
      "[epoch 7 Iteration 669/960] TRAIN loss:  0.819\n",
      "[epoch 7 Iteration 670/960] TRAIN loss:  0.762\n",
      "[epoch 7 Iteration 671/960] TRAIN loss:  1.328\n",
      "[epoch 7 Iteration 672/960] TRAIN loss:  0.822\n",
      "[epoch 7 Iteration 673/960] TRAIN loss:  0.694\n",
      "[epoch 7 Iteration 674/960] TRAIN loss:  0.656\n",
      "[epoch 7 Iteration 675/960] TRAIN loss:  0.710\n",
      "[epoch 7 Iteration 676/960] TRAIN loss:  0.725\n",
      "[epoch 7 Iteration 677/960] TRAIN loss:  0.541\n",
      "[epoch 7 Iteration 678/960] TRAIN loss:  1.052\n",
      "[epoch 7 Iteration 679/960] TRAIN loss:  0.842\n",
      "[epoch 7 Iteration 680/960] TRAIN loss:  0.694\n",
      "[epoch 7 Iteration 681/960] TRAIN loss:  0.894\n",
      "[epoch 7 Iteration 682/960] TRAIN loss:  0.880\n",
      "[epoch 7 Iteration 683/960] TRAIN loss:  0.541\n",
      "[epoch 7 Iteration 684/960] TRAIN loss:  1.179\n",
      "[epoch 7 Iteration 685/960] TRAIN loss:  0.651\n",
      "[epoch 7 Iteration 686/960] TRAIN loss:  0.954\n",
      "[epoch 7 Iteration 687/960] TRAIN loss:  0.606\n",
      "[epoch 7 Iteration 688/960] TRAIN loss:  0.852\n",
      "[epoch 7 Iteration 689/960] TRAIN loss:  0.666\n",
      "[epoch 7 Iteration 690/960] TRAIN loss:  0.635\n",
      "[epoch 7 Iteration 691/960] TRAIN loss:  0.606\n",
      "[epoch 7 Iteration 692/960] TRAIN loss:  0.807\n",
      "[epoch 7 Iteration 693/960] TRAIN loss:  0.675\n",
      "[epoch 7 Iteration 694/960] TRAIN loss:  0.658\n",
      "[epoch 7 Iteration 695/960] TRAIN loss:  0.889\n",
      "[epoch 7 Iteration 696/960] TRAIN loss:  0.688\n",
      "[epoch 7 Iteration 697/960] TRAIN loss:  1.015\n",
      "[epoch 7 Iteration 698/960] TRAIN loss:  0.770\n",
      "[epoch 7 Iteration 699/960] TRAIN loss:  0.717\n",
      "[epoch 7 Iteration 700/960] TRAIN loss:  1.061\n",
      "[epoch 7 Iteration 701/960] TRAIN loss:  0.844\n",
      "[epoch 7 Iteration 702/960] TRAIN loss:  0.648\n",
      "[epoch 7 Iteration 703/960] TRAIN loss:  0.977\n",
      "[epoch 7 Iteration 704/960] TRAIN loss:  0.934\n",
      "[epoch 7 Iteration 705/960] TRAIN loss:  0.766\n",
      "[epoch 7 Iteration 706/960] TRAIN loss:  0.792\n",
      "[epoch 7 Iteration 707/960] TRAIN loss:  0.811\n",
      "[epoch 7 Iteration 708/960] TRAIN loss:  1.027\n",
      "[epoch 7 Iteration 709/960] TRAIN loss:  1.070\n",
      "[epoch 7 Iteration 710/960] TRAIN loss:  0.755\n",
      "[epoch 7 Iteration 711/960] TRAIN loss:  0.698\n",
      "[epoch 7 Iteration 712/960] TRAIN loss:  0.741\n",
      "[epoch 7 Iteration 713/960] TRAIN loss:  0.853\n",
      "[epoch 7 Iteration 714/960] TRAIN loss:  0.768\n",
      "[epoch 7 Iteration 715/960] TRAIN loss:  0.769\n",
      "[epoch 7 Iteration 716/960] TRAIN loss:  0.955\n",
      "[epoch 7 Iteration 717/960] TRAIN loss:  1.023\n",
      "[epoch 7 Iteration 718/960] TRAIN loss:  0.947\n",
      "[epoch 7 Iteration 719/960] TRAIN loss:  0.840\n",
      "[epoch 7 Iteration 720/960] TRAIN loss:  1.071\n",
      "[epoch 7 Iteration 721/960] TRAIN loss:  0.697\n",
      "[epoch 7 Iteration 722/960] TRAIN loss:  0.960\n",
      "[epoch 7 Iteration 723/960] TRAIN loss:  0.963\n",
      "[epoch 7 Iteration 724/960] TRAIN loss:  0.840\n",
      "[epoch 7 Iteration 725/960] TRAIN loss:  0.711\n",
      "[epoch 7 Iteration 726/960] TRAIN loss:  0.915\n",
      "[epoch 7 Iteration 727/960] TRAIN loss:  0.480\n",
      "[epoch 7 Iteration 728/960] TRAIN loss:  0.819\n",
      "[epoch 7 Iteration 729/960] TRAIN loss:  0.932\n",
      "[epoch 7 Iteration 730/960] TRAIN loss:  0.742\n",
      "[epoch 7 Iteration 731/960] TRAIN loss:  1.207\n",
      "[epoch 7 Iteration 732/960] TRAIN loss:  0.889\n",
      "[epoch 7 Iteration 733/960] TRAIN loss:  0.745\n",
      "[epoch 7 Iteration 734/960] TRAIN loss:  0.854\n",
      "[epoch 7 Iteration 735/960] TRAIN loss:  0.759\n",
      "[epoch 7 Iteration 736/960] TRAIN loss:  0.516\n",
      "[epoch 7 Iteration 737/960] TRAIN loss:  0.877\n",
      "[epoch 7 Iteration 738/960] TRAIN loss:  0.718\n",
      "[epoch 7 Iteration 739/960] TRAIN loss:  0.780\n",
      "[epoch 7 Iteration 740/960] TRAIN loss:  1.012\n",
      "[epoch 7 Iteration 741/960] TRAIN loss:  0.759\n",
      "[epoch 7 Iteration 742/960] TRAIN loss:  0.759\n",
      "[epoch 7 Iteration 743/960] TRAIN loss:  0.748\n",
      "[epoch 7 Iteration 744/960] TRAIN loss:  0.595\n",
      "[epoch 7 Iteration 745/960] TRAIN loss:  1.019\n",
      "[epoch 7 Iteration 746/960] TRAIN loss:  0.782\n",
      "[epoch 7 Iteration 747/960] TRAIN loss:  0.906\n",
      "[epoch 7 Iteration 748/960] TRAIN loss:  0.797\n",
      "[epoch 7 Iteration 749/960] TRAIN loss:  0.778\n",
      "[epoch 7 Iteration 750/960] TRAIN loss:  0.515\n",
      "[epoch 7 Iteration 751/960] TRAIN loss:  0.712\n",
      "[epoch 7 Iteration 752/960] TRAIN loss:  1.153\n",
      "[epoch 7 Iteration 753/960] TRAIN loss:  0.720\n",
      "[epoch 7 Iteration 754/960] TRAIN loss:  0.714\n",
      "[epoch 7 Iteration 755/960] TRAIN loss:  0.897\n",
      "[epoch 7 Iteration 756/960] TRAIN loss:  0.870\n",
      "[epoch 7 Iteration 757/960] TRAIN loss:  0.808\n",
      "[epoch 7 Iteration 758/960] TRAIN loss:  0.866\n",
      "[epoch 7 Iteration 759/960] TRAIN loss:  1.007\n",
      "[epoch 7 Iteration 760/960] TRAIN loss:  1.010\n",
      "[epoch 7 Iteration 761/960] TRAIN loss:  0.726\n",
      "[epoch 7 Iteration 762/960] TRAIN loss:  0.620\n",
      "[epoch 7 Iteration 763/960] TRAIN loss:  1.052\n",
      "[epoch 7 Iteration 764/960] TRAIN loss:  0.746\n",
      "[epoch 7 Iteration 765/960] TRAIN loss:  0.918\n",
      "[epoch 7 Iteration 766/960] TRAIN loss:  0.681\n",
      "[epoch 7 Iteration 767/960] TRAIN loss:  0.874\n",
      "[epoch 7 Iteration 768/960] TRAIN loss:  1.002\n",
      "[epoch 7 Iteration 769/960] TRAIN loss:  0.798\n",
      "[epoch 7 Iteration 770/960] TRAIN loss:  0.849\n",
      "[epoch 7 Iteration 771/960] TRAIN loss:  0.844\n",
      "[epoch 7 Iteration 772/960] TRAIN loss:  0.970\n",
      "[epoch 7 Iteration 773/960] TRAIN loss:  0.823\n",
      "[epoch 7 Iteration 774/960] TRAIN loss:  0.678\n",
      "[epoch 7 Iteration 775/960] TRAIN loss:  0.845\n",
      "[epoch 7 Iteration 776/960] TRAIN loss:  0.856\n",
      "[epoch 7 Iteration 777/960] TRAIN loss:  0.937\n",
      "[epoch 7 Iteration 778/960] TRAIN loss:  0.803\n",
      "[epoch 7 Iteration 779/960] TRAIN loss:  1.129\n",
      "[epoch 7 Iteration 780/960] TRAIN loss:  0.629\n",
      "[epoch 7 Iteration 781/960] TRAIN loss:  1.030\n",
      "[epoch 7 Iteration 782/960] TRAIN loss:  0.845\n",
      "[epoch 7 Iteration 783/960] TRAIN loss:  1.039\n",
      "[epoch 7 Iteration 784/960] TRAIN loss:  0.926\n",
      "[epoch 7 Iteration 785/960] TRAIN loss:  1.105\n",
      "[epoch 7 Iteration 786/960] TRAIN loss:  0.821\n",
      "[epoch 7 Iteration 787/960] TRAIN loss:  0.928\n",
      "[epoch 7 Iteration 788/960] TRAIN loss:  0.764\n",
      "[epoch 7 Iteration 789/960] TRAIN loss:  0.940\n",
      "[epoch 7 Iteration 790/960] TRAIN loss:  0.685\n",
      "[epoch 7 Iteration 791/960] TRAIN loss:  0.686\n",
      "[epoch 7 Iteration 792/960] TRAIN loss:  1.072\n",
      "[epoch 7 Iteration 793/960] TRAIN loss:  0.810\n",
      "[epoch 7 Iteration 794/960] TRAIN loss:  1.312\n",
      "[epoch 7 Iteration 795/960] TRAIN loss:  0.568\n",
      "[epoch 7 Iteration 796/960] TRAIN loss:  0.820\n",
      "[epoch 7 Iteration 797/960] TRAIN loss:  0.534\n",
      "[epoch 7 Iteration 798/960] TRAIN loss:  0.918\n",
      "[epoch 7 Iteration 799/960] TRAIN loss:  0.645\n",
      "[epoch 7 Iteration 800/960] TRAIN loss:  0.976\n",
      "[epoch 7 Iteration 801/960] TRAIN loss:  1.026\n",
      "[epoch 7 Iteration 802/960] TRAIN loss:  0.972\n",
      "[epoch 7 Iteration 803/960] TRAIN loss:  1.092\n",
      "[epoch 7 Iteration 804/960] TRAIN loss:  0.901\n",
      "[epoch 7 Iteration 805/960] TRAIN loss:  1.074\n",
      "[epoch 7 Iteration 806/960] TRAIN loss:  0.609\n",
      "[epoch 7 Iteration 807/960] TRAIN loss:  1.037\n",
      "[epoch 7 Iteration 808/960] TRAIN loss:  0.820\n",
      "[epoch 7 Iteration 809/960] TRAIN loss:  0.771\n",
      "[epoch 7 Iteration 810/960] TRAIN loss:  0.938\n",
      "[epoch 7 Iteration 811/960] TRAIN loss:  0.999\n",
      "[epoch 7 Iteration 812/960] TRAIN loss:  0.833\n",
      "[epoch 7 Iteration 813/960] TRAIN loss:  1.046\n",
      "[epoch 7 Iteration 814/960] TRAIN loss:  0.849\n",
      "[epoch 7 Iteration 815/960] TRAIN loss:  0.657\n",
      "[epoch 7 Iteration 816/960] TRAIN loss:  1.229\n",
      "[epoch 7 Iteration 817/960] TRAIN loss:  0.984\n",
      "[epoch 7 Iteration 818/960] TRAIN loss:  0.838\n",
      "[epoch 7 Iteration 819/960] TRAIN loss:  0.728\n",
      "[epoch 7 Iteration 820/960] TRAIN loss:  0.543\n",
      "[epoch 7 Iteration 821/960] TRAIN loss:  0.751\n",
      "[epoch 7 Iteration 822/960] TRAIN loss:  0.764\n",
      "[epoch 7 Iteration 823/960] TRAIN loss:  0.872\n",
      "[epoch 7 Iteration 824/960] TRAIN loss:  0.838\n",
      "[epoch 7 Iteration 825/960] TRAIN loss:  0.635\n",
      "[epoch 7 Iteration 826/960] TRAIN loss:  0.801\n",
      "[epoch 7 Iteration 827/960] TRAIN loss:  0.783\n",
      "[epoch 7 Iteration 828/960] TRAIN loss:  0.811\n",
      "[epoch 7 Iteration 829/960] TRAIN loss:  0.987\n",
      "[epoch 7 Iteration 830/960] TRAIN loss:  0.900\n",
      "[epoch 7 Iteration 831/960] TRAIN loss:  0.650\n",
      "[epoch 7 Iteration 832/960] TRAIN loss:  1.137\n",
      "[epoch 7 Iteration 833/960] TRAIN loss:  1.030\n",
      "[epoch 7 Iteration 834/960] TRAIN loss:  0.729\n",
      "[epoch 7 Iteration 835/960] TRAIN loss:  1.001\n",
      "[epoch 7 Iteration 836/960] TRAIN loss:  0.710\n",
      "[epoch 7 Iteration 837/960] TRAIN loss:  0.842\n",
      "[epoch 7 Iteration 838/960] TRAIN loss:  0.894\n",
      "[epoch 7 Iteration 839/960] TRAIN loss:  0.840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 7 Iteration 840/960] TRAIN loss:  0.874\n",
      "[epoch 7 Iteration 841/960] TRAIN loss:  1.047\n",
      "[epoch 7 Iteration 842/960] TRAIN loss:  0.967\n",
      "[epoch 7 Iteration 843/960] TRAIN loss:  0.688\n",
      "[epoch 7 Iteration 844/960] TRAIN loss:  0.782\n",
      "[epoch 7 Iteration 845/960] TRAIN loss:  0.906\n",
      "[epoch 7 Iteration 846/960] TRAIN loss:  0.574\n",
      "[epoch 7 Iteration 847/960] TRAIN loss:  0.843\n",
      "[epoch 7 Iteration 848/960] TRAIN loss:  0.907\n",
      "[epoch 7 Iteration 849/960] TRAIN loss:  0.917\n",
      "[epoch 7 Iteration 850/960] TRAIN loss:  0.600\n",
      "[epoch 7 Iteration 851/960] TRAIN loss:  0.573\n",
      "[epoch 7 Iteration 852/960] TRAIN loss:  0.985\n",
      "[epoch 7 Iteration 853/960] TRAIN loss:  1.085\n",
      "[epoch 7 Iteration 854/960] TRAIN loss:  0.742\n",
      "[epoch 7 Iteration 855/960] TRAIN loss:  0.708\n",
      "[epoch 7 Iteration 856/960] TRAIN loss:  0.695\n",
      "[epoch 7 Iteration 857/960] TRAIN loss:  1.042\n",
      "[epoch 7 Iteration 858/960] TRAIN loss:  0.824\n",
      "[epoch 7 Iteration 859/960] TRAIN loss:  0.660\n",
      "[epoch 7 Iteration 860/960] TRAIN loss:  0.930\n",
      "[epoch 7 Iteration 861/960] TRAIN loss:  1.062\n",
      "[epoch 7 Iteration 862/960] TRAIN loss:  0.968\n",
      "[epoch 7 Iteration 863/960] TRAIN loss:  1.016\n",
      "[epoch 7 Iteration 864/960] TRAIN loss:  0.862\n",
      "[epoch 7 Iteration 865/960] TRAIN loss:  0.816\n",
      "[epoch 7 Iteration 866/960] TRAIN loss:  0.550\n",
      "[epoch 7 Iteration 867/960] TRAIN loss:  1.052\n",
      "[epoch 7 Iteration 868/960] TRAIN loss:  0.679\n",
      "[epoch 7 Iteration 869/960] TRAIN loss:  0.874\n",
      "[epoch 7 Iteration 870/960] TRAIN loss:  0.826\n",
      "[epoch 7 Iteration 871/960] TRAIN loss:  0.729\n",
      "[epoch 7 Iteration 872/960] TRAIN loss:  0.811\n",
      "[epoch 7 Iteration 873/960] TRAIN loss:  0.926\n",
      "[epoch 7 Iteration 874/960] TRAIN loss:  0.681\n",
      "[epoch 7 Iteration 875/960] TRAIN loss:  0.741\n",
      "[epoch 7 Iteration 876/960] TRAIN loss:  0.600\n",
      "[epoch 7 Iteration 877/960] TRAIN loss:  0.480\n",
      "[epoch 7 Iteration 878/960] TRAIN loss:  0.604\n",
      "[epoch 7 Iteration 879/960] TRAIN loss:  0.940\n",
      "[epoch 7 Iteration 880/960] TRAIN loss:  0.792\n",
      "[epoch 7 Iteration 881/960] TRAIN loss:  0.785\n",
      "[epoch 7 Iteration 882/960] TRAIN loss:  0.594\n",
      "[epoch 7 Iteration 883/960] TRAIN loss:  0.771\n",
      "[epoch 7 Iteration 884/960] TRAIN loss:  0.712\n",
      "[epoch 7 Iteration 885/960] TRAIN loss:  0.729\n",
      "[epoch 7 Iteration 886/960] TRAIN loss:  0.971\n",
      "[epoch 7 Iteration 887/960] TRAIN loss:  1.075\n",
      "[epoch 7 Iteration 888/960] TRAIN loss:  1.027\n",
      "[epoch 7 Iteration 889/960] TRAIN loss:  0.855\n",
      "[epoch 7 Iteration 890/960] TRAIN loss:  0.970\n",
      "[epoch 7 Iteration 891/960] TRAIN loss:  0.871\n",
      "[epoch 7 Iteration 892/960] TRAIN loss:  0.741\n",
      "[epoch 7 Iteration 893/960] TRAIN loss:  0.981\n",
      "[epoch 7 Iteration 894/960] TRAIN loss:  0.912\n",
      "[epoch 7 Iteration 895/960] TRAIN loss:  0.677\n",
      "[epoch 7 Iteration 896/960] TRAIN loss:  1.038\n",
      "[epoch 7 Iteration 897/960] TRAIN loss:  0.674\n",
      "[epoch 7 Iteration 898/960] TRAIN loss:  0.856\n",
      "[epoch 7 Iteration 899/960] TRAIN loss:  0.878\n",
      "[epoch 7 Iteration 900/960] TRAIN loss:  0.684\n",
      "[epoch 7 Iteration 901/960] TRAIN loss:  0.711\n",
      "[epoch 7 Iteration 902/960] TRAIN loss:  0.738\n",
      "[epoch 7 Iteration 903/960] TRAIN loss:  0.781\n",
      "[epoch 7 Iteration 904/960] TRAIN loss:  0.781\n",
      "[epoch 7 Iteration 905/960] TRAIN loss:  0.843\n",
      "[epoch 7 Iteration 906/960] TRAIN loss:  0.788\n",
      "[epoch 7 Iteration 907/960] TRAIN loss:  0.977\n",
      "[epoch 7 Iteration 908/960] TRAIN loss:  1.092\n",
      "[epoch 7 Iteration 909/960] TRAIN loss:  0.695\n",
      "[epoch 7 Iteration 910/960] TRAIN loss:  0.835\n",
      "[epoch 7 Iteration 911/960] TRAIN loss:  0.874\n",
      "[epoch 7 Iteration 912/960] TRAIN loss:  0.809\n",
      "[epoch 7 Iteration 913/960] TRAIN loss:  0.603\n",
      "[epoch 7 Iteration 914/960] TRAIN loss:  0.856\n",
      "[epoch 7 Iteration 915/960] TRAIN loss:  0.999\n",
      "[epoch 7 Iteration 916/960] TRAIN loss:  0.590\n",
      "[epoch 7 Iteration 917/960] TRAIN loss:  1.021\n",
      "[epoch 7 Iteration 918/960] TRAIN loss:  1.007\n",
      "[epoch 7 Iteration 919/960] TRAIN loss:  0.941\n",
      "[epoch 7 Iteration 920/960] TRAIN loss:  0.745\n",
      "[epoch 7 Iteration 921/960] TRAIN loss:  0.836\n",
      "[epoch 7 Iteration 922/960] TRAIN loss:  0.922\n",
      "[epoch 7 Iteration 923/960] TRAIN loss:  0.885\n",
      "[epoch 7 Iteration 924/960] TRAIN loss:  0.960\n",
      "[epoch 7 Iteration 925/960] TRAIN loss:  0.840\n",
      "[epoch 7 Iteration 926/960] TRAIN loss:  0.908\n",
      "[epoch 7 Iteration 927/960] TRAIN loss:  0.987\n",
      "[epoch 7 Iteration 928/960] TRAIN loss:  0.950\n",
      "[epoch 7 Iteration 929/960] TRAIN loss:  0.742\n",
      "[epoch 7 Iteration 930/960] TRAIN loss:  0.832\n",
      "[epoch 7 Iteration 931/960] TRAIN loss:  0.881\n",
      "[epoch 7 Iteration 932/960] TRAIN loss:  0.947\n",
      "[epoch 7 Iteration 933/960] TRAIN loss:  0.750\n",
      "[epoch 7 Iteration 934/960] TRAIN loss:  0.971\n",
      "[epoch 7 Iteration 935/960] TRAIN loss:  1.103\n",
      "[epoch 7 Iteration 936/960] TRAIN loss:  0.875\n",
      "[epoch 7 Iteration 937/960] TRAIN loss:  0.499\n",
      "[epoch 7 Iteration 938/960] TRAIN loss:  0.665\n",
      "[epoch 7 Iteration 939/960] TRAIN loss:  1.427\n",
      "[epoch 7 Iteration 940/960] TRAIN loss:  0.938\n",
      "[epoch 7 Iteration 941/960] TRAIN loss:  0.726\n",
      "[epoch 7 Iteration 942/960] TRAIN loss:  0.892\n",
      "[epoch 7 Iteration 943/960] TRAIN loss:  0.784\n",
      "[epoch 7 Iteration 944/960] TRAIN loss:  0.909\n",
      "[epoch 7 Iteration 945/960] TRAIN loss:  0.845\n",
      "[epoch 7 Iteration 946/960] TRAIN loss:  0.774\n",
      "[epoch 7 Iteration 947/960] TRAIN loss:  0.700\n",
      "[epoch 7 Iteration 948/960] TRAIN loss:  0.936\n",
      "[epoch 7 Iteration 949/960] TRAIN loss:  1.072\n",
      "[epoch 7 Iteration 950/960] TRAIN loss:  0.889\n",
      "[epoch 7 Iteration 951/960] TRAIN loss:  0.839\n",
      "[epoch 7 Iteration 952/960] TRAIN loss:  0.779\n",
      "[epoch 7 Iteration 953/960] TRAIN loss:  0.817\n",
      "[epoch 7 Iteration 954/960] TRAIN loss:  0.944\n",
      "[epoch 7 Iteration 955/960] TRAIN loss:  1.082\n",
      "[epoch 7 Iteration 956/960] TRAIN loss:  1.072\n",
      "[epoch 7 Iteration 957/960] TRAIN loss:  0.765\n",
      "[epoch 7 Iteration 958/960] TRAIN loss:  0.764\n",
      "[epoch 7 Iteration 959/960] TRAIN loss:  0.992\n",
      "[epoch 7/15] TRAIN acc/loss:  0.705/0.992\n",
      "[epoch 7/15] VAL acc/loss:  0.652/0.647\n",
      "[epoch 8 Iteration 0/960] TRAIN loss:  0.688\n",
      "[epoch 8 Iteration 1/960] TRAIN loss:  0.717\n",
      "[epoch 8 Iteration 2/960] TRAIN loss:  0.792\n",
      "[epoch 8 Iteration 3/960] TRAIN loss:  0.710\n",
      "[epoch 8 Iteration 4/960] TRAIN loss:  0.686\n",
      "[epoch 8 Iteration 5/960] TRAIN loss:  0.705\n",
      "[epoch 8 Iteration 6/960] TRAIN loss:  0.969\n",
      "[epoch 8 Iteration 7/960] TRAIN loss:  0.777\n",
      "[epoch 8 Iteration 8/960] TRAIN loss:  0.848\n",
      "[epoch 8 Iteration 9/960] TRAIN loss:  0.896\n",
      "[epoch 8 Iteration 10/960] TRAIN loss:  0.804\n",
      "[epoch 8 Iteration 11/960] TRAIN loss:  0.732\n",
      "[epoch 8 Iteration 12/960] TRAIN loss:  0.909\n",
      "[epoch 8 Iteration 13/960] TRAIN loss:  0.582\n",
      "[epoch 8 Iteration 14/960] TRAIN loss:  0.805\n",
      "[epoch 8 Iteration 15/960] TRAIN loss:  0.787\n",
      "[epoch 8 Iteration 16/960] TRAIN loss:  0.643\n",
      "[epoch 8 Iteration 17/960] TRAIN loss:  0.835\n",
      "[epoch 8 Iteration 18/960] TRAIN loss:  1.032\n",
      "[epoch 8 Iteration 19/960] TRAIN loss:  0.972\n",
      "[epoch 8 Iteration 20/960] TRAIN loss:  0.983\n",
      "[epoch 8 Iteration 21/960] TRAIN loss:  0.796\n",
      "[epoch 8 Iteration 22/960] TRAIN loss:  0.823\n",
      "[epoch 8 Iteration 23/960] TRAIN loss:  0.650\n",
      "[epoch 8 Iteration 24/960] TRAIN loss:  0.693\n",
      "[epoch 8 Iteration 25/960] TRAIN loss:  1.022\n",
      "[epoch 8 Iteration 26/960] TRAIN loss:  0.837\n",
      "[epoch 8 Iteration 27/960] TRAIN loss:  0.696\n",
      "[epoch 8 Iteration 28/960] TRAIN loss:  0.764\n",
      "[epoch 8 Iteration 29/960] TRAIN loss:  0.349\n",
      "[epoch 8 Iteration 30/960] TRAIN loss:  0.739\n",
      "[epoch 8 Iteration 31/960] TRAIN loss:  0.646\n",
      "[epoch 8 Iteration 32/960] TRAIN loss:  1.111\n",
      "[epoch 8 Iteration 33/960] TRAIN loss:  0.783\n",
      "[epoch 8 Iteration 34/960] TRAIN loss:  0.715\n",
      "[epoch 8 Iteration 35/960] TRAIN loss:  0.782\n",
      "[epoch 8 Iteration 36/960] TRAIN loss:  0.940\n",
      "[epoch 8 Iteration 37/960] TRAIN loss:  0.720\n",
      "[epoch 8 Iteration 38/960] TRAIN loss:  0.918\n",
      "[epoch 8 Iteration 39/960] TRAIN loss:  1.037\n",
      "[epoch 8 Iteration 40/960] TRAIN loss:  0.890\n",
      "[epoch 8 Iteration 41/960] TRAIN loss:  0.749\n",
      "[epoch 8 Iteration 42/960] TRAIN loss:  0.824\n",
      "[epoch 8 Iteration 43/960] TRAIN loss:  0.532\n",
      "[epoch 8 Iteration 44/960] TRAIN loss:  0.722\n",
      "[epoch 8 Iteration 45/960] TRAIN loss:  0.485\n",
      "[epoch 8 Iteration 46/960] TRAIN loss:  0.834\n",
      "[epoch 8 Iteration 47/960] TRAIN loss:  0.624\n",
      "[epoch 8 Iteration 48/960] TRAIN loss:  0.779\n",
      "[epoch 8 Iteration 49/960] TRAIN loss:  0.835\n",
      "[epoch 8 Iteration 50/960] TRAIN loss:  0.948\n",
      "[epoch 8 Iteration 51/960] TRAIN loss:  0.819\n",
      "[epoch 8 Iteration 52/960] TRAIN loss:  1.088\n",
      "[epoch 8 Iteration 53/960] TRAIN loss:  0.651\n",
      "[epoch 8 Iteration 54/960] TRAIN loss:  0.477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8 Iteration 55/960] TRAIN loss:  0.629\n",
      "[epoch 8 Iteration 56/960] TRAIN loss:  0.685\n",
      "[epoch 8 Iteration 57/960] TRAIN loss:  0.700\n",
      "[epoch 8 Iteration 58/960] TRAIN loss:  0.709\n",
      "[epoch 8 Iteration 59/960] TRAIN loss:  0.879\n",
      "[epoch 8 Iteration 60/960] TRAIN loss:  0.696\n",
      "[epoch 8 Iteration 61/960] TRAIN loss:  0.759\n",
      "[epoch 8 Iteration 62/960] TRAIN loss:  0.645\n",
      "[epoch 8 Iteration 63/960] TRAIN loss:  0.978\n",
      "[epoch 8 Iteration 64/960] TRAIN loss:  0.705\n",
      "[epoch 8 Iteration 65/960] TRAIN loss:  0.727\n",
      "[epoch 8 Iteration 66/960] TRAIN loss:  0.536\n",
      "[epoch 8 Iteration 67/960] TRAIN loss:  0.876\n",
      "[epoch 8 Iteration 68/960] TRAIN loss:  0.665\n",
      "[epoch 8 Iteration 69/960] TRAIN loss:  0.915\n",
      "[epoch 8 Iteration 70/960] TRAIN loss:  0.779\n",
      "[epoch 8 Iteration 71/960] TRAIN loss:  0.455\n",
      "[epoch 8 Iteration 72/960] TRAIN loss:  0.899\n",
      "[epoch 8 Iteration 73/960] TRAIN loss:  0.791\n",
      "[epoch 8 Iteration 74/960] TRAIN loss:  0.742\n",
      "[epoch 8 Iteration 75/960] TRAIN loss:  0.824\n",
      "[epoch 8 Iteration 76/960] TRAIN loss:  0.612\n",
      "[epoch 8 Iteration 77/960] TRAIN loss:  0.437\n",
      "[epoch 8 Iteration 78/960] TRAIN loss:  0.569\n",
      "[epoch 8 Iteration 79/960] TRAIN loss:  0.706\n",
      "[epoch 8 Iteration 80/960] TRAIN loss:  0.822\n",
      "[epoch 8 Iteration 81/960] TRAIN loss:  0.826\n",
      "[epoch 8 Iteration 82/960] TRAIN loss:  0.672\n",
      "[epoch 8 Iteration 83/960] TRAIN loss:  0.969\n",
      "[epoch 8 Iteration 84/960] TRAIN loss:  0.802\n",
      "[epoch 8 Iteration 85/960] TRAIN loss:  0.595\n",
      "[epoch 8 Iteration 86/960] TRAIN loss:  0.689\n",
      "[epoch 8 Iteration 87/960] TRAIN loss:  0.446\n",
      "[epoch 8 Iteration 88/960] TRAIN loss:  0.600\n",
      "[epoch 8 Iteration 89/960] TRAIN loss:  0.881\n",
      "[epoch 8 Iteration 90/960] TRAIN loss:  0.883\n",
      "[epoch 8 Iteration 91/960] TRAIN loss:  0.588\n",
      "[epoch 8 Iteration 92/960] TRAIN loss:  0.605\n",
      "[epoch 8 Iteration 93/960] TRAIN loss:  0.598\n",
      "[epoch 8 Iteration 94/960] TRAIN loss:  0.592\n",
      "[epoch 8 Iteration 95/960] TRAIN loss:  0.641\n",
      "[epoch 8 Iteration 96/960] TRAIN loss:  0.635\n",
      "[epoch 8 Iteration 97/960] TRAIN loss:  0.865\n",
      "[epoch 8 Iteration 98/960] TRAIN loss:  0.556\n",
      "[epoch 8 Iteration 99/960] TRAIN loss:  0.886\n",
      "[epoch 8 Iteration 100/960] TRAIN loss:  0.900\n",
      "[epoch 8 Iteration 101/960] TRAIN loss:  0.600\n",
      "[epoch 8 Iteration 102/960] TRAIN loss:  0.898\n",
      "[epoch 8 Iteration 103/960] TRAIN loss:  0.886\n",
      "[epoch 8 Iteration 104/960] TRAIN loss:  0.795\n",
      "[epoch 8 Iteration 105/960] TRAIN loss:  0.986\n",
      "[epoch 8 Iteration 106/960] TRAIN loss:  0.707\n",
      "[epoch 8 Iteration 107/960] TRAIN loss:  0.638\n",
      "[epoch 8 Iteration 108/960] TRAIN loss:  0.627\n",
      "[epoch 8 Iteration 109/960] TRAIN loss:  0.645\n",
      "[epoch 8 Iteration 110/960] TRAIN loss:  0.719\n",
      "[epoch 8 Iteration 111/960] TRAIN loss:  0.737\n",
      "[epoch 8 Iteration 112/960] TRAIN loss:  0.631\n",
      "[epoch 8 Iteration 113/960] TRAIN loss:  0.840\n",
      "[epoch 8 Iteration 114/960] TRAIN loss:  0.666\n",
      "[epoch 8 Iteration 115/960] TRAIN loss:  1.134\n",
      "[epoch 8 Iteration 116/960] TRAIN loss:  0.789\n",
      "[epoch 8 Iteration 117/960] TRAIN loss:  0.648\n",
      "[epoch 8 Iteration 118/960] TRAIN loss:  0.596\n",
      "[epoch 8 Iteration 119/960] TRAIN loss:  0.732\n",
      "[epoch 8 Iteration 120/960] TRAIN loss:  0.773\n",
      "[epoch 8 Iteration 121/960] TRAIN loss:  0.732\n",
      "[epoch 8 Iteration 122/960] TRAIN loss:  0.828\n",
      "[epoch 8 Iteration 123/960] TRAIN loss:  1.182\n",
      "[epoch 8 Iteration 124/960] TRAIN loss:  0.962\n",
      "[epoch 8 Iteration 125/960] TRAIN loss:  0.735\n",
      "[epoch 8 Iteration 126/960] TRAIN loss:  0.752\n",
      "[epoch 8 Iteration 127/960] TRAIN loss:  0.813\n",
      "[epoch 8 Iteration 128/960] TRAIN loss:  0.699\n",
      "[epoch 8 Iteration 129/960] TRAIN loss:  0.747\n",
      "[epoch 8 Iteration 130/960] TRAIN loss:  0.749\n",
      "[epoch 8 Iteration 131/960] TRAIN loss:  0.829\n",
      "[epoch 8 Iteration 132/960] TRAIN loss:  0.893\n",
      "[epoch 8 Iteration 133/960] TRAIN loss:  0.739\n",
      "[epoch 8 Iteration 134/960] TRAIN loss:  0.814\n",
      "[epoch 8 Iteration 135/960] TRAIN loss:  0.804\n",
      "[epoch 8 Iteration 136/960] TRAIN loss:  0.547\n",
      "[epoch 8 Iteration 137/960] TRAIN loss:  0.711\n",
      "[epoch 8 Iteration 138/960] TRAIN loss:  0.806\n",
      "[epoch 8 Iteration 139/960] TRAIN loss:  0.787\n",
      "[epoch 8 Iteration 140/960] TRAIN loss:  0.562\n",
      "[epoch 8 Iteration 141/960] TRAIN loss:  0.735\n",
      "[epoch 8 Iteration 142/960] TRAIN loss:  0.708\n",
      "[epoch 8 Iteration 143/960] TRAIN loss:  0.714\n",
      "[epoch 8 Iteration 144/960] TRAIN loss:  0.945\n",
      "[epoch 8 Iteration 145/960] TRAIN loss:  0.842\n",
      "[epoch 8 Iteration 146/960] TRAIN loss:  0.833\n",
      "[epoch 8 Iteration 147/960] TRAIN loss:  0.759\n",
      "[epoch 8 Iteration 148/960] TRAIN loss:  0.663\n",
      "[epoch 8 Iteration 149/960] TRAIN loss:  0.955\n",
      "[epoch 8 Iteration 150/960] TRAIN loss:  0.951\n",
      "[epoch 8 Iteration 151/960] TRAIN loss:  0.704\n",
      "[epoch 8 Iteration 152/960] TRAIN loss:  0.496\n",
      "[epoch 8 Iteration 153/960] TRAIN loss:  0.746\n",
      "[epoch 8 Iteration 154/960] TRAIN loss:  0.616\n",
      "[epoch 8 Iteration 155/960] TRAIN loss:  0.745\n",
      "[epoch 8 Iteration 156/960] TRAIN loss:  1.092\n",
      "[epoch 8 Iteration 157/960] TRAIN loss:  0.697\n",
      "[epoch 8 Iteration 158/960] TRAIN loss:  0.689\n",
      "[epoch 8 Iteration 159/960] TRAIN loss:  0.742\n",
      "[epoch 8 Iteration 160/960] TRAIN loss:  0.832\n",
      "[epoch 8 Iteration 161/960] TRAIN loss:  0.833\n",
      "[epoch 8 Iteration 162/960] TRAIN loss:  1.092\n",
      "[epoch 8 Iteration 163/960] TRAIN loss:  1.104\n",
      "[epoch 8 Iteration 164/960] TRAIN loss:  0.916\n",
      "[epoch 8 Iteration 165/960] TRAIN loss:  0.862\n",
      "[epoch 8 Iteration 166/960] TRAIN loss:  1.056\n",
      "[epoch 8 Iteration 167/960] TRAIN loss:  0.638\n",
      "[epoch 8 Iteration 168/960] TRAIN loss:  0.595\n",
      "[epoch 8 Iteration 169/960] TRAIN loss:  0.781\n",
      "[epoch 8 Iteration 170/960] TRAIN loss:  1.070\n",
      "[epoch 8 Iteration 171/960] TRAIN loss:  0.788\n",
      "[epoch 8 Iteration 172/960] TRAIN loss:  0.707\n",
      "[epoch 8 Iteration 173/960] TRAIN loss:  0.884\n",
      "[epoch 8 Iteration 174/960] TRAIN loss:  0.721\n",
      "[epoch 8 Iteration 175/960] TRAIN loss:  0.798\n",
      "[epoch 8 Iteration 176/960] TRAIN loss:  0.718\n",
      "[epoch 8 Iteration 177/960] TRAIN loss:  0.885\n",
      "[epoch 8 Iteration 178/960] TRAIN loss:  1.017\n",
      "[epoch 8 Iteration 179/960] TRAIN loss:  0.876\n",
      "[epoch 8 Iteration 180/960] TRAIN loss:  0.909\n",
      "[epoch 8 Iteration 181/960] TRAIN loss:  0.691\n",
      "[epoch 8 Iteration 182/960] TRAIN loss:  0.616\n",
      "[epoch 8 Iteration 183/960] TRAIN loss:  1.188\n",
      "[epoch 8 Iteration 184/960] TRAIN loss:  0.615\n",
      "[epoch 8 Iteration 185/960] TRAIN loss:  0.589\n",
      "[epoch 8 Iteration 186/960] TRAIN loss:  0.689\n",
      "[epoch 8 Iteration 187/960] TRAIN loss:  0.769\n",
      "[epoch 8 Iteration 188/960] TRAIN loss:  0.658\n",
      "[epoch 8 Iteration 189/960] TRAIN loss:  0.925\n",
      "[epoch 8 Iteration 190/960] TRAIN loss:  0.914\n",
      "[epoch 8 Iteration 191/960] TRAIN loss:  0.867\n",
      "[epoch 8 Iteration 192/960] TRAIN loss:  0.621\n",
      "[epoch 8 Iteration 193/960] TRAIN loss:  0.732\n",
      "[epoch 8 Iteration 194/960] TRAIN loss:  0.824\n",
      "[epoch 8 Iteration 195/960] TRAIN loss:  0.921\n",
      "[epoch 8 Iteration 196/960] TRAIN loss:  0.855\n",
      "[epoch 8 Iteration 197/960] TRAIN loss:  0.670\n",
      "[epoch 8 Iteration 198/960] TRAIN loss:  0.811\n",
      "[epoch 8 Iteration 199/960] TRAIN loss:  0.728\n",
      "[epoch 8 Iteration 200/960] TRAIN loss:  0.511\n",
      "[epoch 8 Iteration 201/960] TRAIN loss:  0.749\n",
      "[epoch 8 Iteration 202/960] TRAIN loss:  0.775\n",
      "[epoch 8 Iteration 203/960] TRAIN loss:  0.684\n",
      "[epoch 8 Iteration 204/960] TRAIN loss:  0.642\n",
      "[epoch 8 Iteration 205/960] TRAIN loss:  0.757\n",
      "[epoch 8 Iteration 206/960] TRAIN loss:  0.837\n",
      "[epoch 8 Iteration 207/960] TRAIN loss:  0.799\n",
      "[epoch 8 Iteration 208/960] TRAIN loss:  0.892\n",
      "[epoch 8 Iteration 209/960] TRAIN loss:  0.934\n",
      "[epoch 8 Iteration 210/960] TRAIN loss:  0.826\n",
      "[epoch 8 Iteration 211/960] TRAIN loss:  0.781\n",
      "[epoch 8 Iteration 212/960] TRAIN loss:  1.000\n",
      "[epoch 8 Iteration 213/960] TRAIN loss:  1.031\n",
      "[epoch 8 Iteration 214/960] TRAIN loss:  0.682\n",
      "[epoch 8 Iteration 215/960] TRAIN loss:  0.828\n",
      "[epoch 8 Iteration 216/960] TRAIN loss:  0.613\n",
      "[epoch 8 Iteration 217/960] TRAIN loss:  0.609\n",
      "[epoch 8 Iteration 218/960] TRAIN loss:  0.871\n",
      "[epoch 8 Iteration 219/960] TRAIN loss:  0.797\n",
      "[epoch 8 Iteration 220/960] TRAIN loss:  1.076\n",
      "[epoch 8 Iteration 221/960] TRAIN loss:  0.704\n",
      "[epoch 8 Iteration 222/960] TRAIN loss:  0.807\n",
      "[epoch 8 Iteration 223/960] TRAIN loss:  0.668\n",
      "[epoch 8 Iteration 224/960] TRAIN loss:  0.771\n",
      "[epoch 8 Iteration 225/960] TRAIN loss:  0.829\n",
      "[epoch 8 Iteration 226/960] TRAIN loss:  0.626\n",
      "[epoch 8 Iteration 227/960] TRAIN loss:  0.856\n",
      "[epoch 8 Iteration 228/960] TRAIN loss:  0.695\n",
      "[epoch 8 Iteration 229/960] TRAIN loss:  0.830\n",
      "[epoch 8 Iteration 230/960] TRAIN loss:  0.948\n",
      "[epoch 8 Iteration 231/960] TRAIN loss:  0.957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8 Iteration 232/960] TRAIN loss:  0.725\n",
      "[epoch 8 Iteration 233/960] TRAIN loss:  0.593\n",
      "[epoch 8 Iteration 234/960] TRAIN loss:  0.792\n",
      "[epoch 8 Iteration 235/960] TRAIN loss:  0.833\n",
      "[epoch 8 Iteration 236/960] TRAIN loss:  0.829\n",
      "[epoch 8 Iteration 237/960] TRAIN loss:  0.627\n",
      "[epoch 8 Iteration 238/960] TRAIN loss:  0.732\n",
      "[epoch 8 Iteration 239/960] TRAIN loss:  0.576\n",
      "[epoch 8 Iteration 240/960] TRAIN loss:  0.807\n",
      "[epoch 8 Iteration 241/960] TRAIN loss:  0.914\n",
      "[epoch 8 Iteration 242/960] TRAIN loss:  0.715\n",
      "[epoch 8 Iteration 243/960] TRAIN loss:  0.753\n",
      "[epoch 8 Iteration 244/960] TRAIN loss:  0.650\n",
      "[epoch 8 Iteration 245/960] TRAIN loss:  0.925\n",
      "[epoch 8 Iteration 246/960] TRAIN loss:  1.151\n",
      "[epoch 8 Iteration 247/960] TRAIN loss:  0.767\n",
      "[epoch 8 Iteration 248/960] TRAIN loss:  0.823\n",
      "[epoch 8 Iteration 249/960] TRAIN loss:  0.594\n",
      "[epoch 8 Iteration 250/960] TRAIN loss:  0.835\n",
      "[epoch 8 Iteration 251/960] TRAIN loss:  0.691\n",
      "[epoch 8 Iteration 252/960] TRAIN loss:  0.848\n",
      "[epoch 8 Iteration 253/960] TRAIN loss:  0.700\n",
      "[epoch 8 Iteration 254/960] TRAIN loss:  0.836\n",
      "[epoch 8 Iteration 255/960] TRAIN loss:  1.036\n",
      "[epoch 8 Iteration 256/960] TRAIN loss:  0.791\n",
      "[epoch 8 Iteration 257/960] TRAIN loss:  0.724\n",
      "[epoch 8 Iteration 258/960] TRAIN loss:  0.770\n",
      "[epoch 8 Iteration 259/960] TRAIN loss:  0.833\n",
      "[epoch 8 Iteration 260/960] TRAIN loss:  0.629\n",
      "[epoch 8 Iteration 261/960] TRAIN loss:  0.816\n",
      "[epoch 8 Iteration 262/960] TRAIN loss:  1.085\n",
      "[epoch 8 Iteration 263/960] TRAIN loss:  0.906\n",
      "[epoch 8 Iteration 264/960] TRAIN loss:  0.880\n",
      "[epoch 8 Iteration 265/960] TRAIN loss:  0.751\n",
      "[epoch 8 Iteration 266/960] TRAIN loss:  0.632\n",
      "[epoch 8 Iteration 267/960] TRAIN loss:  0.643\n",
      "[epoch 8 Iteration 268/960] TRAIN loss:  0.908\n",
      "[epoch 8 Iteration 269/960] TRAIN loss:  0.533\n",
      "[epoch 8 Iteration 270/960] TRAIN loss:  0.934\n",
      "[epoch 8 Iteration 271/960] TRAIN loss:  0.837\n",
      "[epoch 8 Iteration 272/960] TRAIN loss:  0.648\n",
      "[epoch 8 Iteration 273/960] TRAIN loss:  0.705\n",
      "[epoch 8 Iteration 274/960] TRAIN loss:  0.609\n",
      "[epoch 8 Iteration 275/960] TRAIN loss:  0.792\n",
      "[epoch 8 Iteration 276/960] TRAIN loss:  0.833\n",
      "[epoch 8 Iteration 277/960] TRAIN loss:  0.583\n",
      "[epoch 8 Iteration 278/960] TRAIN loss:  0.705\n",
      "[epoch 8 Iteration 279/960] TRAIN loss:  0.902\n",
      "[epoch 8 Iteration 280/960] TRAIN loss:  0.889\n",
      "[epoch 8 Iteration 281/960] TRAIN loss:  0.668\n",
      "[epoch 8 Iteration 282/960] TRAIN loss:  0.642\n",
      "[epoch 8 Iteration 283/960] TRAIN loss:  0.705\n",
      "[epoch 8 Iteration 284/960] TRAIN loss:  0.610\n",
      "[epoch 8 Iteration 285/960] TRAIN loss:  0.955\n",
      "[epoch 8 Iteration 286/960] TRAIN loss:  0.711\n",
      "[epoch 8 Iteration 287/960] TRAIN loss:  0.698\n",
      "[epoch 8 Iteration 288/960] TRAIN loss:  0.729\n",
      "[epoch 8 Iteration 289/960] TRAIN loss:  0.811\n",
      "[epoch 8 Iteration 290/960] TRAIN loss:  0.732\n",
      "[epoch 8 Iteration 291/960] TRAIN loss:  0.727\n",
      "[epoch 8 Iteration 292/960] TRAIN loss:  0.710\n",
      "[epoch 8 Iteration 293/960] TRAIN loss:  0.614\n",
      "[epoch 8 Iteration 294/960] TRAIN loss:  0.933\n",
      "[epoch 8 Iteration 295/960] TRAIN loss:  0.715\n",
      "[epoch 8 Iteration 296/960] TRAIN loss:  0.976\n",
      "[epoch 8 Iteration 297/960] TRAIN loss:  0.820\n",
      "[epoch 8 Iteration 298/960] TRAIN loss:  0.999\n",
      "[epoch 8 Iteration 299/960] TRAIN loss:  0.712\n",
      "[epoch 8 Iteration 300/960] TRAIN loss:  0.847\n",
      "[epoch 8 Iteration 301/960] TRAIN loss:  0.633\n",
      "[epoch 8 Iteration 302/960] TRAIN loss:  0.842\n",
      "[epoch 8 Iteration 303/960] TRAIN loss:  0.686\n",
      "[epoch 8 Iteration 304/960] TRAIN loss:  0.889\n",
      "[epoch 8 Iteration 305/960] TRAIN loss:  0.615\n",
      "[epoch 8 Iteration 306/960] TRAIN loss:  0.908\n",
      "[epoch 8 Iteration 307/960] TRAIN loss:  0.656\n",
      "[epoch 8 Iteration 308/960] TRAIN loss:  0.732\n",
      "[epoch 8 Iteration 309/960] TRAIN loss:  0.994\n",
      "[epoch 8 Iteration 310/960] TRAIN loss:  0.708\n",
      "[epoch 8 Iteration 311/960] TRAIN loss:  0.896\n",
      "[epoch 8 Iteration 312/960] TRAIN loss:  1.156\n",
      "[epoch 8 Iteration 313/960] TRAIN loss:  0.875\n",
      "[epoch 8 Iteration 314/960] TRAIN loss:  0.661\n",
      "[epoch 8 Iteration 315/960] TRAIN loss:  0.596\n",
      "[epoch 8 Iteration 316/960] TRAIN loss:  0.793\n",
      "[epoch 8 Iteration 317/960] TRAIN loss:  0.666\n",
      "[epoch 8 Iteration 318/960] TRAIN loss:  0.649\n",
      "[epoch 8 Iteration 319/960] TRAIN loss:  0.978\n",
      "[epoch 8 Iteration 320/960] TRAIN loss:  0.622\n",
      "[epoch 8 Iteration 321/960] TRAIN loss:  0.701\n",
      "[epoch 8 Iteration 322/960] TRAIN loss:  0.994\n",
      "[epoch 8 Iteration 323/960] TRAIN loss:  0.618\n",
      "[epoch 8 Iteration 324/960] TRAIN loss:  0.854\n",
      "[epoch 8 Iteration 325/960] TRAIN loss:  0.810\n",
      "[epoch 8 Iteration 326/960] TRAIN loss:  0.975\n",
      "[epoch 8 Iteration 327/960] TRAIN loss:  0.876\n",
      "[epoch 8 Iteration 328/960] TRAIN loss:  0.879\n",
      "[epoch 8 Iteration 329/960] TRAIN loss:  0.799\n",
      "[epoch 8 Iteration 330/960] TRAIN loss:  0.638\n",
      "[epoch 8 Iteration 331/960] TRAIN loss:  0.883\n",
      "[epoch 8 Iteration 332/960] TRAIN loss:  1.076\n",
      "[epoch 8 Iteration 333/960] TRAIN loss:  0.885\n",
      "[epoch 8 Iteration 334/960] TRAIN loss:  0.569\n",
      "[epoch 8 Iteration 335/960] TRAIN loss:  0.498\n",
      "[epoch 8 Iteration 336/960] TRAIN loss:  0.652\n",
      "[epoch 8 Iteration 337/960] TRAIN loss:  0.799\n",
      "[epoch 8 Iteration 338/960] TRAIN loss:  0.880\n",
      "[epoch 8 Iteration 339/960] TRAIN loss:  0.861\n",
      "[epoch 8 Iteration 340/960] TRAIN loss:  0.811\n",
      "[epoch 8 Iteration 341/960] TRAIN loss:  0.877\n",
      "[epoch 8 Iteration 342/960] TRAIN loss:  0.717\n",
      "[epoch 8 Iteration 343/960] TRAIN loss:  0.713\n",
      "[epoch 8 Iteration 344/960] TRAIN loss:  0.659\n",
      "[epoch 8 Iteration 345/960] TRAIN loss:  0.897\n",
      "[epoch 8 Iteration 346/960] TRAIN loss:  0.565\n",
      "[epoch 8 Iteration 347/960] TRAIN loss:  0.713\n",
      "[epoch 8 Iteration 348/960] TRAIN loss:  0.443\n",
      "[epoch 8 Iteration 349/960] TRAIN loss:  0.849\n",
      "[epoch 8 Iteration 350/960] TRAIN loss:  0.631\n",
      "[epoch 8 Iteration 351/960] TRAIN loss:  0.781\n",
      "[epoch 8 Iteration 352/960] TRAIN loss:  1.080\n",
      "[epoch 8 Iteration 353/960] TRAIN loss:  0.814\n",
      "[epoch 8 Iteration 354/960] TRAIN loss:  0.539\n",
      "[epoch 8 Iteration 355/960] TRAIN loss:  0.630\n",
      "[epoch 8 Iteration 356/960] TRAIN loss:  0.834\n",
      "[epoch 8 Iteration 357/960] TRAIN loss:  0.729\n",
      "[epoch 8 Iteration 358/960] TRAIN loss:  0.497\n",
      "[epoch 8 Iteration 359/960] TRAIN loss:  0.824\n",
      "[epoch 8 Iteration 360/960] TRAIN loss:  1.005\n",
      "[epoch 8 Iteration 361/960] TRAIN loss:  0.896\n",
      "[epoch 8 Iteration 362/960] TRAIN loss:  0.950\n",
      "[epoch 8 Iteration 363/960] TRAIN loss:  0.846\n",
      "[epoch 8 Iteration 364/960] TRAIN loss:  0.816\n",
      "[epoch 8 Iteration 365/960] TRAIN loss:  0.733\n",
      "[epoch 8 Iteration 366/960] TRAIN loss:  0.868\n",
      "[epoch 8 Iteration 367/960] TRAIN loss:  0.888\n",
      "[epoch 8 Iteration 368/960] TRAIN loss:  0.632\n",
      "[epoch 8 Iteration 369/960] TRAIN loss:  0.916\n",
      "[epoch 8 Iteration 370/960] TRAIN loss:  1.105\n",
      "[epoch 8 Iteration 371/960] TRAIN loss:  0.611\n",
      "[epoch 8 Iteration 372/960] TRAIN loss:  0.859\n",
      "[epoch 8 Iteration 373/960] TRAIN loss:  0.684\n",
      "[epoch 8 Iteration 374/960] TRAIN loss:  0.728\n",
      "[epoch 8 Iteration 375/960] TRAIN loss:  0.897\n",
      "[epoch 8 Iteration 376/960] TRAIN loss:  0.841\n",
      "[epoch 8 Iteration 377/960] TRAIN loss:  0.672\n",
      "[epoch 8 Iteration 378/960] TRAIN loss:  0.921\n",
      "[epoch 8 Iteration 379/960] TRAIN loss:  0.750\n",
      "[epoch 8 Iteration 380/960] TRAIN loss:  0.882\n",
      "[epoch 8 Iteration 381/960] TRAIN loss:  0.894\n",
      "[epoch 8 Iteration 382/960] TRAIN loss:  0.789\n",
      "[epoch 8 Iteration 383/960] TRAIN loss:  0.885\n",
      "[epoch 8 Iteration 384/960] TRAIN loss:  0.660\n",
      "[epoch 8 Iteration 385/960] TRAIN loss:  1.001\n",
      "[epoch 8 Iteration 386/960] TRAIN loss:  0.776\n",
      "[epoch 8 Iteration 387/960] TRAIN loss:  0.841\n",
      "[epoch 8 Iteration 388/960] TRAIN loss:  0.717\n",
      "[epoch 8 Iteration 389/960] TRAIN loss:  0.748\n",
      "[epoch 8 Iteration 390/960] TRAIN loss:  0.809\n",
      "[epoch 8 Iteration 391/960] TRAIN loss:  0.676\n",
      "[epoch 8 Iteration 392/960] TRAIN loss:  0.724\n",
      "[epoch 8 Iteration 393/960] TRAIN loss:  0.666\n",
      "[epoch 8 Iteration 394/960] TRAIN loss:  0.873\n",
      "[epoch 8 Iteration 395/960] TRAIN loss:  0.632\n",
      "[epoch 8 Iteration 396/960] TRAIN loss:  0.522\n",
      "[epoch 8 Iteration 397/960] TRAIN loss:  0.693\n",
      "[epoch 8 Iteration 398/960] TRAIN loss:  0.484\n",
      "[epoch 8 Iteration 399/960] TRAIN loss:  1.029\n",
      "[epoch 8 Iteration 400/960] TRAIN loss:  0.741\n",
      "[epoch 8 Iteration 401/960] TRAIN loss:  0.932\n",
      "[epoch 8 Iteration 402/960] TRAIN loss:  0.574\n",
      "[epoch 8 Iteration 403/960] TRAIN loss:  0.800\n",
      "[epoch 8 Iteration 404/960] TRAIN loss:  0.705\n",
      "[epoch 8 Iteration 405/960] TRAIN loss:  0.821\n",
      "[epoch 8 Iteration 406/960] TRAIN loss:  0.646\n",
      "[epoch 8 Iteration 407/960] TRAIN loss:  0.744\n",
      "[epoch 8 Iteration 408/960] TRAIN loss:  0.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8 Iteration 409/960] TRAIN loss:  0.766\n",
      "[epoch 8 Iteration 410/960] TRAIN loss:  0.672\n",
      "[epoch 8 Iteration 411/960] TRAIN loss:  0.684\n",
      "[epoch 8 Iteration 412/960] TRAIN loss:  0.793\n",
      "[epoch 8 Iteration 413/960] TRAIN loss:  1.103\n",
      "[epoch 8 Iteration 414/960] TRAIN loss:  0.724\n",
      "[epoch 8 Iteration 415/960] TRAIN loss:  0.953\n",
      "[epoch 8 Iteration 416/960] TRAIN loss:  0.521\n",
      "[epoch 8 Iteration 417/960] TRAIN loss:  1.185\n",
      "[epoch 8 Iteration 418/960] TRAIN loss:  0.820\n",
      "[epoch 8 Iteration 419/960] TRAIN loss:  0.882\n",
      "[epoch 8 Iteration 420/960] TRAIN loss:  0.972\n",
      "[epoch 8 Iteration 421/960] TRAIN loss:  0.997\n",
      "[epoch 8 Iteration 422/960] TRAIN loss:  0.769\n",
      "[epoch 8 Iteration 423/960] TRAIN loss:  0.951\n",
      "[epoch 8 Iteration 424/960] TRAIN loss:  0.805\n",
      "[epoch 8 Iteration 425/960] TRAIN loss:  0.616\n",
      "[epoch 8 Iteration 426/960] TRAIN loss:  0.782\n",
      "[epoch 8 Iteration 427/960] TRAIN loss:  0.747\n",
      "[epoch 8 Iteration 428/960] TRAIN loss:  0.952\n",
      "[epoch 8 Iteration 429/960] TRAIN loss:  0.733\n",
      "[epoch 8 Iteration 430/960] TRAIN loss:  0.769\n",
      "[epoch 8 Iteration 431/960] TRAIN loss:  0.987\n",
      "[epoch 8 Iteration 432/960] TRAIN loss:  0.924\n",
      "[epoch 8 Iteration 433/960] TRAIN loss:  0.769\n",
      "[epoch 8 Iteration 434/960] TRAIN loss:  0.656\n",
      "[epoch 8 Iteration 435/960] TRAIN loss:  0.670\n",
      "[epoch 8 Iteration 436/960] TRAIN loss:  0.771\n",
      "[epoch 8 Iteration 437/960] TRAIN loss:  0.644\n",
      "[epoch 8 Iteration 438/960] TRAIN loss:  0.794\n",
      "[epoch 8 Iteration 439/960] TRAIN loss:  1.022\n",
      "[epoch 8 Iteration 440/960] TRAIN loss:  0.728\n",
      "[epoch 8 Iteration 441/960] TRAIN loss:  0.763\n",
      "[epoch 8 Iteration 442/960] TRAIN loss:  0.815\n",
      "[epoch 8 Iteration 443/960] TRAIN loss:  0.642\n",
      "[epoch 8 Iteration 444/960] TRAIN loss:  0.751\n",
      "[epoch 8 Iteration 445/960] TRAIN loss:  0.843\n",
      "[epoch 8 Iteration 446/960] TRAIN loss:  0.744\n",
      "[epoch 8 Iteration 447/960] TRAIN loss:  0.626\n",
      "[epoch 8 Iteration 448/960] TRAIN loss:  0.897\n",
      "[epoch 8 Iteration 449/960] TRAIN loss:  1.002\n",
      "[epoch 8 Iteration 450/960] TRAIN loss:  1.039\n",
      "[epoch 8 Iteration 451/960] TRAIN loss:  0.764\n",
      "[epoch 8 Iteration 452/960] TRAIN loss:  1.050\n",
      "[epoch 8 Iteration 453/960] TRAIN loss:  0.837\n",
      "[epoch 8 Iteration 454/960] TRAIN loss:  0.770\n",
      "[epoch 8 Iteration 455/960] TRAIN loss:  0.888\n",
      "[epoch 8 Iteration 456/960] TRAIN loss:  0.912\n",
      "[epoch 8 Iteration 457/960] TRAIN loss:  1.001\n",
      "[epoch 8 Iteration 458/960] TRAIN loss:  0.779\n",
      "[epoch 8 Iteration 459/960] TRAIN loss:  0.943\n",
      "[epoch 8 Iteration 460/960] TRAIN loss:  0.891\n",
      "[epoch 8 Iteration 461/960] TRAIN loss:  0.852\n",
      "[epoch 8 Iteration 462/960] TRAIN loss:  0.555\n",
      "[epoch 8 Iteration 463/960] TRAIN loss:  0.924\n",
      "[epoch 8 Iteration 464/960] TRAIN loss:  0.962\n",
      "[epoch 8 Iteration 465/960] TRAIN loss:  0.859\n",
      "[epoch 8 Iteration 466/960] TRAIN loss:  0.714\n",
      "[epoch 8 Iteration 467/960] TRAIN loss:  0.929\n",
      "[epoch 8 Iteration 468/960] TRAIN loss:  0.739\n",
      "[epoch 8 Iteration 469/960] TRAIN loss:  0.771\n",
      "[epoch 8 Iteration 470/960] TRAIN loss:  0.599\n",
      "[epoch 8 Iteration 471/960] TRAIN loss:  0.774\n",
      "[epoch 8 Iteration 472/960] TRAIN loss:  0.764\n",
      "[epoch 8 Iteration 473/960] TRAIN loss:  0.835\n",
      "[epoch 8 Iteration 474/960] TRAIN loss:  0.644\n",
      "[epoch 8 Iteration 475/960] TRAIN loss:  0.738\n",
      "[epoch 8 Iteration 476/960] TRAIN loss:  0.842\n",
      "[epoch 8 Iteration 477/960] TRAIN loss:  0.622\n",
      "[epoch 8 Iteration 478/960] TRAIN loss:  0.647\n",
      "[epoch 8 Iteration 479/960] TRAIN loss:  0.895\n",
      "[epoch 8 Iteration 480/960] TRAIN loss:  0.978\n",
      "[epoch 8 Iteration 481/960] TRAIN loss:  0.618\n",
      "[epoch 8 Iteration 482/960] TRAIN loss:  0.797\n",
      "[epoch 8 Iteration 483/960] TRAIN loss:  0.895\n",
      "[epoch 8 Iteration 484/960] TRAIN loss:  0.823\n",
      "[epoch 8 Iteration 485/960] TRAIN loss:  0.956\n",
      "[epoch 8 Iteration 486/960] TRAIN loss:  0.514\n",
      "[epoch 8 Iteration 487/960] TRAIN loss:  0.494\n",
      "[epoch 8 Iteration 488/960] TRAIN loss:  0.974\n",
      "[epoch 8 Iteration 489/960] TRAIN loss:  0.664\n",
      "[epoch 8 Iteration 490/960] TRAIN loss:  0.897\n",
      "[epoch 8 Iteration 491/960] TRAIN loss:  0.906\n",
      "[epoch 8 Iteration 492/960] TRAIN loss:  0.966\n",
      "[epoch 8 Iteration 493/960] TRAIN loss:  0.786\n",
      "[epoch 8 Iteration 494/960] TRAIN loss:  0.734\n",
      "[epoch 8 Iteration 495/960] TRAIN loss:  0.635\n",
      "[epoch 8 Iteration 496/960] TRAIN loss:  0.763\n",
      "[epoch 8 Iteration 497/960] TRAIN loss:  0.985\n",
      "[epoch 8 Iteration 498/960] TRAIN loss:  0.836\n",
      "[epoch 8 Iteration 499/960] TRAIN loss:  0.682\n",
      "[epoch 8 Iteration 500/960] TRAIN loss:  0.938\n",
      "[epoch 8 Iteration 501/960] TRAIN loss:  0.503\n",
      "[epoch 8 Iteration 502/960] TRAIN loss:  0.790\n",
      "[epoch 8 Iteration 503/960] TRAIN loss:  0.715\n",
      "[epoch 8 Iteration 504/960] TRAIN loss:  0.973\n",
      "[epoch 8 Iteration 505/960] TRAIN loss:  0.750\n",
      "[epoch 8 Iteration 506/960] TRAIN loss:  1.278\n",
      "[epoch 8 Iteration 507/960] TRAIN loss:  0.547\n",
      "[epoch 8 Iteration 508/960] TRAIN loss:  0.856\n",
      "[epoch 8 Iteration 509/960] TRAIN loss:  0.521\n",
      "[epoch 8 Iteration 510/960] TRAIN loss:  0.769\n",
      "[epoch 8 Iteration 511/960] TRAIN loss:  0.558\n",
      "[epoch 8 Iteration 512/960] TRAIN loss:  0.876\n",
      "[epoch 8 Iteration 513/960] TRAIN loss:  0.733\n",
      "[epoch 8 Iteration 514/960] TRAIN loss:  0.740\n",
      "[epoch 8 Iteration 515/960] TRAIN loss:  0.722\n",
      "[epoch 8 Iteration 516/960] TRAIN loss:  1.004\n",
      "[epoch 8 Iteration 517/960] TRAIN loss:  0.657\n",
      "[epoch 8 Iteration 518/960] TRAIN loss:  0.756\n",
      "[epoch 8 Iteration 519/960] TRAIN loss:  1.045\n",
      "[epoch 8 Iteration 520/960] TRAIN loss:  0.638\n",
      "[epoch 8 Iteration 521/960] TRAIN loss:  0.970\n",
      "[epoch 8 Iteration 522/960] TRAIN loss:  0.737\n",
      "[epoch 8 Iteration 523/960] TRAIN loss:  0.552\n",
      "[epoch 8 Iteration 524/960] TRAIN loss:  0.937\n",
      "[epoch 8 Iteration 525/960] TRAIN loss:  0.675\n",
      "[epoch 8 Iteration 526/960] TRAIN loss:  0.826\n",
      "[epoch 8 Iteration 527/960] TRAIN loss:  0.897\n",
      "[epoch 8 Iteration 528/960] TRAIN loss:  0.671\n",
      "[epoch 8 Iteration 529/960] TRAIN loss:  0.577\n",
      "[epoch 8 Iteration 530/960] TRAIN loss:  0.643\n",
      "[epoch 8 Iteration 531/960] TRAIN loss:  0.733\n",
      "[epoch 8 Iteration 532/960] TRAIN loss:  0.719\n",
      "[epoch 8 Iteration 533/960] TRAIN loss:  0.705\n",
      "[epoch 8 Iteration 534/960] TRAIN loss:  0.800\n",
      "[epoch 8 Iteration 535/960] TRAIN loss:  0.608\n",
      "[epoch 8 Iteration 536/960] TRAIN loss:  0.761\n",
      "[epoch 8 Iteration 537/960] TRAIN loss:  1.047\n",
      "[epoch 8 Iteration 538/960] TRAIN loss:  0.777\n",
      "[epoch 8 Iteration 539/960] TRAIN loss:  0.635\n",
      "[epoch 8 Iteration 540/960] TRAIN loss:  0.712\n",
      "[epoch 8 Iteration 541/960] TRAIN loss:  0.751\n",
      "[epoch 8 Iteration 542/960] TRAIN loss:  0.664\n",
      "[epoch 8 Iteration 543/960] TRAIN loss:  0.814\n",
      "[epoch 8 Iteration 544/960] TRAIN loss:  0.663\n",
      "[epoch 8 Iteration 545/960] TRAIN loss:  0.779\n",
      "[epoch 8 Iteration 546/960] TRAIN loss:  0.726\n",
      "[epoch 8 Iteration 547/960] TRAIN loss:  0.682\n",
      "[epoch 8 Iteration 548/960] TRAIN loss:  0.561\n",
      "[epoch 8 Iteration 549/960] TRAIN loss:  0.644\n",
      "[epoch 8 Iteration 550/960] TRAIN loss:  0.837\n",
      "[epoch 8 Iteration 551/960] TRAIN loss:  0.646\n",
      "[epoch 8 Iteration 552/960] TRAIN loss:  0.654\n",
      "[epoch 8 Iteration 553/960] TRAIN loss:  0.677\n",
      "[epoch 8 Iteration 554/960] TRAIN loss:  0.976\n",
      "[epoch 8 Iteration 555/960] TRAIN loss:  0.748\n",
      "[epoch 8 Iteration 556/960] TRAIN loss:  0.820\n",
      "[epoch 8 Iteration 557/960] TRAIN loss:  0.609\n",
      "[epoch 8 Iteration 558/960] TRAIN loss:  0.987\n",
      "[epoch 8 Iteration 559/960] TRAIN loss:  0.785\n",
      "[epoch 8 Iteration 560/960] TRAIN loss:  0.679\n",
      "[epoch 8 Iteration 561/960] TRAIN loss:  0.815\n",
      "[epoch 8 Iteration 562/960] TRAIN loss:  1.193\n",
      "[epoch 8 Iteration 563/960] TRAIN loss:  0.576\n",
      "[epoch 8 Iteration 564/960] TRAIN loss:  0.849\n",
      "[epoch 8 Iteration 565/960] TRAIN loss:  0.852\n",
      "[epoch 8 Iteration 566/960] TRAIN loss:  0.741\n",
      "[epoch 8 Iteration 567/960] TRAIN loss:  0.693\n",
      "[epoch 8 Iteration 568/960] TRAIN loss:  0.867\n",
      "[epoch 8 Iteration 569/960] TRAIN loss:  0.655\n",
      "[epoch 8 Iteration 570/960] TRAIN loss:  0.742\n",
      "[epoch 8 Iteration 571/960] TRAIN loss:  0.617\n",
      "[epoch 8 Iteration 572/960] TRAIN loss:  0.744\n",
      "[epoch 8 Iteration 573/960] TRAIN loss:  0.562\n",
      "[epoch 8 Iteration 574/960] TRAIN loss:  0.642\n",
      "[epoch 8 Iteration 575/960] TRAIN loss:  0.769\n",
      "[epoch 8 Iteration 576/960] TRAIN loss:  0.797\n",
      "[epoch 8 Iteration 577/960] TRAIN loss:  0.854\n",
      "[epoch 8 Iteration 578/960] TRAIN loss:  0.780\n",
      "[epoch 8 Iteration 579/960] TRAIN loss:  0.696\n",
      "[epoch 8 Iteration 580/960] TRAIN loss:  0.620\n",
      "[epoch 8 Iteration 581/960] TRAIN loss:  0.782\n",
      "[epoch 8 Iteration 582/960] TRAIN loss:  1.157\n",
      "[epoch 8 Iteration 583/960] TRAIN loss:  0.827\n",
      "[epoch 8 Iteration 584/960] TRAIN loss:  0.971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8 Iteration 585/960] TRAIN loss:  0.813\n",
      "[epoch 8 Iteration 586/960] TRAIN loss:  0.873\n",
      "[epoch 8 Iteration 587/960] TRAIN loss:  0.788\n",
      "[epoch 8 Iteration 588/960] TRAIN loss:  0.766\n",
      "[epoch 8 Iteration 589/960] TRAIN loss:  1.114\n",
      "[epoch 8 Iteration 590/960] TRAIN loss:  0.749\n",
      "[epoch 8 Iteration 591/960] TRAIN loss:  0.636\n",
      "[epoch 8 Iteration 592/960] TRAIN loss:  0.948\n",
      "[epoch 8 Iteration 593/960] TRAIN loss:  0.959\n",
      "[epoch 8 Iteration 594/960] TRAIN loss:  0.706\n",
      "[epoch 8 Iteration 595/960] TRAIN loss:  0.914\n",
      "[epoch 8 Iteration 596/960] TRAIN loss:  0.799\n",
      "[epoch 8 Iteration 597/960] TRAIN loss:  0.865\n",
      "[epoch 8 Iteration 598/960] TRAIN loss:  0.609\n",
      "[epoch 8 Iteration 599/960] TRAIN loss:  0.530\n",
      "[epoch 8 Iteration 600/960] TRAIN loss:  0.855\n",
      "[epoch 8 Iteration 601/960] TRAIN loss:  0.903\n",
      "[epoch 8 Iteration 602/960] TRAIN loss:  0.934\n",
      "[epoch 8 Iteration 603/960] TRAIN loss:  0.991\n",
      "[epoch 8 Iteration 604/960] TRAIN loss:  0.863\n",
      "[epoch 8 Iteration 605/960] TRAIN loss:  0.758\n",
      "[epoch 8 Iteration 606/960] TRAIN loss:  0.637\n",
      "[epoch 8 Iteration 607/960] TRAIN loss:  0.639\n",
      "[epoch 8 Iteration 608/960] TRAIN loss:  0.923\n",
      "[epoch 8 Iteration 609/960] TRAIN loss:  0.786\n",
      "[epoch 8 Iteration 610/960] TRAIN loss:  0.881\n",
      "[epoch 8 Iteration 611/960] TRAIN loss:  0.716\n",
      "[epoch 8 Iteration 612/960] TRAIN loss:  0.981\n",
      "[epoch 8 Iteration 613/960] TRAIN loss:  0.847\n",
      "[epoch 8 Iteration 614/960] TRAIN loss:  0.619\n",
      "[epoch 8 Iteration 615/960] TRAIN loss:  1.112\n",
      "[epoch 8 Iteration 616/960] TRAIN loss:  0.629\n",
      "[epoch 8 Iteration 617/960] TRAIN loss:  0.610\n",
      "[epoch 8 Iteration 618/960] TRAIN loss:  0.913\n",
      "[epoch 8 Iteration 619/960] TRAIN loss:  0.852\n",
      "[epoch 8 Iteration 620/960] TRAIN loss:  1.026\n",
      "[epoch 8 Iteration 621/960] TRAIN loss:  0.637\n",
      "[epoch 8 Iteration 622/960] TRAIN loss:  0.654\n",
      "[epoch 8 Iteration 623/960] TRAIN loss:  0.745\n",
      "[epoch 8 Iteration 624/960] TRAIN loss:  0.934\n",
      "[epoch 8 Iteration 625/960] TRAIN loss:  0.888\n",
      "[epoch 8 Iteration 626/960] TRAIN loss:  0.934\n",
      "[epoch 8 Iteration 627/960] TRAIN loss:  1.042\n",
      "[epoch 8 Iteration 628/960] TRAIN loss:  0.699\n",
      "[epoch 8 Iteration 629/960] TRAIN loss:  0.852\n",
      "[epoch 8 Iteration 630/960] TRAIN loss:  0.828\n",
      "[epoch 8 Iteration 631/960] TRAIN loss:  0.637\n",
      "[epoch 8 Iteration 632/960] TRAIN loss:  0.617\n",
      "[epoch 8 Iteration 633/960] TRAIN loss:  0.743\n",
      "[epoch 8 Iteration 634/960] TRAIN loss:  0.890\n",
      "[epoch 8 Iteration 635/960] TRAIN loss:  0.794\n",
      "[epoch 8 Iteration 636/960] TRAIN loss:  0.701\n",
      "[epoch 8 Iteration 637/960] TRAIN loss:  0.867\n",
      "[epoch 8 Iteration 638/960] TRAIN loss:  1.299\n",
      "[epoch 8 Iteration 639/960] TRAIN loss:  0.925\n",
      "[epoch 8 Iteration 640/960] TRAIN loss:  0.675\n",
      "[epoch 8 Iteration 641/960] TRAIN loss:  0.872\n",
      "[epoch 8 Iteration 642/960] TRAIN loss:  0.623\n",
      "[epoch 8 Iteration 643/960] TRAIN loss:  0.673\n",
      "[epoch 8 Iteration 644/960] TRAIN loss:  0.989\n",
      "[epoch 8 Iteration 645/960] TRAIN loss:  0.611\n",
      "[epoch 8 Iteration 646/960] TRAIN loss:  0.729\n",
      "[epoch 8 Iteration 647/960] TRAIN loss:  0.746\n",
      "[epoch 8 Iteration 648/960] TRAIN loss:  0.558\n",
      "[epoch 8 Iteration 649/960] TRAIN loss:  0.936\n",
      "[epoch 8 Iteration 650/960] TRAIN loss:  0.896\n",
      "[epoch 8 Iteration 651/960] TRAIN loss:  0.883\n",
      "[epoch 8 Iteration 652/960] TRAIN loss:  0.797\n",
      "[epoch 8 Iteration 653/960] TRAIN loss:  0.895\n",
      "[epoch 8 Iteration 654/960] TRAIN loss:  0.601\n",
      "[epoch 8 Iteration 655/960] TRAIN loss:  0.776\n",
      "[epoch 8 Iteration 656/960] TRAIN loss:  0.828\n",
      "[epoch 8 Iteration 657/960] TRAIN loss:  0.716\n",
      "[epoch 8 Iteration 658/960] TRAIN loss:  0.908\n",
      "[epoch 8 Iteration 659/960] TRAIN loss:  0.788\n",
      "[epoch 8 Iteration 660/960] TRAIN loss:  0.617\n",
      "[epoch 8 Iteration 661/960] TRAIN loss:  0.809\n",
      "[epoch 8 Iteration 662/960] TRAIN loss:  0.608\n",
      "[epoch 8 Iteration 663/960] TRAIN loss:  0.750\n",
      "[epoch 8 Iteration 664/960] TRAIN loss:  0.611\n",
      "[epoch 8 Iteration 665/960] TRAIN loss:  0.642\n",
      "[epoch 8 Iteration 666/960] TRAIN loss:  0.784\n",
      "[epoch 8 Iteration 667/960] TRAIN loss:  0.703\n",
      "[epoch 8 Iteration 668/960] TRAIN loss:  0.648\n",
      "[epoch 8 Iteration 669/960] TRAIN loss:  0.948\n",
      "[epoch 8 Iteration 670/960] TRAIN loss:  0.609\n",
      "[epoch 8 Iteration 671/960] TRAIN loss:  0.913\n",
      "[epoch 8 Iteration 672/960] TRAIN loss:  0.909\n",
      "[epoch 8 Iteration 673/960] TRAIN loss:  0.851\n",
      "[epoch 8 Iteration 674/960] TRAIN loss:  0.612\n",
      "[epoch 8 Iteration 675/960] TRAIN loss:  0.912\n",
      "[epoch 8 Iteration 676/960] TRAIN loss:  0.919\n",
      "[epoch 8 Iteration 677/960] TRAIN loss:  0.873\n",
      "[epoch 8 Iteration 678/960] TRAIN loss:  0.895\n",
      "[epoch 8 Iteration 679/960] TRAIN loss:  0.881\n",
      "[epoch 8 Iteration 680/960] TRAIN loss:  1.113\n",
      "[epoch 8 Iteration 681/960] TRAIN loss:  0.795\n",
      "[epoch 8 Iteration 682/960] TRAIN loss:  0.826\n",
      "[epoch 8 Iteration 683/960] TRAIN loss:  0.844\n",
      "[epoch 8 Iteration 684/960] TRAIN loss:  0.889\n",
      "[epoch 8 Iteration 685/960] TRAIN loss:  0.764\n",
      "[epoch 8 Iteration 686/960] TRAIN loss:  0.800\n",
      "[epoch 8 Iteration 687/960] TRAIN loss:  0.614\n",
      "[epoch 8 Iteration 688/960] TRAIN loss:  0.756\n",
      "[epoch 8 Iteration 689/960] TRAIN loss:  0.808\n",
      "[epoch 8 Iteration 690/960] TRAIN loss:  0.553\n",
      "[epoch 8 Iteration 691/960] TRAIN loss:  0.967\n",
      "[epoch 8 Iteration 692/960] TRAIN loss:  0.837\n",
      "[epoch 8 Iteration 693/960] TRAIN loss:  0.834\n",
      "[epoch 8 Iteration 694/960] TRAIN loss:  0.847\n",
      "[epoch 8 Iteration 695/960] TRAIN loss:  0.773\n",
      "[epoch 8 Iteration 696/960] TRAIN loss:  0.578\n",
      "[epoch 8 Iteration 697/960] TRAIN loss:  0.634\n",
      "[epoch 8 Iteration 698/960] TRAIN loss:  0.988\n",
      "[epoch 8 Iteration 699/960] TRAIN loss:  0.770\n",
      "[epoch 8 Iteration 700/960] TRAIN loss:  0.743\n",
      "[epoch 8 Iteration 701/960] TRAIN loss:  0.661\n",
      "[epoch 8 Iteration 702/960] TRAIN loss:  0.881\n",
      "[epoch 8 Iteration 703/960] TRAIN loss:  0.667\n",
      "[epoch 8 Iteration 704/960] TRAIN loss:  0.658\n",
      "[epoch 8 Iteration 705/960] TRAIN loss:  0.808\n",
      "[epoch 8 Iteration 706/960] TRAIN loss:  1.045\n",
      "[epoch 8 Iteration 707/960] TRAIN loss:  0.621\n",
      "[epoch 8 Iteration 708/960] TRAIN loss:  1.021\n",
      "[epoch 8 Iteration 709/960] TRAIN loss:  0.667\n",
      "[epoch 8 Iteration 710/960] TRAIN loss:  1.112\n",
      "[epoch 8 Iteration 711/960] TRAIN loss:  0.776\n",
      "[epoch 8 Iteration 712/960] TRAIN loss:  0.631\n",
      "[epoch 8 Iteration 713/960] TRAIN loss:  0.659\n",
      "[epoch 8 Iteration 714/960] TRAIN loss:  0.688\n",
      "[epoch 8 Iteration 715/960] TRAIN loss:  1.203\n",
      "[epoch 8 Iteration 716/960] TRAIN loss:  0.910\n",
      "[epoch 8 Iteration 717/960] TRAIN loss:  0.909\n",
      "[epoch 8 Iteration 718/960] TRAIN loss:  0.848\n",
      "[epoch 8 Iteration 719/960] TRAIN loss:  0.770\n",
      "[epoch 8 Iteration 720/960] TRAIN loss:  0.739\n",
      "[epoch 8 Iteration 721/960] TRAIN loss:  0.527\n",
      "[epoch 8 Iteration 722/960] TRAIN loss:  0.812\n",
      "[epoch 8 Iteration 723/960] TRAIN loss:  0.564\n",
      "[epoch 8 Iteration 724/960] TRAIN loss:  0.818\n",
      "[epoch 8 Iteration 725/960] TRAIN loss:  0.900\n",
      "[epoch 8 Iteration 726/960] TRAIN loss:  0.820\n",
      "[epoch 8 Iteration 727/960] TRAIN loss:  0.884\n",
      "[epoch 8 Iteration 728/960] TRAIN loss:  0.668\n",
      "[epoch 8 Iteration 729/960] TRAIN loss:  0.771\n",
      "[epoch 8 Iteration 730/960] TRAIN loss:  0.758\n",
      "[epoch 8 Iteration 731/960] TRAIN loss:  0.815\n",
      "[epoch 8 Iteration 732/960] TRAIN loss:  0.724\n",
      "[epoch 8 Iteration 733/960] TRAIN loss:  0.743\n",
      "[epoch 8 Iteration 734/960] TRAIN loss:  0.719\n",
      "[epoch 8 Iteration 735/960] TRAIN loss:  0.716\n",
      "[epoch 8 Iteration 736/960] TRAIN loss:  0.716\n",
      "[epoch 8 Iteration 737/960] TRAIN loss:  0.949\n",
      "[epoch 8 Iteration 738/960] TRAIN loss:  0.847\n",
      "[epoch 8 Iteration 739/960] TRAIN loss:  0.442\n",
      "[epoch 8 Iteration 740/960] TRAIN loss:  0.734\n",
      "[epoch 8 Iteration 741/960] TRAIN loss:  0.750\n",
      "[epoch 8 Iteration 742/960] TRAIN loss:  0.991\n",
      "[epoch 8 Iteration 743/960] TRAIN loss:  0.737\n",
      "[epoch 8 Iteration 744/960] TRAIN loss:  0.878\n",
      "[epoch 8 Iteration 745/960] TRAIN loss:  0.743\n",
      "[epoch 8 Iteration 746/960] TRAIN loss:  0.787\n",
      "[epoch 8 Iteration 747/960] TRAIN loss:  0.811\n",
      "[epoch 8 Iteration 748/960] TRAIN loss:  0.933\n",
      "[epoch 8 Iteration 749/960] TRAIN loss:  0.793\n",
      "[epoch 8 Iteration 750/960] TRAIN loss:  0.742\n",
      "[epoch 8 Iteration 751/960] TRAIN loss:  0.553\n",
      "[epoch 8 Iteration 752/960] TRAIN loss:  0.777\n",
      "[epoch 8 Iteration 753/960] TRAIN loss:  0.776\n",
      "[epoch 8 Iteration 754/960] TRAIN loss:  0.815\n",
      "[epoch 8 Iteration 755/960] TRAIN loss:  0.882\n",
      "[epoch 8 Iteration 756/960] TRAIN loss:  0.960\n",
      "[epoch 8 Iteration 757/960] TRAIN loss:  1.016\n",
      "[epoch 8 Iteration 758/960] TRAIN loss:  0.866\n",
      "[epoch 8 Iteration 759/960] TRAIN loss:  0.761\n",
      "[epoch 8 Iteration 760/960] TRAIN loss:  0.684\n",
      "[epoch 8 Iteration 761/960] TRAIN loss:  0.814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8 Iteration 762/960] TRAIN loss:  0.831\n",
      "[epoch 8 Iteration 763/960] TRAIN loss:  1.090\n",
      "[epoch 8 Iteration 764/960] TRAIN loss:  0.871\n",
      "[epoch 8 Iteration 765/960] TRAIN loss:  0.803\n",
      "[epoch 8 Iteration 766/960] TRAIN loss:  1.099\n",
      "[epoch 8 Iteration 767/960] TRAIN loss:  1.010\n",
      "[epoch 8 Iteration 768/960] TRAIN loss:  0.769\n",
      "[epoch 8 Iteration 769/960] TRAIN loss:  0.926\n",
      "[epoch 8 Iteration 770/960] TRAIN loss:  0.682\n",
      "[epoch 8 Iteration 771/960] TRAIN loss:  0.657\n",
      "[epoch 8 Iteration 772/960] TRAIN loss:  0.876\n",
      "[epoch 8 Iteration 773/960] TRAIN loss:  0.699\n",
      "[epoch 8 Iteration 774/960] TRAIN loss:  0.812\n",
      "[epoch 8 Iteration 775/960] TRAIN loss:  0.993\n",
      "[epoch 8 Iteration 776/960] TRAIN loss:  0.970\n",
      "[epoch 8 Iteration 777/960] TRAIN loss:  0.636\n",
      "[epoch 8 Iteration 778/960] TRAIN loss:  0.728\n",
      "[epoch 8 Iteration 779/960] TRAIN loss:  0.967\n",
      "[epoch 8 Iteration 780/960] TRAIN loss:  0.562\n",
      "[epoch 8 Iteration 781/960] TRAIN loss:  0.923\n",
      "[epoch 8 Iteration 782/960] TRAIN loss:  1.072\n",
      "[epoch 8 Iteration 783/960] TRAIN loss:  0.809\n",
      "[epoch 8 Iteration 784/960] TRAIN loss:  0.733\n",
      "[epoch 8 Iteration 785/960] TRAIN loss:  0.504\n",
      "[epoch 8 Iteration 786/960] TRAIN loss:  0.595\n",
      "[epoch 8 Iteration 787/960] TRAIN loss:  0.799\n",
      "[epoch 8 Iteration 788/960] TRAIN loss:  1.220\n",
      "[epoch 8 Iteration 789/960] TRAIN loss:  0.646\n",
      "[epoch 8 Iteration 790/960] TRAIN loss:  0.798\n",
      "[epoch 8 Iteration 791/960] TRAIN loss:  0.835\n",
      "[epoch 8 Iteration 792/960] TRAIN loss:  0.916\n",
      "[epoch 8 Iteration 793/960] TRAIN loss:  0.776\n",
      "[epoch 8 Iteration 794/960] TRAIN loss:  0.847\n",
      "[epoch 8 Iteration 795/960] TRAIN loss:  1.111\n",
      "[epoch 8 Iteration 796/960] TRAIN loss:  1.010\n",
      "[epoch 8 Iteration 797/960] TRAIN loss:  0.704\n",
      "[epoch 8 Iteration 798/960] TRAIN loss:  0.827\n",
      "[epoch 8 Iteration 799/960] TRAIN loss:  0.834\n",
      "[epoch 8 Iteration 800/960] TRAIN loss:  0.659\n",
      "[epoch 8 Iteration 801/960] TRAIN loss:  0.857\n",
      "[epoch 8 Iteration 802/960] TRAIN loss:  0.705\n",
      "[epoch 8 Iteration 803/960] TRAIN loss:  0.729\n",
      "[epoch 8 Iteration 804/960] TRAIN loss:  0.817\n",
      "[epoch 8 Iteration 805/960] TRAIN loss:  0.991\n",
      "[epoch 8 Iteration 806/960] TRAIN loss:  0.649\n",
      "[epoch 8 Iteration 807/960] TRAIN loss:  0.849\n",
      "[epoch 8 Iteration 808/960] TRAIN loss:  0.679\n",
      "[epoch 8 Iteration 809/960] TRAIN loss:  0.896\n",
      "[epoch 8 Iteration 810/960] TRAIN loss:  0.705\n",
      "[epoch 8 Iteration 811/960] TRAIN loss:  0.681\n",
      "[epoch 8 Iteration 812/960] TRAIN loss:  0.887\n",
      "[epoch 8 Iteration 813/960] TRAIN loss:  0.642\n",
      "[epoch 8 Iteration 814/960] TRAIN loss:  1.032\n",
      "[epoch 8 Iteration 815/960] TRAIN loss:  0.897\n",
      "[epoch 8 Iteration 816/960] TRAIN loss:  0.777\n",
      "[epoch 8 Iteration 817/960] TRAIN loss:  0.677\n",
      "[epoch 8 Iteration 818/960] TRAIN loss:  0.734\n",
      "[epoch 8 Iteration 819/960] TRAIN loss:  0.820\n",
      "[epoch 8 Iteration 820/960] TRAIN loss:  0.664\n",
      "[epoch 8 Iteration 821/960] TRAIN loss:  0.796\n",
      "[epoch 8 Iteration 822/960] TRAIN loss:  0.827\n",
      "[epoch 8 Iteration 823/960] TRAIN loss:  1.036\n",
      "[epoch 8 Iteration 824/960] TRAIN loss:  0.922\n",
      "[epoch 8 Iteration 825/960] TRAIN loss:  0.802\n",
      "[epoch 8 Iteration 826/960] TRAIN loss:  0.780\n",
      "[epoch 8 Iteration 827/960] TRAIN loss:  0.947\n",
      "[epoch 8 Iteration 828/960] TRAIN loss:  0.710\n",
      "[epoch 8 Iteration 829/960] TRAIN loss:  0.792\n",
      "[epoch 8 Iteration 830/960] TRAIN loss:  0.943\n",
      "[epoch 8 Iteration 831/960] TRAIN loss:  0.968\n",
      "[epoch 8 Iteration 832/960] TRAIN loss:  1.152\n",
      "[epoch 8 Iteration 833/960] TRAIN loss:  0.735\n",
      "[epoch 8 Iteration 834/960] TRAIN loss:  0.908\n",
      "[epoch 8 Iteration 835/960] TRAIN loss:  0.832\n",
      "[epoch 8 Iteration 836/960] TRAIN loss:  1.005\n",
      "[epoch 8 Iteration 837/960] TRAIN loss:  0.663\n",
      "[epoch 8 Iteration 838/960] TRAIN loss:  0.691\n",
      "[epoch 8 Iteration 839/960] TRAIN loss:  0.862\n",
      "[epoch 8 Iteration 840/960] TRAIN loss:  0.834\n",
      "[epoch 8 Iteration 841/960] TRAIN loss:  0.738\n",
      "[epoch 8 Iteration 842/960] TRAIN loss:  0.831\n",
      "[epoch 8 Iteration 843/960] TRAIN loss:  0.709\n",
      "[epoch 8 Iteration 844/960] TRAIN loss:  1.023\n",
      "[epoch 8 Iteration 845/960] TRAIN loss:  0.738\n",
      "[epoch 8 Iteration 846/960] TRAIN loss:  0.832\n",
      "[epoch 8 Iteration 847/960] TRAIN loss:  0.827\n",
      "[epoch 8 Iteration 848/960] TRAIN loss:  0.743\n",
      "[epoch 8 Iteration 849/960] TRAIN loss:  0.589\n",
      "[epoch 8 Iteration 850/960] TRAIN loss:  1.115\n",
      "[epoch 8 Iteration 851/960] TRAIN loss:  0.977\n",
      "[epoch 8 Iteration 852/960] TRAIN loss:  0.905\n",
      "[epoch 8 Iteration 853/960] TRAIN loss:  0.604\n",
      "[epoch 8 Iteration 854/960] TRAIN loss:  0.761\n",
      "[epoch 8 Iteration 855/960] TRAIN loss:  0.783\n",
      "[epoch 8 Iteration 856/960] TRAIN loss:  0.954\n",
      "[epoch 8 Iteration 857/960] TRAIN loss:  0.711\n",
      "[epoch 8 Iteration 858/960] TRAIN loss:  0.790\n",
      "[epoch 8 Iteration 859/960] TRAIN loss:  0.662\n",
      "[epoch 8 Iteration 860/960] TRAIN loss:  0.968\n",
      "[epoch 8 Iteration 861/960] TRAIN loss:  0.837\n",
      "[epoch 8 Iteration 862/960] TRAIN loss:  0.859\n",
      "[epoch 8 Iteration 863/960] TRAIN loss:  1.143\n",
      "[epoch 8 Iteration 864/960] TRAIN loss:  0.682\n",
      "[epoch 8 Iteration 865/960] TRAIN loss:  0.496\n",
      "[epoch 8 Iteration 866/960] TRAIN loss:  0.680\n",
      "[epoch 8 Iteration 867/960] TRAIN loss:  0.763\n",
      "[epoch 8 Iteration 868/960] TRAIN loss:  0.788\n",
      "[epoch 8 Iteration 869/960] TRAIN loss:  0.879\n",
      "[epoch 8 Iteration 870/960] TRAIN loss:  0.909\n",
      "[epoch 8 Iteration 871/960] TRAIN loss:  0.727\n",
      "[epoch 8 Iteration 872/960] TRAIN loss:  0.838\n",
      "[epoch 8 Iteration 873/960] TRAIN loss:  0.706\n",
      "[epoch 8 Iteration 874/960] TRAIN loss:  0.653\n",
      "[epoch 8 Iteration 875/960] TRAIN loss:  0.717\n",
      "[epoch 8 Iteration 876/960] TRAIN loss:  0.881\n",
      "[epoch 8 Iteration 877/960] TRAIN loss:  0.776\n",
      "[epoch 8 Iteration 878/960] TRAIN loss:  0.937\n",
      "[epoch 8 Iteration 879/960] TRAIN loss:  0.506\n",
      "[epoch 8 Iteration 880/960] TRAIN loss:  0.756\n",
      "[epoch 8 Iteration 881/960] TRAIN loss:  1.017\n",
      "[epoch 8 Iteration 882/960] TRAIN loss:  0.943\n",
      "[epoch 8 Iteration 883/960] TRAIN loss:  0.840\n",
      "[epoch 8 Iteration 884/960] TRAIN loss:  0.725\n",
      "[epoch 8 Iteration 885/960] TRAIN loss:  0.593\n",
      "[epoch 8 Iteration 886/960] TRAIN loss:  0.733\n",
      "[epoch 8 Iteration 887/960] TRAIN loss:  0.660\n",
      "[epoch 8 Iteration 888/960] TRAIN loss:  0.654\n",
      "[epoch 8 Iteration 889/960] TRAIN loss:  0.821\n",
      "[epoch 8 Iteration 890/960] TRAIN loss:  0.805\n",
      "[epoch 8 Iteration 891/960] TRAIN loss:  0.722\n",
      "[epoch 8 Iteration 892/960] TRAIN loss:  0.717\n",
      "[epoch 8 Iteration 893/960] TRAIN loss:  0.874\n",
      "[epoch 8 Iteration 894/960] TRAIN loss:  0.863\n",
      "[epoch 8 Iteration 895/960] TRAIN loss:  0.831\n",
      "[epoch 8 Iteration 896/960] TRAIN loss:  0.798\n",
      "[epoch 8 Iteration 897/960] TRAIN loss:  0.699\n",
      "[epoch 8 Iteration 898/960] TRAIN loss:  0.832\n",
      "[epoch 8 Iteration 899/960] TRAIN loss:  0.746\n",
      "[epoch 8 Iteration 900/960] TRAIN loss:  0.851\n",
      "[epoch 8 Iteration 901/960] TRAIN loss:  0.826\n",
      "[epoch 8 Iteration 902/960] TRAIN loss:  0.616\n",
      "[epoch 8 Iteration 903/960] TRAIN loss:  0.802\n",
      "[epoch 8 Iteration 904/960] TRAIN loss:  0.890\n",
      "[epoch 8 Iteration 905/960] TRAIN loss:  0.764\n",
      "[epoch 8 Iteration 906/960] TRAIN loss:  0.732\n",
      "[epoch 8 Iteration 907/960] TRAIN loss:  0.544\n",
      "[epoch 8 Iteration 908/960] TRAIN loss:  0.864\n",
      "[epoch 8 Iteration 909/960] TRAIN loss:  0.846\n",
      "[epoch 8 Iteration 910/960] TRAIN loss:  0.918\n",
      "[epoch 8 Iteration 911/960] TRAIN loss:  0.772\n",
      "[epoch 8 Iteration 912/960] TRAIN loss:  1.000\n",
      "[epoch 8 Iteration 913/960] TRAIN loss:  0.773\n",
      "[epoch 8 Iteration 914/960] TRAIN loss:  0.927\n",
      "[epoch 8 Iteration 915/960] TRAIN loss:  0.723\n",
      "[epoch 8 Iteration 916/960] TRAIN loss:  0.639\n",
      "[epoch 8 Iteration 917/960] TRAIN loss:  0.686\n",
      "[epoch 8 Iteration 918/960] TRAIN loss:  0.932\n",
      "[epoch 8 Iteration 919/960] TRAIN loss:  0.768\n",
      "[epoch 8 Iteration 920/960] TRAIN loss:  0.777\n",
      "[epoch 8 Iteration 921/960] TRAIN loss:  0.774\n",
      "[epoch 8 Iteration 922/960] TRAIN loss:  0.685\n",
      "[epoch 8 Iteration 923/960] TRAIN loss:  0.569\n",
      "[epoch 8 Iteration 924/960] TRAIN loss:  0.627\n",
      "[epoch 8 Iteration 925/960] TRAIN loss:  0.826\n",
      "[epoch 8 Iteration 926/960] TRAIN loss:  0.781\n",
      "[epoch 8 Iteration 927/960] TRAIN loss:  0.914\n",
      "[epoch 8 Iteration 928/960] TRAIN loss:  0.917\n",
      "[epoch 8 Iteration 929/960] TRAIN loss:  0.835\n",
      "[epoch 8 Iteration 930/960] TRAIN loss:  1.029\n",
      "[epoch 8 Iteration 931/960] TRAIN loss:  0.912\n",
      "[epoch 8 Iteration 932/960] TRAIN loss:  0.833\n",
      "[epoch 8 Iteration 933/960] TRAIN loss:  0.955\n",
      "[epoch 8 Iteration 934/960] TRAIN loss:  0.864\n",
      "[epoch 8 Iteration 935/960] TRAIN loss:  0.716\n",
      "[epoch 8 Iteration 936/960] TRAIN loss:  0.937\n",
      "[epoch 8 Iteration 937/960] TRAIN loss:  0.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 8 Iteration 938/960] TRAIN loss:  0.715\n",
      "[epoch 8 Iteration 939/960] TRAIN loss:  0.983\n",
      "[epoch 8 Iteration 940/960] TRAIN loss:  0.510\n",
      "[epoch 8 Iteration 941/960] TRAIN loss:  0.887\n",
      "[epoch 8 Iteration 942/960] TRAIN loss:  0.701\n",
      "[epoch 8 Iteration 943/960] TRAIN loss:  0.647\n",
      "[epoch 8 Iteration 944/960] TRAIN loss:  0.701\n",
      "[epoch 8 Iteration 945/960] TRAIN loss:  0.858\n",
      "[epoch 8 Iteration 946/960] TRAIN loss:  1.003\n",
      "[epoch 8 Iteration 947/960] TRAIN loss:  0.754\n",
      "[epoch 8 Iteration 948/960] TRAIN loss:  0.931\n",
      "[epoch 8 Iteration 949/960] TRAIN loss:  0.625\n",
      "[epoch 8 Iteration 950/960] TRAIN loss:  0.557\n",
      "[epoch 8 Iteration 951/960] TRAIN loss:  0.708\n",
      "[epoch 8 Iteration 952/960] TRAIN loss:  0.758\n",
      "[epoch 8 Iteration 953/960] TRAIN loss:  0.856\n",
      "[epoch 8 Iteration 954/960] TRAIN loss:  0.685\n",
      "[epoch 8 Iteration 955/960] TRAIN loss:  0.694\n",
      "[epoch 8 Iteration 956/960] TRAIN loss:  0.743\n",
      "[epoch 8 Iteration 957/960] TRAIN loss:  0.811\n",
      "[epoch 8 Iteration 958/960] TRAIN loss:  1.111\n",
      "[epoch 8 Iteration 959/960] TRAIN loss:  0.762\n",
      "[epoch 8/15] TRAIN acc/loss:  0.722/0.762\n",
      "[epoch 8/15] VAL acc/loss:  0.652/0.510\n",
      "[epoch 9 Iteration 0/960] TRAIN loss:  0.856\n",
      "[epoch 9 Iteration 1/960] TRAIN loss:  0.539\n",
      "[epoch 9 Iteration 2/960] TRAIN loss:  0.878\n",
      "[epoch 9 Iteration 3/960] TRAIN loss:  0.660\n",
      "[epoch 9 Iteration 4/960] TRAIN loss:  0.880\n",
      "[epoch 9 Iteration 5/960] TRAIN loss:  0.655\n",
      "[epoch 9 Iteration 6/960] TRAIN loss:  0.758\n",
      "[epoch 9 Iteration 7/960] TRAIN loss:  1.022\n",
      "[epoch 9 Iteration 8/960] TRAIN loss:  0.941\n",
      "[epoch 9 Iteration 9/960] TRAIN loss:  0.985\n",
      "[epoch 9 Iteration 10/960] TRAIN loss:  0.796\n",
      "[epoch 9 Iteration 11/960] TRAIN loss:  0.874\n",
      "[epoch 9 Iteration 12/960] TRAIN loss:  0.916\n",
      "[epoch 9 Iteration 13/960] TRAIN loss:  0.934\n",
      "[epoch 9 Iteration 14/960] TRAIN loss:  0.691\n",
      "[epoch 9 Iteration 15/960] TRAIN loss:  0.687\n",
      "[epoch 9 Iteration 16/960] TRAIN loss:  0.613\n",
      "[epoch 9 Iteration 17/960] TRAIN loss:  1.026\n",
      "[epoch 9 Iteration 18/960] TRAIN loss:  1.011\n",
      "[epoch 9 Iteration 19/960] TRAIN loss:  0.774\n",
      "[epoch 9 Iteration 20/960] TRAIN loss:  0.635\n",
      "[epoch 9 Iteration 21/960] TRAIN loss:  0.780\n",
      "[epoch 9 Iteration 22/960] TRAIN loss:  0.713\n",
      "[epoch 9 Iteration 23/960] TRAIN loss:  0.849\n",
      "[epoch 9 Iteration 24/960] TRAIN loss:  0.607\n",
      "[epoch 9 Iteration 25/960] TRAIN loss:  0.667\n",
      "[epoch 9 Iteration 26/960] TRAIN loss:  0.620\n",
      "[epoch 9 Iteration 27/960] TRAIN loss:  0.831\n",
      "[epoch 9 Iteration 28/960] TRAIN loss:  0.704\n",
      "[epoch 9 Iteration 29/960] TRAIN loss:  0.627\n",
      "[epoch 9 Iteration 30/960] TRAIN loss:  0.820\n",
      "[epoch 9 Iteration 31/960] TRAIN loss:  0.572\n",
      "[epoch 9 Iteration 32/960] TRAIN loss:  0.672\n",
      "[epoch 9 Iteration 33/960] TRAIN loss:  0.758\n",
      "[epoch 9 Iteration 34/960] TRAIN loss:  0.730\n",
      "[epoch 9 Iteration 35/960] TRAIN loss:  0.539\n",
      "[epoch 9 Iteration 36/960] TRAIN loss:  1.094\n",
      "[epoch 9 Iteration 37/960] TRAIN loss:  0.605\n",
      "[epoch 9 Iteration 38/960] TRAIN loss:  0.741\n",
      "[epoch 9 Iteration 39/960] TRAIN loss:  0.712\n",
      "[epoch 9 Iteration 40/960] TRAIN loss:  0.579\n",
      "[epoch 9 Iteration 41/960] TRAIN loss:  0.693\n",
      "[epoch 9 Iteration 42/960] TRAIN loss:  0.798\n",
      "[epoch 9 Iteration 43/960] TRAIN loss:  0.734\n",
      "[epoch 9 Iteration 44/960] TRAIN loss:  0.670\n",
      "[epoch 9 Iteration 45/960] TRAIN loss:  0.678\n",
      "[epoch 9 Iteration 46/960] TRAIN loss:  0.743\n",
      "[epoch 9 Iteration 47/960] TRAIN loss:  0.685\n",
      "[epoch 9 Iteration 48/960] TRAIN loss:  0.770\n",
      "[epoch 9 Iteration 49/960] TRAIN loss:  0.523\n",
      "[epoch 9 Iteration 50/960] TRAIN loss:  0.699\n",
      "[epoch 9 Iteration 51/960] TRAIN loss:  0.609\n",
      "[epoch 9 Iteration 52/960] TRAIN loss:  0.743\n",
      "[epoch 9 Iteration 53/960] TRAIN loss:  0.462\n",
      "[epoch 9 Iteration 54/960] TRAIN loss:  0.641\n",
      "[epoch 9 Iteration 55/960] TRAIN loss:  0.914\n",
      "[epoch 9 Iteration 56/960] TRAIN loss:  0.764\n",
      "[epoch 9 Iteration 57/960] TRAIN loss:  0.857\n",
      "[epoch 9 Iteration 58/960] TRAIN loss:  0.811\n",
      "[epoch 9 Iteration 59/960] TRAIN loss:  0.902\n",
      "[epoch 9 Iteration 60/960] TRAIN loss:  0.471\n",
      "[epoch 9 Iteration 61/960] TRAIN loss:  0.458\n",
      "[epoch 9 Iteration 62/960] TRAIN loss:  0.666\n",
      "[epoch 9 Iteration 63/960] TRAIN loss:  0.733\n",
      "[epoch 9 Iteration 64/960] TRAIN loss:  0.608\n",
      "[epoch 9 Iteration 65/960] TRAIN loss:  0.589\n",
      "[epoch 9 Iteration 66/960] TRAIN loss:  0.879\n",
      "[epoch 9 Iteration 67/960] TRAIN loss:  0.623\n",
      "[epoch 9 Iteration 68/960] TRAIN loss:  0.925\n",
      "[epoch 9 Iteration 69/960] TRAIN loss:  0.824\n",
      "[epoch 9 Iteration 70/960] TRAIN loss:  0.458\n",
      "[epoch 9 Iteration 71/960] TRAIN loss:  0.560\n",
      "[epoch 9 Iteration 72/960] TRAIN loss:  0.687\n",
      "[epoch 9 Iteration 73/960] TRAIN loss:  1.028\n",
      "[epoch 9 Iteration 74/960] TRAIN loss:  0.685\n",
      "[epoch 9 Iteration 75/960] TRAIN loss:  0.588\n",
      "[epoch 9 Iteration 76/960] TRAIN loss:  0.772\n",
      "[epoch 9 Iteration 77/960] TRAIN loss:  0.693\n",
      "[epoch 9 Iteration 78/960] TRAIN loss:  0.547\n",
      "[epoch 9 Iteration 79/960] TRAIN loss:  0.835\n",
      "[epoch 9 Iteration 80/960] TRAIN loss:  0.586\n",
      "[epoch 9 Iteration 81/960] TRAIN loss:  0.783\n",
      "[epoch 9 Iteration 82/960] TRAIN loss:  0.815\n",
      "[epoch 9 Iteration 83/960] TRAIN loss:  0.692\n",
      "[epoch 9 Iteration 84/960] TRAIN loss:  0.836\n",
      "[epoch 9 Iteration 85/960] TRAIN loss:  0.500\n",
      "[epoch 9 Iteration 86/960] TRAIN loss:  0.653\n",
      "[epoch 9 Iteration 87/960] TRAIN loss:  0.820\n",
      "[epoch 9 Iteration 88/960] TRAIN loss:  0.842\n",
      "[epoch 9 Iteration 89/960] TRAIN loss:  0.874\n",
      "[epoch 9 Iteration 90/960] TRAIN loss:  0.509\n",
      "[epoch 9 Iteration 91/960] TRAIN loss:  0.842\n",
      "[epoch 9 Iteration 92/960] TRAIN loss:  0.478\n",
      "[epoch 9 Iteration 93/960] TRAIN loss:  0.567\n",
      "[epoch 9 Iteration 94/960] TRAIN loss:  0.948\n",
      "[epoch 9 Iteration 95/960] TRAIN loss:  0.724\n",
      "[epoch 9 Iteration 96/960] TRAIN loss:  0.806\n",
      "[epoch 9 Iteration 97/960] TRAIN loss:  0.577\n",
      "[epoch 9 Iteration 98/960] TRAIN loss:  0.817\n",
      "[epoch 9 Iteration 99/960] TRAIN loss:  0.656\n",
      "[epoch 9 Iteration 100/960] TRAIN loss:  0.752\n",
      "[epoch 9 Iteration 101/960] TRAIN loss:  1.052\n",
      "[epoch 9 Iteration 102/960] TRAIN loss:  0.805\n",
      "[epoch 9 Iteration 103/960] TRAIN loss:  0.597\n",
      "[epoch 9 Iteration 104/960] TRAIN loss:  0.694\n",
      "[epoch 9 Iteration 105/960] TRAIN loss:  0.970\n",
      "[epoch 9 Iteration 106/960] TRAIN loss:  0.764\n",
      "[epoch 9 Iteration 107/960] TRAIN loss:  0.806\n",
      "[epoch 9 Iteration 108/960] TRAIN loss:  1.039\n",
      "[epoch 9 Iteration 109/960] TRAIN loss:  0.449\n",
      "[epoch 9 Iteration 110/960] TRAIN loss:  0.882\n",
      "[epoch 9 Iteration 111/960] TRAIN loss:  0.858\n",
      "[epoch 9 Iteration 112/960] TRAIN loss:  0.839\n",
      "[epoch 9 Iteration 113/960] TRAIN loss:  0.641\n",
      "[epoch 9 Iteration 114/960] TRAIN loss:  0.887\n",
      "[epoch 9 Iteration 115/960] TRAIN loss:  0.597\n",
      "[epoch 9 Iteration 116/960] TRAIN loss:  0.832\n",
      "[epoch 9 Iteration 117/960] TRAIN loss:  0.667\n",
      "[epoch 9 Iteration 118/960] TRAIN loss:  0.982\n",
      "[epoch 9 Iteration 119/960] TRAIN loss:  0.622\n",
      "[epoch 9 Iteration 120/960] TRAIN loss:  0.734\n",
      "[epoch 9 Iteration 121/960] TRAIN loss:  0.608\n",
      "[epoch 9 Iteration 122/960] TRAIN loss:  0.617\n",
      "[epoch 9 Iteration 123/960] TRAIN loss:  0.589\n",
      "[epoch 9 Iteration 124/960] TRAIN loss:  0.661\n",
      "[epoch 9 Iteration 125/960] TRAIN loss:  0.645\n",
      "[epoch 9 Iteration 126/960] TRAIN loss:  0.749\n",
      "[epoch 9 Iteration 127/960] TRAIN loss:  0.819\n",
      "[epoch 9 Iteration 128/960] TRAIN loss:  0.638\n",
      "[epoch 9 Iteration 129/960] TRAIN loss:  0.512\n",
      "[epoch 9 Iteration 130/960] TRAIN loss:  0.631\n",
      "[epoch 9 Iteration 131/960] TRAIN loss:  0.560\n",
      "[epoch 9 Iteration 132/960] TRAIN loss:  0.731\n",
      "[epoch 9 Iteration 133/960] TRAIN loss:  0.561\n",
      "[epoch 9 Iteration 134/960] TRAIN loss:  0.582\n",
      "[epoch 9 Iteration 135/960] TRAIN loss:  0.617\n",
      "[epoch 9 Iteration 136/960] TRAIN loss:  0.913\n",
      "[epoch 9 Iteration 137/960] TRAIN loss:  0.509\n",
      "[epoch 9 Iteration 138/960] TRAIN loss:  0.629\n",
      "[epoch 9 Iteration 139/960] TRAIN loss:  0.675\n",
      "[epoch 9 Iteration 140/960] TRAIN loss:  0.701\n",
      "[epoch 9 Iteration 141/960] TRAIN loss:  0.670\n",
      "[epoch 9 Iteration 142/960] TRAIN loss:  0.705\n",
      "[epoch 9 Iteration 143/960] TRAIN loss:  0.605\n",
      "[epoch 9 Iteration 144/960] TRAIN loss:  0.763\n",
      "[epoch 9 Iteration 145/960] TRAIN loss:  0.583\n",
      "[epoch 9 Iteration 146/960] TRAIN loss:  0.838\n",
      "[epoch 9 Iteration 147/960] TRAIN loss:  0.773\n",
      "[epoch 9 Iteration 148/960] TRAIN loss:  0.665\n",
      "[epoch 9 Iteration 149/960] TRAIN loss:  0.767\n",
      "[epoch 9 Iteration 150/960] TRAIN loss:  0.750\n",
      "[epoch 9 Iteration 151/960] TRAIN loss:  0.671\n",
      "[epoch 9 Iteration 152/960] TRAIN loss:  0.640\n",
      "[epoch 9 Iteration 153/960] TRAIN loss:  0.607\n",
      "[epoch 9 Iteration 154/960] TRAIN loss:  0.772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9 Iteration 155/960] TRAIN loss:  0.804\n",
      "[epoch 9 Iteration 156/960] TRAIN loss:  1.207\n",
      "[epoch 9 Iteration 157/960] TRAIN loss:  0.852\n",
      "[epoch 9 Iteration 158/960] TRAIN loss:  0.764\n",
      "[epoch 9 Iteration 159/960] TRAIN loss:  0.754\n",
      "[epoch 9 Iteration 160/960] TRAIN loss:  0.801\n",
      "[epoch 9 Iteration 161/960] TRAIN loss:  0.638\n",
      "[epoch 9 Iteration 162/960] TRAIN loss:  0.975\n",
      "[epoch 9 Iteration 163/960] TRAIN loss:  0.603\n",
      "[epoch 9 Iteration 164/960] TRAIN loss:  0.671\n",
      "[epoch 9 Iteration 165/960] TRAIN loss:  0.599\n",
      "[epoch 9 Iteration 166/960] TRAIN loss:  0.713\n",
      "[epoch 9 Iteration 167/960] TRAIN loss:  0.799\n",
      "[epoch 9 Iteration 168/960] TRAIN loss:  0.694\n",
      "[epoch 9 Iteration 169/960] TRAIN loss:  0.628\n",
      "[epoch 9 Iteration 170/960] TRAIN loss:  0.621\n",
      "[epoch 9 Iteration 171/960] TRAIN loss:  0.637\n",
      "[epoch 9 Iteration 172/960] TRAIN loss:  0.588\n",
      "[epoch 9 Iteration 173/960] TRAIN loss:  0.752\n",
      "[epoch 9 Iteration 174/960] TRAIN loss:  0.797\n",
      "[epoch 9 Iteration 175/960] TRAIN loss:  0.978\n",
      "[epoch 9 Iteration 176/960] TRAIN loss:  0.632\n",
      "[epoch 9 Iteration 177/960] TRAIN loss:  0.767\n",
      "[epoch 9 Iteration 178/960] TRAIN loss:  1.041\n",
      "[epoch 9 Iteration 179/960] TRAIN loss:  0.713\n",
      "[epoch 9 Iteration 180/960] TRAIN loss:  0.854\n",
      "[epoch 9 Iteration 181/960] TRAIN loss:  0.779\n",
      "[epoch 9 Iteration 182/960] TRAIN loss:  0.602\n",
      "[epoch 9 Iteration 183/960] TRAIN loss:  0.623\n",
      "[epoch 9 Iteration 184/960] TRAIN loss:  0.614\n",
      "[epoch 9 Iteration 185/960] TRAIN loss:  0.912\n",
      "[epoch 9 Iteration 186/960] TRAIN loss:  0.903\n",
      "[epoch 9 Iteration 187/960] TRAIN loss:  0.797\n",
      "[epoch 9 Iteration 188/960] TRAIN loss:  0.575\n",
      "[epoch 9 Iteration 189/960] TRAIN loss:  0.892\n",
      "[epoch 9 Iteration 190/960] TRAIN loss:  0.789\n",
      "[epoch 9 Iteration 191/960] TRAIN loss:  0.724\n",
      "[epoch 9 Iteration 192/960] TRAIN loss:  0.694\n",
      "[epoch 9 Iteration 193/960] TRAIN loss:  0.753\n",
      "[epoch 9 Iteration 194/960] TRAIN loss:  0.680\n",
      "[epoch 9 Iteration 195/960] TRAIN loss:  0.549\n",
      "[epoch 9 Iteration 196/960] TRAIN loss:  0.637\n",
      "[epoch 9 Iteration 197/960] TRAIN loss:  0.781\n",
      "[epoch 9 Iteration 198/960] TRAIN loss:  0.529\n",
      "[epoch 9 Iteration 199/960] TRAIN loss:  0.769\n",
      "[epoch 9 Iteration 200/960] TRAIN loss:  0.987\n",
      "[epoch 9 Iteration 201/960] TRAIN loss:  0.883\n",
      "[epoch 9 Iteration 202/960] TRAIN loss:  0.626\n",
      "[epoch 9 Iteration 203/960] TRAIN loss:  0.653\n",
      "[epoch 9 Iteration 204/960] TRAIN loss:  0.705\n",
      "[epoch 9 Iteration 205/960] TRAIN loss:  0.862\n",
      "[epoch 9 Iteration 206/960] TRAIN loss:  0.901\n",
      "[epoch 9 Iteration 207/960] TRAIN loss:  0.595\n",
      "[epoch 9 Iteration 208/960] TRAIN loss:  0.504\n",
      "[epoch 9 Iteration 209/960] TRAIN loss:  0.757\n",
      "[epoch 9 Iteration 210/960] TRAIN loss:  0.912\n",
      "[epoch 9 Iteration 211/960] TRAIN loss:  0.889\n",
      "[epoch 9 Iteration 212/960] TRAIN loss:  0.694\n",
      "[epoch 9 Iteration 213/960] TRAIN loss:  0.762\n",
      "[epoch 9 Iteration 214/960] TRAIN loss:  0.718\n",
      "[epoch 9 Iteration 215/960] TRAIN loss:  0.706\n",
      "[epoch 9 Iteration 216/960] TRAIN loss:  0.660\n",
      "[epoch 9 Iteration 217/960] TRAIN loss:  0.560\n",
      "[epoch 9 Iteration 218/960] TRAIN loss:  0.609\n",
      "[epoch 9 Iteration 219/960] TRAIN loss:  0.772\n",
      "[epoch 9 Iteration 220/960] TRAIN loss:  0.478\n",
      "[epoch 9 Iteration 221/960] TRAIN loss:  0.576\n",
      "[epoch 9 Iteration 222/960] TRAIN loss:  0.529\n",
      "[epoch 9 Iteration 223/960] TRAIN loss:  0.881\n",
      "[epoch 9 Iteration 224/960] TRAIN loss:  0.757\n",
      "[epoch 9 Iteration 225/960] TRAIN loss:  0.545\n",
      "[epoch 9 Iteration 226/960] TRAIN loss:  0.617\n",
      "[epoch 9 Iteration 227/960] TRAIN loss:  0.853\n",
      "[epoch 9 Iteration 228/960] TRAIN loss:  0.960\n",
      "[epoch 9 Iteration 229/960] TRAIN loss:  0.704\n",
      "[epoch 9 Iteration 230/960] TRAIN loss:  0.604\n",
      "[epoch 9 Iteration 231/960] TRAIN loss:  0.686\n",
      "[epoch 9 Iteration 232/960] TRAIN loss:  0.693\n",
      "[epoch 9 Iteration 233/960] TRAIN loss:  0.754\n",
      "[epoch 9 Iteration 234/960] TRAIN loss:  0.726\n",
      "[epoch 9 Iteration 235/960] TRAIN loss:  0.810\n",
      "[epoch 9 Iteration 236/960] TRAIN loss:  1.000\n",
      "[epoch 9 Iteration 237/960] TRAIN loss:  0.761\n",
      "[epoch 9 Iteration 238/960] TRAIN loss:  0.625\n",
      "[epoch 9 Iteration 239/960] TRAIN loss:  0.668\n",
      "[epoch 9 Iteration 240/960] TRAIN loss:  0.517\n",
      "[epoch 9 Iteration 241/960] TRAIN loss:  0.724\n",
      "[epoch 9 Iteration 242/960] TRAIN loss:  0.631\n",
      "[epoch 9 Iteration 243/960] TRAIN loss:  0.715\n",
      "[epoch 9 Iteration 244/960] TRAIN loss:  0.693\n",
      "[epoch 9 Iteration 245/960] TRAIN loss:  0.786\n",
      "[epoch 9 Iteration 246/960] TRAIN loss:  0.593\n",
      "[epoch 9 Iteration 247/960] TRAIN loss:  0.628\n",
      "[epoch 9 Iteration 248/960] TRAIN loss:  0.771\n",
      "[epoch 9 Iteration 249/960] TRAIN loss:  0.916\n",
      "[epoch 9 Iteration 250/960] TRAIN loss:  0.670\n",
      "[epoch 9 Iteration 251/960] TRAIN loss:  0.638\n",
      "[epoch 9 Iteration 252/960] TRAIN loss:  0.917\n",
      "[epoch 9 Iteration 253/960] TRAIN loss:  0.670\n",
      "[epoch 9 Iteration 254/960] TRAIN loss:  0.856\n",
      "[epoch 9 Iteration 255/960] TRAIN loss:  0.566\n",
      "[epoch 9 Iteration 256/960] TRAIN loss:  0.790\n",
      "[epoch 9 Iteration 257/960] TRAIN loss:  0.631\n",
      "[epoch 9 Iteration 258/960] TRAIN loss:  0.713\n",
      "[epoch 9 Iteration 259/960] TRAIN loss:  0.671\n",
      "[epoch 9 Iteration 260/960] TRAIN loss:  0.848\n",
      "[epoch 9 Iteration 261/960] TRAIN loss:  0.773\n",
      "[epoch 9 Iteration 262/960] TRAIN loss:  0.770\n",
      "[epoch 9 Iteration 263/960] TRAIN loss:  0.727\n",
      "[epoch 9 Iteration 264/960] TRAIN loss:  0.833\n",
      "[epoch 9 Iteration 265/960] TRAIN loss:  0.605\n",
      "[epoch 9 Iteration 266/960] TRAIN loss:  0.903\n",
      "[epoch 9 Iteration 267/960] TRAIN loss:  0.673\n",
      "[epoch 9 Iteration 268/960] TRAIN loss:  0.920\n",
      "[epoch 9 Iteration 269/960] TRAIN loss:  0.615\n",
      "[epoch 9 Iteration 270/960] TRAIN loss:  0.887\n",
      "[epoch 9 Iteration 271/960] TRAIN loss:  0.764\n",
      "[epoch 9 Iteration 272/960] TRAIN loss:  0.754\n",
      "[epoch 9 Iteration 273/960] TRAIN loss:  0.883\n",
      "[epoch 9 Iteration 274/960] TRAIN loss:  0.584\n",
      "[epoch 9 Iteration 275/960] TRAIN loss:  0.784\n",
      "[epoch 9 Iteration 276/960] TRAIN loss:  0.699\n",
      "[epoch 9 Iteration 277/960] TRAIN loss:  0.868\n",
      "[epoch 9 Iteration 278/960] TRAIN loss:  0.892\n",
      "[epoch 9 Iteration 279/960] TRAIN loss:  0.888\n",
      "[epoch 9 Iteration 280/960] TRAIN loss:  0.609\n",
      "[epoch 9 Iteration 281/960] TRAIN loss:  0.769\n",
      "[epoch 9 Iteration 282/960] TRAIN loss:  0.673\n",
      "[epoch 9 Iteration 283/960] TRAIN loss:  0.836\n",
      "[epoch 9 Iteration 284/960] TRAIN loss:  0.631\n",
      "[epoch 9 Iteration 285/960] TRAIN loss:  0.750\n",
      "[epoch 9 Iteration 286/960] TRAIN loss:  0.768\n",
      "[epoch 9 Iteration 287/960] TRAIN loss:  0.685\n",
      "[epoch 9 Iteration 288/960] TRAIN loss:  0.704\n",
      "[epoch 9 Iteration 289/960] TRAIN loss:  0.606\n",
      "[epoch 9 Iteration 290/960] TRAIN loss:  0.720\n",
      "[epoch 9 Iteration 291/960] TRAIN loss:  0.527\n",
      "[epoch 9 Iteration 292/960] TRAIN loss:  0.413\n",
      "[epoch 9 Iteration 293/960] TRAIN loss:  0.734\n",
      "[epoch 9 Iteration 294/960] TRAIN loss:  0.789\n",
      "[epoch 9 Iteration 295/960] TRAIN loss:  0.590\n",
      "[epoch 9 Iteration 296/960] TRAIN loss:  0.690\n",
      "[epoch 9 Iteration 297/960] TRAIN loss:  0.897\n",
      "[epoch 9 Iteration 298/960] TRAIN loss:  1.000\n",
      "[epoch 9 Iteration 299/960] TRAIN loss:  0.686\n",
      "[epoch 9 Iteration 300/960] TRAIN loss:  0.770\n",
      "[epoch 9 Iteration 301/960] TRAIN loss:  0.591\n",
      "[epoch 9 Iteration 302/960] TRAIN loss:  0.610\n",
      "[epoch 9 Iteration 303/960] TRAIN loss:  0.874\n",
      "[epoch 9 Iteration 304/960] TRAIN loss:  0.763\n",
      "[epoch 9 Iteration 305/960] TRAIN loss:  0.685\n",
      "[epoch 9 Iteration 306/960] TRAIN loss:  0.573\n",
      "[epoch 9 Iteration 307/960] TRAIN loss:  0.813\n",
      "[epoch 9 Iteration 308/960] TRAIN loss:  0.659\n",
      "[epoch 9 Iteration 309/960] TRAIN loss:  0.675\n",
      "[epoch 9 Iteration 310/960] TRAIN loss:  0.682\n",
      "[epoch 9 Iteration 311/960] TRAIN loss:  0.862\n",
      "[epoch 9 Iteration 312/960] TRAIN loss:  1.138\n",
      "[epoch 9 Iteration 313/960] TRAIN loss:  0.994\n",
      "[epoch 9 Iteration 314/960] TRAIN loss:  0.976\n",
      "[epoch 9 Iteration 315/960] TRAIN loss:  0.801\n",
      "[epoch 9 Iteration 316/960] TRAIN loss:  0.769\n",
      "[epoch 9 Iteration 317/960] TRAIN loss:  0.710\n",
      "[epoch 9 Iteration 318/960] TRAIN loss:  0.830\n",
      "[epoch 9 Iteration 319/960] TRAIN loss:  0.792\n",
      "[epoch 9 Iteration 320/960] TRAIN loss:  0.752\n",
      "[epoch 9 Iteration 321/960] TRAIN loss:  0.614\n",
      "[epoch 9 Iteration 322/960] TRAIN loss:  0.866\n",
      "[epoch 9 Iteration 323/960] TRAIN loss:  0.881\n",
      "[epoch 9 Iteration 324/960] TRAIN loss:  0.609\n",
      "[epoch 9 Iteration 325/960] TRAIN loss:  0.730\n",
      "[epoch 9 Iteration 326/960] TRAIN loss:  0.693\n",
      "[epoch 9 Iteration 327/960] TRAIN loss:  0.566\n",
      "[epoch 9 Iteration 328/960] TRAIN loss:  0.641\n",
      "[epoch 9 Iteration 329/960] TRAIN loss:  0.650\n",
      "[epoch 9 Iteration 330/960] TRAIN loss:  0.758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9 Iteration 331/960] TRAIN loss:  0.617\n",
      "[epoch 9 Iteration 332/960] TRAIN loss:  0.591\n",
      "[epoch 9 Iteration 333/960] TRAIN loss:  0.747\n",
      "[epoch 9 Iteration 334/960] TRAIN loss:  0.835\n",
      "[epoch 9 Iteration 335/960] TRAIN loss:  0.895\n",
      "[epoch 9 Iteration 336/960] TRAIN loss:  0.641\n",
      "[epoch 9 Iteration 337/960] TRAIN loss:  0.796\n",
      "[epoch 9 Iteration 338/960] TRAIN loss:  0.513\n",
      "[epoch 9 Iteration 339/960] TRAIN loss:  0.749\n",
      "[epoch 9 Iteration 340/960] TRAIN loss:  1.063\n",
      "[epoch 9 Iteration 341/960] TRAIN loss:  0.570\n",
      "[epoch 9 Iteration 342/960] TRAIN loss:  0.537\n",
      "[epoch 9 Iteration 343/960] TRAIN loss:  0.905\n",
      "[epoch 9 Iteration 344/960] TRAIN loss:  0.653\n",
      "[epoch 9 Iteration 345/960] TRAIN loss:  0.644\n",
      "[epoch 9 Iteration 346/960] TRAIN loss:  0.522\n",
      "[epoch 9 Iteration 347/960] TRAIN loss:  1.054\n",
      "[epoch 9 Iteration 348/960] TRAIN loss:  0.672\n",
      "[epoch 9 Iteration 349/960] TRAIN loss:  0.746\n",
      "[epoch 9 Iteration 350/960] TRAIN loss:  0.915\n",
      "[epoch 9 Iteration 351/960] TRAIN loss:  0.517\n",
      "[epoch 9 Iteration 352/960] TRAIN loss:  0.781\n",
      "[epoch 9 Iteration 353/960] TRAIN loss:  0.642\n",
      "[epoch 9 Iteration 354/960] TRAIN loss:  0.883\n",
      "[epoch 9 Iteration 355/960] TRAIN loss:  0.733\n",
      "[epoch 9 Iteration 356/960] TRAIN loss:  0.947\n",
      "[epoch 9 Iteration 357/960] TRAIN loss:  0.679\n",
      "[epoch 9 Iteration 358/960] TRAIN loss:  0.731\n",
      "[epoch 9 Iteration 359/960] TRAIN loss:  0.683\n",
      "[epoch 9 Iteration 360/960] TRAIN loss:  0.485\n",
      "[epoch 9 Iteration 361/960] TRAIN loss:  0.847\n",
      "[epoch 9 Iteration 362/960] TRAIN loss:  0.612\n",
      "[epoch 9 Iteration 363/960] TRAIN loss:  0.572\n",
      "[epoch 9 Iteration 364/960] TRAIN loss:  1.041\n",
      "[epoch 9 Iteration 365/960] TRAIN loss:  0.752\n",
      "[epoch 9 Iteration 366/960] TRAIN loss:  1.018\n",
      "[epoch 9 Iteration 367/960] TRAIN loss:  0.473\n",
      "[epoch 9 Iteration 368/960] TRAIN loss:  0.801\n",
      "[epoch 9 Iteration 369/960] TRAIN loss:  0.562\n",
      "[epoch 9 Iteration 370/960] TRAIN loss:  0.777\n",
      "[epoch 9 Iteration 371/960] TRAIN loss:  0.810\n",
      "[epoch 9 Iteration 372/960] TRAIN loss:  0.897\n",
      "[epoch 9 Iteration 373/960] TRAIN loss:  0.674\n",
      "[epoch 9 Iteration 374/960] TRAIN loss:  0.620\n",
      "[epoch 9 Iteration 375/960] TRAIN loss:  0.917\n",
      "[epoch 9 Iteration 376/960] TRAIN loss:  0.925\n",
      "[epoch 9 Iteration 377/960] TRAIN loss:  0.836\n",
      "[epoch 9 Iteration 378/960] TRAIN loss:  0.814\n",
      "[epoch 9 Iteration 379/960] TRAIN loss:  0.515\n",
      "[epoch 9 Iteration 380/960] TRAIN loss:  0.614\n",
      "[epoch 9 Iteration 381/960] TRAIN loss:  0.722\n",
      "[epoch 9 Iteration 382/960] TRAIN loss:  0.859\n",
      "[epoch 9 Iteration 383/960] TRAIN loss:  0.938\n",
      "[epoch 9 Iteration 384/960] TRAIN loss:  0.578\n",
      "[epoch 9 Iteration 385/960] TRAIN loss:  0.812\n",
      "[epoch 9 Iteration 386/960] TRAIN loss:  0.918\n",
      "[epoch 9 Iteration 387/960] TRAIN loss:  0.998\n",
      "[epoch 9 Iteration 388/960] TRAIN loss:  0.845\n",
      "[epoch 9 Iteration 389/960] TRAIN loss:  0.628\n",
      "[epoch 9 Iteration 390/960] TRAIN loss:  0.759\n",
      "[epoch 9 Iteration 391/960] TRAIN loss:  0.988\n",
      "[epoch 9 Iteration 392/960] TRAIN loss:  0.772\n",
      "[epoch 9 Iteration 393/960] TRAIN loss:  0.819\n",
      "[epoch 9 Iteration 394/960] TRAIN loss:  0.643\n",
      "[epoch 9 Iteration 395/960] TRAIN loss:  0.974\n",
      "[epoch 9 Iteration 396/960] TRAIN loss:  0.928\n",
      "[epoch 9 Iteration 397/960] TRAIN loss:  0.910\n",
      "[epoch 9 Iteration 398/960] TRAIN loss:  0.750\n",
      "[epoch 9 Iteration 399/960] TRAIN loss:  0.660\n",
      "[epoch 9 Iteration 400/960] TRAIN loss:  1.006\n",
      "[epoch 9 Iteration 401/960] TRAIN loss:  0.968\n",
      "[epoch 9 Iteration 402/960] TRAIN loss:  0.801\n",
      "[epoch 9 Iteration 403/960] TRAIN loss:  1.042\n",
      "[epoch 9 Iteration 404/960] TRAIN loss:  0.931\n",
      "[epoch 9 Iteration 405/960] TRAIN loss:  0.515\n",
      "[epoch 9 Iteration 406/960] TRAIN loss:  0.693\n",
      "[epoch 9 Iteration 407/960] TRAIN loss:  0.601\n",
      "[epoch 9 Iteration 408/960] TRAIN loss:  1.386\n",
      "[epoch 9 Iteration 409/960] TRAIN loss:  1.070\n",
      "[epoch 9 Iteration 410/960] TRAIN loss:  0.680\n",
      "[epoch 9 Iteration 411/960] TRAIN loss:  0.809\n",
      "[epoch 9 Iteration 412/960] TRAIN loss:  0.513\n",
      "[epoch 9 Iteration 413/960] TRAIN loss:  0.777\n",
      "[epoch 9 Iteration 414/960] TRAIN loss:  0.641\n",
      "[epoch 9 Iteration 415/960] TRAIN loss:  0.719\n",
      "[epoch 9 Iteration 416/960] TRAIN loss:  0.866\n",
      "[epoch 9 Iteration 417/960] TRAIN loss:  0.871\n",
      "[epoch 9 Iteration 418/960] TRAIN loss:  0.810\n",
      "[epoch 9 Iteration 419/960] TRAIN loss:  0.878\n",
      "[epoch 9 Iteration 420/960] TRAIN loss:  0.821\n",
      "[epoch 9 Iteration 421/960] TRAIN loss:  0.883\n",
      "[epoch 9 Iteration 422/960] TRAIN loss:  0.691\n",
      "[epoch 9 Iteration 423/960] TRAIN loss:  0.994\n",
      "[epoch 9 Iteration 424/960] TRAIN loss:  0.511\n",
      "[epoch 9 Iteration 425/960] TRAIN loss:  0.840\n",
      "[epoch 9 Iteration 426/960] TRAIN loss:  0.828\n",
      "[epoch 9 Iteration 427/960] TRAIN loss:  0.801\n",
      "[epoch 9 Iteration 428/960] TRAIN loss:  0.579\n",
      "[epoch 9 Iteration 429/960] TRAIN loss:  1.069\n",
      "[epoch 9 Iteration 430/960] TRAIN loss:  0.601\n",
      "[epoch 9 Iteration 431/960] TRAIN loss:  0.829\n",
      "[epoch 9 Iteration 432/960] TRAIN loss:  0.825\n",
      "[epoch 9 Iteration 433/960] TRAIN loss:  0.769\n",
      "[epoch 9 Iteration 434/960] TRAIN loss:  0.885\n",
      "[epoch 9 Iteration 435/960] TRAIN loss:  0.738\n",
      "[epoch 9 Iteration 436/960] TRAIN loss:  0.817\n",
      "[epoch 9 Iteration 437/960] TRAIN loss:  0.774\n",
      "[epoch 9 Iteration 438/960] TRAIN loss:  0.626\n",
      "[epoch 9 Iteration 439/960] TRAIN loss:  0.783\n",
      "[epoch 9 Iteration 440/960] TRAIN loss:  0.751\n",
      "[epoch 9 Iteration 441/960] TRAIN loss:  0.711\n",
      "[epoch 9 Iteration 442/960] TRAIN loss:  0.553\n",
      "[epoch 9 Iteration 443/960] TRAIN loss:  0.713\n",
      "[epoch 9 Iteration 444/960] TRAIN loss:  0.808\n",
      "[epoch 9 Iteration 445/960] TRAIN loss:  0.761\n",
      "[epoch 9 Iteration 446/960] TRAIN loss:  0.970\n",
      "[epoch 9 Iteration 447/960] TRAIN loss:  0.470\n",
      "[epoch 9 Iteration 448/960] TRAIN loss:  0.926\n",
      "[epoch 9 Iteration 449/960] TRAIN loss:  0.712\n",
      "[epoch 9 Iteration 450/960] TRAIN loss:  0.751\n",
      "[epoch 9 Iteration 451/960] TRAIN loss:  0.772\n",
      "[epoch 9 Iteration 452/960] TRAIN loss:  0.629\n",
      "[epoch 9 Iteration 453/960] TRAIN loss:  0.741\n",
      "[epoch 9 Iteration 454/960] TRAIN loss:  0.744\n",
      "[epoch 9 Iteration 455/960] TRAIN loss:  0.757\n",
      "[epoch 9 Iteration 456/960] TRAIN loss:  0.672\n",
      "[epoch 9 Iteration 457/960] TRAIN loss:  0.731\n",
      "[epoch 9 Iteration 458/960] TRAIN loss:  0.519\n",
      "[epoch 9 Iteration 459/960] TRAIN loss:  0.817\n",
      "[epoch 9 Iteration 460/960] TRAIN loss:  0.540\n",
      "[epoch 9 Iteration 461/960] TRAIN loss:  0.685\n",
      "[epoch 9 Iteration 462/960] TRAIN loss:  0.939\n",
      "[epoch 9 Iteration 463/960] TRAIN loss:  0.503\n",
      "[epoch 9 Iteration 464/960] TRAIN loss:  0.952\n",
      "[epoch 9 Iteration 465/960] TRAIN loss:  0.563\n",
      "[epoch 9 Iteration 466/960] TRAIN loss:  0.720\n",
      "[epoch 9 Iteration 467/960] TRAIN loss:  0.643\n",
      "[epoch 9 Iteration 468/960] TRAIN loss:  0.823\n",
      "[epoch 9 Iteration 469/960] TRAIN loss:  0.766\n",
      "[epoch 9 Iteration 470/960] TRAIN loss:  0.825\n",
      "[epoch 9 Iteration 471/960] TRAIN loss:  1.036\n",
      "[epoch 9 Iteration 472/960] TRAIN loss:  0.667\n",
      "[epoch 9 Iteration 473/960] TRAIN loss:  0.898\n",
      "[epoch 9 Iteration 474/960] TRAIN loss:  0.822\n",
      "[epoch 9 Iteration 475/960] TRAIN loss:  0.619\n",
      "[epoch 9 Iteration 476/960] TRAIN loss:  0.937\n",
      "[epoch 9 Iteration 477/960] TRAIN loss:  0.677\n",
      "[epoch 9 Iteration 478/960] TRAIN loss:  0.427\n",
      "[epoch 9 Iteration 479/960] TRAIN loss:  0.509\n",
      "[epoch 9 Iteration 480/960] TRAIN loss:  0.786\n",
      "[epoch 9 Iteration 481/960] TRAIN loss:  0.659\n",
      "[epoch 9 Iteration 482/960] TRAIN loss:  0.770\n",
      "[epoch 9 Iteration 483/960] TRAIN loss:  1.032\n",
      "[epoch 9 Iteration 484/960] TRAIN loss:  0.692\n",
      "[epoch 9 Iteration 485/960] TRAIN loss:  0.888\n",
      "[epoch 9 Iteration 486/960] TRAIN loss:  0.877\n",
      "[epoch 9 Iteration 487/960] TRAIN loss:  0.740\n",
      "[epoch 9 Iteration 488/960] TRAIN loss:  0.539\n",
      "[epoch 9 Iteration 489/960] TRAIN loss:  0.550\n",
      "[epoch 9 Iteration 490/960] TRAIN loss:  0.531\n",
      "[epoch 9 Iteration 491/960] TRAIN loss:  0.703\n",
      "[epoch 9 Iteration 492/960] TRAIN loss:  0.564\n",
      "[epoch 9 Iteration 493/960] TRAIN loss:  0.868\n",
      "[epoch 9 Iteration 494/960] TRAIN loss:  0.767\n",
      "[epoch 9 Iteration 495/960] TRAIN loss:  0.785\n",
      "[epoch 9 Iteration 496/960] TRAIN loss:  0.623\n",
      "[epoch 9 Iteration 497/960] TRAIN loss:  0.795\n",
      "[epoch 9 Iteration 498/960] TRAIN loss:  0.697\n",
      "[epoch 9 Iteration 499/960] TRAIN loss:  0.842\n",
      "[epoch 9 Iteration 500/960] TRAIN loss:  0.518\n",
      "[epoch 9 Iteration 501/960] TRAIN loss:  0.881\n",
      "[epoch 9 Iteration 502/960] TRAIN loss:  1.144\n",
      "[epoch 9 Iteration 503/960] TRAIN loss:  0.973\n",
      "[epoch 9 Iteration 504/960] TRAIN loss:  0.839\n",
      "[epoch 9 Iteration 505/960] TRAIN loss:  0.900\n",
      "[epoch 9 Iteration 506/960] TRAIN loss:  0.807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9 Iteration 507/960] TRAIN loss:  0.485\n",
      "[epoch 9 Iteration 508/960] TRAIN loss:  0.874\n",
      "[epoch 9 Iteration 509/960] TRAIN loss:  0.482\n",
      "[epoch 9 Iteration 510/960] TRAIN loss:  0.690\n",
      "[epoch 9 Iteration 511/960] TRAIN loss:  0.719\n",
      "[epoch 9 Iteration 512/960] TRAIN loss:  0.713\n",
      "[epoch 9 Iteration 513/960] TRAIN loss:  0.680\n",
      "[epoch 9 Iteration 514/960] TRAIN loss:  0.597\n",
      "[epoch 9 Iteration 515/960] TRAIN loss:  1.058\n",
      "[epoch 9 Iteration 516/960] TRAIN loss:  0.753\n",
      "[epoch 9 Iteration 517/960] TRAIN loss:  0.726\n",
      "[epoch 9 Iteration 518/960] TRAIN loss:  0.814\n",
      "[epoch 9 Iteration 519/960] TRAIN loss:  0.796\n",
      "[epoch 9 Iteration 520/960] TRAIN loss:  0.753\n",
      "[epoch 9 Iteration 521/960] TRAIN loss:  0.604\n",
      "[epoch 9 Iteration 522/960] TRAIN loss:  0.629\n",
      "[epoch 9 Iteration 523/960] TRAIN loss:  0.911\n",
      "[epoch 9 Iteration 524/960] TRAIN loss:  0.766\n",
      "[epoch 9 Iteration 525/960] TRAIN loss:  0.673\n",
      "[epoch 9 Iteration 526/960] TRAIN loss:  0.532\n",
      "[epoch 9 Iteration 527/960] TRAIN loss:  0.682\n",
      "[epoch 9 Iteration 528/960] TRAIN loss:  0.750\n",
      "[epoch 9 Iteration 529/960] TRAIN loss:  0.422\n",
      "[epoch 9 Iteration 530/960] TRAIN loss:  0.695\n",
      "[epoch 9 Iteration 531/960] TRAIN loss:  0.842\n",
      "[epoch 9 Iteration 532/960] TRAIN loss:  0.900\n",
      "[epoch 9 Iteration 533/960] TRAIN loss:  0.969\n",
      "[epoch 9 Iteration 534/960] TRAIN loss:  0.686\n",
      "[epoch 9 Iteration 535/960] TRAIN loss:  0.626\n",
      "[epoch 9 Iteration 536/960] TRAIN loss:  0.745\n",
      "[epoch 9 Iteration 537/960] TRAIN loss:  0.831\n",
      "[epoch 9 Iteration 538/960] TRAIN loss:  0.612\n",
      "[epoch 9 Iteration 539/960] TRAIN loss:  0.727\n",
      "[epoch 9 Iteration 540/960] TRAIN loss:  0.639\n",
      "[epoch 9 Iteration 541/960] TRAIN loss:  0.975\n",
      "[epoch 9 Iteration 542/960] TRAIN loss:  0.896\n",
      "[epoch 9 Iteration 543/960] TRAIN loss:  0.651\n",
      "[epoch 9 Iteration 544/960] TRAIN loss:  0.815\n",
      "[epoch 9 Iteration 545/960] TRAIN loss:  0.708\n",
      "[epoch 9 Iteration 546/960] TRAIN loss:  0.733\n",
      "[epoch 9 Iteration 547/960] TRAIN loss:  0.723\n",
      "[epoch 9 Iteration 548/960] TRAIN loss:  0.487\n",
      "[epoch 9 Iteration 549/960] TRAIN loss:  0.868\n",
      "[epoch 9 Iteration 550/960] TRAIN loss:  0.792\n",
      "[epoch 9 Iteration 551/960] TRAIN loss:  0.953\n",
      "[epoch 9 Iteration 552/960] TRAIN loss:  0.716\n",
      "[epoch 9 Iteration 553/960] TRAIN loss:  0.695\n",
      "[epoch 9 Iteration 554/960] TRAIN loss:  0.588\n",
      "[epoch 9 Iteration 555/960] TRAIN loss:  0.603\n",
      "[epoch 9 Iteration 556/960] TRAIN loss:  0.487\n",
      "[epoch 9 Iteration 557/960] TRAIN loss:  0.881\n",
      "[epoch 9 Iteration 558/960] TRAIN loss:  0.696\n",
      "[epoch 9 Iteration 559/960] TRAIN loss:  0.649\n",
      "[epoch 9 Iteration 560/960] TRAIN loss:  0.640\n",
      "[epoch 9 Iteration 561/960] TRAIN loss:  0.732\n",
      "[epoch 9 Iteration 562/960] TRAIN loss:  0.820\n",
      "[epoch 9 Iteration 563/960] TRAIN loss:  0.565\n",
      "[epoch 9 Iteration 564/960] TRAIN loss:  0.712\n",
      "[epoch 9 Iteration 565/960] TRAIN loss:  0.860\n",
      "[epoch 9 Iteration 566/960] TRAIN loss:  0.742\n",
      "[epoch 9 Iteration 567/960] TRAIN loss:  0.748\n",
      "[epoch 9 Iteration 568/960] TRAIN loss:  0.921\n",
      "[epoch 9 Iteration 569/960] TRAIN loss:  0.757\n",
      "[epoch 9 Iteration 570/960] TRAIN loss:  0.825\n",
      "[epoch 9 Iteration 571/960] TRAIN loss:  0.562\n",
      "[epoch 9 Iteration 572/960] TRAIN loss:  0.676\n",
      "[epoch 9 Iteration 573/960] TRAIN loss:  0.944\n",
      "[epoch 9 Iteration 574/960] TRAIN loss:  0.720\n",
      "[epoch 9 Iteration 575/960] TRAIN loss:  0.778\n",
      "[epoch 9 Iteration 576/960] TRAIN loss:  0.715\n",
      "[epoch 9 Iteration 577/960] TRAIN loss:  0.799\n",
      "[epoch 9 Iteration 578/960] TRAIN loss:  0.637\n",
      "[epoch 9 Iteration 579/960] TRAIN loss:  0.799\n",
      "[epoch 9 Iteration 580/960] TRAIN loss:  0.867\n",
      "[epoch 9 Iteration 581/960] TRAIN loss:  0.826\n",
      "[epoch 9 Iteration 582/960] TRAIN loss:  0.686\n",
      "[epoch 9 Iteration 583/960] TRAIN loss:  0.640\n",
      "[epoch 9 Iteration 584/960] TRAIN loss:  0.454\n",
      "[epoch 9 Iteration 585/960] TRAIN loss:  0.764\n",
      "[epoch 9 Iteration 586/960] TRAIN loss:  0.572\n",
      "[epoch 9 Iteration 587/960] TRAIN loss:  0.780\n",
      "[epoch 9 Iteration 588/960] TRAIN loss:  0.808\n",
      "[epoch 9 Iteration 589/960] TRAIN loss:  0.962\n",
      "[epoch 9 Iteration 590/960] TRAIN loss:  0.837\n",
      "[epoch 9 Iteration 591/960] TRAIN loss:  0.488\n",
      "[epoch 9 Iteration 592/960] TRAIN loss:  0.664\n",
      "[epoch 9 Iteration 593/960] TRAIN loss:  0.813\n",
      "[epoch 9 Iteration 594/960] TRAIN loss:  0.738\n",
      "[epoch 9 Iteration 595/960] TRAIN loss:  0.739\n",
      "[epoch 9 Iteration 596/960] TRAIN loss:  0.697\n",
      "[epoch 9 Iteration 597/960] TRAIN loss:  0.703\n",
      "[epoch 9 Iteration 598/960] TRAIN loss:  0.918\n",
      "[epoch 9 Iteration 599/960] TRAIN loss:  0.668\n",
      "[epoch 9 Iteration 600/960] TRAIN loss:  0.811\n",
      "[epoch 9 Iteration 601/960] TRAIN loss:  1.018\n",
      "[epoch 9 Iteration 602/960] TRAIN loss:  0.996\n",
      "[epoch 9 Iteration 603/960] TRAIN loss:  0.742\n",
      "[epoch 9 Iteration 604/960] TRAIN loss:  0.873\n",
      "[epoch 9 Iteration 605/960] TRAIN loss:  0.858\n",
      "[epoch 9 Iteration 606/960] TRAIN loss:  0.417\n",
      "[epoch 9 Iteration 607/960] TRAIN loss:  0.647\n",
      "[epoch 9 Iteration 608/960] TRAIN loss:  0.458\n",
      "[epoch 9 Iteration 609/960] TRAIN loss:  0.706\n",
      "[epoch 9 Iteration 610/960] TRAIN loss:  0.828\n",
      "[epoch 9 Iteration 611/960] TRAIN loss:  0.666\n",
      "[epoch 9 Iteration 612/960] TRAIN loss:  0.671\n",
      "[epoch 9 Iteration 613/960] TRAIN loss:  0.650\n",
      "[epoch 9 Iteration 614/960] TRAIN loss:  0.609\n",
      "[epoch 9 Iteration 615/960] TRAIN loss:  0.857\n",
      "[epoch 9 Iteration 616/960] TRAIN loss:  0.406\n",
      "[epoch 9 Iteration 617/960] TRAIN loss:  0.857\n",
      "[epoch 9 Iteration 618/960] TRAIN loss:  0.728\n",
      "[epoch 9 Iteration 619/960] TRAIN loss:  0.670\n",
      "[epoch 9 Iteration 620/960] TRAIN loss:  0.580\n",
      "[epoch 9 Iteration 621/960] TRAIN loss:  0.751\n",
      "[epoch 9 Iteration 622/960] TRAIN loss:  0.489\n",
      "[epoch 9 Iteration 623/960] TRAIN loss:  0.586\n",
      "[epoch 9 Iteration 624/960] TRAIN loss:  0.745\n",
      "[epoch 9 Iteration 625/960] TRAIN loss:  0.847\n",
      "[epoch 9 Iteration 626/960] TRAIN loss:  0.766\n",
      "[epoch 9 Iteration 627/960] TRAIN loss:  0.767\n",
      "[epoch 9 Iteration 628/960] TRAIN loss:  0.876\n",
      "[epoch 9 Iteration 629/960] TRAIN loss:  0.514\n",
      "[epoch 9 Iteration 630/960] TRAIN loss:  0.843\n",
      "[epoch 9 Iteration 631/960] TRAIN loss:  0.718\n",
      "[epoch 9 Iteration 632/960] TRAIN loss:  0.631\n",
      "[epoch 9 Iteration 633/960] TRAIN loss:  0.636\n",
      "[epoch 9 Iteration 634/960] TRAIN loss:  0.610\n",
      "[epoch 9 Iteration 635/960] TRAIN loss:  0.839\n",
      "[epoch 9 Iteration 636/960] TRAIN loss:  0.532\n",
      "[epoch 9 Iteration 637/960] TRAIN loss:  0.616\n",
      "[epoch 9 Iteration 638/960] TRAIN loss:  0.767\n",
      "[epoch 9 Iteration 639/960] TRAIN loss:  0.625\n",
      "[epoch 9 Iteration 640/960] TRAIN loss:  0.748\n",
      "[epoch 9 Iteration 641/960] TRAIN loss:  0.550\n",
      "[epoch 9 Iteration 642/960] TRAIN loss:  0.632\n",
      "[epoch 9 Iteration 643/960] TRAIN loss:  0.637\n",
      "[epoch 9 Iteration 644/960] TRAIN loss:  0.500\n",
      "[epoch 9 Iteration 645/960] TRAIN loss:  0.933\n",
      "[epoch 9 Iteration 646/960] TRAIN loss:  0.556\n",
      "[epoch 9 Iteration 647/960] TRAIN loss:  0.508\n",
      "[epoch 9 Iteration 648/960] TRAIN loss:  0.641\n",
      "[epoch 9 Iteration 649/960] TRAIN loss:  1.008\n",
      "[epoch 9 Iteration 650/960] TRAIN loss:  0.851\n",
      "[epoch 9 Iteration 651/960] TRAIN loss:  0.757\n",
      "[epoch 9 Iteration 652/960] TRAIN loss:  0.891\n",
      "[epoch 9 Iteration 653/960] TRAIN loss:  0.768\n",
      "[epoch 9 Iteration 654/960] TRAIN loss:  0.587\n",
      "[epoch 9 Iteration 655/960] TRAIN loss:  0.646\n",
      "[epoch 9 Iteration 656/960] TRAIN loss:  0.725\n",
      "[epoch 9 Iteration 657/960] TRAIN loss:  0.594\n",
      "[epoch 9 Iteration 658/960] TRAIN loss:  0.805\n",
      "[epoch 9 Iteration 659/960] TRAIN loss:  0.850\n",
      "[epoch 9 Iteration 660/960] TRAIN loss:  0.881\n",
      "[epoch 9 Iteration 661/960] TRAIN loss:  0.996\n",
      "[epoch 9 Iteration 662/960] TRAIN loss:  0.588\n",
      "[epoch 9 Iteration 663/960] TRAIN loss:  0.557\n",
      "[epoch 9 Iteration 664/960] TRAIN loss:  0.734\n",
      "[epoch 9 Iteration 665/960] TRAIN loss:  0.690\n",
      "[epoch 9 Iteration 666/960] TRAIN loss:  0.719\n",
      "[epoch 9 Iteration 667/960] TRAIN loss:  0.881\n",
      "[epoch 9 Iteration 668/960] TRAIN loss:  0.793\n",
      "[epoch 9 Iteration 669/960] TRAIN loss:  0.706\n",
      "[epoch 9 Iteration 670/960] TRAIN loss:  0.710\n",
      "[epoch 9 Iteration 671/960] TRAIN loss:  0.685\n",
      "[epoch 9 Iteration 672/960] TRAIN loss:  0.842\n",
      "[epoch 9 Iteration 673/960] TRAIN loss:  0.679\n",
      "[epoch 9 Iteration 674/960] TRAIN loss:  0.804\n",
      "[epoch 9 Iteration 675/960] TRAIN loss:  0.510\n",
      "[epoch 9 Iteration 676/960] TRAIN loss:  0.940\n",
      "[epoch 9 Iteration 677/960] TRAIN loss:  0.703\n",
      "[epoch 9 Iteration 678/960] TRAIN loss:  0.759\n",
      "[epoch 9 Iteration 679/960] TRAIN loss:  0.774\n",
      "[epoch 9 Iteration 680/960] TRAIN loss:  0.966\n",
      "[epoch 9 Iteration 681/960] TRAIN loss:  1.065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9 Iteration 682/960] TRAIN loss:  0.758\n",
      "[epoch 9 Iteration 683/960] TRAIN loss:  0.696\n",
      "[epoch 9 Iteration 684/960] TRAIN loss:  0.847\n",
      "[epoch 9 Iteration 685/960] TRAIN loss:  0.729\n",
      "[epoch 9 Iteration 686/960] TRAIN loss:  0.972\n",
      "[epoch 9 Iteration 687/960] TRAIN loss:  0.738\n",
      "[epoch 9 Iteration 688/960] TRAIN loss:  0.714\n",
      "[epoch 9 Iteration 689/960] TRAIN loss:  0.511\n",
      "[epoch 9 Iteration 690/960] TRAIN loss:  0.518\n",
      "[epoch 9 Iteration 691/960] TRAIN loss:  0.766\n",
      "[epoch 9 Iteration 692/960] TRAIN loss:  0.770\n",
      "[epoch 9 Iteration 693/960] TRAIN loss:  0.887\n",
      "[epoch 9 Iteration 694/960] TRAIN loss:  0.738\n",
      "[epoch 9 Iteration 695/960] TRAIN loss:  0.812\n",
      "[epoch 9 Iteration 696/960] TRAIN loss:  0.905\n",
      "[epoch 9 Iteration 697/960] TRAIN loss:  0.808\n",
      "[epoch 9 Iteration 698/960] TRAIN loss:  0.702\n",
      "[epoch 9 Iteration 699/960] TRAIN loss:  0.940\n",
      "[epoch 9 Iteration 700/960] TRAIN loss:  0.638\n",
      "[epoch 9 Iteration 701/960] TRAIN loss:  0.929\n",
      "[epoch 9 Iteration 702/960] TRAIN loss:  0.770\n",
      "[epoch 9 Iteration 703/960] TRAIN loss:  0.775\n",
      "[epoch 9 Iteration 704/960] TRAIN loss:  0.757\n",
      "[epoch 9 Iteration 705/960] TRAIN loss:  0.692\n",
      "[epoch 9 Iteration 706/960] TRAIN loss:  0.712\n",
      "[epoch 9 Iteration 707/960] TRAIN loss:  0.778\n",
      "[epoch 9 Iteration 708/960] TRAIN loss:  0.817\n",
      "[epoch 9 Iteration 709/960] TRAIN loss:  0.686\n",
      "[epoch 9 Iteration 710/960] TRAIN loss:  0.974\n",
      "[epoch 9 Iteration 711/960] TRAIN loss:  0.886\n",
      "[epoch 9 Iteration 712/960] TRAIN loss:  0.806\n",
      "[epoch 9 Iteration 713/960] TRAIN loss:  0.782\n",
      "[epoch 9 Iteration 714/960] TRAIN loss:  0.738\n",
      "[epoch 9 Iteration 715/960] TRAIN loss:  0.952\n",
      "[epoch 9 Iteration 716/960] TRAIN loss:  0.618\n",
      "[epoch 9 Iteration 717/960] TRAIN loss:  0.651\n",
      "[epoch 9 Iteration 718/960] TRAIN loss:  0.749\n",
      "[epoch 9 Iteration 719/960] TRAIN loss:  0.719\n",
      "[epoch 9 Iteration 720/960] TRAIN loss:  1.007\n",
      "[epoch 9 Iteration 721/960] TRAIN loss:  0.809\n",
      "[epoch 9 Iteration 722/960] TRAIN loss:  0.807\n",
      "[epoch 9 Iteration 723/960] TRAIN loss:  0.614\n",
      "[epoch 9 Iteration 724/960] TRAIN loss:  0.665\n",
      "[epoch 9 Iteration 725/960] TRAIN loss:  0.915\n",
      "[epoch 9 Iteration 726/960] TRAIN loss:  0.546\n",
      "[epoch 9 Iteration 727/960] TRAIN loss:  0.699\n",
      "[epoch 9 Iteration 728/960] TRAIN loss:  0.713\n",
      "[epoch 9 Iteration 729/960] TRAIN loss:  0.692\n",
      "[epoch 9 Iteration 730/960] TRAIN loss:  0.552\n",
      "[epoch 9 Iteration 731/960] TRAIN loss:  0.822\n",
      "[epoch 9 Iteration 732/960] TRAIN loss:  0.855\n",
      "[epoch 9 Iteration 733/960] TRAIN loss:  0.549\n",
      "[epoch 9 Iteration 734/960] TRAIN loss:  0.465\n",
      "[epoch 9 Iteration 735/960] TRAIN loss:  0.722\n",
      "[epoch 9 Iteration 736/960] TRAIN loss:  0.843\n",
      "[epoch 9 Iteration 737/960] TRAIN loss:  0.683\n",
      "[epoch 9 Iteration 738/960] TRAIN loss:  0.647\n",
      "[epoch 9 Iteration 739/960] TRAIN loss:  0.572\n",
      "[epoch 9 Iteration 740/960] TRAIN loss:  0.607\n",
      "[epoch 9 Iteration 741/960] TRAIN loss:  0.438\n",
      "[epoch 9 Iteration 742/960] TRAIN loss:  0.755\n",
      "[epoch 9 Iteration 743/960] TRAIN loss:  0.684\n",
      "[epoch 9 Iteration 744/960] TRAIN loss:  0.554\n",
      "[epoch 9 Iteration 745/960] TRAIN loss:  0.764\n",
      "[epoch 9 Iteration 746/960] TRAIN loss:  0.682\n",
      "[epoch 9 Iteration 747/960] TRAIN loss:  0.682\n",
      "[epoch 9 Iteration 748/960] TRAIN loss:  0.966\n",
      "[epoch 9 Iteration 749/960] TRAIN loss:  0.746\n",
      "[epoch 9 Iteration 750/960] TRAIN loss:  0.631\n",
      "[epoch 9 Iteration 751/960] TRAIN loss:  0.891\n",
      "[epoch 9 Iteration 752/960] TRAIN loss:  0.519\n",
      "[epoch 9 Iteration 753/960] TRAIN loss:  0.622\n",
      "[epoch 9 Iteration 754/960] TRAIN loss:  0.668\n",
      "[epoch 9 Iteration 755/960] TRAIN loss:  0.620\n",
      "[epoch 9 Iteration 756/960] TRAIN loss:  0.570\n",
      "[epoch 9 Iteration 757/960] TRAIN loss:  1.115\n",
      "[epoch 9 Iteration 758/960] TRAIN loss:  0.998\n",
      "[epoch 9 Iteration 759/960] TRAIN loss:  0.618\n",
      "[epoch 9 Iteration 760/960] TRAIN loss:  0.875\n",
      "[epoch 9 Iteration 761/960] TRAIN loss:  1.006\n",
      "[epoch 9 Iteration 762/960] TRAIN loss:  0.612\n",
      "[epoch 9 Iteration 763/960] TRAIN loss:  0.903\n",
      "[epoch 9 Iteration 764/960] TRAIN loss:  0.853\n",
      "[epoch 9 Iteration 765/960] TRAIN loss:  1.036\n",
      "[epoch 9 Iteration 766/960] TRAIN loss:  0.763\n",
      "[epoch 9 Iteration 767/960] TRAIN loss:  0.776\n",
      "[epoch 9 Iteration 768/960] TRAIN loss:  0.950\n",
      "[epoch 9 Iteration 769/960] TRAIN loss:  0.645\n",
      "[epoch 9 Iteration 770/960] TRAIN loss:  0.672\n",
      "[epoch 9 Iteration 771/960] TRAIN loss:  0.720\n",
      "[epoch 9 Iteration 772/960] TRAIN loss:  0.747\n",
      "[epoch 9 Iteration 773/960] TRAIN loss:  0.671\n",
      "[epoch 9 Iteration 774/960] TRAIN loss:  0.713\n",
      "[epoch 9 Iteration 775/960] TRAIN loss:  0.902\n",
      "[epoch 9 Iteration 776/960] TRAIN loss:  0.795\n",
      "[epoch 9 Iteration 777/960] TRAIN loss:  1.006\n",
      "[epoch 9 Iteration 778/960] TRAIN loss:  0.878\n",
      "[epoch 9 Iteration 779/960] TRAIN loss:  0.964\n",
      "[epoch 9 Iteration 780/960] TRAIN loss:  0.810\n",
      "[epoch 9 Iteration 781/960] TRAIN loss:  0.775\n",
      "[epoch 9 Iteration 782/960] TRAIN loss:  0.548\n",
      "[epoch 9 Iteration 783/960] TRAIN loss:  0.623\n",
      "[epoch 9 Iteration 784/960] TRAIN loss:  0.581\n",
      "[epoch 9 Iteration 785/960] TRAIN loss:  0.891\n",
      "[epoch 9 Iteration 786/960] TRAIN loss:  1.057\n",
      "[epoch 9 Iteration 787/960] TRAIN loss:  0.701\n",
      "[epoch 9 Iteration 788/960] TRAIN loss:  0.585\n",
      "[epoch 9 Iteration 789/960] TRAIN loss:  1.005\n",
      "[epoch 9 Iteration 790/960] TRAIN loss:  0.802\n",
      "[epoch 9 Iteration 791/960] TRAIN loss:  0.634\n",
      "[epoch 9 Iteration 792/960] TRAIN loss:  1.014\n",
      "[epoch 9 Iteration 793/960] TRAIN loss:  0.868\n",
      "[epoch 9 Iteration 794/960] TRAIN loss:  0.837\n",
      "[epoch 9 Iteration 795/960] TRAIN loss:  0.970\n",
      "[epoch 9 Iteration 796/960] TRAIN loss:  0.631\n",
      "[epoch 9 Iteration 797/960] TRAIN loss:  0.974\n",
      "[epoch 9 Iteration 798/960] TRAIN loss:  0.548\n",
      "[epoch 9 Iteration 799/960] TRAIN loss:  0.750\n",
      "[epoch 9 Iteration 800/960] TRAIN loss:  0.884\n",
      "[epoch 9 Iteration 801/960] TRAIN loss:  0.610\n",
      "[epoch 9 Iteration 802/960] TRAIN loss:  0.618\n",
      "[epoch 9 Iteration 803/960] TRAIN loss:  0.657\n",
      "[epoch 9 Iteration 804/960] TRAIN loss:  0.914\n",
      "[epoch 9 Iteration 805/960] TRAIN loss:  0.662\n",
      "[epoch 9 Iteration 806/960] TRAIN loss:  0.883\n",
      "[epoch 9 Iteration 807/960] TRAIN loss:  0.684\n",
      "[epoch 9 Iteration 808/960] TRAIN loss:  0.835\n",
      "[epoch 9 Iteration 809/960] TRAIN loss:  1.006\n",
      "[epoch 9 Iteration 810/960] TRAIN loss:  0.857\n",
      "[epoch 9 Iteration 811/960] TRAIN loss:  0.887\n",
      "[epoch 9 Iteration 812/960] TRAIN loss:  0.831\n",
      "[epoch 9 Iteration 813/960] TRAIN loss:  0.702\n",
      "[epoch 9 Iteration 814/960] TRAIN loss:  0.700\n",
      "[epoch 9 Iteration 815/960] TRAIN loss:  0.686\n",
      "[epoch 9 Iteration 816/960] TRAIN loss:  0.555\n",
      "[epoch 9 Iteration 817/960] TRAIN loss:  0.560\n",
      "[epoch 9 Iteration 818/960] TRAIN loss:  0.836\n",
      "[epoch 9 Iteration 819/960] TRAIN loss:  1.152\n",
      "[epoch 9 Iteration 820/960] TRAIN loss:  0.609\n",
      "[epoch 9 Iteration 821/960] TRAIN loss:  0.962\n",
      "[epoch 9 Iteration 822/960] TRAIN loss:  0.622\n",
      "[epoch 9 Iteration 823/960] TRAIN loss:  0.568\n",
      "[epoch 9 Iteration 824/960] TRAIN loss:  0.916\n",
      "[epoch 9 Iteration 825/960] TRAIN loss:  0.782\n",
      "[epoch 9 Iteration 826/960] TRAIN loss:  0.767\n",
      "[epoch 9 Iteration 827/960] TRAIN loss:  0.699\n",
      "[epoch 9 Iteration 828/960] TRAIN loss:  0.824\n",
      "[epoch 9 Iteration 829/960] TRAIN loss:  0.796\n",
      "[epoch 9 Iteration 830/960] TRAIN loss:  0.645\n",
      "[epoch 9 Iteration 831/960] TRAIN loss:  0.809\n",
      "[epoch 9 Iteration 832/960] TRAIN loss:  0.726\n",
      "[epoch 9 Iteration 833/960] TRAIN loss:  0.604\n",
      "[epoch 9 Iteration 834/960] TRAIN loss:  0.677\n",
      "[epoch 9 Iteration 835/960] TRAIN loss:  0.645\n",
      "[epoch 9 Iteration 836/960] TRAIN loss:  0.827\n",
      "[epoch 9 Iteration 837/960] TRAIN loss:  0.799\n",
      "[epoch 9 Iteration 838/960] TRAIN loss:  0.498\n",
      "[epoch 9 Iteration 839/960] TRAIN loss:  0.910\n",
      "[epoch 9 Iteration 840/960] TRAIN loss:  0.631\n",
      "[epoch 9 Iteration 841/960] TRAIN loss:  0.830\n",
      "[epoch 9 Iteration 842/960] TRAIN loss:  0.618\n",
      "[epoch 9 Iteration 843/960] TRAIN loss:  0.821\n",
      "[epoch 9 Iteration 844/960] TRAIN loss:  0.994\n",
      "[epoch 9 Iteration 845/960] TRAIN loss:  0.682\n",
      "[epoch 9 Iteration 846/960] TRAIN loss:  0.678\n",
      "[epoch 9 Iteration 847/960] TRAIN loss:  0.533\n",
      "[epoch 9 Iteration 848/960] TRAIN loss:  0.739\n",
      "[epoch 9 Iteration 849/960] TRAIN loss:  1.018\n",
      "[epoch 9 Iteration 850/960] TRAIN loss:  0.710\n",
      "[epoch 9 Iteration 851/960] TRAIN loss:  0.735\n",
      "[epoch 9 Iteration 852/960] TRAIN loss:  0.725\n",
      "[epoch 9 Iteration 853/960] TRAIN loss:  0.877\n",
      "[epoch 9 Iteration 854/960] TRAIN loss:  0.630\n",
      "[epoch 9 Iteration 855/960] TRAIN loss:  0.807\n",
      "[epoch 9 Iteration 856/960] TRAIN loss:  0.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 9 Iteration 857/960] TRAIN loss:  0.712\n",
      "[epoch 9 Iteration 858/960] TRAIN loss:  0.627\n",
      "[epoch 9 Iteration 859/960] TRAIN loss:  0.651\n",
      "[epoch 9 Iteration 860/960] TRAIN loss:  0.815\n",
      "[epoch 9 Iteration 861/960] TRAIN loss:  0.789\n",
      "[epoch 9 Iteration 862/960] TRAIN loss:  0.966\n",
      "[epoch 9 Iteration 863/960] TRAIN loss:  0.872\n",
      "[epoch 9 Iteration 864/960] TRAIN loss:  0.834\n",
      "[epoch 9 Iteration 865/960] TRAIN loss:  0.704\n",
      "[epoch 9 Iteration 866/960] TRAIN loss:  1.067\n",
      "[epoch 9 Iteration 867/960] TRAIN loss:  0.631\n",
      "[epoch 9 Iteration 868/960] TRAIN loss:  0.495\n",
      "[epoch 9 Iteration 869/960] TRAIN loss:  0.734\n",
      "[epoch 9 Iteration 870/960] TRAIN loss:  0.623\n",
      "[epoch 9 Iteration 871/960] TRAIN loss:  0.791\n",
      "[epoch 9 Iteration 872/960] TRAIN loss:  0.832\n",
      "[epoch 9 Iteration 873/960] TRAIN loss:  0.734\n",
      "[epoch 9 Iteration 874/960] TRAIN loss:  0.758\n",
      "[epoch 9 Iteration 875/960] TRAIN loss:  0.603\n",
      "[epoch 9 Iteration 876/960] TRAIN loss:  0.792\n",
      "[epoch 9 Iteration 877/960] TRAIN loss:  1.081\n",
      "[epoch 9 Iteration 878/960] TRAIN loss:  0.866\n",
      "[epoch 9 Iteration 879/960] TRAIN loss:  0.746\n",
      "[epoch 9 Iteration 880/960] TRAIN loss:  0.724\n",
      "[epoch 9 Iteration 881/960] TRAIN loss:  0.938\n",
      "[epoch 9 Iteration 882/960] TRAIN loss:  0.605\n",
      "[epoch 9 Iteration 883/960] TRAIN loss:  0.776\n",
      "[epoch 9 Iteration 884/960] TRAIN loss:  0.594\n",
      "[epoch 9 Iteration 885/960] TRAIN loss:  0.838\n",
      "[epoch 9 Iteration 886/960] TRAIN loss:  0.871\n",
      "[epoch 9 Iteration 887/960] TRAIN loss:  0.500\n",
      "[epoch 9 Iteration 888/960] TRAIN loss:  0.720\n",
      "[epoch 9 Iteration 889/960] TRAIN loss:  1.065\n",
      "[epoch 9 Iteration 890/960] TRAIN loss:  0.849\n",
      "[epoch 9 Iteration 891/960] TRAIN loss:  0.909\n",
      "[epoch 9 Iteration 892/960] TRAIN loss:  0.763\n",
      "[epoch 9 Iteration 893/960] TRAIN loss:  0.631\n",
      "[epoch 9 Iteration 894/960] TRAIN loss:  0.783\n",
      "[epoch 9 Iteration 895/960] TRAIN loss:  0.492\n",
      "[epoch 9 Iteration 896/960] TRAIN loss:  0.647\n",
      "[epoch 9 Iteration 897/960] TRAIN loss:  0.640\n",
      "[epoch 9 Iteration 898/960] TRAIN loss:  0.731\n",
      "[epoch 9 Iteration 899/960] TRAIN loss:  0.542\n",
      "[epoch 9 Iteration 900/960] TRAIN loss:  0.870\n",
      "[epoch 9 Iteration 901/960] TRAIN loss:  0.881\n",
      "[epoch 9 Iteration 902/960] TRAIN loss:  0.658\n",
      "[epoch 9 Iteration 903/960] TRAIN loss:  1.120\n",
      "[epoch 9 Iteration 904/960] TRAIN loss:  0.700\n",
      "[epoch 9 Iteration 905/960] TRAIN loss:  0.648\n",
      "[epoch 9 Iteration 906/960] TRAIN loss:  0.704\n",
      "[epoch 9 Iteration 907/960] TRAIN loss:  0.833\n",
      "[epoch 9 Iteration 908/960] TRAIN loss:  1.005\n",
      "[epoch 9 Iteration 909/960] TRAIN loss:  0.898\n",
      "[epoch 9 Iteration 910/960] TRAIN loss:  1.035\n",
      "[epoch 9 Iteration 911/960] TRAIN loss:  0.502\n",
      "[epoch 9 Iteration 912/960] TRAIN loss:  0.667\n",
      "[epoch 9 Iteration 913/960] TRAIN loss:  0.734\n",
      "[epoch 9 Iteration 914/960] TRAIN loss:  0.956\n",
      "[epoch 9 Iteration 915/960] TRAIN loss:  1.022\n",
      "[epoch 9 Iteration 916/960] TRAIN loss:  0.895\n",
      "[epoch 9 Iteration 917/960] TRAIN loss:  0.770\n",
      "[epoch 9 Iteration 918/960] TRAIN loss:  0.892\n",
      "[epoch 9 Iteration 919/960] TRAIN loss:  0.664\n",
      "[epoch 9 Iteration 920/960] TRAIN loss:  0.678\n",
      "[epoch 9 Iteration 921/960] TRAIN loss:  0.945\n",
      "[epoch 9 Iteration 922/960] TRAIN loss:  0.959\n",
      "[epoch 9 Iteration 923/960] TRAIN loss:  0.758\n",
      "[epoch 9 Iteration 924/960] TRAIN loss:  0.634\n",
      "[epoch 9 Iteration 925/960] TRAIN loss:  0.623\n",
      "[epoch 9 Iteration 926/960] TRAIN loss:  0.871\n",
      "[epoch 9 Iteration 927/960] TRAIN loss:  0.894\n",
      "[epoch 9 Iteration 928/960] TRAIN loss:  0.812\n",
      "[epoch 9 Iteration 929/960] TRAIN loss:  0.712\n",
      "[epoch 9 Iteration 930/960] TRAIN loss:  0.868\n",
      "[epoch 9 Iteration 931/960] TRAIN loss:  0.930\n",
      "[epoch 9 Iteration 932/960] TRAIN loss:  0.551\n",
      "[epoch 9 Iteration 933/960] TRAIN loss:  0.934\n",
      "[epoch 9 Iteration 934/960] TRAIN loss:  0.910\n",
      "[epoch 9 Iteration 935/960] TRAIN loss:  0.915\n",
      "[epoch 9 Iteration 936/960] TRAIN loss:  0.777\n",
      "[epoch 9 Iteration 937/960] TRAIN loss:  0.906\n",
      "[epoch 9 Iteration 938/960] TRAIN loss:  0.856\n",
      "[epoch 9 Iteration 939/960] TRAIN loss:  0.978\n",
      "[epoch 9 Iteration 940/960] TRAIN loss:  0.741\n",
      "[epoch 9 Iteration 941/960] TRAIN loss:  0.618\n",
      "[epoch 9 Iteration 942/960] TRAIN loss:  0.765\n",
      "[epoch 9 Iteration 943/960] TRAIN loss:  0.762\n",
      "[epoch 9 Iteration 944/960] TRAIN loss:  0.814\n",
      "[epoch 9 Iteration 945/960] TRAIN loss:  0.982\n",
      "[epoch 9 Iteration 946/960] TRAIN loss:  0.608\n",
      "[epoch 9 Iteration 947/960] TRAIN loss:  0.875\n",
      "[epoch 9 Iteration 948/960] TRAIN loss:  0.717\n",
      "[epoch 9 Iteration 949/960] TRAIN loss:  0.807\n",
      "[epoch 9 Iteration 950/960] TRAIN loss:  0.944\n",
      "[epoch 9 Iteration 951/960] TRAIN loss:  0.717\n",
      "[epoch 9 Iteration 952/960] TRAIN loss:  0.765\n",
      "[epoch 9 Iteration 953/960] TRAIN loss:  0.806\n",
      "[epoch 9 Iteration 954/960] TRAIN loss:  0.665\n",
      "[epoch 9 Iteration 955/960] TRAIN loss:  0.578\n",
      "[epoch 9 Iteration 956/960] TRAIN loss:  0.879\n",
      "[epoch 9 Iteration 957/960] TRAIN loss:  0.844\n",
      "[epoch 9 Iteration 958/960] TRAIN loss:  0.721\n",
      "[epoch 9 Iteration 959/960] TRAIN loss:  0.585\n",
      "[epoch 9/15] TRAIN acc/loss:  0.737/0.585\n",
      "[epoch 9/15] VAL acc/loss:  0.661/0.536\n",
      "[epoch 10 Iteration 0/960] TRAIN loss:  0.489\n",
      "[epoch 10 Iteration 1/960] TRAIN loss:  0.604\n",
      "[epoch 10 Iteration 2/960] TRAIN loss:  0.439\n",
      "[epoch 10 Iteration 3/960] TRAIN loss:  0.642\n",
      "[epoch 10 Iteration 4/960] TRAIN loss:  0.644\n",
      "[epoch 10 Iteration 5/960] TRAIN loss:  0.479\n",
      "[epoch 10 Iteration 6/960] TRAIN loss:  0.450\n",
      "[epoch 10 Iteration 7/960] TRAIN loss:  0.597\n",
      "[epoch 10 Iteration 8/960] TRAIN loss:  1.029\n",
      "[epoch 10 Iteration 9/960] TRAIN loss:  0.796\n",
      "[epoch 10 Iteration 10/960] TRAIN loss:  0.714\n",
      "[epoch 10 Iteration 11/960] TRAIN loss:  0.522\n",
      "[epoch 10 Iteration 12/960] TRAIN loss:  0.906\n",
      "[epoch 10 Iteration 13/960] TRAIN loss:  0.527\n",
      "[epoch 10 Iteration 14/960] TRAIN loss:  0.591\n",
      "[epoch 10 Iteration 15/960] TRAIN loss:  0.751\n",
      "[epoch 10 Iteration 16/960] TRAIN loss:  0.597\n",
      "[epoch 10 Iteration 17/960] TRAIN loss:  0.593\n",
      "[epoch 10 Iteration 18/960] TRAIN loss:  0.727\n",
      "[epoch 10 Iteration 19/960] TRAIN loss:  0.738\n",
      "[epoch 10 Iteration 20/960] TRAIN loss:  0.476\n",
      "[epoch 10 Iteration 21/960] TRAIN loss:  0.723\n",
      "[epoch 10 Iteration 22/960] TRAIN loss:  0.740\n",
      "[epoch 10 Iteration 23/960] TRAIN loss:  0.580\n",
      "[epoch 10 Iteration 24/960] TRAIN loss:  0.831\n",
      "[epoch 10 Iteration 25/960] TRAIN loss:  0.843\n",
      "[epoch 10 Iteration 26/960] TRAIN loss:  0.776\n",
      "[epoch 10 Iteration 27/960] TRAIN loss:  0.642\n",
      "[epoch 10 Iteration 28/960] TRAIN loss:  0.841\n",
      "[epoch 10 Iteration 29/960] TRAIN loss:  0.552\n",
      "[epoch 10 Iteration 30/960] TRAIN loss:  0.424\n",
      "[epoch 10 Iteration 31/960] TRAIN loss:  0.621\n",
      "[epoch 10 Iteration 32/960] TRAIN loss:  0.660\n",
      "[epoch 10 Iteration 33/960] TRAIN loss:  0.756\n",
      "[epoch 10 Iteration 34/960] TRAIN loss:  0.593\n",
      "[epoch 10 Iteration 35/960] TRAIN loss:  0.569\n",
      "[epoch 10 Iteration 36/960] TRAIN loss:  0.683\n",
      "[epoch 10 Iteration 37/960] TRAIN loss:  0.528\n",
      "[epoch 10 Iteration 38/960] TRAIN loss:  0.609\n",
      "[epoch 10 Iteration 39/960] TRAIN loss:  0.578\n",
      "[epoch 10 Iteration 40/960] TRAIN loss:  0.584\n",
      "[epoch 10 Iteration 41/960] TRAIN loss:  0.634\n",
      "[epoch 10 Iteration 42/960] TRAIN loss:  0.584\n",
      "[epoch 10 Iteration 43/960] TRAIN loss:  0.622\n",
      "[epoch 10 Iteration 44/960] TRAIN loss:  0.745\n",
      "[epoch 10 Iteration 45/960] TRAIN loss:  0.527\n",
      "[epoch 10 Iteration 46/960] TRAIN loss:  0.723\n",
      "[epoch 10 Iteration 47/960] TRAIN loss:  0.727\n",
      "[epoch 10 Iteration 48/960] TRAIN loss:  0.655\n",
      "[epoch 10 Iteration 49/960] TRAIN loss:  0.914\n",
      "[epoch 10 Iteration 50/960] TRAIN loss:  0.574\n",
      "[epoch 10 Iteration 51/960] TRAIN loss:  0.773\n",
      "[epoch 10 Iteration 52/960] TRAIN loss:  0.827\n",
      "[epoch 10 Iteration 53/960] TRAIN loss:  0.482\n",
      "[epoch 10 Iteration 54/960] TRAIN loss:  0.627\n",
      "[epoch 10 Iteration 55/960] TRAIN loss:  0.512\n",
      "[epoch 10 Iteration 56/960] TRAIN loss:  0.668\n",
      "[epoch 10 Iteration 57/960] TRAIN loss:  0.705\n",
      "[epoch 10 Iteration 58/960] TRAIN loss:  0.828\n",
      "[epoch 10 Iteration 59/960] TRAIN loss:  0.871\n",
      "[epoch 10 Iteration 60/960] TRAIN loss:  0.767\n",
      "[epoch 10 Iteration 61/960] TRAIN loss:  0.539\n",
      "[epoch 10 Iteration 62/960] TRAIN loss:  0.972\n",
      "[epoch 10 Iteration 63/960] TRAIN loss:  0.862\n",
      "[epoch 10 Iteration 64/960] TRAIN loss:  0.647\n",
      "[epoch 10 Iteration 65/960] TRAIN loss:  0.790\n",
      "[epoch 10 Iteration 66/960] TRAIN loss:  0.525\n",
      "[epoch 10 Iteration 67/960] TRAIN loss:  0.547\n",
      "[epoch 10 Iteration 68/960] TRAIN loss:  0.632\n",
      "[epoch 10 Iteration 69/960] TRAIN loss:  1.204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10 Iteration 70/960] TRAIN loss:  0.506\n",
      "[epoch 10 Iteration 71/960] TRAIN loss:  0.590\n",
      "[epoch 10 Iteration 72/960] TRAIN loss:  0.600\n",
      "[epoch 10 Iteration 73/960] TRAIN loss:  0.855\n",
      "[epoch 10 Iteration 74/960] TRAIN loss:  0.683\n",
      "[epoch 10 Iteration 75/960] TRAIN loss:  0.605\n",
      "[epoch 10 Iteration 76/960] TRAIN loss:  0.606\n",
      "[epoch 10 Iteration 77/960] TRAIN loss:  0.753\n",
      "[epoch 10 Iteration 78/960] TRAIN loss:  0.767\n",
      "[epoch 10 Iteration 79/960] TRAIN loss:  0.549\n",
      "[epoch 10 Iteration 80/960] TRAIN loss:  0.754\n",
      "[epoch 10 Iteration 81/960] TRAIN loss:  0.538\n",
      "[epoch 10 Iteration 82/960] TRAIN loss:  0.558\n",
      "[epoch 10 Iteration 83/960] TRAIN loss:  0.696\n",
      "[epoch 10 Iteration 84/960] TRAIN loss:  0.705\n",
      "[epoch 10 Iteration 85/960] TRAIN loss:  0.754\n",
      "[epoch 10 Iteration 86/960] TRAIN loss:  0.684\n",
      "[epoch 10 Iteration 87/960] TRAIN loss:  0.805\n",
      "[epoch 10 Iteration 88/960] TRAIN loss:  0.806\n",
      "[epoch 10 Iteration 89/960] TRAIN loss:  0.679\n",
      "[epoch 10 Iteration 90/960] TRAIN loss:  0.339\n",
      "[epoch 10 Iteration 91/960] TRAIN loss:  0.652\n",
      "[epoch 10 Iteration 92/960] TRAIN loss:  0.924\n",
      "[epoch 10 Iteration 93/960] TRAIN loss:  0.529\n",
      "[epoch 10 Iteration 94/960] TRAIN loss:  0.684\n",
      "[epoch 10 Iteration 95/960] TRAIN loss:  0.611\n",
      "[epoch 10 Iteration 96/960] TRAIN loss:  0.548\n",
      "[epoch 10 Iteration 97/960] TRAIN loss:  0.718\n",
      "[epoch 10 Iteration 98/960] TRAIN loss:  0.683\n",
      "[epoch 10 Iteration 99/960] TRAIN loss:  0.470\n",
      "[epoch 10 Iteration 100/960] TRAIN loss:  0.509\n",
      "[epoch 10 Iteration 101/960] TRAIN loss:  0.645\n",
      "[epoch 10 Iteration 102/960] TRAIN loss:  0.646\n",
      "[epoch 10 Iteration 103/960] TRAIN loss:  0.616\n",
      "[epoch 10 Iteration 104/960] TRAIN loss:  0.614\n",
      "[epoch 10 Iteration 105/960] TRAIN loss:  0.830\n",
      "[epoch 10 Iteration 106/960] TRAIN loss:  0.471\n",
      "[epoch 10 Iteration 107/960] TRAIN loss:  0.633\n",
      "[epoch 10 Iteration 108/960] TRAIN loss:  0.476\n",
      "[epoch 10 Iteration 109/960] TRAIN loss:  0.751\n",
      "[epoch 10 Iteration 110/960] TRAIN loss:  0.413\n",
      "[epoch 10 Iteration 111/960] TRAIN loss:  0.870\n",
      "[epoch 10 Iteration 112/960] TRAIN loss:  0.535\n",
      "[epoch 10 Iteration 113/960] TRAIN loss:  0.873\n",
      "[epoch 10 Iteration 114/960] TRAIN loss:  0.559\n",
      "[epoch 10 Iteration 115/960] TRAIN loss:  0.923\n",
      "[epoch 10 Iteration 116/960] TRAIN loss:  0.984\n",
      "[epoch 10 Iteration 117/960] TRAIN loss:  0.740\n",
      "[epoch 10 Iteration 118/960] TRAIN loss:  0.489\n",
      "[epoch 10 Iteration 119/960] TRAIN loss:  0.586\n",
      "[epoch 10 Iteration 120/960] TRAIN loss:  0.764\n",
      "[epoch 10 Iteration 121/960] TRAIN loss:  0.439\n",
      "[epoch 10 Iteration 122/960] TRAIN loss:  0.693\n",
      "[epoch 10 Iteration 123/960] TRAIN loss:  0.606\n",
      "[epoch 10 Iteration 124/960] TRAIN loss:  0.451\n",
      "[epoch 10 Iteration 125/960] TRAIN loss:  0.726\n",
      "[epoch 10 Iteration 126/960] TRAIN loss:  0.711\n",
      "[epoch 10 Iteration 127/960] TRAIN loss:  0.842\n",
      "[epoch 10 Iteration 128/960] TRAIN loss:  0.767\n",
      "[epoch 10 Iteration 129/960] TRAIN loss:  0.833\n",
      "[epoch 10 Iteration 130/960] TRAIN loss:  0.652\n",
      "[epoch 10 Iteration 131/960] TRAIN loss:  0.555\n",
      "[epoch 10 Iteration 132/960] TRAIN loss:  0.648\n",
      "[epoch 10 Iteration 133/960] TRAIN loss:  0.843\n",
      "[epoch 10 Iteration 134/960] TRAIN loss:  0.620\n",
      "[epoch 10 Iteration 135/960] TRAIN loss:  0.583\n",
      "[epoch 10 Iteration 136/960] TRAIN loss:  0.621\n",
      "[epoch 10 Iteration 137/960] TRAIN loss:  0.560\n",
      "[epoch 10 Iteration 138/960] TRAIN loss:  0.482\n",
      "[epoch 10 Iteration 139/960] TRAIN loss:  0.721\n",
      "[epoch 10 Iteration 140/960] TRAIN loss:  0.753\n",
      "[epoch 10 Iteration 141/960] TRAIN loss:  0.793\n",
      "[epoch 10 Iteration 142/960] TRAIN loss:  0.905\n",
      "[epoch 10 Iteration 143/960] TRAIN loss:  0.601\n",
      "[epoch 10 Iteration 144/960] TRAIN loss:  0.613\n",
      "[epoch 10 Iteration 145/960] TRAIN loss:  0.643\n",
      "[epoch 10 Iteration 146/960] TRAIN loss:  0.563\n",
      "[epoch 10 Iteration 147/960] TRAIN loss:  0.902\n",
      "[epoch 10 Iteration 148/960] TRAIN loss:  0.599\n",
      "[epoch 10 Iteration 149/960] TRAIN loss:  0.373\n",
      "[epoch 10 Iteration 150/960] TRAIN loss:  0.634\n",
      "[epoch 10 Iteration 151/960] TRAIN loss:  0.695\n",
      "[epoch 10 Iteration 152/960] TRAIN loss:  0.847\n",
      "[epoch 10 Iteration 153/960] TRAIN loss:  0.504\n",
      "[epoch 10 Iteration 154/960] TRAIN loss:  0.641\n",
      "[epoch 10 Iteration 155/960] TRAIN loss:  0.682\n",
      "[epoch 10 Iteration 156/960] TRAIN loss:  0.604\n",
      "[epoch 10 Iteration 157/960] TRAIN loss:  0.521\n",
      "[epoch 10 Iteration 158/960] TRAIN loss:  0.630\n",
      "[epoch 10 Iteration 159/960] TRAIN loss:  0.784\n",
      "[epoch 10 Iteration 160/960] TRAIN loss:  0.598\n",
      "[epoch 10 Iteration 161/960] TRAIN loss:  0.535\n",
      "[epoch 10 Iteration 162/960] TRAIN loss:  0.671\n",
      "[epoch 10 Iteration 163/960] TRAIN loss:  0.472\n",
      "[epoch 10 Iteration 164/960] TRAIN loss:  0.958\n",
      "[epoch 10 Iteration 165/960] TRAIN loss:  0.705\n",
      "[epoch 10 Iteration 166/960] TRAIN loss:  0.596\n",
      "[epoch 10 Iteration 167/960] TRAIN loss:  0.936\n",
      "[epoch 10 Iteration 168/960] TRAIN loss:  0.698\n",
      "[epoch 10 Iteration 169/960] TRAIN loss:  0.872\n",
      "[epoch 10 Iteration 170/960] TRAIN loss:  0.907\n",
      "[epoch 10 Iteration 171/960] TRAIN loss:  0.788\n",
      "[epoch 10 Iteration 172/960] TRAIN loss:  0.642\n",
      "[epoch 10 Iteration 173/960] TRAIN loss:  0.879\n",
      "[epoch 10 Iteration 174/960] TRAIN loss:  1.029\n",
      "[epoch 10 Iteration 175/960] TRAIN loss:  0.754\n",
      "[epoch 10 Iteration 176/960] TRAIN loss:  0.674\n",
      "[epoch 10 Iteration 177/960] TRAIN loss:  0.676\n",
      "[epoch 10 Iteration 178/960] TRAIN loss:  0.762\n",
      "[epoch 10 Iteration 179/960] TRAIN loss:  0.517\n",
      "[epoch 10 Iteration 180/960] TRAIN loss:  0.683\n",
      "[epoch 10 Iteration 181/960] TRAIN loss:  0.884\n",
      "[epoch 10 Iteration 182/960] TRAIN loss:  0.623\n",
      "[epoch 10 Iteration 183/960] TRAIN loss:  0.838\n",
      "[epoch 10 Iteration 184/960] TRAIN loss:  0.785\n",
      "[epoch 10 Iteration 185/960] TRAIN loss:  0.817\n",
      "[epoch 10 Iteration 186/960] TRAIN loss:  0.601\n",
      "[epoch 10 Iteration 187/960] TRAIN loss:  0.766\n",
      "[epoch 10 Iteration 188/960] TRAIN loss:  0.826\n",
      "[epoch 10 Iteration 189/960] TRAIN loss:  0.784\n",
      "[epoch 10 Iteration 190/960] TRAIN loss:  0.655\n",
      "[epoch 10 Iteration 191/960] TRAIN loss:  0.483\n",
      "[epoch 10 Iteration 192/960] TRAIN loss:  0.836\n",
      "[epoch 10 Iteration 193/960] TRAIN loss:  0.661\n",
      "[epoch 10 Iteration 194/960] TRAIN loss:  0.690\n",
      "[epoch 10 Iteration 195/960] TRAIN loss:  0.753\n",
      "[epoch 10 Iteration 196/960] TRAIN loss:  0.724\n",
      "[epoch 10 Iteration 197/960] TRAIN loss:  0.745\n",
      "[epoch 10 Iteration 198/960] TRAIN loss:  0.751\n",
      "[epoch 10 Iteration 199/960] TRAIN loss:  0.866\n",
      "[epoch 10 Iteration 200/960] TRAIN loss:  0.676\n",
      "[epoch 10 Iteration 201/960] TRAIN loss:  0.571\n",
      "[epoch 10 Iteration 202/960] TRAIN loss:  0.685\n",
      "[epoch 10 Iteration 203/960] TRAIN loss:  0.564\n",
      "[epoch 10 Iteration 204/960] TRAIN loss:  0.723\n",
      "[epoch 10 Iteration 205/960] TRAIN loss:  0.515\n",
      "[epoch 10 Iteration 206/960] TRAIN loss:  0.795\n",
      "[epoch 10 Iteration 207/960] TRAIN loss:  0.844\n",
      "[epoch 10 Iteration 208/960] TRAIN loss:  0.761\n",
      "[epoch 10 Iteration 209/960] TRAIN loss:  0.671\n",
      "[epoch 10 Iteration 210/960] TRAIN loss:  0.819\n",
      "[epoch 10 Iteration 211/960] TRAIN loss:  0.592\n",
      "[epoch 10 Iteration 212/960] TRAIN loss:  0.801\n",
      "[epoch 10 Iteration 213/960] TRAIN loss:  0.471\n",
      "[epoch 10 Iteration 214/960] TRAIN loss:  0.694\n",
      "[epoch 10 Iteration 215/960] TRAIN loss:  0.867\n",
      "[epoch 10 Iteration 216/960] TRAIN loss:  0.597\n",
      "[epoch 10 Iteration 217/960] TRAIN loss:  0.451\n",
      "[epoch 10 Iteration 218/960] TRAIN loss:  0.556\n",
      "[epoch 10 Iteration 219/960] TRAIN loss:  0.616\n",
      "[epoch 10 Iteration 220/960] TRAIN loss:  0.591\n",
      "[epoch 10 Iteration 221/960] TRAIN loss:  0.575\n",
      "[epoch 10 Iteration 222/960] TRAIN loss:  0.494\n",
      "[epoch 10 Iteration 223/960] TRAIN loss:  0.734\n",
      "[epoch 10 Iteration 224/960] TRAIN loss:  0.741\n",
      "[epoch 10 Iteration 225/960] TRAIN loss:  0.873\n",
      "[epoch 10 Iteration 226/960] TRAIN loss:  0.689\n",
      "[epoch 10 Iteration 227/960] TRAIN loss:  0.764\n",
      "[epoch 10 Iteration 228/960] TRAIN loss:  0.682\n",
      "[epoch 10 Iteration 229/960] TRAIN loss:  0.569\n",
      "[epoch 10 Iteration 230/960] TRAIN loss:  0.741\n",
      "[epoch 10 Iteration 231/960] TRAIN loss:  0.754\n",
      "[epoch 10 Iteration 232/960] TRAIN loss:  0.798\n",
      "[epoch 10 Iteration 233/960] TRAIN loss:  0.708\n",
      "[epoch 10 Iteration 234/960] TRAIN loss:  0.608\n",
      "[epoch 10 Iteration 235/960] TRAIN loss:  0.679\n",
      "[epoch 10 Iteration 236/960] TRAIN loss:  0.814\n",
      "[epoch 10 Iteration 237/960] TRAIN loss:  0.893\n",
      "[epoch 10 Iteration 238/960] TRAIN loss:  0.878\n",
      "[epoch 10 Iteration 239/960] TRAIN loss:  0.868\n",
      "[epoch 10 Iteration 240/960] TRAIN loss:  0.743\n",
      "[epoch 10 Iteration 241/960] TRAIN loss:  0.723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10 Iteration 242/960] TRAIN loss:  0.723\n",
      "[epoch 10 Iteration 243/960] TRAIN loss:  0.388\n",
      "[epoch 10 Iteration 244/960] TRAIN loss:  0.613\n",
      "[epoch 10 Iteration 245/960] TRAIN loss:  0.638\n",
      "[epoch 10 Iteration 246/960] TRAIN loss:  0.771\n",
      "[epoch 10 Iteration 247/960] TRAIN loss:  0.713\n",
      "[epoch 10 Iteration 248/960] TRAIN loss:  0.770\n",
      "[epoch 10 Iteration 249/960] TRAIN loss:  0.520\n",
      "[epoch 10 Iteration 250/960] TRAIN loss:  0.799\n",
      "[epoch 10 Iteration 251/960] TRAIN loss:  0.686\n",
      "[epoch 10 Iteration 252/960] TRAIN loss:  0.707\n",
      "[epoch 10 Iteration 253/960] TRAIN loss:  0.482\n",
      "[epoch 10 Iteration 254/960] TRAIN loss:  0.826\n",
      "[epoch 10 Iteration 255/960] TRAIN loss:  0.583\n",
      "[epoch 10 Iteration 256/960] TRAIN loss:  0.773\n",
      "[epoch 10 Iteration 257/960] TRAIN loss:  0.736\n",
      "[epoch 10 Iteration 258/960] TRAIN loss:  0.702\n",
      "[epoch 10 Iteration 259/960] TRAIN loss:  0.774\n",
      "[epoch 10 Iteration 260/960] TRAIN loss:  0.589\n",
      "[epoch 10 Iteration 261/960] TRAIN loss:  0.854\n",
      "[epoch 10 Iteration 262/960] TRAIN loss:  0.588\n",
      "[epoch 10 Iteration 263/960] TRAIN loss:  0.699\n",
      "[epoch 10 Iteration 264/960] TRAIN loss:  0.728\n",
      "[epoch 10 Iteration 265/960] TRAIN loss:  0.666\n",
      "[epoch 10 Iteration 266/960] TRAIN loss:  0.875\n",
      "[epoch 10 Iteration 267/960] TRAIN loss:  0.632\n",
      "[epoch 10 Iteration 268/960] TRAIN loss:  0.991\n",
      "[epoch 10 Iteration 269/960] TRAIN loss:  0.711\n",
      "[epoch 10 Iteration 270/960] TRAIN loss:  0.525\n",
      "[epoch 10 Iteration 271/960] TRAIN loss:  0.443\n",
      "[epoch 10 Iteration 272/960] TRAIN loss:  0.522\n",
      "[epoch 10 Iteration 273/960] TRAIN loss:  0.766\n",
      "[epoch 10 Iteration 274/960] TRAIN loss:  0.412\n",
      "[epoch 10 Iteration 275/960] TRAIN loss:  0.930\n",
      "[epoch 10 Iteration 276/960] TRAIN loss:  0.554\n",
      "[epoch 10 Iteration 277/960] TRAIN loss:  0.704\n",
      "[epoch 10 Iteration 278/960] TRAIN loss:  0.582\n",
      "[epoch 10 Iteration 279/960] TRAIN loss:  0.776\n",
      "[epoch 10 Iteration 280/960] TRAIN loss:  0.713\n",
      "[epoch 10 Iteration 281/960] TRAIN loss:  0.675\n",
      "[epoch 10 Iteration 282/960] TRAIN loss:  0.734\n",
      "[epoch 10 Iteration 283/960] TRAIN loss:  0.689\n",
      "[epoch 10 Iteration 284/960] TRAIN loss:  0.959\n",
      "[epoch 10 Iteration 285/960] TRAIN loss:  0.757\n",
      "[epoch 10 Iteration 286/960] TRAIN loss:  0.511\n",
      "[epoch 10 Iteration 287/960] TRAIN loss:  0.664\n",
      "[epoch 10 Iteration 288/960] TRAIN loss:  0.612\n",
      "[epoch 10 Iteration 289/960] TRAIN loss:  0.540\n",
      "[epoch 10 Iteration 290/960] TRAIN loss:  0.620\n",
      "[epoch 10 Iteration 291/960] TRAIN loss:  0.776\n",
      "[epoch 10 Iteration 292/960] TRAIN loss:  0.646\n",
      "[epoch 10 Iteration 293/960] TRAIN loss:  0.569\n",
      "[epoch 10 Iteration 294/960] TRAIN loss:  0.838\n",
      "[epoch 10 Iteration 295/960] TRAIN loss:  0.637\n",
      "[epoch 10 Iteration 296/960] TRAIN loss:  0.638\n",
      "[epoch 10 Iteration 297/960] TRAIN loss:  0.755\n",
      "[epoch 10 Iteration 298/960] TRAIN loss:  0.671\n",
      "[epoch 10 Iteration 299/960] TRAIN loss:  0.712\n",
      "[epoch 10 Iteration 300/960] TRAIN loss:  0.885\n",
      "[epoch 10 Iteration 301/960] TRAIN loss:  0.599\n",
      "[epoch 10 Iteration 302/960] TRAIN loss:  0.838\n",
      "[epoch 10 Iteration 303/960] TRAIN loss:  0.685\n",
      "[epoch 10 Iteration 304/960] TRAIN loss:  0.583\n",
      "[epoch 10 Iteration 305/960] TRAIN loss:  0.721\n",
      "[epoch 10 Iteration 306/960] TRAIN loss:  0.729\n",
      "[epoch 10 Iteration 307/960] TRAIN loss:  0.774\n",
      "[epoch 10 Iteration 308/960] TRAIN loss:  0.745\n",
      "[epoch 10 Iteration 309/960] TRAIN loss:  0.819\n",
      "[epoch 10 Iteration 310/960] TRAIN loss:  0.787\n",
      "[epoch 10 Iteration 311/960] TRAIN loss:  0.779\n",
      "[epoch 10 Iteration 312/960] TRAIN loss:  0.561\n",
      "[epoch 10 Iteration 313/960] TRAIN loss:  0.580\n",
      "[epoch 10 Iteration 314/960] TRAIN loss:  0.724\n",
      "[epoch 10 Iteration 315/960] TRAIN loss:  0.964\n",
      "[epoch 10 Iteration 316/960] TRAIN loss:  0.607\n",
      "[epoch 10 Iteration 317/960] TRAIN loss:  0.551\n",
      "[epoch 10 Iteration 318/960] TRAIN loss:  0.771\n",
      "[epoch 10 Iteration 319/960] TRAIN loss:  0.681\n",
      "[epoch 10 Iteration 320/960] TRAIN loss:  0.602\n",
      "[epoch 10 Iteration 321/960] TRAIN loss:  0.935\n",
      "[epoch 10 Iteration 322/960] TRAIN loss:  0.761\n",
      "[epoch 10 Iteration 323/960] TRAIN loss:  0.531\n",
      "[epoch 10 Iteration 324/960] TRAIN loss:  0.617\n",
      "[epoch 10 Iteration 325/960] TRAIN loss:  0.729\n",
      "[epoch 10 Iteration 326/960] TRAIN loss:  0.746\n",
      "[epoch 10 Iteration 327/960] TRAIN loss:  0.674\n",
      "[epoch 10 Iteration 328/960] TRAIN loss:  0.932\n",
      "[epoch 10 Iteration 329/960] TRAIN loss:  0.667\n",
      "[epoch 10 Iteration 330/960] TRAIN loss:  0.746\n",
      "[epoch 10 Iteration 331/960] TRAIN loss:  0.732\n",
      "[epoch 10 Iteration 332/960] TRAIN loss:  0.765\n",
      "[epoch 10 Iteration 333/960] TRAIN loss:  0.664\n",
      "[epoch 10 Iteration 334/960] TRAIN loss:  0.579\n",
      "[epoch 10 Iteration 335/960] TRAIN loss:  0.774\n",
      "[epoch 10 Iteration 336/960] TRAIN loss:  0.802\n",
      "[epoch 10 Iteration 337/960] TRAIN loss:  0.647\n",
      "[epoch 10 Iteration 338/960] TRAIN loss:  0.753\n",
      "[epoch 10 Iteration 339/960] TRAIN loss:  0.633\n",
      "[epoch 10 Iteration 340/960] TRAIN loss:  0.606\n",
      "[epoch 10 Iteration 341/960] TRAIN loss:  0.612\n",
      "[epoch 10 Iteration 342/960] TRAIN loss:  0.861\n",
      "[epoch 10 Iteration 343/960] TRAIN loss:  0.868\n",
      "[epoch 10 Iteration 344/960] TRAIN loss:  0.749\n",
      "[epoch 10 Iteration 345/960] TRAIN loss:  0.849\n",
      "[epoch 10 Iteration 346/960] TRAIN loss:  0.707\n",
      "[epoch 10 Iteration 347/960] TRAIN loss:  0.481\n",
      "[epoch 10 Iteration 348/960] TRAIN loss:  0.928\n",
      "[epoch 10 Iteration 349/960] TRAIN loss:  0.734\n",
      "[epoch 10 Iteration 350/960] TRAIN loss:  0.857\n",
      "[epoch 10 Iteration 351/960] TRAIN loss:  0.610\n",
      "[epoch 10 Iteration 352/960] TRAIN loss:  0.602\n",
      "[epoch 10 Iteration 353/960] TRAIN loss:  0.728\n",
      "[epoch 10 Iteration 354/960] TRAIN loss:  0.749\n",
      "[epoch 10 Iteration 355/960] TRAIN loss:  0.684\n",
      "[epoch 10 Iteration 356/960] TRAIN loss:  0.767\n",
      "[epoch 10 Iteration 357/960] TRAIN loss:  0.566\n",
      "[epoch 10 Iteration 358/960] TRAIN loss:  0.575\n",
      "[epoch 10 Iteration 359/960] TRAIN loss:  0.638\n",
      "[epoch 10 Iteration 360/960] TRAIN loss:  0.808\n",
      "[epoch 10 Iteration 361/960] TRAIN loss:  1.194\n",
      "[epoch 10 Iteration 362/960] TRAIN loss:  0.791\n",
      "[epoch 10 Iteration 363/960] TRAIN loss:  0.593\n",
      "[epoch 10 Iteration 364/960] TRAIN loss:  0.667\n",
      "[epoch 10 Iteration 365/960] TRAIN loss:  0.859\n",
      "[epoch 10 Iteration 366/960] TRAIN loss:  0.914\n",
      "[epoch 10 Iteration 367/960] TRAIN loss:  0.665\n",
      "[epoch 10 Iteration 368/960] TRAIN loss:  0.843\n",
      "[epoch 10 Iteration 369/960] TRAIN loss:  0.683\n",
      "[epoch 10 Iteration 370/960] TRAIN loss:  0.714\n",
      "[epoch 10 Iteration 371/960] TRAIN loss:  0.572\n",
      "[epoch 10 Iteration 372/960] TRAIN loss:  0.657\n",
      "[epoch 10 Iteration 373/960] TRAIN loss:  0.626\n",
      "[epoch 10 Iteration 374/960] TRAIN loss:  0.746\n",
      "[epoch 10 Iteration 375/960] TRAIN loss:  0.800\n",
      "[epoch 10 Iteration 376/960] TRAIN loss:  0.955\n",
      "[epoch 10 Iteration 377/960] TRAIN loss:  0.636\n",
      "[epoch 10 Iteration 378/960] TRAIN loss:  0.534\n",
      "[epoch 10 Iteration 379/960] TRAIN loss:  0.556\n",
      "[epoch 10 Iteration 380/960] TRAIN loss:  0.686\n",
      "[epoch 10 Iteration 381/960] TRAIN loss:  0.875\n",
      "[epoch 10 Iteration 382/960] TRAIN loss:  0.764\n",
      "[epoch 10 Iteration 383/960] TRAIN loss:  0.941\n",
      "[epoch 10 Iteration 384/960] TRAIN loss:  0.615\n",
      "[epoch 10 Iteration 385/960] TRAIN loss:  0.640\n",
      "[epoch 10 Iteration 386/960] TRAIN loss:  0.630\n",
      "[epoch 10 Iteration 387/960] TRAIN loss:  0.562\n",
      "[epoch 10 Iteration 388/960] TRAIN loss:  0.657\n",
      "[epoch 10 Iteration 389/960] TRAIN loss:  0.774\n",
      "[epoch 10 Iteration 390/960] TRAIN loss:  0.518\n",
      "[epoch 10 Iteration 391/960] TRAIN loss:  0.539\n",
      "[epoch 10 Iteration 392/960] TRAIN loss:  0.419\n",
      "[epoch 10 Iteration 393/960] TRAIN loss:  0.802\n",
      "[epoch 10 Iteration 394/960] TRAIN loss:  0.630\n",
      "[epoch 10 Iteration 395/960] TRAIN loss:  0.809\n",
      "[epoch 10 Iteration 396/960] TRAIN loss:  0.806\n",
      "[epoch 10 Iteration 397/960] TRAIN loss:  0.548\n",
      "[epoch 10 Iteration 398/960] TRAIN loss:  0.883\n",
      "[epoch 10 Iteration 399/960] TRAIN loss:  0.726\n",
      "[epoch 10 Iteration 400/960] TRAIN loss:  0.813\n",
      "[epoch 10 Iteration 401/960] TRAIN loss:  0.855\n",
      "[epoch 10 Iteration 402/960] TRAIN loss:  0.571\n",
      "[epoch 10 Iteration 403/960] TRAIN loss:  0.757\n",
      "[epoch 10 Iteration 404/960] TRAIN loss:  0.747\n",
      "[epoch 10 Iteration 405/960] TRAIN loss:  0.877\n",
      "[epoch 10 Iteration 406/960] TRAIN loss:  0.877\n",
      "[epoch 10 Iteration 407/960] TRAIN loss:  0.618\n",
      "[epoch 10 Iteration 408/960] TRAIN loss:  1.051\n",
      "[epoch 10 Iteration 409/960] TRAIN loss:  0.489\n",
      "[epoch 10 Iteration 410/960] TRAIN loss:  0.653\n",
      "[epoch 10 Iteration 411/960] TRAIN loss:  0.916\n",
      "[epoch 10 Iteration 412/960] TRAIN loss:  0.731\n",
      "[epoch 10 Iteration 413/960] TRAIN loss:  0.566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10 Iteration 414/960] TRAIN loss:  0.604\n",
      "[epoch 10 Iteration 415/960] TRAIN loss:  0.819\n",
      "[epoch 10 Iteration 416/960] TRAIN loss:  0.645\n",
      "[epoch 10 Iteration 417/960] TRAIN loss:  0.547\n",
      "[epoch 10 Iteration 418/960] TRAIN loss:  0.690\n",
      "[epoch 10 Iteration 419/960] TRAIN loss:  0.692\n",
      "[epoch 10 Iteration 420/960] TRAIN loss:  0.721\n",
      "[epoch 10 Iteration 421/960] TRAIN loss:  0.677\n",
      "[epoch 10 Iteration 422/960] TRAIN loss:  0.659\n",
      "[epoch 10 Iteration 423/960] TRAIN loss:  0.902\n",
      "[epoch 10 Iteration 424/960] TRAIN loss:  0.705\n",
      "[epoch 10 Iteration 425/960] TRAIN loss:  0.773\n",
      "[epoch 10 Iteration 426/960] TRAIN loss:  0.656\n",
      "[epoch 10 Iteration 427/960] TRAIN loss:  0.699\n",
      "[epoch 10 Iteration 428/960] TRAIN loss:  0.592\n",
      "[epoch 10 Iteration 429/960] TRAIN loss:  0.676\n",
      "[epoch 10 Iteration 430/960] TRAIN loss:  0.548\n",
      "[epoch 10 Iteration 431/960] TRAIN loss:  0.685\n",
      "[epoch 10 Iteration 432/960] TRAIN loss:  0.652\n",
      "[epoch 10 Iteration 433/960] TRAIN loss:  0.918\n",
      "[epoch 10 Iteration 434/960] TRAIN loss:  0.683\n",
      "[epoch 10 Iteration 435/960] TRAIN loss:  0.809\n",
      "[epoch 10 Iteration 436/960] TRAIN loss:  0.489\n",
      "[epoch 10 Iteration 437/960] TRAIN loss:  0.448\n",
      "[epoch 10 Iteration 438/960] TRAIN loss:  0.705\n",
      "[epoch 10 Iteration 439/960] TRAIN loss:  0.777\n",
      "[epoch 10 Iteration 440/960] TRAIN loss:  0.941\n",
      "[epoch 10 Iteration 441/960] TRAIN loss:  0.604\n",
      "[epoch 10 Iteration 442/960] TRAIN loss:  0.664\n",
      "[epoch 10 Iteration 443/960] TRAIN loss:  0.960\n",
      "[epoch 10 Iteration 444/960] TRAIN loss:  0.950\n",
      "[epoch 10 Iteration 445/960] TRAIN loss:  0.699\n",
      "[epoch 10 Iteration 446/960] TRAIN loss:  0.769\n",
      "[epoch 10 Iteration 447/960] TRAIN loss:  0.837\n",
      "[epoch 10 Iteration 448/960] TRAIN loss:  0.839\n",
      "[epoch 10 Iteration 449/960] TRAIN loss:  0.737\n",
      "[epoch 10 Iteration 450/960] TRAIN loss:  0.631\n",
      "[epoch 10 Iteration 451/960] TRAIN loss:  0.446\n",
      "[epoch 10 Iteration 452/960] TRAIN loss:  0.766\n",
      "[epoch 10 Iteration 453/960] TRAIN loss:  0.588\n",
      "[epoch 10 Iteration 454/960] TRAIN loss:  0.596\n",
      "[epoch 10 Iteration 455/960] TRAIN loss:  0.782\n",
      "[epoch 10 Iteration 456/960] TRAIN loss:  0.779\n",
      "[epoch 10 Iteration 457/960] TRAIN loss:  0.806\n",
      "[epoch 10 Iteration 458/960] TRAIN loss:  0.842\n",
      "[epoch 10 Iteration 459/960] TRAIN loss:  0.727\n",
      "[epoch 10 Iteration 460/960] TRAIN loss:  0.814\n",
      "[epoch 10 Iteration 461/960] TRAIN loss:  0.695\n",
      "[epoch 10 Iteration 462/960] TRAIN loss:  0.567\n",
      "[epoch 10 Iteration 463/960] TRAIN loss:  0.391\n",
      "[epoch 10 Iteration 464/960] TRAIN loss:  0.589\n",
      "[epoch 10 Iteration 465/960] TRAIN loss:  0.765\n",
      "[epoch 10 Iteration 466/960] TRAIN loss:  0.821\n",
      "[epoch 10 Iteration 467/960] TRAIN loss:  0.755\n",
      "[epoch 10 Iteration 468/960] TRAIN loss:  0.830\n",
      "[epoch 10 Iteration 469/960] TRAIN loss:  0.797\n",
      "[epoch 10 Iteration 470/960] TRAIN loss:  0.532\n",
      "[epoch 10 Iteration 471/960] TRAIN loss:  0.603\n",
      "[epoch 10 Iteration 472/960] TRAIN loss:  0.584\n",
      "[epoch 10 Iteration 473/960] TRAIN loss:  0.664\n",
      "[epoch 10 Iteration 474/960] TRAIN loss:  0.796\n",
      "[epoch 10 Iteration 475/960] TRAIN loss:  0.798\n",
      "[epoch 10 Iteration 476/960] TRAIN loss:  0.746\n",
      "[epoch 10 Iteration 477/960] TRAIN loss:  0.660\n",
      "[epoch 10 Iteration 478/960] TRAIN loss:  0.630\n",
      "[epoch 10 Iteration 479/960] TRAIN loss:  0.952\n",
      "[epoch 10 Iteration 480/960] TRAIN loss:  0.713\n",
      "[epoch 10 Iteration 481/960] TRAIN loss:  0.746\n",
      "[epoch 10 Iteration 482/960] TRAIN loss:  0.823\n",
      "[epoch 10 Iteration 483/960] TRAIN loss:  0.706\n",
      "[epoch 10 Iteration 484/960] TRAIN loss:  0.676\n",
      "[epoch 10 Iteration 485/960] TRAIN loss:  0.853\n",
      "[epoch 10 Iteration 486/960] TRAIN loss:  0.621\n",
      "[epoch 10 Iteration 487/960] TRAIN loss:  0.553\n",
      "[epoch 10 Iteration 488/960] TRAIN loss:  0.576\n",
      "[epoch 10 Iteration 489/960] TRAIN loss:  0.812\n",
      "[epoch 10 Iteration 490/960] TRAIN loss:  0.845\n",
      "[epoch 10 Iteration 491/960] TRAIN loss:  0.784\n",
      "[epoch 10 Iteration 492/960] TRAIN loss:  0.754\n",
      "[epoch 10 Iteration 493/960] TRAIN loss:  0.493\n",
      "[epoch 10 Iteration 494/960] TRAIN loss:  0.523\n",
      "[epoch 10 Iteration 495/960] TRAIN loss:  0.660\n",
      "[epoch 10 Iteration 496/960] TRAIN loss:  0.624\n",
      "[epoch 10 Iteration 497/960] TRAIN loss:  0.919\n",
      "[epoch 10 Iteration 498/960] TRAIN loss:  0.907\n",
      "[epoch 10 Iteration 499/960] TRAIN loss:  0.514\n",
      "[epoch 10 Iteration 500/960] TRAIN loss:  0.765\n",
      "[epoch 10 Iteration 501/960] TRAIN loss:  0.635\n",
      "[epoch 10 Iteration 502/960] TRAIN loss:  0.465\n",
      "[epoch 10 Iteration 503/960] TRAIN loss:  0.643\n",
      "[epoch 10 Iteration 504/960] TRAIN loss:  0.606\n",
      "[epoch 10 Iteration 505/960] TRAIN loss:  0.873\n",
      "[epoch 10 Iteration 506/960] TRAIN loss:  0.568\n",
      "[epoch 10 Iteration 507/960] TRAIN loss:  0.531\n",
      "[epoch 10 Iteration 508/960] TRAIN loss:  0.618\n",
      "[epoch 10 Iteration 509/960] TRAIN loss:  0.755\n",
      "[epoch 10 Iteration 510/960] TRAIN loss:  0.962\n",
      "[epoch 10 Iteration 511/960] TRAIN loss:  0.541\n",
      "[epoch 10 Iteration 512/960] TRAIN loss:  0.586\n",
      "[epoch 10 Iteration 513/960] TRAIN loss:  0.800\n",
      "[epoch 10 Iteration 514/960] TRAIN loss:  0.678\n",
      "[epoch 10 Iteration 515/960] TRAIN loss:  0.839\n",
      "[epoch 10 Iteration 516/960] TRAIN loss:  0.769\n",
      "[epoch 10 Iteration 517/960] TRAIN loss:  0.742\n",
      "[epoch 10 Iteration 518/960] TRAIN loss:  0.819\n",
      "[epoch 10 Iteration 519/960] TRAIN loss:  0.687\n",
      "[epoch 10 Iteration 520/960] TRAIN loss:  0.747\n",
      "[epoch 10 Iteration 521/960] TRAIN loss:  0.910\n",
      "[epoch 10 Iteration 522/960] TRAIN loss:  0.417\n",
      "[epoch 10 Iteration 523/960] TRAIN loss:  0.729\n",
      "[epoch 10 Iteration 524/960] TRAIN loss:  0.751\n",
      "[epoch 10 Iteration 525/960] TRAIN loss:  0.724\n",
      "[epoch 10 Iteration 526/960] TRAIN loss:  0.819\n",
      "[epoch 10 Iteration 527/960] TRAIN loss:  0.943\n",
      "[epoch 10 Iteration 528/960] TRAIN loss:  0.880\n",
      "[epoch 10 Iteration 529/960] TRAIN loss:  0.550\n",
      "[epoch 10 Iteration 530/960] TRAIN loss:  0.634\n",
      "[epoch 10 Iteration 531/960] TRAIN loss:  0.689\n",
      "[epoch 10 Iteration 532/960] TRAIN loss:  0.668\n",
      "[epoch 10 Iteration 533/960] TRAIN loss:  0.763\n",
      "[epoch 10 Iteration 534/960] TRAIN loss:  0.745\n",
      "[epoch 10 Iteration 535/960] TRAIN loss:  0.595\n",
      "[epoch 10 Iteration 536/960] TRAIN loss:  0.518\n",
      "[epoch 10 Iteration 537/960] TRAIN loss:  0.742\n",
      "[epoch 10 Iteration 538/960] TRAIN loss:  0.743\n",
      "[epoch 10 Iteration 539/960] TRAIN loss:  0.951\n",
      "[epoch 10 Iteration 540/960] TRAIN loss:  0.739\n",
      "[epoch 10 Iteration 541/960] TRAIN loss:  0.782\n",
      "[epoch 10 Iteration 542/960] TRAIN loss:  0.587\n",
      "[epoch 10 Iteration 543/960] TRAIN loss:  0.594\n",
      "[epoch 10 Iteration 544/960] TRAIN loss:  0.553\n",
      "[epoch 10 Iteration 545/960] TRAIN loss:  0.631\n",
      "[epoch 10 Iteration 546/960] TRAIN loss:  0.804\n",
      "[epoch 10 Iteration 547/960] TRAIN loss:  0.667\n",
      "[epoch 10 Iteration 548/960] TRAIN loss:  0.595\n",
      "[epoch 10 Iteration 549/960] TRAIN loss:  0.876\n",
      "[epoch 10 Iteration 550/960] TRAIN loss:  0.579\n",
      "[epoch 10 Iteration 551/960] TRAIN loss:  0.637\n",
      "[epoch 10 Iteration 552/960] TRAIN loss:  0.532\n",
      "[epoch 10 Iteration 553/960] TRAIN loss:  0.451\n",
      "[epoch 10 Iteration 554/960] TRAIN loss:  0.700\n",
      "[epoch 10 Iteration 555/960] TRAIN loss:  0.743\n",
      "[epoch 10 Iteration 556/960] TRAIN loss:  0.666\n",
      "[epoch 10 Iteration 557/960] TRAIN loss:  0.533\n",
      "[epoch 10 Iteration 558/960] TRAIN loss:  1.095\n",
      "[epoch 10 Iteration 559/960] TRAIN loss:  0.606\n",
      "[epoch 10 Iteration 560/960] TRAIN loss:  0.795\n",
      "[epoch 10 Iteration 561/960] TRAIN loss:  0.756\n",
      "[epoch 10 Iteration 562/960] TRAIN loss:  0.777\n",
      "[epoch 10 Iteration 563/960] TRAIN loss:  0.473\n",
      "[epoch 10 Iteration 564/960] TRAIN loss:  0.874\n",
      "[epoch 10 Iteration 565/960] TRAIN loss:  0.774\n",
      "[epoch 10 Iteration 566/960] TRAIN loss:  0.856\n",
      "[epoch 10 Iteration 567/960] TRAIN loss:  0.838\n",
      "[epoch 10 Iteration 568/960] TRAIN loss:  0.757\n",
      "[epoch 10 Iteration 569/960] TRAIN loss:  0.545\n",
      "[epoch 10 Iteration 570/960] TRAIN loss:  0.631\n",
      "[epoch 10 Iteration 571/960] TRAIN loss:  0.712\n",
      "[epoch 10 Iteration 572/960] TRAIN loss:  0.574\n",
      "[epoch 10 Iteration 573/960] TRAIN loss:  1.029\n",
      "[epoch 10 Iteration 574/960] TRAIN loss:  0.661\n",
      "[epoch 10 Iteration 575/960] TRAIN loss:  0.768\n",
      "[epoch 10 Iteration 576/960] TRAIN loss:  0.758\n",
      "[epoch 10 Iteration 577/960] TRAIN loss:  0.529\n",
      "[epoch 10 Iteration 578/960] TRAIN loss:  0.510\n",
      "[epoch 10 Iteration 579/960] TRAIN loss:  0.595\n",
      "[epoch 10 Iteration 580/960] TRAIN loss:  0.726\n",
      "[epoch 10 Iteration 581/960] TRAIN loss:  0.778\n",
      "[epoch 10 Iteration 582/960] TRAIN loss:  0.857\n",
      "[epoch 10 Iteration 583/960] TRAIN loss:  0.620\n",
      "[epoch 10 Iteration 584/960] TRAIN loss:  0.634\n",
      "[epoch 10 Iteration 585/960] TRAIN loss:  0.697\n",
      "[epoch 10 Iteration 586/960] TRAIN loss:  0.534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10 Iteration 587/960] TRAIN loss:  0.792\n",
      "[epoch 10 Iteration 588/960] TRAIN loss:  0.823\n",
      "[epoch 10 Iteration 589/960] TRAIN loss:  0.512\n",
      "[epoch 10 Iteration 590/960] TRAIN loss:  0.778\n",
      "[epoch 10 Iteration 591/960] TRAIN loss:  0.667\n",
      "[epoch 10 Iteration 592/960] TRAIN loss:  0.526\n",
      "[epoch 10 Iteration 593/960] TRAIN loss:  0.771\n",
      "[epoch 10 Iteration 594/960] TRAIN loss:  0.731\n",
      "[epoch 10 Iteration 595/960] TRAIN loss:  0.611\n",
      "[epoch 10 Iteration 596/960] TRAIN loss:  0.555\n",
      "[epoch 10 Iteration 597/960] TRAIN loss:  0.767\n",
      "[epoch 10 Iteration 598/960] TRAIN loss:  0.680\n",
      "[epoch 10 Iteration 599/960] TRAIN loss:  0.909\n",
      "[epoch 10 Iteration 600/960] TRAIN loss:  0.675\n",
      "[epoch 10 Iteration 601/960] TRAIN loss:  0.831\n",
      "[epoch 10 Iteration 602/960] TRAIN loss:  0.761\n",
      "[epoch 10 Iteration 603/960] TRAIN loss:  0.891\n",
      "[epoch 10 Iteration 604/960] TRAIN loss:  0.556\n",
      "[epoch 10 Iteration 605/960] TRAIN loss:  0.745\n",
      "[epoch 10 Iteration 606/960] TRAIN loss:  0.661\n",
      "[epoch 10 Iteration 607/960] TRAIN loss:  0.446\n",
      "[epoch 10 Iteration 608/960] TRAIN loss:  0.822\n",
      "[epoch 10 Iteration 609/960] TRAIN loss:  0.589\n",
      "[epoch 10 Iteration 610/960] TRAIN loss:  0.443\n",
      "[epoch 10 Iteration 611/960] TRAIN loss:  0.707\n",
      "[epoch 10 Iteration 612/960] TRAIN loss:  0.747\n",
      "[epoch 10 Iteration 613/960] TRAIN loss:  0.453\n",
      "[epoch 10 Iteration 614/960] TRAIN loss:  0.428\n",
      "[epoch 10 Iteration 615/960] TRAIN loss:  1.089\n",
      "[epoch 10 Iteration 616/960] TRAIN loss:  0.824\n",
      "[epoch 10 Iteration 617/960] TRAIN loss:  0.811\n",
      "[epoch 10 Iteration 618/960] TRAIN loss:  0.584\n",
      "[epoch 10 Iteration 619/960] TRAIN loss:  0.789\n",
      "[epoch 10 Iteration 620/960] TRAIN loss:  0.606\n",
      "[epoch 10 Iteration 621/960] TRAIN loss:  0.621\n",
      "[epoch 10 Iteration 622/960] TRAIN loss:  0.802\n",
      "[epoch 10 Iteration 623/960] TRAIN loss:  1.009\n",
      "[epoch 10 Iteration 624/960] TRAIN loss:  0.693\n",
      "[epoch 10 Iteration 625/960] TRAIN loss:  0.483\n",
      "[epoch 10 Iteration 626/960] TRAIN loss:  0.820\n",
      "[epoch 10 Iteration 627/960] TRAIN loss:  0.658\n",
      "[epoch 10 Iteration 628/960] TRAIN loss:  0.654\n",
      "[epoch 10 Iteration 629/960] TRAIN loss:  0.580\n",
      "[epoch 10 Iteration 630/960] TRAIN loss:  0.478\n",
      "[epoch 10 Iteration 631/960] TRAIN loss:  0.606\n",
      "[epoch 10 Iteration 632/960] TRAIN loss:  0.944\n",
      "[epoch 10 Iteration 633/960] TRAIN loss:  0.668\n",
      "[epoch 10 Iteration 634/960] TRAIN loss:  0.821\n",
      "[epoch 10 Iteration 635/960] TRAIN loss:  0.752\n",
      "[epoch 10 Iteration 636/960] TRAIN loss:  0.905\n",
      "[epoch 10 Iteration 637/960] TRAIN loss:  0.597\n",
      "[epoch 10 Iteration 638/960] TRAIN loss:  0.598\n",
      "[epoch 10 Iteration 639/960] TRAIN loss:  0.645\n",
      "[epoch 10 Iteration 640/960] TRAIN loss:  0.518\n",
      "[epoch 10 Iteration 641/960] TRAIN loss:  0.812\n",
      "[epoch 10 Iteration 642/960] TRAIN loss:  0.817\n",
      "[epoch 10 Iteration 643/960] TRAIN loss:  0.867\n",
      "[epoch 10 Iteration 644/960] TRAIN loss:  0.735\n",
      "[epoch 10 Iteration 645/960] TRAIN loss:  0.869\n",
      "[epoch 10 Iteration 646/960] TRAIN loss:  0.777\n",
      "[epoch 10 Iteration 647/960] TRAIN loss:  0.590\n",
      "[epoch 10 Iteration 648/960] TRAIN loss:  0.720\n",
      "[epoch 10 Iteration 649/960] TRAIN loss:  0.652\n",
      "[epoch 10 Iteration 650/960] TRAIN loss:  0.660\n",
      "[epoch 10 Iteration 651/960] TRAIN loss:  0.997\n",
      "[epoch 10 Iteration 652/960] TRAIN loss:  0.811\n",
      "[epoch 10 Iteration 653/960] TRAIN loss:  0.938\n",
      "[epoch 10 Iteration 654/960] TRAIN loss:  0.827\n",
      "[epoch 10 Iteration 655/960] TRAIN loss:  0.410\n",
      "[epoch 10 Iteration 656/960] TRAIN loss:  0.566\n",
      "[epoch 10 Iteration 657/960] TRAIN loss:  0.786\n",
      "[epoch 10 Iteration 658/960] TRAIN loss:  0.527\n",
      "[epoch 10 Iteration 659/960] TRAIN loss:  0.772\n",
      "[epoch 10 Iteration 660/960] TRAIN loss:  0.501\n",
      "[epoch 10 Iteration 661/960] TRAIN loss:  0.862\n",
      "[epoch 10 Iteration 662/960] TRAIN loss:  0.846\n",
      "[epoch 10 Iteration 663/960] TRAIN loss:  0.439\n",
      "[epoch 10 Iteration 664/960] TRAIN loss:  0.571\n",
      "[epoch 10 Iteration 665/960] TRAIN loss:  0.692\n",
      "[epoch 10 Iteration 666/960] TRAIN loss:  0.592\n",
      "[epoch 10 Iteration 667/960] TRAIN loss:  0.838\n",
      "[epoch 10 Iteration 668/960] TRAIN loss:  0.474\n",
      "[epoch 10 Iteration 669/960] TRAIN loss:  0.412\n",
      "[epoch 10 Iteration 670/960] TRAIN loss:  1.082\n",
      "[epoch 10 Iteration 671/960] TRAIN loss:  0.650\n",
      "[epoch 10 Iteration 672/960] TRAIN loss:  1.036\n",
      "[epoch 10 Iteration 673/960] TRAIN loss:  0.671\n",
      "[epoch 10 Iteration 674/960] TRAIN loss:  0.700\n",
      "[epoch 10 Iteration 675/960] TRAIN loss:  0.775\n",
      "[epoch 10 Iteration 676/960] TRAIN loss:  0.877\n",
      "[epoch 10 Iteration 677/960] TRAIN loss:  0.503\n",
      "[epoch 10 Iteration 678/960] TRAIN loss:  0.726\n",
      "[epoch 10 Iteration 679/960] TRAIN loss:  0.598\n",
      "[epoch 10 Iteration 680/960] TRAIN loss:  0.633\n",
      "[epoch 10 Iteration 681/960] TRAIN loss:  0.920\n",
      "[epoch 10 Iteration 682/960] TRAIN loss:  0.875\n",
      "[epoch 10 Iteration 683/960] TRAIN loss:  0.614\n",
      "[epoch 10 Iteration 684/960] TRAIN loss:  0.658\n",
      "[epoch 10 Iteration 685/960] TRAIN loss:  0.568\n",
      "[epoch 10 Iteration 686/960] TRAIN loss:  0.743\n",
      "[epoch 10 Iteration 687/960] TRAIN loss:  0.561\n",
      "[epoch 10 Iteration 688/960] TRAIN loss:  0.634\n",
      "[epoch 10 Iteration 689/960] TRAIN loss:  0.697\n",
      "[epoch 10 Iteration 690/960] TRAIN loss:  1.082\n",
      "[epoch 10 Iteration 691/960] TRAIN loss:  0.881\n",
      "[epoch 10 Iteration 692/960] TRAIN loss:  0.596\n",
      "[epoch 10 Iteration 693/960] TRAIN loss:  0.606\n",
      "[epoch 10 Iteration 694/960] TRAIN loss:  0.908\n",
      "[epoch 10 Iteration 695/960] TRAIN loss:  0.745\n",
      "[epoch 10 Iteration 696/960] TRAIN loss:  0.772\n",
      "[epoch 10 Iteration 697/960] TRAIN loss:  0.624\n",
      "[epoch 10 Iteration 698/960] TRAIN loss:  0.893\n",
      "[epoch 10 Iteration 699/960] TRAIN loss:  0.764\n",
      "[epoch 10 Iteration 700/960] TRAIN loss:  0.658\n",
      "[epoch 10 Iteration 701/960] TRAIN loss:  1.016\n",
      "[epoch 10 Iteration 702/960] TRAIN loss:  0.775\n",
      "[epoch 10 Iteration 703/960] TRAIN loss:  0.885\n",
      "[epoch 10 Iteration 704/960] TRAIN loss:  0.785\n",
      "[epoch 10 Iteration 705/960] TRAIN loss:  0.707\n",
      "[epoch 10 Iteration 706/960] TRAIN loss:  0.665\n",
      "[epoch 10 Iteration 707/960] TRAIN loss:  0.694\n",
      "[epoch 10 Iteration 708/960] TRAIN loss:  0.521\n",
      "[epoch 10 Iteration 709/960] TRAIN loss:  0.583\n",
      "[epoch 10 Iteration 710/960] TRAIN loss:  0.857\n",
      "[epoch 10 Iteration 711/960] TRAIN loss:  0.685\n",
      "[epoch 10 Iteration 712/960] TRAIN loss:  0.657\n",
      "[epoch 10 Iteration 713/960] TRAIN loss:  0.712\n",
      "[epoch 10 Iteration 714/960] TRAIN loss:  0.673\n",
      "[epoch 10 Iteration 715/960] TRAIN loss:  0.711\n",
      "[epoch 10 Iteration 716/960] TRAIN loss:  0.530\n",
      "[epoch 10 Iteration 717/960] TRAIN loss:  0.757\n",
      "[epoch 10 Iteration 718/960] TRAIN loss:  0.802\n",
      "[epoch 10 Iteration 719/960] TRAIN loss:  0.681\n",
      "[epoch 10 Iteration 720/960] TRAIN loss:  0.712\n",
      "[epoch 10 Iteration 721/960] TRAIN loss:  0.779\n",
      "[epoch 10 Iteration 722/960] TRAIN loss:  0.793\n",
      "[epoch 10 Iteration 723/960] TRAIN loss:  0.733\n",
      "[epoch 10 Iteration 724/960] TRAIN loss:  0.655\n",
      "[epoch 10 Iteration 725/960] TRAIN loss:  0.897\n",
      "[epoch 10 Iteration 726/960] TRAIN loss:  0.710\n",
      "[epoch 10 Iteration 727/960] TRAIN loss:  0.638\n",
      "[epoch 10 Iteration 728/960] TRAIN loss:  0.914\n",
      "[epoch 10 Iteration 729/960] TRAIN loss:  0.952\n",
      "[epoch 10 Iteration 730/960] TRAIN loss:  0.847\n",
      "[epoch 10 Iteration 731/960] TRAIN loss:  0.561\n",
      "[epoch 10 Iteration 732/960] TRAIN loss:  0.581\n",
      "[epoch 10 Iteration 733/960] TRAIN loss:  0.895\n",
      "[epoch 10 Iteration 734/960] TRAIN loss:  0.559\n",
      "[epoch 10 Iteration 735/960] TRAIN loss:  0.676\n",
      "[epoch 10 Iteration 736/960] TRAIN loss:  0.725\n",
      "[epoch 10 Iteration 737/960] TRAIN loss:  0.905\n",
      "[epoch 10 Iteration 738/960] TRAIN loss:  0.639\n",
      "[epoch 10 Iteration 739/960] TRAIN loss:  0.699\n",
      "[epoch 10 Iteration 740/960] TRAIN loss:  0.828\n",
      "[epoch 10 Iteration 741/960] TRAIN loss:  0.877\n",
      "[epoch 10 Iteration 742/960] TRAIN loss:  0.698\n",
      "[epoch 10 Iteration 743/960] TRAIN loss:  0.579\n",
      "[epoch 10 Iteration 744/960] TRAIN loss:  0.578\n",
      "[epoch 10 Iteration 745/960] TRAIN loss:  0.633\n",
      "[epoch 10 Iteration 746/960] TRAIN loss:  0.496\n",
      "[epoch 10 Iteration 747/960] TRAIN loss:  0.817\n",
      "[epoch 10 Iteration 748/960] TRAIN loss:  0.761\n",
      "[epoch 10 Iteration 749/960] TRAIN loss:  0.623\n",
      "[epoch 10 Iteration 750/960] TRAIN loss:  0.768\n",
      "[epoch 10 Iteration 751/960] TRAIN loss:  0.675\n",
      "[epoch 10 Iteration 752/960] TRAIN loss:  0.951\n",
      "[epoch 10 Iteration 753/960] TRAIN loss:  0.773\n",
      "[epoch 10 Iteration 754/960] TRAIN loss:  0.742\n",
      "[epoch 10 Iteration 755/960] TRAIN loss:  0.830\n",
      "[epoch 10 Iteration 756/960] TRAIN loss:  0.713\n",
      "[epoch 10 Iteration 757/960] TRAIN loss:  0.792\n",
      "[epoch 10 Iteration 758/960] TRAIN loss:  0.638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10 Iteration 759/960] TRAIN loss:  0.684\n",
      "[epoch 10 Iteration 760/960] TRAIN loss:  0.810\n",
      "[epoch 10 Iteration 761/960] TRAIN loss:  0.997\n",
      "[epoch 10 Iteration 762/960] TRAIN loss:  0.532\n",
      "[epoch 10 Iteration 763/960] TRAIN loss:  0.604\n",
      "[epoch 10 Iteration 764/960] TRAIN loss:  0.517\n",
      "[epoch 10 Iteration 765/960] TRAIN loss:  0.753\n",
      "[epoch 10 Iteration 766/960] TRAIN loss:  0.948\n",
      "[epoch 10 Iteration 767/960] TRAIN loss:  0.655\n",
      "[epoch 10 Iteration 768/960] TRAIN loss:  0.483\n",
      "[epoch 10 Iteration 769/960] TRAIN loss:  0.780\n",
      "[epoch 10 Iteration 770/960] TRAIN loss:  0.679\n",
      "[epoch 10 Iteration 771/960] TRAIN loss:  0.472\n",
      "[epoch 10 Iteration 772/960] TRAIN loss:  0.696\n",
      "[epoch 10 Iteration 773/960] TRAIN loss:  0.573\n",
      "[epoch 10 Iteration 774/960] TRAIN loss:  0.824\n",
      "[epoch 10 Iteration 775/960] TRAIN loss:  0.858\n",
      "[epoch 10 Iteration 776/960] TRAIN loss:  0.903\n",
      "[epoch 10 Iteration 777/960] TRAIN loss:  0.762\n",
      "[epoch 10 Iteration 778/960] TRAIN loss:  0.399\n",
      "[epoch 10 Iteration 779/960] TRAIN loss:  0.692\n",
      "[epoch 10 Iteration 780/960] TRAIN loss:  0.807\n",
      "[epoch 10 Iteration 781/960] TRAIN loss:  0.663\n",
      "[epoch 10 Iteration 782/960] TRAIN loss:  0.518\n",
      "[epoch 10 Iteration 783/960] TRAIN loss:  0.705\n",
      "[epoch 10 Iteration 784/960] TRAIN loss:  0.778\n",
      "[epoch 10 Iteration 785/960] TRAIN loss:  0.586\n",
      "[epoch 10 Iteration 786/960] TRAIN loss:  0.891\n",
      "[epoch 10 Iteration 787/960] TRAIN loss:  0.768\n",
      "[epoch 10 Iteration 788/960] TRAIN loss:  0.746\n",
      "[epoch 10 Iteration 789/960] TRAIN loss:  0.367\n",
      "[epoch 10 Iteration 790/960] TRAIN loss:  0.617\n",
      "[epoch 10 Iteration 791/960] TRAIN loss:  0.641\n",
      "[epoch 10 Iteration 792/960] TRAIN loss:  0.597\n",
      "[epoch 10 Iteration 793/960] TRAIN loss:  0.794\n",
      "[epoch 10 Iteration 794/960] TRAIN loss:  0.409\n",
      "[epoch 10 Iteration 795/960] TRAIN loss:  0.653\n",
      "[epoch 10 Iteration 796/960] TRAIN loss:  0.656\n",
      "[epoch 10 Iteration 797/960] TRAIN loss:  0.730\n",
      "[epoch 10 Iteration 798/960] TRAIN loss:  0.786\n",
      "[epoch 10 Iteration 799/960] TRAIN loss:  0.558\n",
      "[epoch 10 Iteration 800/960] TRAIN loss:  0.828\n",
      "[epoch 10 Iteration 801/960] TRAIN loss:  0.762\n",
      "[epoch 10 Iteration 802/960] TRAIN loss:  0.646\n",
      "[epoch 10 Iteration 803/960] TRAIN loss:  0.996\n",
      "[epoch 10 Iteration 804/960] TRAIN loss:  0.851\n",
      "[epoch 10 Iteration 805/960] TRAIN loss:  0.647\n",
      "[epoch 10 Iteration 806/960] TRAIN loss:  0.754\n",
      "[epoch 10 Iteration 807/960] TRAIN loss:  0.859\n",
      "[epoch 10 Iteration 808/960] TRAIN loss:  0.687\n",
      "[epoch 10 Iteration 809/960] TRAIN loss:  0.701\n",
      "[epoch 10 Iteration 810/960] TRAIN loss:  0.604\n",
      "[epoch 10 Iteration 811/960] TRAIN loss:  0.783\n",
      "[epoch 10 Iteration 812/960] TRAIN loss:  0.840\n",
      "[epoch 10 Iteration 813/960] TRAIN loss:  0.918\n",
      "[epoch 10 Iteration 814/960] TRAIN loss:  0.972\n",
      "[epoch 10 Iteration 815/960] TRAIN loss:  0.432\n",
      "[epoch 10 Iteration 816/960] TRAIN loss:  0.877\n",
      "[epoch 10 Iteration 817/960] TRAIN loss:  1.032\n",
      "[epoch 10 Iteration 818/960] TRAIN loss:  1.046\n",
      "[epoch 10 Iteration 819/960] TRAIN loss:  0.561\n",
      "[epoch 10 Iteration 820/960] TRAIN loss:  0.930\n",
      "[epoch 10 Iteration 821/960] TRAIN loss:  0.696\n",
      "[epoch 10 Iteration 822/960] TRAIN loss:  0.646\n",
      "[epoch 10 Iteration 823/960] TRAIN loss:  0.626\n",
      "[epoch 10 Iteration 824/960] TRAIN loss:  0.684\n",
      "[epoch 10 Iteration 825/960] TRAIN loss:  0.500\n",
      "[epoch 10 Iteration 826/960] TRAIN loss:  0.502\n",
      "[epoch 10 Iteration 827/960] TRAIN loss:  0.544\n",
      "[epoch 10 Iteration 828/960] TRAIN loss:  0.672\n",
      "[epoch 10 Iteration 829/960] TRAIN loss:  0.991\n",
      "[epoch 10 Iteration 830/960] TRAIN loss:  0.887\n",
      "[epoch 10 Iteration 831/960] TRAIN loss:  0.886\n",
      "[epoch 10 Iteration 832/960] TRAIN loss:  0.604\n",
      "[epoch 10 Iteration 833/960] TRAIN loss:  0.671\n",
      "[epoch 10 Iteration 834/960] TRAIN loss:  0.650\n",
      "[epoch 10 Iteration 835/960] TRAIN loss:  0.747\n",
      "[epoch 10 Iteration 836/960] TRAIN loss:  0.897\n",
      "[epoch 10 Iteration 837/960] TRAIN loss:  0.918\n",
      "[epoch 10 Iteration 838/960] TRAIN loss:  0.508\n",
      "[epoch 10 Iteration 839/960] TRAIN loss:  0.895\n",
      "[epoch 10 Iteration 840/960] TRAIN loss:  0.754\n",
      "[epoch 10 Iteration 841/960] TRAIN loss:  0.721\n",
      "[epoch 10 Iteration 842/960] TRAIN loss:  0.576\n",
      "[epoch 10 Iteration 843/960] TRAIN loss:  0.441\n",
      "[epoch 10 Iteration 844/960] TRAIN loss:  0.649\n",
      "[epoch 10 Iteration 845/960] TRAIN loss:  0.811\n",
      "[epoch 10 Iteration 846/960] TRAIN loss:  0.897\n",
      "[epoch 10 Iteration 847/960] TRAIN loss:  0.835\n",
      "[epoch 10 Iteration 848/960] TRAIN loss:  0.668\n",
      "[epoch 10 Iteration 849/960] TRAIN loss:  0.836\n",
      "[epoch 10 Iteration 850/960] TRAIN loss:  0.443\n",
      "[epoch 10 Iteration 851/960] TRAIN loss:  0.677\n",
      "[epoch 10 Iteration 852/960] TRAIN loss:  0.497\n",
      "[epoch 10 Iteration 853/960] TRAIN loss:  0.751\n",
      "[epoch 10 Iteration 854/960] TRAIN loss:  0.555\n",
      "[epoch 10 Iteration 855/960] TRAIN loss:  0.570\n",
      "[epoch 10 Iteration 856/960] TRAIN loss:  0.794\n",
      "[epoch 10 Iteration 857/960] TRAIN loss:  0.859\n",
      "[epoch 10 Iteration 858/960] TRAIN loss:  0.873\n",
      "[epoch 10 Iteration 859/960] TRAIN loss:  0.789\n",
      "[epoch 10 Iteration 860/960] TRAIN loss:  0.690\n",
      "[epoch 10 Iteration 861/960] TRAIN loss:  0.595\n",
      "[epoch 10 Iteration 862/960] TRAIN loss:  0.939\n",
      "[epoch 10 Iteration 863/960] TRAIN loss:  0.908\n",
      "[epoch 10 Iteration 864/960] TRAIN loss:  0.626\n",
      "[epoch 10 Iteration 865/960] TRAIN loss:  0.865\n",
      "[epoch 10 Iteration 866/960] TRAIN loss:  0.475\n",
      "[epoch 10 Iteration 867/960] TRAIN loss:  0.642\n",
      "[epoch 10 Iteration 868/960] TRAIN loss:  0.724\n",
      "[epoch 10 Iteration 869/960] TRAIN loss:  0.655\n",
      "[epoch 10 Iteration 870/960] TRAIN loss:  1.049\n",
      "[epoch 10 Iteration 871/960] TRAIN loss:  0.518\n",
      "[epoch 10 Iteration 872/960] TRAIN loss:  0.826\n",
      "[epoch 10 Iteration 873/960] TRAIN loss:  0.826\n",
      "[epoch 10 Iteration 874/960] TRAIN loss:  0.842\n",
      "[epoch 10 Iteration 875/960] TRAIN loss:  0.766\n",
      "[epoch 10 Iteration 876/960] TRAIN loss:  0.661\n",
      "[epoch 10 Iteration 877/960] TRAIN loss:  0.758\n",
      "[epoch 10 Iteration 878/960] TRAIN loss:  0.558\n",
      "[epoch 10 Iteration 879/960] TRAIN loss:  0.915\n",
      "[epoch 10 Iteration 880/960] TRAIN loss:  0.677\n",
      "[epoch 10 Iteration 881/960] TRAIN loss:  0.839\n",
      "[epoch 10 Iteration 882/960] TRAIN loss:  0.802\n",
      "[epoch 10 Iteration 883/960] TRAIN loss:  0.552\n",
      "[epoch 10 Iteration 884/960] TRAIN loss:  0.603\n",
      "[epoch 10 Iteration 885/960] TRAIN loss:  0.668\n",
      "[epoch 10 Iteration 886/960] TRAIN loss:  0.904\n",
      "[epoch 10 Iteration 887/960] TRAIN loss:  0.643\n",
      "[epoch 10 Iteration 888/960] TRAIN loss:  0.793\n",
      "[epoch 10 Iteration 889/960] TRAIN loss:  0.730\n",
      "[epoch 10 Iteration 890/960] TRAIN loss:  0.831\n",
      "[epoch 10 Iteration 891/960] TRAIN loss:  0.903\n",
      "[epoch 10 Iteration 892/960] TRAIN loss:  0.877\n",
      "[epoch 10 Iteration 893/960] TRAIN loss:  0.950\n",
      "[epoch 10 Iteration 894/960] TRAIN loss:  0.799\n",
      "[epoch 10 Iteration 895/960] TRAIN loss:  0.839\n",
      "[epoch 10 Iteration 896/960] TRAIN loss:  0.870\n",
      "[epoch 10 Iteration 897/960] TRAIN loss:  0.951\n",
      "[epoch 10 Iteration 898/960] TRAIN loss:  0.644\n",
      "[epoch 10 Iteration 899/960] TRAIN loss:  0.967\n",
      "[epoch 10 Iteration 900/960] TRAIN loss:  0.805\n",
      "[epoch 10 Iteration 901/960] TRAIN loss:  0.667\n",
      "[epoch 10 Iteration 902/960] TRAIN loss:  0.611\n",
      "[epoch 10 Iteration 903/960] TRAIN loss:  0.936\n",
      "[epoch 10 Iteration 904/960] TRAIN loss:  0.880\n",
      "[epoch 10 Iteration 905/960] TRAIN loss:  0.667\n",
      "[epoch 10 Iteration 906/960] TRAIN loss:  0.787\n",
      "[epoch 10 Iteration 907/960] TRAIN loss:  0.914\n",
      "[epoch 10 Iteration 908/960] TRAIN loss:  0.639\n",
      "[epoch 10 Iteration 909/960] TRAIN loss:  0.989\n",
      "[epoch 10 Iteration 910/960] TRAIN loss:  1.127\n",
      "[epoch 10 Iteration 911/960] TRAIN loss:  0.777\n",
      "[epoch 10 Iteration 912/960] TRAIN loss:  0.817\n",
      "[epoch 10 Iteration 913/960] TRAIN loss:  0.638\n",
      "[epoch 10 Iteration 914/960] TRAIN loss:  0.651\n",
      "[epoch 10 Iteration 915/960] TRAIN loss:  1.247\n",
      "[epoch 10 Iteration 916/960] TRAIN loss:  0.768\n",
      "[epoch 10 Iteration 917/960] TRAIN loss:  1.094\n",
      "[epoch 10 Iteration 918/960] TRAIN loss:  0.734\n",
      "[epoch 10 Iteration 919/960] TRAIN loss:  0.751\n",
      "[epoch 10 Iteration 920/960] TRAIN loss:  0.623\n",
      "[epoch 10 Iteration 921/960] TRAIN loss:  0.633\n",
      "[epoch 10 Iteration 922/960] TRAIN loss:  0.864\n",
      "[epoch 10 Iteration 923/960] TRAIN loss:  0.860\n",
      "[epoch 10 Iteration 924/960] TRAIN loss:  0.635\n",
      "[epoch 10 Iteration 925/960] TRAIN loss:  0.585\n",
      "[epoch 10 Iteration 926/960] TRAIN loss:  0.771\n",
      "[epoch 10 Iteration 927/960] TRAIN loss:  0.919\n",
      "[epoch 10 Iteration 928/960] TRAIN loss:  0.657\n",
      "[epoch 10 Iteration 929/960] TRAIN loss:  0.780\n",
      "[epoch 10 Iteration 930/960] TRAIN loss:  0.636\n",
      "[epoch 10 Iteration 931/960] TRAIN loss:  0.756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 10 Iteration 932/960] TRAIN loss:  0.687\n",
      "[epoch 10 Iteration 933/960] TRAIN loss:  0.761\n",
      "[epoch 10 Iteration 934/960] TRAIN loss:  0.879\n",
      "[epoch 10 Iteration 935/960] TRAIN loss:  0.812\n",
      "[epoch 10 Iteration 936/960] TRAIN loss:  0.738\n",
      "[epoch 10 Iteration 937/960] TRAIN loss:  0.632\n",
      "[epoch 10 Iteration 938/960] TRAIN loss:  0.608\n",
      "[epoch 10 Iteration 939/960] TRAIN loss:  0.625\n",
      "[epoch 10 Iteration 940/960] TRAIN loss:  0.743\n",
      "[epoch 10 Iteration 941/960] TRAIN loss:  0.804\n",
      "[epoch 10 Iteration 942/960] TRAIN loss:  0.718\n",
      "[epoch 10 Iteration 943/960] TRAIN loss:  0.751\n",
      "[epoch 10 Iteration 944/960] TRAIN loss:  0.825\n",
      "[epoch 10 Iteration 945/960] TRAIN loss:  0.767\n",
      "[epoch 10 Iteration 946/960] TRAIN loss:  0.698\n",
      "[epoch 10 Iteration 947/960] TRAIN loss:  0.556\n",
      "[epoch 10 Iteration 948/960] TRAIN loss:  0.493\n",
      "[epoch 10 Iteration 949/960] TRAIN loss:  0.748\n",
      "[epoch 10 Iteration 950/960] TRAIN loss:  0.781\n",
      "[epoch 10 Iteration 951/960] TRAIN loss:  0.469\n",
      "[epoch 10 Iteration 952/960] TRAIN loss:  0.516\n",
      "[epoch 10 Iteration 953/960] TRAIN loss:  0.769\n",
      "[epoch 10 Iteration 954/960] TRAIN loss:  0.747\n",
      "[epoch 10 Iteration 955/960] TRAIN loss:  0.616\n",
      "[epoch 10 Iteration 956/960] TRAIN loss:  0.764\n",
      "[epoch 10 Iteration 957/960] TRAIN loss:  0.608\n",
      "[epoch 10 Iteration 958/960] TRAIN loss:  1.180\n",
      "[epoch 10 Iteration 959/960] TRAIN loss:  0.466\n",
      "[epoch 10/15] TRAIN acc/loss:  0.750/0.466\n",
      "[epoch 10/15] VAL acc/loss:  0.666/0.497\n",
      "[epoch 11 Iteration 0/960] TRAIN loss:  0.568\n",
      "[epoch 11 Iteration 1/960] TRAIN loss:  0.464\n",
      "[epoch 11 Iteration 2/960] TRAIN loss:  0.731\n",
      "[epoch 11 Iteration 3/960] TRAIN loss:  0.638\n",
      "[epoch 11 Iteration 4/960] TRAIN loss:  0.538\n",
      "[epoch 11 Iteration 5/960] TRAIN loss:  0.491\n",
      "[epoch 11 Iteration 6/960] TRAIN loss:  0.475\n",
      "[epoch 11 Iteration 7/960] TRAIN loss:  0.758\n",
      "[epoch 11 Iteration 8/960] TRAIN loss:  0.876\n",
      "[epoch 11 Iteration 9/960] TRAIN loss:  0.985\n",
      "[epoch 11 Iteration 10/960] TRAIN loss:  0.600\n",
      "[epoch 11 Iteration 11/960] TRAIN loss:  0.523\n",
      "[epoch 11 Iteration 12/960] TRAIN loss:  0.651\n",
      "[epoch 11 Iteration 13/960] TRAIN loss:  0.493\n",
      "[epoch 11 Iteration 14/960] TRAIN loss:  0.818\n",
      "[epoch 11 Iteration 15/960] TRAIN loss:  0.602\n",
      "[epoch 11 Iteration 16/960] TRAIN loss:  0.425\n",
      "[epoch 11 Iteration 17/960] TRAIN loss:  0.489\n",
      "[epoch 11 Iteration 18/960] TRAIN loss:  0.527\n",
      "[epoch 11 Iteration 19/960] TRAIN loss:  0.673\n",
      "[epoch 11 Iteration 20/960] TRAIN loss:  0.540\n",
      "[epoch 11 Iteration 21/960] TRAIN loss:  0.474\n",
      "[epoch 11 Iteration 22/960] TRAIN loss:  0.517\n",
      "[epoch 11 Iteration 23/960] TRAIN loss:  0.784\n",
      "[epoch 11 Iteration 24/960] TRAIN loss:  0.702\n",
      "[epoch 11 Iteration 25/960] TRAIN loss:  0.391\n",
      "[epoch 11 Iteration 26/960] TRAIN loss:  0.588\n",
      "[epoch 11 Iteration 27/960] TRAIN loss:  0.728\n",
      "[epoch 11 Iteration 28/960] TRAIN loss:  0.472\n",
      "[epoch 11 Iteration 29/960] TRAIN loss:  0.656\n",
      "[epoch 11 Iteration 30/960] TRAIN loss:  0.458\n",
      "[epoch 11 Iteration 31/960] TRAIN loss:  0.603\n",
      "[epoch 11 Iteration 32/960] TRAIN loss:  0.688\n",
      "[epoch 11 Iteration 33/960] TRAIN loss:  0.565\n",
      "[epoch 11 Iteration 34/960] TRAIN loss:  0.639\n",
      "[epoch 11 Iteration 35/960] TRAIN loss:  0.852\n",
      "[epoch 11 Iteration 36/960] TRAIN loss:  0.772\n",
      "[epoch 11 Iteration 37/960] TRAIN loss:  0.744\n",
      "[epoch 11 Iteration 38/960] TRAIN loss:  0.722\n",
      "[epoch 11 Iteration 39/960] TRAIN loss:  0.506\n",
      "[epoch 11 Iteration 40/960] TRAIN loss:  0.808\n",
      "[epoch 11 Iteration 41/960] TRAIN loss:  0.799\n",
      "[epoch 11 Iteration 42/960] TRAIN loss:  0.444\n",
      "[epoch 11 Iteration 43/960] TRAIN loss:  0.600\n",
      "[epoch 11 Iteration 44/960] TRAIN loss:  0.599\n",
      "[epoch 11 Iteration 45/960] TRAIN loss:  0.684\n",
      "[epoch 11 Iteration 46/960] TRAIN loss:  0.498\n",
      "[epoch 11 Iteration 47/960] TRAIN loss:  0.559\n",
      "[epoch 11 Iteration 48/960] TRAIN loss:  0.606\n",
      "[epoch 11 Iteration 49/960] TRAIN loss:  0.611\n",
      "[epoch 11 Iteration 50/960] TRAIN loss:  0.694\n",
      "[epoch 11 Iteration 51/960] TRAIN loss:  0.874\n",
      "[epoch 11 Iteration 52/960] TRAIN loss:  0.854\n",
      "[epoch 11 Iteration 53/960] TRAIN loss:  0.642\n",
      "[epoch 11 Iteration 54/960] TRAIN loss:  0.684\n",
      "[epoch 11 Iteration 55/960] TRAIN loss:  0.621\n",
      "[epoch 11 Iteration 56/960] TRAIN loss:  0.640\n",
      "[epoch 11 Iteration 57/960] TRAIN loss:  0.480\n",
      "[epoch 11 Iteration 58/960] TRAIN loss:  0.467\n",
      "[epoch 11 Iteration 59/960] TRAIN loss:  0.828\n",
      "[epoch 11 Iteration 60/960] TRAIN loss:  0.656\n",
      "[epoch 11 Iteration 61/960] TRAIN loss:  0.713\n",
      "[epoch 11 Iteration 62/960] TRAIN loss:  0.476\n",
      "[epoch 11 Iteration 63/960] TRAIN loss:  0.594\n",
      "[epoch 11 Iteration 64/960] TRAIN loss:  0.594\n",
      "[epoch 11 Iteration 65/960] TRAIN loss:  0.501\n",
      "[epoch 11 Iteration 66/960] TRAIN loss:  0.501\n",
      "[epoch 11 Iteration 67/960] TRAIN loss:  0.812\n",
      "[epoch 11 Iteration 68/960] TRAIN loss:  0.603\n",
      "[epoch 11 Iteration 69/960] TRAIN loss:  0.751\n",
      "[epoch 11 Iteration 70/960] TRAIN loss:  0.509\n",
      "[epoch 11 Iteration 71/960] TRAIN loss:  0.461\n",
      "[epoch 11 Iteration 72/960] TRAIN loss:  0.622\n",
      "[epoch 11 Iteration 73/960] TRAIN loss:  0.814\n",
      "[epoch 11 Iteration 74/960] TRAIN loss:  0.595\n",
      "[epoch 11 Iteration 75/960] TRAIN loss:  0.640\n",
      "[epoch 11 Iteration 76/960] TRAIN loss:  0.619\n",
      "[epoch 11 Iteration 77/960] TRAIN loss:  0.586\n",
      "[epoch 11 Iteration 78/960] TRAIN loss:  0.643\n",
      "[epoch 11 Iteration 79/960] TRAIN loss:  0.449\n",
      "[epoch 11 Iteration 80/960] TRAIN loss:  0.810\n",
      "[epoch 11 Iteration 81/960] TRAIN loss:  0.792\n",
      "[epoch 11 Iteration 82/960] TRAIN loss:  0.528\n",
      "[epoch 11 Iteration 83/960] TRAIN loss:  0.665\n",
      "[epoch 11 Iteration 84/960] TRAIN loss:  0.667\n",
      "[epoch 11 Iteration 85/960] TRAIN loss:  0.637\n",
      "[epoch 11 Iteration 86/960] TRAIN loss:  0.532\n",
      "[epoch 11 Iteration 87/960] TRAIN loss:  0.652\n",
      "[epoch 11 Iteration 88/960] TRAIN loss:  0.528\n",
      "[epoch 11 Iteration 89/960] TRAIN loss:  0.658\n",
      "[epoch 11 Iteration 90/960] TRAIN loss:  0.912\n",
      "[epoch 11 Iteration 91/960] TRAIN loss:  0.545\n",
      "[epoch 11 Iteration 92/960] TRAIN loss:  0.710\n",
      "[epoch 11 Iteration 93/960] TRAIN loss:  0.518\n",
      "[epoch 11 Iteration 94/960] TRAIN loss:  0.648\n",
      "[epoch 11 Iteration 95/960] TRAIN loss:  0.805\n",
      "[epoch 11 Iteration 96/960] TRAIN loss:  0.843\n",
      "[epoch 11 Iteration 97/960] TRAIN loss:  0.764\n",
      "[epoch 11 Iteration 98/960] TRAIN loss:  0.697\n",
      "[epoch 11 Iteration 99/960] TRAIN loss:  0.566\n",
      "[epoch 11 Iteration 100/960] TRAIN loss:  0.610\n",
      "[epoch 11 Iteration 101/960] TRAIN loss:  0.627\n",
      "[epoch 11 Iteration 102/960] TRAIN loss:  0.634\n",
      "[epoch 11 Iteration 103/960] TRAIN loss:  0.756\n",
      "[epoch 11 Iteration 104/960] TRAIN loss:  0.502\n",
      "[epoch 11 Iteration 105/960] TRAIN loss:  0.486\n",
      "[epoch 11 Iteration 106/960] TRAIN loss:  0.680\n",
      "[epoch 11 Iteration 107/960] TRAIN loss:  0.651\n",
      "[epoch 11 Iteration 108/960] TRAIN loss:  0.559\n",
      "[epoch 11 Iteration 109/960] TRAIN loss:  0.544\n",
      "[epoch 11 Iteration 110/960] TRAIN loss:  0.500\n",
      "[epoch 11 Iteration 111/960] TRAIN loss:  0.708\n",
      "[epoch 11 Iteration 112/960] TRAIN loss:  0.630\n",
      "[epoch 11 Iteration 113/960] TRAIN loss:  0.413\n",
      "[epoch 11 Iteration 114/960] TRAIN loss:  0.492\n",
      "[epoch 11 Iteration 115/960] TRAIN loss:  0.637\n",
      "[epoch 11 Iteration 116/960] TRAIN loss:  0.582\n",
      "[epoch 11 Iteration 117/960] TRAIN loss:  0.812\n",
      "[epoch 11 Iteration 118/960] TRAIN loss:  0.734\n",
      "[epoch 11 Iteration 119/960] TRAIN loss:  0.725\n",
      "[epoch 11 Iteration 120/960] TRAIN loss:  0.640\n",
      "[epoch 11 Iteration 121/960] TRAIN loss:  0.470\n",
      "[epoch 11 Iteration 122/960] TRAIN loss:  0.720\n",
      "[epoch 11 Iteration 123/960] TRAIN loss:  0.516\n",
      "[epoch 11 Iteration 124/960] TRAIN loss:  0.565\n",
      "[epoch 11 Iteration 125/960] TRAIN loss:  0.920\n",
      "[epoch 11 Iteration 126/960] TRAIN loss:  0.642\n",
      "[epoch 11 Iteration 127/960] TRAIN loss:  0.838\n",
      "[epoch 11 Iteration 128/960] TRAIN loss:  0.718\n",
      "[epoch 11 Iteration 129/960] TRAIN loss:  0.744\n",
      "[epoch 11 Iteration 130/960] TRAIN loss:  0.890\n",
      "[epoch 11 Iteration 131/960] TRAIN loss:  0.679\n",
      "[epoch 11 Iteration 132/960] TRAIN loss:  0.849\n",
      "[epoch 11 Iteration 133/960] TRAIN loss:  0.674\n",
      "[epoch 11 Iteration 134/960] TRAIN loss:  0.931\n",
      "[epoch 11 Iteration 135/960] TRAIN loss:  0.645\n",
      "[epoch 11 Iteration 136/960] TRAIN loss:  0.736\n",
      "[epoch 11 Iteration 137/960] TRAIN loss:  0.768\n",
      "[epoch 11 Iteration 138/960] TRAIN loss:  0.824\n",
      "[epoch 11 Iteration 139/960] TRAIN loss:  0.518\n",
      "[epoch 11 Iteration 140/960] TRAIN loss:  0.674\n",
      "[epoch 11 Iteration 141/960] TRAIN loss:  0.622\n",
      "[epoch 11 Iteration 142/960] TRAIN loss:  0.744\n",
      "[epoch 11 Iteration 143/960] TRAIN loss:  0.691\n",
      "[epoch 11 Iteration 144/960] TRAIN loss:  0.690\n",
      "[epoch 11 Iteration 145/960] TRAIN loss:  0.534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11 Iteration 146/960] TRAIN loss:  0.622\n",
      "[epoch 11 Iteration 147/960] TRAIN loss:  0.670\n",
      "[epoch 11 Iteration 148/960] TRAIN loss:  0.790\n",
      "[epoch 11 Iteration 149/960] TRAIN loss:  0.528\n",
      "[epoch 11 Iteration 150/960] TRAIN loss:  0.713\n",
      "[epoch 11 Iteration 151/960] TRAIN loss:  0.513\n",
      "[epoch 11 Iteration 152/960] TRAIN loss:  0.964\n",
      "[epoch 11 Iteration 153/960] TRAIN loss:  0.606\n",
      "[epoch 11 Iteration 154/960] TRAIN loss:  0.539\n",
      "[epoch 11 Iteration 155/960] TRAIN loss:  0.677\n",
      "[epoch 11 Iteration 156/960] TRAIN loss:  0.499\n",
      "[epoch 11 Iteration 157/960] TRAIN loss:  0.625\n",
      "[epoch 11 Iteration 158/960] TRAIN loss:  0.533\n",
      "[epoch 11 Iteration 159/960] TRAIN loss:  0.583\n",
      "[epoch 11 Iteration 160/960] TRAIN loss:  0.624\n",
      "[epoch 11 Iteration 161/960] TRAIN loss:  0.621\n",
      "[epoch 11 Iteration 162/960] TRAIN loss:  0.791\n",
      "[epoch 11 Iteration 163/960] TRAIN loss:  0.487\n",
      "[epoch 11 Iteration 164/960] TRAIN loss:  0.682\n",
      "[epoch 11 Iteration 165/960] TRAIN loss:  0.630\n",
      "[epoch 11 Iteration 166/960] TRAIN loss:  0.661\n",
      "[epoch 11 Iteration 167/960] TRAIN loss:  0.668\n",
      "[epoch 11 Iteration 168/960] TRAIN loss:  0.425\n",
      "[epoch 11 Iteration 169/960] TRAIN loss:  0.836\n",
      "[epoch 11 Iteration 170/960] TRAIN loss:  0.468\n",
      "[epoch 11 Iteration 171/960] TRAIN loss:  0.667\n",
      "[epoch 11 Iteration 172/960] TRAIN loss:  0.638\n",
      "[epoch 11 Iteration 173/960] TRAIN loss:  0.651\n",
      "[epoch 11 Iteration 174/960] TRAIN loss:  0.565\n",
      "[epoch 11 Iteration 175/960] TRAIN loss:  0.672\n",
      "[epoch 11 Iteration 176/960] TRAIN loss:  0.563\n",
      "[epoch 11 Iteration 177/960] TRAIN loss:  0.473\n",
      "[epoch 11 Iteration 178/960] TRAIN loss:  0.685\n",
      "[epoch 11 Iteration 179/960] TRAIN loss:  0.591\n",
      "[epoch 11 Iteration 180/960] TRAIN loss:  0.724\n",
      "[epoch 11 Iteration 181/960] TRAIN loss:  0.399\n",
      "[epoch 11 Iteration 182/960] TRAIN loss:  0.476\n",
      "[epoch 11 Iteration 183/960] TRAIN loss:  0.716\n",
      "[epoch 11 Iteration 184/960] TRAIN loss:  0.775\n",
      "[epoch 11 Iteration 185/960] TRAIN loss:  0.618\n",
      "[epoch 11 Iteration 186/960] TRAIN loss:  0.826\n",
      "[epoch 11 Iteration 187/960] TRAIN loss:  0.783\n",
      "[epoch 11 Iteration 188/960] TRAIN loss:  0.838\n",
      "[epoch 11 Iteration 189/960] TRAIN loss:  0.566\n",
      "[epoch 11 Iteration 190/960] TRAIN loss:  0.714\n",
      "[epoch 11 Iteration 191/960] TRAIN loss:  0.555\n",
      "[epoch 11 Iteration 192/960] TRAIN loss:  0.656\n",
      "[epoch 11 Iteration 193/960] TRAIN loss:  0.719\n",
      "[epoch 11 Iteration 194/960] TRAIN loss:  0.567\n",
      "[epoch 11 Iteration 195/960] TRAIN loss:  0.508\n",
      "[epoch 11 Iteration 196/960] TRAIN loss:  0.715\n",
      "[epoch 11 Iteration 197/960] TRAIN loss:  0.633\n",
      "[epoch 11 Iteration 198/960] TRAIN loss:  0.531\n",
      "[epoch 11 Iteration 199/960] TRAIN loss:  0.656\n",
      "[epoch 11 Iteration 200/960] TRAIN loss:  0.701\n",
      "[epoch 11 Iteration 201/960] TRAIN loss:  0.679\n",
      "[epoch 11 Iteration 202/960] TRAIN loss:  0.537\n",
      "[epoch 11 Iteration 203/960] TRAIN loss:  0.649\n",
      "[epoch 11 Iteration 204/960] TRAIN loss:  0.587\n",
      "[epoch 11 Iteration 205/960] TRAIN loss:  0.479\n",
      "[epoch 11 Iteration 206/960] TRAIN loss:  0.704\n",
      "[epoch 11 Iteration 207/960] TRAIN loss:  0.588\n",
      "[epoch 11 Iteration 208/960] TRAIN loss:  0.673\n",
      "[epoch 11 Iteration 209/960] TRAIN loss:  0.609\n",
      "[epoch 11 Iteration 210/960] TRAIN loss:  0.522\n",
      "[epoch 11 Iteration 211/960] TRAIN loss:  1.011\n",
      "[epoch 11 Iteration 212/960] TRAIN loss:  0.634\n",
      "[epoch 11 Iteration 213/960] TRAIN loss:  0.565\n",
      "[epoch 11 Iteration 214/960] TRAIN loss:  0.887\n",
      "[epoch 11 Iteration 215/960] TRAIN loss:  0.426\n",
      "[epoch 11 Iteration 216/960] TRAIN loss:  0.522\n",
      "[epoch 11 Iteration 217/960] TRAIN loss:  0.719\n",
      "[epoch 11 Iteration 218/960] TRAIN loss:  0.552\n",
      "[epoch 11 Iteration 219/960] TRAIN loss:  0.558\n",
      "[epoch 11 Iteration 220/960] TRAIN loss:  0.624\n",
      "[epoch 11 Iteration 221/960] TRAIN loss:  0.724\n",
      "[epoch 11 Iteration 222/960] TRAIN loss:  0.701\n",
      "[epoch 11 Iteration 223/960] TRAIN loss:  0.414\n",
      "[epoch 11 Iteration 224/960] TRAIN loss:  0.672\n",
      "[epoch 11 Iteration 225/960] TRAIN loss:  0.486\n",
      "[epoch 11 Iteration 226/960] TRAIN loss:  0.571\n",
      "[epoch 11 Iteration 227/960] TRAIN loss:  0.589\n",
      "[epoch 11 Iteration 228/960] TRAIN loss:  0.628\n",
      "[epoch 11 Iteration 229/960] TRAIN loss:  0.887\n",
      "[epoch 11 Iteration 230/960] TRAIN loss:  0.776\n",
      "[epoch 11 Iteration 231/960] TRAIN loss:  0.665\n",
      "[epoch 11 Iteration 232/960] TRAIN loss:  0.543\n",
      "[epoch 11 Iteration 233/960] TRAIN loss:  0.399\n",
      "[epoch 11 Iteration 234/960] TRAIN loss:  0.892\n",
      "[epoch 11 Iteration 235/960] TRAIN loss:  0.543\n",
      "[epoch 11 Iteration 236/960] TRAIN loss:  1.115\n",
      "[epoch 11 Iteration 237/960] TRAIN loss:  0.643\n",
      "[epoch 11 Iteration 238/960] TRAIN loss:  0.665\n",
      "[epoch 11 Iteration 239/960] TRAIN loss:  0.427\n",
      "[epoch 11 Iteration 240/960] TRAIN loss:  0.587\n",
      "[epoch 11 Iteration 241/960] TRAIN loss:  0.743\n",
      "[epoch 11 Iteration 242/960] TRAIN loss:  0.634\n",
      "[epoch 11 Iteration 243/960] TRAIN loss:  0.855\n",
      "[epoch 11 Iteration 244/960] TRAIN loss:  0.704\n",
      "[epoch 11 Iteration 245/960] TRAIN loss:  0.586\n",
      "[epoch 11 Iteration 246/960] TRAIN loss:  0.798\n",
      "[epoch 11 Iteration 247/960] TRAIN loss:  0.822\n",
      "[epoch 11 Iteration 248/960] TRAIN loss:  0.584\n",
      "[epoch 11 Iteration 249/960] TRAIN loss:  0.576\n",
      "[epoch 11 Iteration 250/960] TRAIN loss:  0.638\n",
      "[epoch 11 Iteration 251/960] TRAIN loss:  0.492\n",
      "[epoch 11 Iteration 252/960] TRAIN loss:  0.660\n",
      "[epoch 11 Iteration 253/960] TRAIN loss:  0.601\n",
      "[epoch 11 Iteration 254/960] TRAIN loss:  0.537\n",
      "[epoch 11 Iteration 255/960] TRAIN loss:  0.895\n",
      "[epoch 11 Iteration 256/960] TRAIN loss:  0.789\n",
      "[epoch 11 Iteration 257/960] TRAIN loss:  0.532\n",
      "[epoch 11 Iteration 258/960] TRAIN loss:  0.741\n",
      "[epoch 11 Iteration 259/960] TRAIN loss:  0.633\n",
      "[epoch 11 Iteration 260/960] TRAIN loss:  0.484\n",
      "[epoch 11 Iteration 261/960] TRAIN loss:  0.665\n",
      "[epoch 11 Iteration 262/960] TRAIN loss:  0.787\n",
      "[epoch 11 Iteration 263/960] TRAIN loss:  0.642\n",
      "[epoch 11 Iteration 264/960] TRAIN loss:  0.675\n",
      "[epoch 11 Iteration 265/960] TRAIN loss:  1.043\n",
      "[epoch 11 Iteration 266/960] TRAIN loss:  0.720\n",
      "[epoch 11 Iteration 267/960] TRAIN loss:  0.575\n",
      "[epoch 11 Iteration 268/960] TRAIN loss:  0.625\n",
      "[epoch 11 Iteration 269/960] TRAIN loss:  0.875\n",
      "[epoch 11 Iteration 270/960] TRAIN loss:  0.500\n",
      "[epoch 11 Iteration 271/960] TRAIN loss:  0.950\n",
      "[epoch 11 Iteration 272/960] TRAIN loss:  0.731\n",
      "[epoch 11 Iteration 273/960] TRAIN loss:  0.464\n",
      "[epoch 11 Iteration 274/960] TRAIN loss:  0.449\n",
      "[epoch 11 Iteration 275/960] TRAIN loss:  0.629\n",
      "[epoch 11 Iteration 276/960] TRAIN loss:  0.733\n",
      "[epoch 11 Iteration 277/960] TRAIN loss:  0.483\n",
      "[epoch 11 Iteration 278/960] TRAIN loss:  0.658\n",
      "[epoch 11 Iteration 279/960] TRAIN loss:  0.823\n",
      "[epoch 11 Iteration 280/960] TRAIN loss:  0.519\n",
      "[epoch 11 Iteration 281/960] TRAIN loss:  0.680\n",
      "[epoch 11 Iteration 282/960] TRAIN loss:  0.836\n",
      "[epoch 11 Iteration 283/960] TRAIN loss:  0.567\n",
      "[epoch 11 Iteration 284/960] TRAIN loss:  0.699\n",
      "[epoch 11 Iteration 285/960] TRAIN loss:  0.568\n",
      "[epoch 11 Iteration 286/960] TRAIN loss:  0.954\n",
      "[epoch 11 Iteration 287/960] TRAIN loss:  0.763\n",
      "[epoch 11 Iteration 288/960] TRAIN loss:  0.708\n",
      "[epoch 11 Iteration 289/960] TRAIN loss:  0.709\n",
      "[epoch 11 Iteration 290/960] TRAIN loss:  0.680\n",
      "[epoch 11 Iteration 291/960] TRAIN loss:  0.418\n",
      "[epoch 11 Iteration 292/960] TRAIN loss:  0.622\n",
      "[epoch 11 Iteration 293/960] TRAIN loss:  0.509\n",
      "[epoch 11 Iteration 294/960] TRAIN loss:  0.628\n",
      "[epoch 11 Iteration 295/960] TRAIN loss:  0.759\n",
      "[epoch 11 Iteration 296/960] TRAIN loss:  0.646\n",
      "[epoch 11 Iteration 297/960] TRAIN loss:  0.601\n",
      "[epoch 11 Iteration 298/960] TRAIN loss:  0.671\n",
      "[epoch 11 Iteration 299/960] TRAIN loss:  0.615\n",
      "[epoch 11 Iteration 300/960] TRAIN loss:  0.579\n",
      "[epoch 11 Iteration 301/960] TRAIN loss:  0.817\n",
      "[epoch 11 Iteration 302/960] TRAIN loss:  0.805\n",
      "[epoch 11 Iteration 303/960] TRAIN loss:  0.732\n",
      "[epoch 11 Iteration 304/960] TRAIN loss:  0.958\n",
      "[epoch 11 Iteration 305/960] TRAIN loss:  0.806\n",
      "[epoch 11 Iteration 306/960] TRAIN loss:  0.652\n",
      "[epoch 11 Iteration 307/960] TRAIN loss:  0.598\n",
      "[epoch 11 Iteration 308/960] TRAIN loss:  0.453\n",
      "[epoch 11 Iteration 309/960] TRAIN loss:  0.772\n",
      "[epoch 11 Iteration 310/960] TRAIN loss:  0.635\n",
      "[epoch 11 Iteration 311/960] TRAIN loss:  0.449\n",
      "[epoch 11 Iteration 312/960] TRAIN loss:  0.548\n",
      "[epoch 11 Iteration 313/960] TRAIN loss:  0.805\n",
      "[epoch 11 Iteration 314/960] TRAIN loss:  0.720\n",
      "[epoch 11 Iteration 315/960] TRAIN loss:  0.646\n",
      "[epoch 11 Iteration 316/960] TRAIN loss:  0.464\n",
      "[epoch 11 Iteration 317/960] TRAIN loss:  0.554\n",
      "[epoch 11 Iteration 318/960] TRAIN loss:  0.618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11 Iteration 319/960] TRAIN loss:  0.588\n",
      "[epoch 11 Iteration 320/960] TRAIN loss:  0.653\n",
      "[epoch 11 Iteration 321/960] TRAIN loss:  0.634\n",
      "[epoch 11 Iteration 322/960] TRAIN loss:  0.612\n",
      "[epoch 11 Iteration 323/960] TRAIN loss:  0.773\n",
      "[epoch 11 Iteration 324/960] TRAIN loss:  0.536\n",
      "[epoch 11 Iteration 325/960] TRAIN loss:  0.759\n",
      "[epoch 11 Iteration 326/960] TRAIN loss:  0.656\n",
      "[epoch 11 Iteration 327/960] TRAIN loss:  0.529\n",
      "[epoch 11 Iteration 328/960] TRAIN loss:  0.835\n",
      "[epoch 11 Iteration 329/960] TRAIN loss:  0.598\n",
      "[epoch 11 Iteration 330/960] TRAIN loss:  0.651\n",
      "[epoch 11 Iteration 331/960] TRAIN loss:  0.757\n",
      "[epoch 11 Iteration 332/960] TRAIN loss:  0.515\n",
      "[epoch 11 Iteration 333/960] TRAIN loss:  1.018\n",
      "[epoch 11 Iteration 334/960] TRAIN loss:  0.895\n",
      "[epoch 11 Iteration 335/960] TRAIN loss:  0.660\n",
      "[epoch 11 Iteration 336/960] TRAIN loss:  0.672\n",
      "[epoch 11 Iteration 337/960] TRAIN loss:  0.681\n",
      "[epoch 11 Iteration 338/960] TRAIN loss:  0.918\n",
      "[epoch 11 Iteration 339/960] TRAIN loss:  0.764\n",
      "[epoch 11 Iteration 340/960] TRAIN loss:  0.852\n",
      "[epoch 11 Iteration 341/960] TRAIN loss:  0.802\n",
      "[epoch 11 Iteration 342/960] TRAIN loss:  0.614\n",
      "[epoch 11 Iteration 343/960] TRAIN loss:  0.680\n",
      "[epoch 11 Iteration 344/960] TRAIN loss:  0.578\n",
      "[epoch 11 Iteration 345/960] TRAIN loss:  0.744\n",
      "[epoch 11 Iteration 346/960] TRAIN loss:  0.588\n",
      "[epoch 11 Iteration 347/960] TRAIN loss:  0.724\n",
      "[epoch 11 Iteration 348/960] TRAIN loss:  0.820\n",
      "[epoch 11 Iteration 349/960] TRAIN loss:  0.707\n",
      "[epoch 11 Iteration 350/960] TRAIN loss:  0.671\n",
      "[epoch 11 Iteration 351/960] TRAIN loss:  0.576\n",
      "[epoch 11 Iteration 352/960] TRAIN loss:  0.606\n",
      "[epoch 11 Iteration 353/960] TRAIN loss:  0.447\n",
      "[epoch 11 Iteration 354/960] TRAIN loss:  0.667\n",
      "[epoch 11 Iteration 355/960] TRAIN loss:  0.532\n",
      "[epoch 11 Iteration 356/960] TRAIN loss:  0.546\n",
      "[epoch 11 Iteration 357/960] TRAIN loss:  0.699\n",
      "[epoch 11 Iteration 358/960] TRAIN loss:  0.499\n",
      "[epoch 11 Iteration 359/960] TRAIN loss:  0.744\n",
      "[epoch 11 Iteration 360/960] TRAIN loss:  0.628\n",
      "[epoch 11 Iteration 361/960] TRAIN loss:  0.768\n",
      "[epoch 11 Iteration 362/960] TRAIN loss:  0.498\n",
      "[epoch 11 Iteration 363/960] TRAIN loss:  0.731\n",
      "[epoch 11 Iteration 364/960] TRAIN loss:  0.415\n",
      "[epoch 11 Iteration 365/960] TRAIN loss:  0.633\n",
      "[epoch 11 Iteration 366/960] TRAIN loss:  0.842\n",
      "[epoch 11 Iteration 367/960] TRAIN loss:  0.542\n",
      "[epoch 11 Iteration 368/960] TRAIN loss:  0.709\n",
      "[epoch 11 Iteration 369/960] TRAIN loss:  0.587\n",
      "[epoch 11 Iteration 370/960] TRAIN loss:  0.589\n",
      "[epoch 11 Iteration 371/960] TRAIN loss:  0.930\n",
      "[epoch 11 Iteration 372/960] TRAIN loss:  0.621\n",
      "[epoch 11 Iteration 373/960] TRAIN loss:  0.496\n",
      "[epoch 11 Iteration 374/960] TRAIN loss:  0.799\n",
      "[epoch 11 Iteration 375/960] TRAIN loss:  0.767\n",
      "[epoch 11 Iteration 376/960] TRAIN loss:  0.775\n",
      "[epoch 11 Iteration 377/960] TRAIN loss:  0.562\n",
      "[epoch 11 Iteration 378/960] TRAIN loss:  0.579\n",
      "[epoch 11 Iteration 379/960] TRAIN loss:  0.685\n",
      "[epoch 11 Iteration 380/960] TRAIN loss:  0.909\n",
      "[epoch 11 Iteration 381/960] TRAIN loss:  0.693\n",
      "[epoch 11 Iteration 382/960] TRAIN loss:  0.615\n",
      "[epoch 11 Iteration 383/960] TRAIN loss:  0.631\n",
      "[epoch 11 Iteration 384/960] TRAIN loss:  0.703\n",
      "[epoch 11 Iteration 385/960] TRAIN loss:  0.485\n",
      "[epoch 11 Iteration 386/960] TRAIN loss:  0.609\n",
      "[epoch 11 Iteration 387/960] TRAIN loss:  0.692\n",
      "[epoch 11 Iteration 388/960] TRAIN loss:  0.701\n",
      "[epoch 11 Iteration 389/960] TRAIN loss:  0.601\n",
      "[epoch 11 Iteration 390/960] TRAIN loss:  0.685\n",
      "[epoch 11 Iteration 391/960] TRAIN loss:  0.427\n",
      "[epoch 11 Iteration 392/960] TRAIN loss:  0.647\n",
      "[epoch 11 Iteration 393/960] TRAIN loss:  0.529\n",
      "[epoch 11 Iteration 394/960] TRAIN loss:  0.587\n",
      "[epoch 11 Iteration 395/960] TRAIN loss:  1.047\n",
      "[epoch 11 Iteration 396/960] TRAIN loss:  0.721\n",
      "[epoch 11 Iteration 397/960] TRAIN loss:  0.587\n",
      "[epoch 11 Iteration 398/960] TRAIN loss:  0.728\n",
      "[epoch 11 Iteration 399/960] TRAIN loss:  0.595\n",
      "[epoch 11 Iteration 400/960] TRAIN loss:  0.731\n",
      "[epoch 11 Iteration 401/960] TRAIN loss:  0.613\n",
      "[epoch 11 Iteration 402/960] TRAIN loss:  0.631\n",
      "[epoch 11 Iteration 403/960] TRAIN loss:  0.749\n",
      "[epoch 11 Iteration 404/960] TRAIN loss:  0.559\n",
      "[epoch 11 Iteration 405/960] TRAIN loss:  0.828\n",
      "[epoch 11 Iteration 406/960] TRAIN loss:  0.671\n",
      "[epoch 11 Iteration 407/960] TRAIN loss:  0.426\n",
      "[epoch 11 Iteration 408/960] TRAIN loss:  0.471\n",
      "[epoch 11 Iteration 409/960] TRAIN loss:  0.826\n",
      "[epoch 11 Iteration 410/960] TRAIN loss:  0.606\n",
      "[epoch 11 Iteration 411/960] TRAIN loss:  0.781\n",
      "[epoch 11 Iteration 412/960] TRAIN loss:  0.691\n",
      "[epoch 11 Iteration 413/960] TRAIN loss:  0.525\n",
      "[epoch 11 Iteration 414/960] TRAIN loss:  0.615\n",
      "[epoch 11 Iteration 415/960] TRAIN loss:  0.889\n",
      "[epoch 11 Iteration 416/960] TRAIN loss:  0.637\n",
      "[epoch 11 Iteration 417/960] TRAIN loss:  0.564\n",
      "[epoch 11 Iteration 418/960] TRAIN loss:  0.715\n",
      "[epoch 11 Iteration 419/960] TRAIN loss:  0.691\n",
      "[epoch 11 Iteration 420/960] TRAIN loss:  0.527\n",
      "[epoch 11 Iteration 421/960] TRAIN loss:  0.650\n",
      "[epoch 11 Iteration 422/960] TRAIN loss:  0.535\n",
      "[epoch 11 Iteration 423/960] TRAIN loss:  0.657\n",
      "[epoch 11 Iteration 424/960] TRAIN loss:  0.635\n",
      "[epoch 11 Iteration 425/960] TRAIN loss:  0.596\n",
      "[epoch 11 Iteration 426/960] TRAIN loss:  0.682\n",
      "[epoch 11 Iteration 427/960] TRAIN loss:  0.564\n",
      "[epoch 11 Iteration 428/960] TRAIN loss:  0.710\n",
      "[epoch 11 Iteration 429/960] TRAIN loss:  0.677\n",
      "[epoch 11 Iteration 430/960] TRAIN loss:  0.537\n",
      "[epoch 11 Iteration 431/960] TRAIN loss:  0.745\n",
      "[epoch 11 Iteration 432/960] TRAIN loss:  0.693\n",
      "[epoch 11 Iteration 433/960] TRAIN loss:  0.658\n",
      "[epoch 11 Iteration 434/960] TRAIN loss:  0.696\n",
      "[epoch 11 Iteration 435/960] TRAIN loss:  0.538\n",
      "[epoch 11 Iteration 436/960] TRAIN loss:  0.800\n",
      "[epoch 11 Iteration 437/960] TRAIN loss:  0.626\n",
      "[epoch 11 Iteration 438/960] TRAIN loss:  0.335\n",
      "[epoch 11 Iteration 439/960] TRAIN loss:  0.578\n",
      "[epoch 11 Iteration 440/960] TRAIN loss:  0.899\n",
      "[epoch 11 Iteration 441/960] TRAIN loss:  0.603\n",
      "[epoch 11 Iteration 442/960] TRAIN loss:  0.689\n",
      "[epoch 11 Iteration 443/960] TRAIN loss:  0.444\n",
      "[epoch 11 Iteration 444/960] TRAIN loss:  0.752\n",
      "[epoch 11 Iteration 445/960] TRAIN loss:  0.613\n",
      "[epoch 11 Iteration 446/960] TRAIN loss:  0.596\n",
      "[epoch 11 Iteration 447/960] TRAIN loss:  0.656\n",
      "[epoch 11 Iteration 448/960] TRAIN loss:  0.547\n",
      "[epoch 11 Iteration 449/960] TRAIN loss:  0.530\n",
      "[epoch 11 Iteration 450/960] TRAIN loss:  0.511\n",
      "[epoch 11 Iteration 451/960] TRAIN loss:  0.539\n",
      "[epoch 11 Iteration 452/960] TRAIN loss:  0.615\n",
      "[epoch 11 Iteration 453/960] TRAIN loss:  0.606\n",
      "[epoch 11 Iteration 454/960] TRAIN loss:  0.571\n",
      "[epoch 11 Iteration 455/960] TRAIN loss:  0.517\n",
      "[epoch 11 Iteration 456/960] TRAIN loss:  0.957\n",
      "[epoch 11 Iteration 457/960] TRAIN loss:  0.625\n",
      "[epoch 11 Iteration 458/960] TRAIN loss:  0.606\n",
      "[epoch 11 Iteration 459/960] TRAIN loss:  0.451\n",
      "[epoch 11 Iteration 460/960] TRAIN loss:  0.595\n",
      "[epoch 11 Iteration 461/960] TRAIN loss:  0.748\n",
      "[epoch 11 Iteration 462/960] TRAIN loss:  0.633\n",
      "[epoch 11 Iteration 463/960] TRAIN loss:  0.552\n",
      "[epoch 11 Iteration 464/960] TRAIN loss:  0.663\n",
      "[epoch 11 Iteration 465/960] TRAIN loss:  0.626\n",
      "[epoch 11 Iteration 466/960] TRAIN loss:  0.865\n",
      "[epoch 11 Iteration 467/960] TRAIN loss:  0.709\n",
      "[epoch 11 Iteration 468/960] TRAIN loss:  0.797\n",
      "[epoch 11 Iteration 469/960] TRAIN loss:  0.820\n",
      "[epoch 11 Iteration 470/960] TRAIN loss:  0.734\n",
      "[epoch 11 Iteration 471/960] TRAIN loss:  0.722\n",
      "[epoch 11 Iteration 472/960] TRAIN loss:  0.654\n",
      "[epoch 11 Iteration 473/960] TRAIN loss:  0.620\n",
      "[epoch 11 Iteration 474/960] TRAIN loss:  0.324\n",
      "[epoch 11 Iteration 475/960] TRAIN loss:  0.465\n",
      "[epoch 11 Iteration 476/960] TRAIN loss:  0.861\n",
      "[epoch 11 Iteration 477/960] TRAIN loss:  0.646\n",
      "[epoch 11 Iteration 478/960] TRAIN loss:  0.722\n",
      "[epoch 11 Iteration 479/960] TRAIN loss:  0.556\n",
      "[epoch 11 Iteration 480/960] TRAIN loss:  0.712\n",
      "[epoch 11 Iteration 481/960] TRAIN loss:  0.784\n",
      "[epoch 11 Iteration 482/960] TRAIN loss:  0.650\n",
      "[epoch 11 Iteration 483/960] TRAIN loss:  0.514\n",
      "[epoch 11 Iteration 484/960] TRAIN loss:  0.466\n",
      "[epoch 11 Iteration 485/960] TRAIN loss:  0.840\n",
      "[epoch 11 Iteration 486/960] TRAIN loss:  0.632\n",
      "[epoch 11 Iteration 487/960] TRAIN loss:  0.898\n",
      "[epoch 11 Iteration 488/960] TRAIN loss:  0.555\n",
      "[epoch 11 Iteration 489/960] TRAIN loss:  0.535\n",
      "[epoch 11 Iteration 490/960] TRAIN loss:  0.733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11 Iteration 491/960] TRAIN loss:  0.608\n",
      "[epoch 11 Iteration 492/960] TRAIN loss:  0.704\n",
      "[epoch 11 Iteration 493/960] TRAIN loss:  0.648\n",
      "[epoch 11 Iteration 494/960] TRAIN loss:  0.719\n",
      "[epoch 11 Iteration 495/960] TRAIN loss:  0.452\n",
      "[epoch 11 Iteration 496/960] TRAIN loss:  0.694\n",
      "[epoch 11 Iteration 497/960] TRAIN loss:  0.801\n",
      "[epoch 11 Iteration 498/960] TRAIN loss:  0.527\n",
      "[epoch 11 Iteration 499/960] TRAIN loss:  0.776\n",
      "[epoch 11 Iteration 500/960] TRAIN loss:  0.603\n",
      "[epoch 11 Iteration 501/960] TRAIN loss:  0.698\n",
      "[epoch 11 Iteration 502/960] TRAIN loss:  0.592\n",
      "[epoch 11 Iteration 503/960] TRAIN loss:  0.675\n",
      "[epoch 11 Iteration 504/960] TRAIN loss:  0.989\n",
      "[epoch 11 Iteration 505/960] TRAIN loss:  0.839\n",
      "[epoch 11 Iteration 506/960] TRAIN loss:  0.730\n",
      "[epoch 11 Iteration 507/960] TRAIN loss:  0.532\n",
      "[epoch 11 Iteration 508/960] TRAIN loss:  0.604\n",
      "[epoch 11 Iteration 509/960] TRAIN loss:  0.744\n",
      "[epoch 11 Iteration 510/960] TRAIN loss:  0.565\n",
      "[epoch 11 Iteration 511/960] TRAIN loss:  0.759\n",
      "[epoch 11 Iteration 512/960] TRAIN loss:  0.695\n",
      "[epoch 11 Iteration 513/960] TRAIN loss:  0.934\n",
      "[epoch 11 Iteration 514/960] TRAIN loss:  0.733\n",
      "[epoch 11 Iteration 515/960] TRAIN loss:  0.968\n",
      "[epoch 11 Iteration 516/960] TRAIN loss:  0.782\n",
      "[epoch 11 Iteration 517/960] TRAIN loss:  0.716\n",
      "[epoch 11 Iteration 518/960] TRAIN loss:  0.740\n",
      "[epoch 11 Iteration 519/960] TRAIN loss:  0.610\n",
      "[epoch 11 Iteration 520/960] TRAIN loss:  0.440\n",
      "[epoch 11 Iteration 521/960] TRAIN loss:  0.673\n",
      "[epoch 11 Iteration 522/960] TRAIN loss:  0.653\n",
      "[epoch 11 Iteration 523/960] TRAIN loss:  0.587\n",
      "[epoch 11 Iteration 524/960] TRAIN loss:  0.710\n",
      "[epoch 11 Iteration 525/960] TRAIN loss:  0.488\n",
      "[epoch 11 Iteration 526/960] TRAIN loss:  0.619\n",
      "[epoch 11 Iteration 527/960] TRAIN loss:  0.870\n",
      "[epoch 11 Iteration 528/960] TRAIN loss:  0.643\n",
      "[epoch 11 Iteration 529/960] TRAIN loss:  0.711\n",
      "[epoch 11 Iteration 530/960] TRAIN loss:  0.583\n",
      "[epoch 11 Iteration 531/960] TRAIN loss:  0.753\n",
      "[epoch 11 Iteration 532/960] TRAIN loss:  0.533\n",
      "[epoch 11 Iteration 533/960] TRAIN loss:  0.577\n",
      "[epoch 11 Iteration 534/960] TRAIN loss:  0.906\n",
      "[epoch 11 Iteration 535/960] TRAIN loss:  0.643\n",
      "[epoch 11 Iteration 536/960] TRAIN loss:  0.522\n",
      "[epoch 11 Iteration 537/960] TRAIN loss:  0.696\n",
      "[epoch 11 Iteration 538/960] TRAIN loss:  0.480\n",
      "[epoch 11 Iteration 539/960] TRAIN loss:  0.625\n",
      "[epoch 11 Iteration 540/960] TRAIN loss:  0.662\n",
      "[epoch 11 Iteration 541/960] TRAIN loss:  0.861\n",
      "[epoch 11 Iteration 542/960] TRAIN loss:  0.684\n",
      "[epoch 11 Iteration 543/960] TRAIN loss:  0.771\n",
      "[epoch 11 Iteration 544/960] TRAIN loss:  0.837\n",
      "[epoch 11 Iteration 545/960] TRAIN loss:  0.625\n",
      "[epoch 11 Iteration 546/960] TRAIN loss:  0.516\n",
      "[epoch 11 Iteration 547/960] TRAIN loss:  0.618\n",
      "[epoch 11 Iteration 548/960] TRAIN loss:  0.477\n",
      "[epoch 11 Iteration 549/960] TRAIN loss:  0.570\n",
      "[epoch 11 Iteration 550/960] TRAIN loss:  0.709\n",
      "[epoch 11 Iteration 551/960] TRAIN loss:  0.729\n",
      "[epoch 11 Iteration 552/960] TRAIN loss:  0.771\n",
      "[epoch 11 Iteration 553/960] TRAIN loss:  0.490\n",
      "[epoch 11 Iteration 554/960] TRAIN loss:  0.601\n",
      "[epoch 11 Iteration 555/960] TRAIN loss:  0.478\n",
      "[epoch 11 Iteration 556/960] TRAIN loss:  0.830\n",
      "[epoch 11 Iteration 557/960] TRAIN loss:  0.347\n",
      "[epoch 11 Iteration 558/960] TRAIN loss:  0.545\n",
      "[epoch 11 Iteration 559/960] TRAIN loss:  0.668\n",
      "[epoch 11 Iteration 560/960] TRAIN loss:  0.778\n",
      "[epoch 11 Iteration 561/960] TRAIN loss:  0.693\n",
      "[epoch 11 Iteration 562/960] TRAIN loss:  0.694\n",
      "[epoch 11 Iteration 563/960] TRAIN loss:  0.721\n",
      "[epoch 11 Iteration 564/960] TRAIN loss:  0.687\n",
      "[epoch 11 Iteration 565/960] TRAIN loss:  0.750\n",
      "[epoch 11 Iteration 566/960] TRAIN loss:  0.590\n",
      "[epoch 11 Iteration 567/960] TRAIN loss:  0.558\n",
      "[epoch 11 Iteration 568/960] TRAIN loss:  0.715\n",
      "[epoch 11 Iteration 569/960] TRAIN loss:  0.671\n",
      "[epoch 11 Iteration 570/960] TRAIN loss:  0.394\n",
      "[epoch 11 Iteration 571/960] TRAIN loss:  0.450\n",
      "[epoch 11 Iteration 572/960] TRAIN loss:  0.657\n",
      "[epoch 11 Iteration 573/960] TRAIN loss:  0.526\n",
      "[epoch 11 Iteration 574/960] TRAIN loss:  0.726\n",
      "[epoch 11 Iteration 575/960] TRAIN loss:  0.701\n",
      "[epoch 11 Iteration 576/960] TRAIN loss:  0.683\n",
      "[epoch 11 Iteration 577/960] TRAIN loss:  0.983\n",
      "[epoch 11 Iteration 578/960] TRAIN loss:  0.678\n",
      "[epoch 11 Iteration 579/960] TRAIN loss:  0.998\n",
      "[epoch 11 Iteration 580/960] TRAIN loss:  0.503\n",
      "[epoch 11 Iteration 581/960] TRAIN loss:  0.794\n",
      "[epoch 11 Iteration 582/960] TRAIN loss:  1.124\n",
      "[epoch 11 Iteration 583/960] TRAIN loss:  0.966\n",
      "[epoch 11 Iteration 584/960] TRAIN loss:  1.015\n",
      "[epoch 11 Iteration 585/960] TRAIN loss:  0.775\n",
      "[epoch 11 Iteration 586/960] TRAIN loss:  0.838\n",
      "[epoch 11 Iteration 587/960] TRAIN loss:  0.561\n",
      "[epoch 11 Iteration 588/960] TRAIN loss:  0.733\n",
      "[epoch 11 Iteration 589/960] TRAIN loss:  0.551\n",
      "[epoch 11 Iteration 590/960] TRAIN loss:  0.668\n",
      "[epoch 11 Iteration 591/960] TRAIN loss:  0.600\n",
      "[epoch 11 Iteration 592/960] TRAIN loss:  1.071\n",
      "[epoch 11 Iteration 593/960] TRAIN loss:  0.418\n",
      "[epoch 11 Iteration 594/960] TRAIN loss:  0.643\n",
      "[epoch 11 Iteration 595/960] TRAIN loss:  0.758\n",
      "[epoch 11 Iteration 596/960] TRAIN loss:  0.579\n",
      "[epoch 11 Iteration 597/960] TRAIN loss:  0.639\n",
      "[epoch 11 Iteration 598/960] TRAIN loss:  0.583\n",
      "[epoch 11 Iteration 599/960] TRAIN loss:  0.502\n",
      "[epoch 11 Iteration 600/960] TRAIN loss:  0.881\n",
      "[epoch 11 Iteration 601/960] TRAIN loss:  0.857\n",
      "[epoch 11 Iteration 602/960] TRAIN loss:  0.596\n",
      "[epoch 11 Iteration 603/960] TRAIN loss:  0.527\n",
      "[epoch 11 Iteration 604/960] TRAIN loss:  0.753\n",
      "[epoch 11 Iteration 605/960] TRAIN loss:  0.644\n",
      "[epoch 11 Iteration 606/960] TRAIN loss:  0.678\n",
      "[epoch 11 Iteration 607/960] TRAIN loss:  0.870\n",
      "[epoch 11 Iteration 608/960] TRAIN loss:  0.742\n",
      "[epoch 11 Iteration 609/960] TRAIN loss:  0.594\n",
      "[epoch 11 Iteration 610/960] TRAIN loss:  0.800\n",
      "[epoch 11 Iteration 611/960] TRAIN loss:  0.666\n",
      "[epoch 11 Iteration 612/960] TRAIN loss:  0.600\n",
      "[epoch 11 Iteration 613/960] TRAIN loss:  0.586\n",
      "[epoch 11 Iteration 614/960] TRAIN loss:  0.442\n",
      "[epoch 11 Iteration 615/960] TRAIN loss:  0.775\n",
      "[epoch 11 Iteration 616/960] TRAIN loss:  0.658\n",
      "[epoch 11 Iteration 617/960] TRAIN loss:  0.718\n",
      "[epoch 11 Iteration 618/960] TRAIN loss:  0.587\n",
      "[epoch 11 Iteration 619/960] TRAIN loss:  0.851\n",
      "[epoch 11 Iteration 620/960] TRAIN loss:  0.454\n",
      "[epoch 11 Iteration 621/960] TRAIN loss:  0.588\n",
      "[epoch 11 Iteration 622/960] TRAIN loss:  0.542\n",
      "[epoch 11 Iteration 623/960] TRAIN loss:  0.642\n",
      "[epoch 11 Iteration 624/960] TRAIN loss:  0.800\n",
      "[epoch 11 Iteration 625/960] TRAIN loss:  0.698\n",
      "[epoch 11 Iteration 626/960] TRAIN loss:  0.746\n",
      "[epoch 11 Iteration 627/960] TRAIN loss:  0.643\n",
      "[epoch 11 Iteration 628/960] TRAIN loss:  0.710\n",
      "[epoch 11 Iteration 629/960] TRAIN loss:  0.518\n",
      "[epoch 11 Iteration 630/960] TRAIN loss:  0.746\n",
      "[epoch 11 Iteration 631/960] TRAIN loss:  0.676\n",
      "[epoch 11 Iteration 632/960] TRAIN loss:  0.623\n",
      "[epoch 11 Iteration 633/960] TRAIN loss:  0.726\n",
      "[epoch 11 Iteration 634/960] TRAIN loss:  0.885\n",
      "[epoch 11 Iteration 635/960] TRAIN loss:  0.458\n",
      "[epoch 11 Iteration 636/960] TRAIN loss:  0.575\n",
      "[epoch 11 Iteration 637/960] TRAIN loss:  0.703\n",
      "[epoch 11 Iteration 638/960] TRAIN loss:  0.725\n",
      "[epoch 11 Iteration 639/960] TRAIN loss:  0.748\n",
      "[epoch 11 Iteration 640/960] TRAIN loss:  0.683\n",
      "[epoch 11 Iteration 641/960] TRAIN loss:  0.637\n",
      "[epoch 11 Iteration 642/960] TRAIN loss:  0.834\n",
      "[epoch 11 Iteration 643/960] TRAIN loss:  0.608\n",
      "[epoch 11 Iteration 644/960] TRAIN loss:  0.555\n",
      "[epoch 11 Iteration 645/960] TRAIN loss:  0.754\n",
      "[epoch 11 Iteration 646/960] TRAIN loss:  0.596\n",
      "[epoch 11 Iteration 647/960] TRAIN loss:  0.765\n",
      "[epoch 11 Iteration 648/960] TRAIN loss:  0.846\n",
      "[epoch 11 Iteration 649/960] TRAIN loss:  0.984\n",
      "[epoch 11 Iteration 650/960] TRAIN loss:  0.645\n",
      "[epoch 11 Iteration 651/960] TRAIN loss:  0.566\n",
      "[epoch 11 Iteration 652/960] TRAIN loss:  0.552\n",
      "[epoch 11 Iteration 653/960] TRAIN loss:  0.803\n",
      "[epoch 11 Iteration 654/960] TRAIN loss:  0.554\n",
      "[epoch 11 Iteration 655/960] TRAIN loss:  0.580\n",
      "[epoch 11 Iteration 656/960] TRAIN loss:  0.778\n",
      "[epoch 11 Iteration 657/960] TRAIN loss:  0.775\n",
      "[epoch 11 Iteration 658/960] TRAIN loss:  0.645\n",
      "[epoch 11 Iteration 659/960] TRAIN loss:  0.619\n",
      "[epoch 11 Iteration 660/960] TRAIN loss:  0.690\n",
      "[epoch 11 Iteration 661/960] TRAIN loss:  0.568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11 Iteration 662/960] TRAIN loss:  0.624\n",
      "[epoch 11 Iteration 663/960] TRAIN loss:  0.400\n",
      "[epoch 11 Iteration 664/960] TRAIN loss:  0.591\n",
      "[epoch 11 Iteration 665/960] TRAIN loss:  0.669\n",
      "[epoch 11 Iteration 666/960] TRAIN loss:  0.766\n",
      "[epoch 11 Iteration 667/960] TRAIN loss:  0.849\n",
      "[epoch 11 Iteration 668/960] TRAIN loss:  0.544\n",
      "[epoch 11 Iteration 669/960] TRAIN loss:  0.835\n",
      "[epoch 11 Iteration 670/960] TRAIN loss:  0.622\n",
      "[epoch 11 Iteration 671/960] TRAIN loss:  0.414\n",
      "[epoch 11 Iteration 672/960] TRAIN loss:  0.756\n",
      "[epoch 11 Iteration 673/960] TRAIN loss:  0.442\n",
      "[epoch 11 Iteration 674/960] TRAIN loss:  0.560\n",
      "[epoch 11 Iteration 675/960] TRAIN loss:  0.558\n",
      "[epoch 11 Iteration 676/960] TRAIN loss:  0.766\n",
      "[epoch 11 Iteration 677/960] TRAIN loss:  0.582\n",
      "[epoch 11 Iteration 678/960] TRAIN loss:  0.911\n",
      "[epoch 11 Iteration 679/960] TRAIN loss:  0.740\n",
      "[epoch 11 Iteration 680/960] TRAIN loss:  0.802\n",
      "[epoch 11 Iteration 681/960] TRAIN loss:  0.717\n",
      "[epoch 11 Iteration 682/960] TRAIN loss:  0.731\n",
      "[epoch 11 Iteration 683/960] TRAIN loss:  0.755\n",
      "[epoch 11 Iteration 684/960] TRAIN loss:  0.933\n",
      "[epoch 11 Iteration 685/960] TRAIN loss:  0.623\n",
      "[epoch 11 Iteration 686/960] TRAIN loss:  0.777\n",
      "[epoch 11 Iteration 687/960] TRAIN loss:  0.640\n",
      "[epoch 11 Iteration 688/960] TRAIN loss:  0.765\n",
      "[epoch 11 Iteration 689/960] TRAIN loss:  0.595\n",
      "[epoch 11 Iteration 690/960] TRAIN loss:  0.753\n",
      "[epoch 11 Iteration 691/960] TRAIN loss:  1.137\n",
      "[epoch 11 Iteration 692/960] TRAIN loss:  0.552\n",
      "[epoch 11 Iteration 693/960] TRAIN loss:  0.764\n",
      "[epoch 11 Iteration 694/960] TRAIN loss:  0.945\n",
      "[epoch 11 Iteration 695/960] TRAIN loss:  0.783\n",
      "[epoch 11 Iteration 696/960] TRAIN loss:  0.512\n",
      "[epoch 11 Iteration 697/960] TRAIN loss:  0.551\n",
      "[epoch 11 Iteration 698/960] TRAIN loss:  0.537\n",
      "[epoch 11 Iteration 699/960] TRAIN loss:  0.728\n",
      "[epoch 11 Iteration 700/960] TRAIN loss:  0.455\n",
      "[epoch 11 Iteration 701/960] TRAIN loss:  0.854\n",
      "[epoch 11 Iteration 702/960] TRAIN loss:  0.866\n",
      "[epoch 11 Iteration 703/960] TRAIN loss:  0.754\n",
      "[epoch 11 Iteration 704/960] TRAIN loss:  0.738\n",
      "[epoch 11 Iteration 705/960] TRAIN loss:  0.899\n",
      "[epoch 11 Iteration 706/960] TRAIN loss:  0.516\n",
      "[epoch 11 Iteration 707/960] TRAIN loss:  0.684\n",
      "[epoch 11 Iteration 708/960] TRAIN loss:  0.572\n",
      "[epoch 11 Iteration 709/960] TRAIN loss:  0.787\n",
      "[epoch 11 Iteration 710/960] TRAIN loss:  0.725\n",
      "[epoch 11 Iteration 711/960] TRAIN loss:  0.678\n",
      "[epoch 11 Iteration 712/960] TRAIN loss:  0.547\n",
      "[epoch 11 Iteration 713/960] TRAIN loss:  0.487\n",
      "[epoch 11 Iteration 714/960] TRAIN loss:  0.727\n",
      "[epoch 11 Iteration 715/960] TRAIN loss:  0.582\n",
      "[epoch 11 Iteration 716/960] TRAIN loss:  0.799\n",
      "[epoch 11 Iteration 717/960] TRAIN loss:  0.997\n",
      "[epoch 11 Iteration 718/960] TRAIN loss:  0.556\n",
      "[epoch 11 Iteration 719/960] TRAIN loss:  0.648\n",
      "[epoch 11 Iteration 720/960] TRAIN loss:  0.548\n",
      "[epoch 11 Iteration 721/960] TRAIN loss:  0.673\n",
      "[epoch 11 Iteration 722/960] TRAIN loss:  0.714\n",
      "[epoch 11 Iteration 723/960] TRAIN loss:  0.299\n",
      "[epoch 11 Iteration 724/960] TRAIN loss:  0.435\n",
      "[epoch 11 Iteration 725/960] TRAIN loss:  0.567\n",
      "[epoch 11 Iteration 726/960] TRAIN loss:  0.875\n",
      "[epoch 11 Iteration 727/960] TRAIN loss:  0.606\n",
      "[epoch 11 Iteration 728/960] TRAIN loss:  0.522\n",
      "[epoch 11 Iteration 729/960] TRAIN loss:  0.818\n",
      "[epoch 11 Iteration 730/960] TRAIN loss:  0.747\n",
      "[epoch 11 Iteration 731/960] TRAIN loss:  0.446\n",
      "[epoch 11 Iteration 732/960] TRAIN loss:  0.674\n",
      "[epoch 11 Iteration 733/960] TRAIN loss:  0.682\n",
      "[epoch 11 Iteration 734/960] TRAIN loss:  0.810\n",
      "[epoch 11 Iteration 735/960] TRAIN loss:  0.415\n",
      "[epoch 11 Iteration 736/960] TRAIN loss:  0.797\n",
      "[epoch 11 Iteration 737/960] TRAIN loss:  0.666\n",
      "[epoch 11 Iteration 738/960] TRAIN loss:  0.689\n",
      "[epoch 11 Iteration 739/960] TRAIN loss:  0.514\n",
      "[epoch 11 Iteration 740/960] TRAIN loss:  0.555\n",
      "[epoch 11 Iteration 741/960] TRAIN loss:  0.644\n",
      "[epoch 11 Iteration 742/960] TRAIN loss:  0.663\n",
      "[epoch 11 Iteration 743/960] TRAIN loss:  0.775\n",
      "[epoch 11 Iteration 744/960] TRAIN loss:  0.754\n",
      "[epoch 11 Iteration 745/960] TRAIN loss:  0.588\n",
      "[epoch 11 Iteration 746/960] TRAIN loss:  0.933\n",
      "[epoch 11 Iteration 747/960] TRAIN loss:  0.649\n",
      "[epoch 11 Iteration 748/960] TRAIN loss:  0.741\n",
      "[epoch 11 Iteration 749/960] TRAIN loss:  0.626\n",
      "[epoch 11 Iteration 750/960] TRAIN loss:  0.718\n",
      "[epoch 11 Iteration 751/960] TRAIN loss:  0.437\n",
      "[epoch 11 Iteration 752/960] TRAIN loss:  0.675\n",
      "[epoch 11 Iteration 753/960] TRAIN loss:  1.165\n",
      "[epoch 11 Iteration 754/960] TRAIN loss:  1.085\n",
      "[epoch 11 Iteration 755/960] TRAIN loss:  0.587\n",
      "[epoch 11 Iteration 756/960] TRAIN loss:  0.626\n",
      "[epoch 11 Iteration 757/960] TRAIN loss:  0.737\n",
      "[epoch 11 Iteration 758/960] TRAIN loss:  0.691\n",
      "[epoch 11 Iteration 759/960] TRAIN loss:  0.507\n",
      "[epoch 11 Iteration 760/960] TRAIN loss:  0.611\n",
      "[epoch 11 Iteration 761/960] TRAIN loss:  0.679\n",
      "[epoch 11 Iteration 762/960] TRAIN loss:  0.675\n",
      "[epoch 11 Iteration 763/960] TRAIN loss:  0.550\n",
      "[epoch 11 Iteration 764/960] TRAIN loss:  0.663\n",
      "[epoch 11 Iteration 765/960] TRAIN loss:  0.684\n",
      "[epoch 11 Iteration 766/960] TRAIN loss:  0.688\n",
      "[epoch 11 Iteration 767/960] TRAIN loss:  0.713\n",
      "[epoch 11 Iteration 768/960] TRAIN loss:  0.418\n",
      "[epoch 11 Iteration 769/960] TRAIN loss:  0.665\n",
      "[epoch 11 Iteration 770/960] TRAIN loss:  0.676\n",
      "[epoch 11 Iteration 771/960] TRAIN loss:  0.560\n",
      "[epoch 11 Iteration 772/960] TRAIN loss:  1.038\n",
      "[epoch 11 Iteration 773/960] TRAIN loss:  0.715\n",
      "[epoch 11 Iteration 774/960] TRAIN loss:  0.821\n",
      "[epoch 11 Iteration 775/960] TRAIN loss:  0.561\n",
      "[epoch 11 Iteration 776/960] TRAIN loss:  0.645\n",
      "[epoch 11 Iteration 777/960] TRAIN loss:  0.714\n",
      "[epoch 11 Iteration 778/960] TRAIN loss:  0.515\n",
      "[epoch 11 Iteration 779/960] TRAIN loss:  0.670\n",
      "[epoch 11 Iteration 780/960] TRAIN loss:  0.556\n",
      "[epoch 11 Iteration 781/960] TRAIN loss:  0.821\n",
      "[epoch 11 Iteration 782/960] TRAIN loss:  0.775\n",
      "[epoch 11 Iteration 783/960] TRAIN loss:  0.530\n",
      "[epoch 11 Iteration 784/960] TRAIN loss:  0.589\n",
      "[epoch 11 Iteration 785/960] TRAIN loss:  0.877\n",
      "[epoch 11 Iteration 786/960] TRAIN loss:  0.716\n",
      "[epoch 11 Iteration 787/960] TRAIN loss:  0.558\n",
      "[epoch 11 Iteration 788/960] TRAIN loss:  0.607\n",
      "[epoch 11 Iteration 789/960] TRAIN loss:  0.805\n",
      "[epoch 11 Iteration 790/960] TRAIN loss:  0.711\n",
      "[epoch 11 Iteration 791/960] TRAIN loss:  0.683\n",
      "[epoch 11 Iteration 792/960] TRAIN loss:  1.025\n",
      "[epoch 11 Iteration 793/960] TRAIN loss:  0.608\n",
      "[epoch 11 Iteration 794/960] TRAIN loss:  0.598\n",
      "[epoch 11 Iteration 795/960] TRAIN loss:  0.769\n",
      "[epoch 11 Iteration 796/960] TRAIN loss:  0.723\n",
      "[epoch 11 Iteration 797/960] TRAIN loss:  0.610\n",
      "[epoch 11 Iteration 798/960] TRAIN loss:  0.597\n",
      "[epoch 11 Iteration 799/960] TRAIN loss:  0.668\n",
      "[epoch 11 Iteration 800/960] TRAIN loss:  0.550\n",
      "[epoch 11 Iteration 801/960] TRAIN loss:  0.681\n",
      "[epoch 11 Iteration 802/960] TRAIN loss:  0.835\n",
      "[epoch 11 Iteration 803/960] TRAIN loss:  0.710\n",
      "[epoch 11 Iteration 804/960] TRAIN loss:  0.659\n",
      "[epoch 11 Iteration 805/960] TRAIN loss:  0.687\n",
      "[epoch 11 Iteration 806/960] TRAIN loss:  0.861\n",
      "[epoch 11 Iteration 807/960] TRAIN loss:  0.569\n",
      "[epoch 11 Iteration 808/960] TRAIN loss:  0.612\n",
      "[epoch 11 Iteration 809/960] TRAIN loss:  1.013\n",
      "[epoch 11 Iteration 810/960] TRAIN loss:  0.657\n",
      "[epoch 11 Iteration 811/960] TRAIN loss:  0.590\n",
      "[epoch 11 Iteration 812/960] TRAIN loss:  0.630\n",
      "[epoch 11 Iteration 813/960] TRAIN loss:  0.981\n",
      "[epoch 11 Iteration 814/960] TRAIN loss:  0.794\n",
      "[epoch 11 Iteration 815/960] TRAIN loss:  1.048\n",
      "[epoch 11 Iteration 816/960] TRAIN loss:  0.890\n",
      "[epoch 11 Iteration 817/960] TRAIN loss:  0.838\n",
      "[epoch 11 Iteration 818/960] TRAIN loss:  0.582\n",
      "[epoch 11 Iteration 819/960] TRAIN loss:  0.488\n",
      "[epoch 11 Iteration 820/960] TRAIN loss:  0.650\n",
      "[epoch 11 Iteration 821/960] TRAIN loss:  0.477\n",
      "[epoch 11 Iteration 822/960] TRAIN loss:  0.456\n",
      "[epoch 11 Iteration 823/960] TRAIN loss:  0.731\n",
      "[epoch 11 Iteration 824/960] TRAIN loss:  0.591\n",
      "[epoch 11 Iteration 825/960] TRAIN loss:  0.715\n",
      "[epoch 11 Iteration 826/960] TRAIN loss:  0.786\n",
      "[epoch 11 Iteration 827/960] TRAIN loss:  0.585\n",
      "[epoch 11 Iteration 828/960] TRAIN loss:  0.676\n",
      "[epoch 11 Iteration 829/960] TRAIN loss:  0.725\n",
      "[epoch 11 Iteration 830/960] TRAIN loss:  0.737\n",
      "[epoch 11 Iteration 831/960] TRAIN loss:  0.819\n",
      "[epoch 11 Iteration 832/960] TRAIN loss:  0.572\n",
      "[epoch 11 Iteration 833/960] TRAIN loss:  0.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11 Iteration 834/960] TRAIN loss:  0.986\n",
      "[epoch 11 Iteration 835/960] TRAIN loss:  0.586\n",
      "[epoch 11 Iteration 836/960] TRAIN loss:  0.805\n",
      "[epoch 11 Iteration 837/960] TRAIN loss:  0.893\n",
      "[epoch 11 Iteration 838/960] TRAIN loss:  0.549\n",
      "[epoch 11 Iteration 839/960] TRAIN loss:  0.474\n",
      "[epoch 11 Iteration 840/960] TRAIN loss:  0.469\n",
      "[epoch 11 Iteration 841/960] TRAIN loss:  0.578\n",
      "[epoch 11 Iteration 842/960] TRAIN loss:  0.725\n",
      "[epoch 11 Iteration 843/960] TRAIN loss:  0.703\n",
      "[epoch 11 Iteration 844/960] TRAIN loss:  0.725\n",
      "[epoch 11 Iteration 845/960] TRAIN loss:  0.648\n",
      "[epoch 11 Iteration 846/960] TRAIN loss:  0.737\n",
      "[epoch 11 Iteration 847/960] TRAIN loss:  0.726\n",
      "[epoch 11 Iteration 848/960] TRAIN loss:  0.688\n",
      "[epoch 11 Iteration 849/960] TRAIN loss:  0.791\n",
      "[epoch 11 Iteration 850/960] TRAIN loss:  0.437\n",
      "[epoch 11 Iteration 851/960] TRAIN loss:  0.699\n",
      "[epoch 11 Iteration 852/960] TRAIN loss:  0.680\n",
      "[epoch 11 Iteration 853/960] TRAIN loss:  0.658\n",
      "[epoch 11 Iteration 854/960] TRAIN loss:  0.599\n",
      "[epoch 11 Iteration 855/960] TRAIN loss:  0.564\n",
      "[epoch 11 Iteration 856/960] TRAIN loss:  1.038\n",
      "[epoch 11 Iteration 857/960] TRAIN loss:  0.774\n",
      "[epoch 11 Iteration 858/960] TRAIN loss:  0.729\n",
      "[epoch 11 Iteration 859/960] TRAIN loss:  0.969\n",
      "[epoch 11 Iteration 860/960] TRAIN loss:  0.502\n",
      "[epoch 11 Iteration 861/960] TRAIN loss:  0.633\n",
      "[epoch 11 Iteration 862/960] TRAIN loss:  1.012\n",
      "[epoch 11 Iteration 863/960] TRAIN loss:  0.877\n",
      "[epoch 11 Iteration 864/960] TRAIN loss:  0.752\n",
      "[epoch 11 Iteration 865/960] TRAIN loss:  0.604\n",
      "[epoch 11 Iteration 866/960] TRAIN loss:  0.579\n",
      "[epoch 11 Iteration 867/960] TRAIN loss:  0.776\n",
      "[epoch 11 Iteration 868/960] TRAIN loss:  0.740\n",
      "[epoch 11 Iteration 869/960] TRAIN loss:  0.645\n",
      "[epoch 11 Iteration 870/960] TRAIN loss:  0.854\n",
      "[epoch 11 Iteration 871/960] TRAIN loss:  0.574\n",
      "[epoch 11 Iteration 872/960] TRAIN loss:  0.731\n",
      "[epoch 11 Iteration 873/960] TRAIN loss:  0.470\n",
      "[epoch 11 Iteration 874/960] TRAIN loss:  0.966\n",
      "[epoch 11 Iteration 875/960] TRAIN loss:  0.707\n",
      "[epoch 11 Iteration 876/960] TRAIN loss:  0.641\n",
      "[epoch 11 Iteration 877/960] TRAIN loss:  0.534\n",
      "[epoch 11 Iteration 878/960] TRAIN loss:  0.633\n",
      "[epoch 11 Iteration 879/960] TRAIN loss:  0.569\n",
      "[epoch 11 Iteration 880/960] TRAIN loss:  0.871\n",
      "[epoch 11 Iteration 881/960] TRAIN loss:  0.437\n",
      "[epoch 11 Iteration 882/960] TRAIN loss:  0.720\n",
      "[epoch 11 Iteration 883/960] TRAIN loss:  0.774\n",
      "[epoch 11 Iteration 884/960] TRAIN loss:  0.723\n",
      "[epoch 11 Iteration 885/960] TRAIN loss:  0.597\n",
      "[epoch 11 Iteration 886/960] TRAIN loss:  0.821\n",
      "[epoch 11 Iteration 887/960] TRAIN loss:  0.902\n",
      "[epoch 11 Iteration 888/960] TRAIN loss:  0.512\n",
      "[epoch 11 Iteration 889/960] TRAIN loss:  0.707\n",
      "[epoch 11 Iteration 890/960] TRAIN loss:  0.967\n",
      "[epoch 11 Iteration 891/960] TRAIN loss:  0.407\n",
      "[epoch 11 Iteration 892/960] TRAIN loss:  0.774\n",
      "[epoch 11 Iteration 893/960] TRAIN loss:  0.821\n",
      "[epoch 11 Iteration 894/960] TRAIN loss:  0.750\n",
      "[epoch 11 Iteration 895/960] TRAIN loss:  0.506\n",
      "[epoch 11 Iteration 896/960] TRAIN loss:  0.601\n",
      "[epoch 11 Iteration 897/960] TRAIN loss:  0.507\n",
      "[epoch 11 Iteration 898/960] TRAIN loss:  0.847\n",
      "[epoch 11 Iteration 899/960] TRAIN loss:  0.808\n",
      "[epoch 11 Iteration 900/960] TRAIN loss:  0.500\n",
      "[epoch 11 Iteration 901/960] TRAIN loss:  0.500\n",
      "[epoch 11 Iteration 902/960] TRAIN loss:  0.810\n",
      "[epoch 11 Iteration 903/960] TRAIN loss:  0.902\n",
      "[epoch 11 Iteration 904/960] TRAIN loss:  0.614\n",
      "[epoch 11 Iteration 905/960] TRAIN loss:  0.847\n",
      "[epoch 11 Iteration 906/960] TRAIN loss:  0.768\n",
      "[epoch 11 Iteration 907/960] TRAIN loss:  0.720\n",
      "[epoch 11 Iteration 908/960] TRAIN loss:  0.988\n",
      "[epoch 11 Iteration 909/960] TRAIN loss:  0.617\n",
      "[epoch 11 Iteration 910/960] TRAIN loss:  0.592\n",
      "[epoch 11 Iteration 911/960] TRAIN loss:  0.637\n",
      "[epoch 11 Iteration 912/960] TRAIN loss:  0.751\n",
      "[epoch 11 Iteration 913/960] TRAIN loss:  0.562\n",
      "[epoch 11 Iteration 914/960] TRAIN loss:  0.752\n",
      "[epoch 11 Iteration 915/960] TRAIN loss:  0.567\n",
      "[epoch 11 Iteration 916/960] TRAIN loss:  0.513\n",
      "[epoch 11 Iteration 917/960] TRAIN loss:  0.548\n",
      "[epoch 11 Iteration 918/960] TRAIN loss:  0.879\n",
      "[epoch 11 Iteration 919/960] TRAIN loss:  0.537\n",
      "[epoch 11 Iteration 920/960] TRAIN loss:  0.850\n",
      "[epoch 11 Iteration 921/960] TRAIN loss:  0.846\n",
      "[epoch 11 Iteration 922/960] TRAIN loss:  0.951\n",
      "[epoch 11 Iteration 923/960] TRAIN loss:  0.505\n",
      "[epoch 11 Iteration 924/960] TRAIN loss:  0.644\n",
      "[epoch 11 Iteration 925/960] TRAIN loss:  0.609\n",
      "[epoch 11 Iteration 926/960] TRAIN loss:  0.967\n",
      "[epoch 11 Iteration 927/960] TRAIN loss:  0.434\n",
      "[epoch 11 Iteration 928/960] TRAIN loss:  0.762\n",
      "[epoch 11 Iteration 929/960] TRAIN loss:  0.846\n",
      "[epoch 11 Iteration 930/960] TRAIN loss:  0.681\n",
      "[epoch 11 Iteration 931/960] TRAIN loss:  0.709\n",
      "[epoch 11 Iteration 932/960] TRAIN loss:  0.756\n",
      "[epoch 11 Iteration 933/960] TRAIN loss:  0.616\n",
      "[epoch 11 Iteration 934/960] TRAIN loss:  0.704\n",
      "[epoch 11 Iteration 935/960] TRAIN loss:  0.487\n",
      "[epoch 11 Iteration 936/960] TRAIN loss:  0.670\n",
      "[epoch 11 Iteration 937/960] TRAIN loss:  0.725\n",
      "[epoch 11 Iteration 938/960] TRAIN loss:  0.713\n",
      "[epoch 11 Iteration 939/960] TRAIN loss:  0.851\n",
      "[epoch 11 Iteration 940/960] TRAIN loss:  0.763\n",
      "[epoch 11 Iteration 941/960] TRAIN loss:  0.923\n",
      "[epoch 11 Iteration 942/960] TRAIN loss:  0.653\n",
      "[epoch 11 Iteration 943/960] TRAIN loss:  0.493\n",
      "[epoch 11 Iteration 944/960] TRAIN loss:  0.551\n",
      "[epoch 11 Iteration 945/960] TRAIN loss:  0.662\n",
      "[epoch 11 Iteration 946/960] TRAIN loss:  0.600\n",
      "[epoch 11 Iteration 947/960] TRAIN loss:  0.622\n",
      "[epoch 11 Iteration 948/960] TRAIN loss:  0.548\n",
      "[epoch 11 Iteration 949/960] TRAIN loss:  0.541\n",
      "[epoch 11 Iteration 950/960] TRAIN loss:  0.698\n",
      "[epoch 11 Iteration 951/960] TRAIN loss:  0.671\n",
      "[epoch 11 Iteration 952/960] TRAIN loss:  0.784\n",
      "[epoch 11 Iteration 953/960] TRAIN loss:  0.769\n",
      "[epoch 11 Iteration 954/960] TRAIN loss:  0.683\n",
      "[epoch 11 Iteration 955/960] TRAIN loss:  0.876\n",
      "[epoch 11 Iteration 956/960] TRAIN loss:  0.759\n",
      "[epoch 11 Iteration 957/960] TRAIN loss:  0.669\n",
      "[epoch 11 Iteration 958/960] TRAIN loss:  0.869\n",
      "[epoch 11 Iteration 959/960] TRAIN loss:  0.525\n",
      "[epoch 11/15] TRAIN acc/loss:  0.765/0.525\n",
      "[epoch 11/15] VAL acc/loss:  0.659/0.577\n",
      "[epoch 12 Iteration 0/960] TRAIN loss:  0.607\n",
      "[epoch 12 Iteration 1/960] TRAIN loss:  0.719\n",
      "[epoch 12 Iteration 2/960] TRAIN loss:  0.586\n",
      "[epoch 12 Iteration 3/960] TRAIN loss:  0.708\n",
      "[epoch 12 Iteration 4/960] TRAIN loss:  0.817\n",
      "[epoch 12 Iteration 5/960] TRAIN loss:  0.501\n",
      "[epoch 12 Iteration 6/960] TRAIN loss:  0.594\n",
      "[epoch 12 Iteration 7/960] TRAIN loss:  0.750\n",
      "[epoch 12 Iteration 8/960] TRAIN loss:  0.542\n",
      "[epoch 12 Iteration 9/960] TRAIN loss:  0.692\n",
      "[epoch 12 Iteration 10/960] TRAIN loss:  0.535\n",
      "[epoch 12 Iteration 11/960] TRAIN loss:  0.614\n",
      "[epoch 12 Iteration 12/960] TRAIN loss:  0.308\n",
      "[epoch 12 Iteration 13/960] TRAIN loss:  0.547\n",
      "[epoch 12 Iteration 14/960] TRAIN loss:  0.771\n",
      "[epoch 12 Iteration 15/960] TRAIN loss:  0.438\n",
      "[epoch 12 Iteration 16/960] TRAIN loss:  0.423\n",
      "[epoch 12 Iteration 17/960] TRAIN loss:  0.578\n",
      "[epoch 12 Iteration 18/960] TRAIN loss:  0.579\n",
      "[epoch 12 Iteration 19/960] TRAIN loss:  0.290\n",
      "[epoch 12 Iteration 20/960] TRAIN loss:  0.616\n",
      "[epoch 12 Iteration 21/960] TRAIN loss:  0.668\n",
      "[epoch 12 Iteration 22/960] TRAIN loss:  0.658\n",
      "[epoch 12 Iteration 23/960] TRAIN loss:  0.380\n",
      "[epoch 12 Iteration 24/960] TRAIN loss:  0.580\n",
      "[epoch 12 Iteration 25/960] TRAIN loss:  0.590\n",
      "[epoch 12 Iteration 26/960] TRAIN loss:  0.563\n",
      "[epoch 12 Iteration 27/960] TRAIN loss:  0.635\n",
      "[epoch 12 Iteration 28/960] TRAIN loss:  0.486\n",
      "[epoch 12 Iteration 29/960] TRAIN loss:  0.404\n",
      "[epoch 12 Iteration 30/960] TRAIN loss:  0.680\n",
      "[epoch 12 Iteration 31/960] TRAIN loss:  0.739\n",
      "[epoch 12 Iteration 32/960] TRAIN loss:  0.565\n",
      "[epoch 12 Iteration 33/960] TRAIN loss:  0.616\n",
      "[epoch 12 Iteration 34/960] TRAIN loss:  0.617\n",
      "[epoch 12 Iteration 35/960] TRAIN loss:  0.357\n",
      "[epoch 12 Iteration 36/960] TRAIN loss:  0.556\n",
      "[epoch 12 Iteration 37/960] TRAIN loss:  0.557\n",
      "[epoch 12 Iteration 38/960] TRAIN loss:  0.557\n",
      "[epoch 12 Iteration 39/960] TRAIN loss:  0.963\n",
      "[epoch 12 Iteration 40/960] TRAIN loss:  0.574\n",
      "[epoch 12 Iteration 41/960] TRAIN loss:  0.858\n",
      "[epoch 12 Iteration 42/960] TRAIN loss:  0.734\n",
      "[epoch 12 Iteration 43/960] TRAIN loss:  0.672\n",
      "[epoch 12 Iteration 44/960] TRAIN loss:  0.671\n",
      "[epoch 12 Iteration 45/960] TRAIN loss:  0.548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12 Iteration 46/960] TRAIN loss:  0.415\n",
      "[epoch 12 Iteration 47/960] TRAIN loss:  0.486\n",
      "[epoch 12 Iteration 48/960] TRAIN loss:  0.562\n",
      "[epoch 12 Iteration 49/960] TRAIN loss:  0.512\n",
      "[epoch 12 Iteration 50/960] TRAIN loss:  0.551\n",
      "[epoch 12 Iteration 51/960] TRAIN loss:  0.484\n",
      "[epoch 12 Iteration 52/960] TRAIN loss:  0.511\n",
      "[epoch 12 Iteration 53/960] TRAIN loss:  0.585\n",
      "[epoch 12 Iteration 54/960] TRAIN loss:  0.880\n",
      "[epoch 12 Iteration 55/960] TRAIN loss:  0.622\n",
      "[epoch 12 Iteration 56/960] TRAIN loss:  0.610\n",
      "[epoch 12 Iteration 57/960] TRAIN loss:  0.399\n",
      "[epoch 12 Iteration 58/960] TRAIN loss:  0.418\n",
      "[epoch 12 Iteration 59/960] TRAIN loss:  0.527\n",
      "[epoch 12 Iteration 60/960] TRAIN loss:  0.362\n",
      "[epoch 12 Iteration 61/960] TRAIN loss:  0.820\n",
      "[epoch 12 Iteration 62/960] TRAIN loss:  0.487\n",
      "[epoch 12 Iteration 63/960] TRAIN loss:  0.568\n",
      "[epoch 12 Iteration 64/960] TRAIN loss:  0.526\n",
      "[epoch 12 Iteration 65/960] TRAIN loss:  0.631\n",
      "[epoch 12 Iteration 66/960] TRAIN loss:  0.870\n",
      "[epoch 12 Iteration 67/960] TRAIN loss:  0.629\n",
      "[epoch 12 Iteration 68/960] TRAIN loss:  0.628\n",
      "[epoch 12 Iteration 69/960] TRAIN loss:  0.442\n",
      "[epoch 12 Iteration 70/960] TRAIN loss:  0.622\n",
      "[epoch 12 Iteration 71/960] TRAIN loss:  0.747\n",
      "[epoch 12 Iteration 72/960] TRAIN loss:  0.737\n",
      "[epoch 12 Iteration 73/960] TRAIN loss:  0.507\n",
      "[epoch 12 Iteration 74/960] TRAIN loss:  0.636\n",
      "[epoch 12 Iteration 75/960] TRAIN loss:  0.524\n",
      "[epoch 12 Iteration 76/960] TRAIN loss:  0.532\n",
      "[epoch 12 Iteration 77/960] TRAIN loss:  0.472\n",
      "[epoch 12 Iteration 78/960] TRAIN loss:  0.405\n",
      "[epoch 12 Iteration 79/960] TRAIN loss:  0.511\n",
      "[epoch 12 Iteration 80/960] TRAIN loss:  0.710\n",
      "[epoch 12 Iteration 81/960] TRAIN loss:  0.419\n",
      "[epoch 12 Iteration 82/960] TRAIN loss:  0.776\n",
      "[epoch 12 Iteration 83/960] TRAIN loss:  0.477\n",
      "[epoch 12 Iteration 84/960] TRAIN loss:  0.947\n",
      "[epoch 12 Iteration 85/960] TRAIN loss:  0.712\n",
      "[epoch 12 Iteration 86/960] TRAIN loss:  0.749\n",
      "[epoch 12 Iteration 87/960] TRAIN loss:  0.466\n",
      "[epoch 12 Iteration 88/960] TRAIN loss:  0.507\n",
      "[epoch 12 Iteration 89/960] TRAIN loss:  0.794\n",
      "[epoch 12 Iteration 90/960] TRAIN loss:  0.640\n",
      "[epoch 12 Iteration 91/960] TRAIN loss:  0.736\n",
      "[epoch 12 Iteration 92/960] TRAIN loss:  0.669\n",
      "[epoch 12 Iteration 93/960] TRAIN loss:  0.595\n",
      "[epoch 12 Iteration 94/960] TRAIN loss:  0.503\n",
      "[epoch 12 Iteration 95/960] TRAIN loss:  0.704\n",
      "[epoch 12 Iteration 96/960] TRAIN loss:  0.380\n",
      "[epoch 12 Iteration 97/960] TRAIN loss:  0.707\n",
      "[epoch 12 Iteration 98/960] TRAIN loss:  0.699\n",
      "[epoch 12 Iteration 99/960] TRAIN loss:  0.714\n",
      "[epoch 12 Iteration 100/960] TRAIN loss:  0.573\n",
      "[epoch 12 Iteration 101/960] TRAIN loss:  0.501\n",
      "[epoch 12 Iteration 102/960] TRAIN loss:  0.800\n",
      "[epoch 12 Iteration 103/960] TRAIN loss:  0.459\n",
      "[epoch 12 Iteration 104/960] TRAIN loss:  0.673\n",
      "[epoch 12 Iteration 105/960] TRAIN loss:  0.614\n",
      "[epoch 12 Iteration 106/960] TRAIN loss:  0.712\n",
      "[epoch 12 Iteration 107/960] TRAIN loss:  0.404\n",
      "[epoch 12 Iteration 108/960] TRAIN loss:  0.663\n",
      "[epoch 12 Iteration 109/960] TRAIN loss:  0.519\n",
      "[epoch 12 Iteration 110/960] TRAIN loss:  0.508\n",
      "[epoch 12 Iteration 111/960] TRAIN loss:  0.543\n",
      "[epoch 12 Iteration 112/960] TRAIN loss:  0.687\n",
      "[epoch 12 Iteration 113/960] TRAIN loss:  0.632\n",
      "[epoch 12 Iteration 114/960] TRAIN loss:  0.700\n",
      "[epoch 12 Iteration 115/960] TRAIN loss:  0.844\n",
      "[epoch 12 Iteration 116/960] TRAIN loss:  0.553\n",
      "[epoch 12 Iteration 117/960] TRAIN loss:  0.619\n",
      "[epoch 12 Iteration 118/960] TRAIN loss:  0.606\n",
      "[epoch 12 Iteration 119/960] TRAIN loss:  0.645\n",
      "[epoch 12 Iteration 120/960] TRAIN loss:  0.481\n",
      "[epoch 12 Iteration 121/960] TRAIN loss:  0.792\n",
      "[epoch 12 Iteration 122/960] TRAIN loss:  0.718\n",
      "[epoch 12 Iteration 123/960] TRAIN loss:  0.664\n",
      "[epoch 12 Iteration 124/960] TRAIN loss:  0.688\n",
      "[epoch 12 Iteration 125/960] TRAIN loss:  0.331\n",
      "[epoch 12 Iteration 126/960] TRAIN loss:  0.748\n",
      "[epoch 12 Iteration 127/960] TRAIN loss:  0.672\n",
      "[epoch 12 Iteration 128/960] TRAIN loss:  0.700\n",
      "[epoch 12 Iteration 129/960] TRAIN loss:  0.660\n",
      "[epoch 12 Iteration 130/960] TRAIN loss:  0.443\n",
      "[epoch 12 Iteration 131/960] TRAIN loss:  0.517\n",
      "[epoch 12 Iteration 132/960] TRAIN loss:  0.576\n",
      "[epoch 12 Iteration 133/960] TRAIN loss:  0.494\n",
      "[epoch 12 Iteration 134/960] TRAIN loss:  0.530\n",
      "[epoch 12 Iteration 135/960] TRAIN loss:  0.632\n",
      "[epoch 12 Iteration 136/960] TRAIN loss:  0.733\n",
      "[epoch 12 Iteration 137/960] TRAIN loss:  0.652\n",
      "[epoch 12 Iteration 138/960] TRAIN loss:  0.631\n",
      "[epoch 12 Iteration 139/960] TRAIN loss:  0.412\n",
      "[epoch 12 Iteration 140/960] TRAIN loss:  0.779\n",
      "[epoch 12 Iteration 141/960] TRAIN loss:  0.591\n",
      "[epoch 12 Iteration 142/960] TRAIN loss:  0.570\n",
      "[epoch 12 Iteration 143/960] TRAIN loss:  0.622\n",
      "[epoch 12 Iteration 144/960] TRAIN loss:  0.517\n",
      "[epoch 12 Iteration 145/960] TRAIN loss:  0.542\n",
      "[epoch 12 Iteration 146/960] TRAIN loss:  0.386\n",
      "[epoch 12 Iteration 147/960] TRAIN loss:  0.678\n",
      "[epoch 12 Iteration 148/960] TRAIN loss:  0.616\n",
      "[epoch 12 Iteration 149/960] TRAIN loss:  0.448\n",
      "[epoch 12 Iteration 150/960] TRAIN loss:  0.467\n",
      "[epoch 12 Iteration 151/960] TRAIN loss:  0.477\n",
      "[epoch 12 Iteration 152/960] TRAIN loss:  0.632\n",
      "[epoch 12 Iteration 153/960] TRAIN loss:  0.697\n",
      "[epoch 12 Iteration 154/960] TRAIN loss:  0.609\n",
      "[epoch 12 Iteration 155/960] TRAIN loss:  0.389\n",
      "[epoch 12 Iteration 156/960] TRAIN loss:  0.839\n",
      "[epoch 12 Iteration 157/960] TRAIN loss:  0.633\n",
      "[epoch 12 Iteration 158/960] TRAIN loss:  0.801\n",
      "[epoch 12 Iteration 159/960] TRAIN loss:  0.734\n",
      "[epoch 12 Iteration 160/960] TRAIN loss:  0.643\n",
      "[epoch 12 Iteration 161/960] TRAIN loss:  0.578\n",
      "[epoch 12 Iteration 162/960] TRAIN loss:  0.671\n",
      "[epoch 12 Iteration 163/960] TRAIN loss:  0.600\n",
      "[epoch 12 Iteration 164/960] TRAIN loss:  0.842\n",
      "[epoch 12 Iteration 165/960] TRAIN loss:  0.673\n",
      "[epoch 12 Iteration 166/960] TRAIN loss:  0.587\n",
      "[epoch 12 Iteration 167/960] TRAIN loss:  0.376\n",
      "[epoch 12 Iteration 168/960] TRAIN loss:  0.441\n",
      "[epoch 12 Iteration 169/960] TRAIN loss:  0.944\n",
      "[epoch 12 Iteration 170/960] TRAIN loss:  0.538\n",
      "[epoch 12 Iteration 171/960] TRAIN loss:  0.907\n",
      "[epoch 12 Iteration 172/960] TRAIN loss:  0.400\n",
      "[epoch 12 Iteration 173/960] TRAIN loss:  0.737\n",
      "[epoch 12 Iteration 174/960] TRAIN loss:  0.500\n",
      "[epoch 12 Iteration 175/960] TRAIN loss:  0.648\n",
      "[epoch 12 Iteration 176/960] TRAIN loss:  0.440\n",
      "[epoch 12 Iteration 177/960] TRAIN loss:  0.594\n",
      "[epoch 12 Iteration 178/960] TRAIN loss:  0.664\n",
      "[epoch 12 Iteration 179/960] TRAIN loss:  0.787\n",
      "[epoch 12 Iteration 180/960] TRAIN loss:  0.367\n",
      "[epoch 12 Iteration 181/960] TRAIN loss:  0.695\n",
      "[epoch 12 Iteration 182/960] TRAIN loss:  0.713\n",
      "[epoch 12 Iteration 183/960] TRAIN loss:  0.445\n",
      "[epoch 12 Iteration 184/960] TRAIN loss:  0.760\n",
      "[epoch 12 Iteration 185/960] TRAIN loss:  0.787\n",
      "[epoch 12 Iteration 186/960] TRAIN loss:  0.488\n",
      "[epoch 12 Iteration 187/960] TRAIN loss:  0.460\n",
      "[epoch 12 Iteration 188/960] TRAIN loss:  0.617\n",
      "[epoch 12 Iteration 189/960] TRAIN loss:  0.614\n",
      "[epoch 12 Iteration 190/960] TRAIN loss:  0.475\n",
      "[epoch 12 Iteration 191/960] TRAIN loss:  0.518\n",
      "[epoch 12 Iteration 192/960] TRAIN loss:  0.554\n",
      "[epoch 12 Iteration 193/960] TRAIN loss:  0.555\n",
      "[epoch 12 Iteration 194/960] TRAIN loss:  0.614\n",
      "[epoch 12 Iteration 195/960] TRAIN loss:  0.600\n",
      "[epoch 12 Iteration 196/960] TRAIN loss:  0.521\n",
      "[epoch 12 Iteration 197/960] TRAIN loss:  0.479\n",
      "[epoch 12 Iteration 198/960] TRAIN loss:  0.568\n",
      "[epoch 12 Iteration 199/960] TRAIN loss:  0.628\n",
      "[epoch 12 Iteration 200/960] TRAIN loss:  0.658\n",
      "[epoch 12 Iteration 201/960] TRAIN loss:  0.657\n",
      "[epoch 12 Iteration 202/960] TRAIN loss:  0.716\n",
      "[epoch 12 Iteration 203/960] TRAIN loss:  0.457\n",
      "[epoch 12 Iteration 204/960] TRAIN loss:  0.927\n",
      "[epoch 12 Iteration 205/960] TRAIN loss:  0.741\n",
      "[epoch 12 Iteration 206/960] TRAIN loss:  0.668\n",
      "[epoch 12 Iteration 207/960] TRAIN loss:  0.710\n",
      "[epoch 12 Iteration 208/960] TRAIN loss:  0.460\n",
      "[epoch 12 Iteration 209/960] TRAIN loss:  0.437\n",
      "[epoch 12 Iteration 210/960] TRAIN loss:  0.563\n",
      "[epoch 12 Iteration 211/960] TRAIN loss:  0.791\n",
      "[epoch 12 Iteration 212/960] TRAIN loss:  0.579\n",
      "[epoch 12 Iteration 213/960] TRAIN loss:  0.628\n",
      "[epoch 12 Iteration 214/960] TRAIN loss:  0.605\n",
      "[epoch 12 Iteration 215/960] TRAIN loss:  0.553\n",
      "[epoch 12 Iteration 216/960] TRAIN loss:  0.652\n",
      "[epoch 12 Iteration 217/960] TRAIN loss:  0.832\n",
      "[epoch 12 Iteration 218/960] TRAIN loss:  0.824\n",
      "[epoch 12 Iteration 219/960] TRAIN loss:  0.715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12 Iteration 220/960] TRAIN loss:  0.577\n",
      "[epoch 12 Iteration 221/960] TRAIN loss:  0.563\n",
      "[epoch 12 Iteration 222/960] TRAIN loss:  0.856\n",
      "[epoch 12 Iteration 223/960] TRAIN loss:  0.689\n",
      "[epoch 12 Iteration 224/960] TRAIN loss:  0.750\n",
      "[epoch 12 Iteration 225/960] TRAIN loss:  0.699\n",
      "[epoch 12 Iteration 226/960] TRAIN loss:  0.575\n",
      "[epoch 12 Iteration 227/960] TRAIN loss:  0.762\n",
      "[epoch 12 Iteration 228/960] TRAIN loss:  0.614\n",
      "[epoch 12 Iteration 229/960] TRAIN loss:  0.674\n",
      "[epoch 12 Iteration 230/960] TRAIN loss:  0.603\n",
      "[epoch 12 Iteration 231/960] TRAIN loss:  0.544\n",
      "[epoch 12 Iteration 232/960] TRAIN loss:  0.598\n",
      "[epoch 12 Iteration 233/960] TRAIN loss:  0.669\n",
      "[epoch 12 Iteration 234/960] TRAIN loss:  0.549\n",
      "[epoch 12 Iteration 235/960] TRAIN loss:  0.580\n",
      "[epoch 12 Iteration 236/960] TRAIN loss:  0.549\n",
      "[epoch 12 Iteration 237/960] TRAIN loss:  0.576\n",
      "[epoch 12 Iteration 238/960] TRAIN loss:  0.756\n",
      "[epoch 12 Iteration 239/960] TRAIN loss:  0.584\n",
      "[epoch 12 Iteration 240/960] TRAIN loss:  0.507\n",
      "[epoch 12 Iteration 241/960] TRAIN loss:  0.581\n",
      "[epoch 12 Iteration 242/960] TRAIN loss:  0.356\n",
      "[epoch 12 Iteration 243/960] TRAIN loss:  0.483\n",
      "[epoch 12 Iteration 244/960] TRAIN loss:  0.719\n",
      "[epoch 12 Iteration 245/960] TRAIN loss:  0.641\n",
      "[epoch 12 Iteration 246/960] TRAIN loss:  0.499\n",
      "[epoch 12 Iteration 247/960] TRAIN loss:  0.565\n",
      "[epoch 12 Iteration 248/960] TRAIN loss:  0.623\n",
      "[epoch 12 Iteration 249/960] TRAIN loss:  0.539\n",
      "[epoch 12 Iteration 250/960] TRAIN loss:  0.875\n",
      "[epoch 12 Iteration 251/960] TRAIN loss:  0.719\n",
      "[epoch 12 Iteration 252/960] TRAIN loss:  0.727\n",
      "[epoch 12 Iteration 253/960] TRAIN loss:  0.766\n",
      "[epoch 12 Iteration 254/960] TRAIN loss:  0.787\n",
      "[epoch 12 Iteration 255/960] TRAIN loss:  0.618\n",
      "[epoch 12 Iteration 256/960] TRAIN loss:  0.582\n",
      "[epoch 12 Iteration 257/960] TRAIN loss:  0.615\n",
      "[epoch 12 Iteration 258/960] TRAIN loss:  0.560\n",
      "[epoch 12 Iteration 259/960] TRAIN loss:  0.595\n",
      "[epoch 12 Iteration 260/960] TRAIN loss:  0.738\n",
      "[epoch 12 Iteration 261/960] TRAIN loss:  0.602\n",
      "[epoch 12 Iteration 262/960] TRAIN loss:  0.535\n",
      "[epoch 12 Iteration 263/960] TRAIN loss:  0.580\n",
      "[epoch 12 Iteration 264/960] TRAIN loss:  0.599\n",
      "[epoch 12 Iteration 265/960] TRAIN loss:  0.534\n",
      "[epoch 12 Iteration 266/960] TRAIN loss:  0.619\n",
      "[epoch 12 Iteration 267/960] TRAIN loss:  0.565\n",
      "[epoch 12 Iteration 268/960] TRAIN loss:  0.511\n",
      "[epoch 12 Iteration 269/960] TRAIN loss:  0.341\n",
      "[epoch 12 Iteration 270/960] TRAIN loss:  0.400\n",
      "[epoch 12 Iteration 271/960] TRAIN loss:  0.751\n",
      "[epoch 12 Iteration 272/960] TRAIN loss:  0.356\n",
      "[epoch 12 Iteration 273/960] TRAIN loss:  0.861\n",
      "[epoch 12 Iteration 274/960] TRAIN loss:  0.449\n",
      "[epoch 12 Iteration 275/960] TRAIN loss:  0.593\n",
      "[epoch 12 Iteration 276/960] TRAIN loss:  0.704\n",
      "[epoch 12 Iteration 277/960] TRAIN loss:  0.580\n",
      "[epoch 12 Iteration 278/960] TRAIN loss:  0.935\n",
      "[epoch 12 Iteration 279/960] TRAIN loss:  0.661\n",
      "[epoch 12 Iteration 280/960] TRAIN loss:  0.652\n",
      "[epoch 12 Iteration 281/960] TRAIN loss:  0.548\n",
      "[epoch 12 Iteration 282/960] TRAIN loss:  0.610\n",
      "[epoch 12 Iteration 283/960] TRAIN loss:  0.678\n",
      "[epoch 12 Iteration 284/960] TRAIN loss:  0.528\n",
      "[epoch 12 Iteration 285/960] TRAIN loss:  0.779\n",
      "[epoch 12 Iteration 286/960] TRAIN loss:  0.574\n",
      "[epoch 12 Iteration 287/960] TRAIN loss:  0.683\n",
      "[epoch 12 Iteration 288/960] TRAIN loss:  0.779\n",
      "[epoch 12 Iteration 289/960] TRAIN loss:  0.548\n",
      "[epoch 12 Iteration 290/960] TRAIN loss:  0.494\n",
      "[epoch 12 Iteration 291/960] TRAIN loss:  0.657\n",
      "[epoch 12 Iteration 292/960] TRAIN loss:  0.495\n",
      "[epoch 12 Iteration 293/960] TRAIN loss:  0.906\n",
      "[epoch 12 Iteration 294/960] TRAIN loss:  0.849\n",
      "[epoch 12 Iteration 295/960] TRAIN loss:  0.442\n",
      "[epoch 12 Iteration 296/960] TRAIN loss:  0.582\n",
      "[epoch 12 Iteration 297/960] TRAIN loss:  0.526\n",
      "[epoch 12 Iteration 298/960] TRAIN loss:  0.623\n",
      "[epoch 12 Iteration 299/960] TRAIN loss:  0.461\n",
      "[epoch 12 Iteration 300/960] TRAIN loss:  0.580\n",
      "[epoch 12 Iteration 301/960] TRAIN loss:  0.488\n",
      "[epoch 12 Iteration 302/960] TRAIN loss:  0.719\n",
      "[epoch 12 Iteration 303/960] TRAIN loss:  0.743\n",
      "[epoch 12 Iteration 304/960] TRAIN loss:  0.486\n",
      "[epoch 12 Iteration 305/960] TRAIN loss:  0.690\n",
      "[epoch 12 Iteration 306/960] TRAIN loss:  0.800\n",
      "[epoch 12 Iteration 307/960] TRAIN loss:  0.732\n",
      "[epoch 12 Iteration 308/960] TRAIN loss:  0.921\n",
      "[epoch 12 Iteration 309/960] TRAIN loss:  0.609\n",
      "[epoch 12 Iteration 310/960] TRAIN loss:  0.653\n",
      "[epoch 12 Iteration 311/960] TRAIN loss:  0.705\n",
      "[epoch 12 Iteration 312/960] TRAIN loss:  0.720\n",
      "[epoch 12 Iteration 313/960] TRAIN loss:  0.591\n",
      "[epoch 12 Iteration 314/960] TRAIN loss:  0.503\n",
      "[epoch 12 Iteration 315/960] TRAIN loss:  1.000\n",
      "[epoch 12 Iteration 316/960] TRAIN loss:  0.656\n",
      "[epoch 12 Iteration 317/960] TRAIN loss:  0.548\n",
      "[epoch 12 Iteration 318/960] TRAIN loss:  0.695\n",
      "[epoch 12 Iteration 319/960] TRAIN loss:  0.803\n",
      "[epoch 12 Iteration 320/960] TRAIN loss:  0.422\n",
      "[epoch 12 Iteration 321/960] TRAIN loss:  0.720\n",
      "[epoch 12 Iteration 322/960] TRAIN loss:  0.651\n",
      "[epoch 12 Iteration 323/960] TRAIN loss:  0.699\n",
      "[epoch 12 Iteration 324/960] TRAIN loss:  0.763\n",
      "[epoch 12 Iteration 325/960] TRAIN loss:  0.589\n",
      "[epoch 12 Iteration 326/960] TRAIN loss:  0.656\n",
      "[epoch 12 Iteration 327/960] TRAIN loss:  0.688\n",
      "[epoch 12 Iteration 328/960] TRAIN loss:  0.326\n",
      "[epoch 12 Iteration 329/960] TRAIN loss:  0.440\n",
      "[epoch 12 Iteration 330/960] TRAIN loss:  0.588\n",
      "[epoch 12 Iteration 331/960] TRAIN loss:  0.516\n",
      "[epoch 12 Iteration 332/960] TRAIN loss:  0.739\n",
      "[epoch 12 Iteration 333/960] TRAIN loss:  0.723\n",
      "[epoch 12 Iteration 334/960] TRAIN loss:  0.566\n",
      "[epoch 12 Iteration 335/960] TRAIN loss:  0.483\n",
      "[epoch 12 Iteration 336/960] TRAIN loss:  0.418\n",
      "[epoch 12 Iteration 337/960] TRAIN loss:  0.621\n",
      "[epoch 12 Iteration 338/960] TRAIN loss:  0.413\n",
      "[epoch 12 Iteration 339/960] TRAIN loss:  0.608\n",
      "[epoch 12 Iteration 340/960] TRAIN loss:  0.629\n",
      "[epoch 12 Iteration 341/960] TRAIN loss:  0.866\n",
      "[epoch 12 Iteration 342/960] TRAIN loss:  0.669\n",
      "[epoch 12 Iteration 343/960] TRAIN loss:  0.646\n",
      "[epoch 12 Iteration 344/960] TRAIN loss:  0.492\n",
      "[epoch 12 Iteration 345/960] TRAIN loss:  0.480\n",
      "[epoch 12 Iteration 346/960] TRAIN loss:  0.554\n",
      "[epoch 12 Iteration 347/960] TRAIN loss:  0.793\n",
      "[epoch 12 Iteration 348/960] TRAIN loss:  0.561\n",
      "[epoch 12 Iteration 349/960] TRAIN loss:  0.613\n",
      "[epoch 12 Iteration 350/960] TRAIN loss:  0.613\n",
      "[epoch 12 Iteration 351/960] TRAIN loss:  0.452\n",
      "[epoch 12 Iteration 352/960] TRAIN loss:  0.717\n",
      "[epoch 12 Iteration 353/960] TRAIN loss:  0.673\n",
      "[epoch 12 Iteration 354/960] TRAIN loss:  0.491\n",
      "[epoch 12 Iteration 355/960] TRAIN loss:  0.601\n",
      "[epoch 12 Iteration 356/960] TRAIN loss:  0.410\n",
      "[epoch 12 Iteration 357/960] TRAIN loss:  0.625\n",
      "[epoch 12 Iteration 358/960] TRAIN loss:  0.708\n",
      "[epoch 12 Iteration 359/960] TRAIN loss:  0.613\n",
      "[epoch 12 Iteration 360/960] TRAIN loss:  0.365\n",
      "[epoch 12 Iteration 361/960] TRAIN loss:  0.566\n",
      "[epoch 12 Iteration 362/960] TRAIN loss:  0.489\n",
      "[epoch 12 Iteration 363/960] TRAIN loss:  0.567\n",
      "[epoch 12 Iteration 364/960] TRAIN loss:  0.715\n",
      "[epoch 12 Iteration 365/960] TRAIN loss:  0.696\n",
      "[epoch 12 Iteration 366/960] TRAIN loss:  0.594\n",
      "[epoch 12 Iteration 367/960] TRAIN loss:  0.729\n",
      "[epoch 12 Iteration 368/960] TRAIN loss:  0.718\n",
      "[epoch 12 Iteration 369/960] TRAIN loss:  0.713\n",
      "[epoch 12 Iteration 370/960] TRAIN loss:  0.598\n",
      "[epoch 12 Iteration 371/960] TRAIN loss:  0.784\n",
      "[epoch 12 Iteration 372/960] TRAIN loss:  0.622\n",
      "[epoch 12 Iteration 373/960] TRAIN loss:  0.537\n",
      "[epoch 12 Iteration 374/960] TRAIN loss:  0.689\n",
      "[epoch 12 Iteration 375/960] TRAIN loss:  0.732\n",
      "[epoch 12 Iteration 376/960] TRAIN loss:  0.669\n",
      "[epoch 12 Iteration 377/960] TRAIN loss:  0.779\n",
      "[epoch 12 Iteration 378/960] TRAIN loss:  0.669\n",
      "[epoch 12 Iteration 379/960] TRAIN loss:  0.527\n",
      "[epoch 12 Iteration 380/960] TRAIN loss:  0.689\n",
      "[epoch 12 Iteration 381/960] TRAIN loss:  0.821\n",
      "[epoch 12 Iteration 382/960] TRAIN loss:  0.694\n",
      "[epoch 12 Iteration 383/960] TRAIN loss:  0.564\n",
      "[epoch 12 Iteration 384/960] TRAIN loss:  0.811\n",
      "[epoch 12 Iteration 385/960] TRAIN loss:  0.901\n",
      "[epoch 12 Iteration 386/960] TRAIN loss:  0.634\n",
      "[epoch 12 Iteration 387/960] TRAIN loss:  0.634\n",
      "[epoch 12 Iteration 388/960] TRAIN loss:  0.747\n",
      "[epoch 12 Iteration 389/960] TRAIN loss:  0.672\n",
      "[epoch 12 Iteration 390/960] TRAIN loss:  0.878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12 Iteration 391/960] TRAIN loss:  0.539\n",
      "[epoch 12 Iteration 392/960] TRAIN loss:  0.564\n",
      "[epoch 12 Iteration 393/960] TRAIN loss:  0.572\n",
      "[epoch 12 Iteration 394/960] TRAIN loss:  0.776\n",
      "[epoch 12 Iteration 395/960] TRAIN loss:  0.680\n",
      "[epoch 12 Iteration 396/960] TRAIN loss:  0.632\n",
      "[epoch 12 Iteration 397/960] TRAIN loss:  0.621\n",
      "[epoch 12 Iteration 398/960] TRAIN loss:  0.575\n",
      "[epoch 12 Iteration 399/960] TRAIN loss:  0.692\n",
      "[epoch 12 Iteration 400/960] TRAIN loss:  0.568\n",
      "[epoch 12 Iteration 401/960] TRAIN loss:  0.648\n",
      "[epoch 12 Iteration 402/960] TRAIN loss:  0.672\n",
      "[epoch 12 Iteration 403/960] TRAIN loss:  0.593\n",
      "[epoch 12 Iteration 404/960] TRAIN loss:  0.511\n",
      "[epoch 12 Iteration 405/960] TRAIN loss:  0.450\n",
      "[epoch 12 Iteration 406/960] TRAIN loss:  0.563\n",
      "[epoch 12 Iteration 407/960] TRAIN loss:  0.663\n",
      "[epoch 12 Iteration 408/960] TRAIN loss:  0.533\n",
      "[epoch 12 Iteration 409/960] TRAIN loss:  0.664\n",
      "[epoch 12 Iteration 410/960] TRAIN loss:  0.570\n",
      "[epoch 12 Iteration 411/960] TRAIN loss:  0.864\n",
      "[epoch 12 Iteration 412/960] TRAIN loss:  0.734\n",
      "[epoch 12 Iteration 413/960] TRAIN loss:  0.556\n",
      "[epoch 12 Iteration 414/960] TRAIN loss:  0.469\n",
      "[epoch 12 Iteration 415/960] TRAIN loss:  0.595\n",
      "[epoch 12 Iteration 416/960] TRAIN loss:  0.572\n",
      "[epoch 12 Iteration 417/960] TRAIN loss:  0.852\n",
      "[epoch 12 Iteration 418/960] TRAIN loss:  0.572\n",
      "[epoch 12 Iteration 419/960] TRAIN loss:  0.808\n",
      "[epoch 12 Iteration 420/960] TRAIN loss:  0.555\n",
      "[epoch 12 Iteration 421/960] TRAIN loss:  0.654\n",
      "[epoch 12 Iteration 422/960] TRAIN loss:  0.502\n",
      "[epoch 12 Iteration 423/960] TRAIN loss:  0.434\n",
      "[epoch 12 Iteration 424/960] TRAIN loss:  0.740\n",
      "[epoch 12 Iteration 425/960] TRAIN loss:  0.608\n",
      "[epoch 12 Iteration 426/960] TRAIN loss:  0.909\n",
      "[epoch 12 Iteration 427/960] TRAIN loss:  0.607\n",
      "[epoch 12 Iteration 428/960] TRAIN loss:  0.596\n",
      "[epoch 12 Iteration 429/960] TRAIN loss:  0.580\n",
      "[epoch 12 Iteration 430/960] TRAIN loss:  0.583\n",
      "[epoch 12 Iteration 431/960] TRAIN loss:  0.655\n",
      "[epoch 12 Iteration 432/960] TRAIN loss:  0.662\n",
      "[epoch 12 Iteration 433/960] TRAIN loss:  0.552\n",
      "[epoch 12 Iteration 434/960] TRAIN loss:  0.758\n",
      "[epoch 12 Iteration 435/960] TRAIN loss:  0.482\n",
      "[epoch 12 Iteration 436/960] TRAIN loss:  0.690\n",
      "[epoch 12 Iteration 437/960] TRAIN loss:  0.613\n",
      "[epoch 12 Iteration 438/960] TRAIN loss:  0.642\n",
      "[epoch 12 Iteration 439/960] TRAIN loss:  0.713\n",
      "[epoch 12 Iteration 440/960] TRAIN loss:  0.578\n",
      "[epoch 12 Iteration 441/960] TRAIN loss:  0.939\n",
      "[epoch 12 Iteration 442/960] TRAIN loss:  0.572\n",
      "[epoch 12 Iteration 443/960] TRAIN loss:  0.487\n",
      "[epoch 12 Iteration 444/960] TRAIN loss:  0.742\n",
      "[epoch 12 Iteration 445/960] TRAIN loss:  0.923\n",
      "[epoch 12 Iteration 446/960] TRAIN loss:  0.507\n",
      "[epoch 12 Iteration 447/960] TRAIN loss:  0.568\n",
      "[epoch 12 Iteration 448/960] TRAIN loss:  0.788\n",
      "[epoch 12 Iteration 449/960] TRAIN loss:  0.450\n",
      "[epoch 12 Iteration 450/960] TRAIN loss:  0.444\n",
      "[epoch 12 Iteration 451/960] TRAIN loss:  0.664\n",
      "[epoch 12 Iteration 452/960] TRAIN loss:  0.797\n",
      "[epoch 12 Iteration 453/960] TRAIN loss:  0.578\n",
      "[epoch 12 Iteration 454/960] TRAIN loss:  0.672\n",
      "[epoch 12 Iteration 455/960] TRAIN loss:  0.522\n",
      "[epoch 12 Iteration 456/960] TRAIN loss:  0.663\n",
      "[epoch 12 Iteration 457/960] TRAIN loss:  0.880\n",
      "[epoch 12 Iteration 458/960] TRAIN loss:  0.773\n",
      "[epoch 12 Iteration 459/960] TRAIN loss:  0.589\n",
      "[epoch 12 Iteration 460/960] TRAIN loss:  0.645\n",
      "[epoch 12 Iteration 461/960] TRAIN loss:  0.472\n",
      "[epoch 12 Iteration 462/960] TRAIN loss:  0.748\n",
      "[epoch 12 Iteration 463/960] TRAIN loss:  0.572\n",
      "[epoch 12 Iteration 464/960] TRAIN loss:  0.649\n",
      "[epoch 12 Iteration 465/960] TRAIN loss:  0.501\n",
      "[epoch 12 Iteration 466/960] TRAIN loss:  0.449\n",
      "[epoch 12 Iteration 467/960] TRAIN loss:  0.702\n",
      "[epoch 12 Iteration 468/960] TRAIN loss:  0.535\n",
      "[epoch 12 Iteration 469/960] TRAIN loss:  0.740\n",
      "[epoch 12 Iteration 470/960] TRAIN loss:  0.707\n",
      "[epoch 12 Iteration 471/960] TRAIN loss:  0.594\n",
      "[epoch 12 Iteration 472/960] TRAIN loss:  0.450\n",
      "[epoch 12 Iteration 473/960] TRAIN loss:  0.516\n",
      "[epoch 12 Iteration 474/960] TRAIN loss:  0.571\n",
      "[epoch 12 Iteration 475/960] TRAIN loss:  0.617\n",
      "[epoch 12 Iteration 476/960] TRAIN loss:  0.565\n",
      "[epoch 12 Iteration 477/960] TRAIN loss:  0.651\n",
      "[epoch 12 Iteration 478/960] TRAIN loss:  0.623\n",
      "[epoch 12 Iteration 479/960] TRAIN loss:  0.757\n",
      "[epoch 12 Iteration 480/960] TRAIN loss:  0.530\n",
      "[epoch 12 Iteration 481/960] TRAIN loss:  0.763\n",
      "[epoch 12 Iteration 482/960] TRAIN loss:  0.600\n",
      "[epoch 12 Iteration 483/960] TRAIN loss:  0.591\n",
      "[epoch 12 Iteration 484/960] TRAIN loss:  0.846\n",
      "[epoch 12 Iteration 485/960] TRAIN loss:  0.963\n",
      "[epoch 12 Iteration 486/960] TRAIN loss:  0.673\n",
      "[epoch 12 Iteration 487/960] TRAIN loss:  0.722\n",
      "[epoch 12 Iteration 488/960] TRAIN loss:  0.509\n",
      "[epoch 12 Iteration 489/960] TRAIN loss:  0.587\n",
      "[epoch 12 Iteration 490/960] TRAIN loss:  0.532\n",
      "[epoch 12 Iteration 491/960] TRAIN loss:  0.911\n",
      "[epoch 12 Iteration 492/960] TRAIN loss:  0.685\n",
      "[epoch 12 Iteration 493/960] TRAIN loss:  0.580\n",
      "[epoch 12 Iteration 494/960] TRAIN loss:  0.557\n",
      "[epoch 12 Iteration 495/960] TRAIN loss:  0.638\n",
      "[epoch 12 Iteration 496/960] TRAIN loss:  0.762\n",
      "[epoch 12 Iteration 497/960] TRAIN loss:  0.683\n",
      "[epoch 12 Iteration 498/960] TRAIN loss:  0.476\n",
      "[epoch 12 Iteration 499/960] TRAIN loss:  0.473\n",
      "[epoch 12 Iteration 500/960] TRAIN loss:  0.625\n",
      "[epoch 12 Iteration 501/960] TRAIN loss:  0.614\n",
      "[epoch 12 Iteration 502/960] TRAIN loss:  0.469\n",
      "[epoch 12 Iteration 503/960] TRAIN loss:  0.442\n",
      "[epoch 12 Iteration 504/960] TRAIN loss:  0.599\n",
      "[epoch 12 Iteration 505/960] TRAIN loss:  0.631\n",
      "[epoch 12 Iteration 506/960] TRAIN loss:  1.051\n",
      "[epoch 12 Iteration 507/960] TRAIN loss:  0.658\n",
      "[epoch 12 Iteration 508/960] TRAIN loss:  0.623\n",
      "[epoch 12 Iteration 509/960] TRAIN loss:  0.609\n",
      "[epoch 12 Iteration 510/960] TRAIN loss:  0.613\n",
      "[epoch 12 Iteration 511/960] TRAIN loss:  0.965\n",
      "[epoch 12 Iteration 512/960] TRAIN loss:  0.479\n",
      "[epoch 12 Iteration 513/960] TRAIN loss:  0.635\n",
      "[epoch 12 Iteration 514/960] TRAIN loss:  0.574\n",
      "[epoch 12 Iteration 515/960] TRAIN loss:  0.765\n",
      "[epoch 12 Iteration 516/960] TRAIN loss:  0.612\n",
      "[epoch 12 Iteration 517/960] TRAIN loss:  0.564\n",
      "[epoch 12 Iteration 518/960] TRAIN loss:  0.633\n",
      "[epoch 12 Iteration 519/960] TRAIN loss:  0.632\n",
      "[epoch 12 Iteration 520/960] TRAIN loss:  0.521\n",
      "[epoch 12 Iteration 521/960] TRAIN loss:  0.599\n",
      "[epoch 12 Iteration 522/960] TRAIN loss:  0.541\n",
      "[epoch 12 Iteration 523/960] TRAIN loss:  0.573\n",
      "[epoch 12 Iteration 524/960] TRAIN loss:  0.678\n",
      "[epoch 12 Iteration 525/960] TRAIN loss:  0.890\n",
      "[epoch 12 Iteration 526/960] TRAIN loss:  0.691\n",
      "[epoch 12 Iteration 527/960] TRAIN loss:  0.708\n",
      "[epoch 12 Iteration 528/960] TRAIN loss:  0.532\n",
      "[epoch 12 Iteration 529/960] TRAIN loss:  0.391\n",
      "[epoch 12 Iteration 530/960] TRAIN loss:  0.410\n",
      "[epoch 12 Iteration 531/960] TRAIN loss:  0.430\n",
      "[epoch 12 Iteration 532/960] TRAIN loss:  0.419\n",
      "[epoch 12 Iteration 533/960] TRAIN loss:  0.631\n",
      "[epoch 12 Iteration 534/960] TRAIN loss:  0.666\n",
      "[epoch 12 Iteration 535/960] TRAIN loss:  0.739\n",
      "[epoch 12 Iteration 536/960] TRAIN loss:  0.764\n",
      "[epoch 12 Iteration 537/960] TRAIN loss:  0.678\n",
      "[epoch 12 Iteration 538/960] TRAIN loss:  0.432\n",
      "[epoch 12 Iteration 539/960] TRAIN loss:  0.652\n",
      "[epoch 12 Iteration 540/960] TRAIN loss:  0.537\n",
      "[epoch 12 Iteration 541/960] TRAIN loss:  0.670\n",
      "[epoch 12 Iteration 542/960] TRAIN loss:  0.587\n",
      "[epoch 12 Iteration 543/960] TRAIN loss:  0.494\n",
      "[epoch 12 Iteration 544/960] TRAIN loss:  0.479\n",
      "[epoch 12 Iteration 545/960] TRAIN loss:  0.602\n",
      "[epoch 12 Iteration 546/960] TRAIN loss:  0.592\n",
      "[epoch 12 Iteration 547/960] TRAIN loss:  0.563\n",
      "[epoch 12 Iteration 548/960] TRAIN loss:  0.497\n",
      "[epoch 12 Iteration 549/960] TRAIN loss:  0.455\n",
      "[epoch 12 Iteration 550/960] TRAIN loss:  0.562\n",
      "[epoch 12 Iteration 551/960] TRAIN loss:  0.663\n",
      "[epoch 12 Iteration 552/960] TRAIN loss:  1.077\n",
      "[epoch 12 Iteration 553/960] TRAIN loss:  0.659\n",
      "[epoch 12 Iteration 554/960] TRAIN loss:  0.823\n",
      "[epoch 12 Iteration 555/960] TRAIN loss:  0.464\n",
      "[epoch 12 Iteration 556/960] TRAIN loss:  0.713\n",
      "[epoch 12 Iteration 557/960] TRAIN loss:  0.801\n",
      "[epoch 12 Iteration 558/960] TRAIN loss:  0.600\n",
      "[epoch 12 Iteration 559/960] TRAIN loss:  0.739\n",
      "[epoch 12 Iteration 560/960] TRAIN loss:  0.693\n",
      "[epoch 12 Iteration 561/960] TRAIN loss:  0.624\n",
      "[epoch 12 Iteration 562/960] TRAIN loss:  0.709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12 Iteration 563/960] TRAIN loss:  0.602\n",
      "[epoch 12 Iteration 564/960] TRAIN loss:  0.695\n",
      "[epoch 12 Iteration 565/960] TRAIN loss:  0.505\n",
      "[epoch 12 Iteration 566/960] TRAIN loss:  0.635\n",
      "[epoch 12 Iteration 567/960] TRAIN loss:  0.673\n",
      "[epoch 12 Iteration 568/960] TRAIN loss:  0.418\n",
      "[epoch 12 Iteration 569/960] TRAIN loss:  0.441\n",
      "[epoch 12 Iteration 570/960] TRAIN loss:  0.417\n",
      "[epoch 12 Iteration 571/960] TRAIN loss:  0.739\n",
      "[epoch 12 Iteration 572/960] TRAIN loss:  0.524\n",
      "[epoch 12 Iteration 573/960] TRAIN loss:  0.573\n",
      "[epoch 12 Iteration 574/960] TRAIN loss:  0.354\n",
      "[epoch 12 Iteration 575/960] TRAIN loss:  0.722\n",
      "[epoch 12 Iteration 576/960] TRAIN loss:  0.650\n",
      "[epoch 12 Iteration 577/960] TRAIN loss:  0.637\n",
      "[epoch 12 Iteration 578/960] TRAIN loss:  0.740\n",
      "[epoch 12 Iteration 579/960] TRAIN loss:  0.592\n",
      "[epoch 12 Iteration 580/960] TRAIN loss:  0.838\n",
      "[epoch 12 Iteration 581/960] TRAIN loss:  0.605\n",
      "[epoch 12 Iteration 582/960] TRAIN loss:  0.719\n",
      "[epoch 12 Iteration 583/960] TRAIN loss:  0.722\n",
      "[epoch 12 Iteration 584/960] TRAIN loss:  0.664\n",
      "[epoch 12 Iteration 585/960] TRAIN loss:  0.686\n",
      "[epoch 12 Iteration 586/960] TRAIN loss:  0.978\n",
      "[epoch 12 Iteration 587/960] TRAIN loss:  0.485\n",
      "[epoch 12 Iteration 588/960] TRAIN loss:  0.635\n",
      "[epoch 12 Iteration 589/960] TRAIN loss:  0.778\n",
      "[epoch 12 Iteration 590/960] TRAIN loss:  0.550\n",
      "[epoch 12 Iteration 591/960] TRAIN loss:  0.681\n",
      "[epoch 12 Iteration 592/960] TRAIN loss:  0.548\n",
      "[epoch 12 Iteration 593/960] TRAIN loss:  0.439\n",
      "[epoch 12 Iteration 594/960] TRAIN loss:  0.594\n",
      "[epoch 12 Iteration 595/960] TRAIN loss:  0.649\n",
      "[epoch 12 Iteration 596/960] TRAIN loss:  0.564\n",
      "[epoch 12 Iteration 597/960] TRAIN loss:  0.661\n",
      "[epoch 12 Iteration 598/960] TRAIN loss:  0.663\n",
      "[epoch 12 Iteration 599/960] TRAIN loss:  0.438\n",
      "[epoch 12 Iteration 600/960] TRAIN loss:  0.604\n",
      "[epoch 12 Iteration 601/960] TRAIN loss:  0.539\n",
      "[epoch 12 Iteration 602/960] TRAIN loss:  0.844\n",
      "[epoch 12 Iteration 603/960] TRAIN loss:  0.505\n",
      "[epoch 12 Iteration 604/960] TRAIN loss:  0.882\n",
      "[epoch 12 Iteration 605/960] TRAIN loss:  0.987\n",
      "[epoch 12 Iteration 606/960] TRAIN loss:  0.692\n",
      "[epoch 12 Iteration 607/960] TRAIN loss:  0.599\n",
      "[epoch 12 Iteration 608/960] TRAIN loss:  1.148\n",
      "[epoch 12 Iteration 609/960] TRAIN loss:  0.591\n",
      "[epoch 12 Iteration 610/960] TRAIN loss:  0.761\n",
      "[epoch 12 Iteration 611/960] TRAIN loss:  0.471\n",
      "[epoch 12 Iteration 612/960] TRAIN loss:  0.768\n",
      "[epoch 12 Iteration 613/960] TRAIN loss:  0.826\n",
      "[epoch 12 Iteration 614/960] TRAIN loss:  0.747\n",
      "[epoch 12 Iteration 615/960] TRAIN loss:  0.782\n",
      "[epoch 12 Iteration 616/960] TRAIN loss:  0.657\n",
      "[epoch 12 Iteration 617/960] TRAIN loss:  0.621\n",
      "[epoch 12 Iteration 618/960] TRAIN loss:  0.839\n",
      "[epoch 12 Iteration 619/960] TRAIN loss:  0.524\n",
      "[epoch 12 Iteration 620/960] TRAIN loss:  0.744\n",
      "[epoch 12 Iteration 621/960] TRAIN loss:  0.822\n",
      "[epoch 12 Iteration 622/960] TRAIN loss:  0.467\n",
      "[epoch 12 Iteration 623/960] TRAIN loss:  0.585\n",
      "[epoch 12 Iteration 624/960] TRAIN loss:  0.683\n",
      "[epoch 12 Iteration 625/960] TRAIN loss:  0.554\n",
      "[epoch 12 Iteration 626/960] TRAIN loss:  1.060\n",
      "[epoch 12 Iteration 627/960] TRAIN loss:  0.550\n",
      "[epoch 12 Iteration 628/960] TRAIN loss:  0.644\n",
      "[epoch 12 Iteration 629/960] TRAIN loss:  0.642\n",
      "[epoch 12 Iteration 630/960] TRAIN loss:  0.462\n",
      "[epoch 12 Iteration 631/960] TRAIN loss:  0.610\n",
      "[epoch 12 Iteration 632/960] TRAIN loss:  0.600\n",
      "[epoch 12 Iteration 633/960] TRAIN loss:  0.663\n",
      "[epoch 12 Iteration 634/960] TRAIN loss:  0.700\n",
      "[epoch 12 Iteration 635/960] TRAIN loss:  0.913\n",
      "[epoch 12 Iteration 636/960] TRAIN loss:  0.622\n",
      "[epoch 12 Iteration 637/960] TRAIN loss:  0.799\n",
      "[epoch 12 Iteration 638/960] TRAIN loss:  0.713\n",
      "[epoch 12 Iteration 639/960] TRAIN loss:  0.496\n",
      "[epoch 12 Iteration 640/960] TRAIN loss:  0.632\n",
      "[epoch 12 Iteration 641/960] TRAIN loss:  0.706\n",
      "[epoch 12 Iteration 642/960] TRAIN loss:  0.648\n",
      "[epoch 12 Iteration 643/960] TRAIN loss:  0.517\n",
      "[epoch 12 Iteration 644/960] TRAIN loss:  0.409\n",
      "[epoch 12 Iteration 645/960] TRAIN loss:  0.473\n",
      "[epoch 12 Iteration 646/960] TRAIN loss:  0.593\n",
      "[epoch 12 Iteration 647/960] TRAIN loss:  0.761\n",
      "[epoch 12 Iteration 648/960] TRAIN loss:  0.510\n",
      "[epoch 12 Iteration 649/960] TRAIN loss:  0.390\n",
      "[epoch 12 Iteration 650/960] TRAIN loss:  0.574\n",
      "[epoch 12 Iteration 651/960] TRAIN loss:  0.534\n",
      "[epoch 12 Iteration 652/960] TRAIN loss:  0.598\n",
      "[epoch 12 Iteration 653/960] TRAIN loss:  0.511\n",
      "[epoch 12 Iteration 654/960] TRAIN loss:  0.442\n",
      "[epoch 12 Iteration 655/960] TRAIN loss:  0.549\n",
      "[epoch 12 Iteration 656/960] TRAIN loss:  0.600\n",
      "[epoch 12 Iteration 657/960] TRAIN loss:  0.529\n",
      "[epoch 12 Iteration 658/960] TRAIN loss:  0.598\n",
      "[epoch 12 Iteration 659/960] TRAIN loss:  0.443\n",
      "[epoch 12 Iteration 660/960] TRAIN loss:  0.700\n",
      "[epoch 12 Iteration 661/960] TRAIN loss:  0.591\n",
      "[epoch 12 Iteration 662/960] TRAIN loss:  0.661\n",
      "[epoch 12 Iteration 663/960] TRAIN loss:  0.926\n",
      "[epoch 12 Iteration 664/960] TRAIN loss:  0.540\n",
      "[epoch 12 Iteration 665/960] TRAIN loss:  0.683\n",
      "[epoch 12 Iteration 666/960] TRAIN loss:  0.650\n",
      "[epoch 12 Iteration 667/960] TRAIN loss:  0.531\n",
      "[epoch 12 Iteration 668/960] TRAIN loss:  0.859\n",
      "[epoch 12 Iteration 669/960] TRAIN loss:  0.647\n",
      "[epoch 12 Iteration 670/960] TRAIN loss:  0.772\n",
      "[epoch 12 Iteration 671/960] TRAIN loss:  0.586\n",
      "[epoch 12 Iteration 672/960] TRAIN loss:  0.614\n",
      "[epoch 12 Iteration 673/960] TRAIN loss:  0.913\n",
      "[epoch 12 Iteration 674/960] TRAIN loss:  0.568\n",
      "[epoch 12 Iteration 675/960] TRAIN loss:  0.737\n",
      "[epoch 12 Iteration 676/960] TRAIN loss:  0.467\n",
      "[epoch 12 Iteration 677/960] TRAIN loss:  0.682\n",
      "[epoch 12 Iteration 678/960] TRAIN loss:  0.773\n",
      "[epoch 12 Iteration 679/960] TRAIN loss:  0.566\n",
      "[epoch 12 Iteration 680/960] TRAIN loss:  0.981\n",
      "[epoch 12 Iteration 681/960] TRAIN loss:  0.678\n",
      "[epoch 12 Iteration 682/960] TRAIN loss:  0.797\n",
      "[epoch 12 Iteration 683/960] TRAIN loss:  0.632\n",
      "[epoch 12 Iteration 684/960] TRAIN loss:  0.608\n",
      "[epoch 12 Iteration 685/960] TRAIN loss:  0.556\n",
      "[epoch 12 Iteration 686/960] TRAIN loss:  0.530\n",
      "[epoch 12 Iteration 687/960] TRAIN loss:  0.407\n",
      "[epoch 12 Iteration 688/960] TRAIN loss:  0.734\n",
      "[epoch 12 Iteration 689/960] TRAIN loss:  0.607\n",
      "[epoch 12 Iteration 690/960] TRAIN loss:  0.546\n",
      "[epoch 12 Iteration 691/960] TRAIN loss:  0.480\n",
      "[epoch 12 Iteration 692/960] TRAIN loss:  0.564\n",
      "[epoch 12 Iteration 693/960] TRAIN loss:  0.684\n",
      "[epoch 12 Iteration 694/960] TRAIN loss:  0.726\n",
      "[epoch 12 Iteration 695/960] TRAIN loss:  0.806\n",
      "[epoch 12 Iteration 696/960] TRAIN loss:  0.549\n",
      "[epoch 12 Iteration 697/960] TRAIN loss:  0.774\n",
      "[epoch 12 Iteration 698/960] TRAIN loss:  0.750\n",
      "[epoch 12 Iteration 699/960] TRAIN loss:  0.431\n",
      "[epoch 12 Iteration 700/960] TRAIN loss:  0.715\n",
      "[epoch 12 Iteration 701/960] TRAIN loss:  0.698\n",
      "[epoch 12 Iteration 702/960] TRAIN loss:  0.637\n",
      "[epoch 12 Iteration 703/960] TRAIN loss:  0.692\n",
      "[epoch 12 Iteration 704/960] TRAIN loss:  0.447\n",
      "[epoch 12 Iteration 705/960] TRAIN loss:  0.553\n",
      "[epoch 12 Iteration 706/960] TRAIN loss:  0.586\n",
      "[epoch 12 Iteration 707/960] TRAIN loss:  0.574\n",
      "[epoch 12 Iteration 708/960] TRAIN loss:  0.682\n",
      "[epoch 12 Iteration 709/960] TRAIN loss:  0.494\n",
      "[epoch 12 Iteration 710/960] TRAIN loss:  0.786\n",
      "[epoch 12 Iteration 711/960] TRAIN loss:  0.492\n",
      "[epoch 12 Iteration 712/960] TRAIN loss:  0.628\n",
      "[epoch 12 Iteration 713/960] TRAIN loss:  0.667\n",
      "[epoch 12 Iteration 714/960] TRAIN loss:  0.690\n",
      "[epoch 12 Iteration 715/960] TRAIN loss:  0.571\n",
      "[epoch 12 Iteration 716/960] TRAIN loss:  0.751\n",
      "[epoch 12 Iteration 717/960] TRAIN loss:  0.564\n",
      "[epoch 12 Iteration 718/960] TRAIN loss:  0.741\n",
      "[epoch 12 Iteration 719/960] TRAIN loss:  0.374\n",
      "[epoch 12 Iteration 720/960] TRAIN loss:  0.599\n",
      "[epoch 12 Iteration 721/960] TRAIN loss:  0.491\n",
      "[epoch 12 Iteration 722/960] TRAIN loss:  0.559\n",
      "[epoch 12 Iteration 723/960] TRAIN loss:  0.694\n",
      "[epoch 12 Iteration 724/960] TRAIN loss:  0.519\n",
      "[epoch 12 Iteration 725/960] TRAIN loss:  0.784\n",
      "[epoch 12 Iteration 726/960] TRAIN loss:  0.513\n",
      "[epoch 12 Iteration 727/960] TRAIN loss:  0.738\n",
      "[epoch 12 Iteration 728/960] TRAIN loss:  0.524\n",
      "[epoch 12 Iteration 729/960] TRAIN loss:  0.691\n",
      "[epoch 12 Iteration 730/960] TRAIN loss:  0.644\n",
      "[epoch 12 Iteration 731/960] TRAIN loss:  0.666\n",
      "[epoch 12 Iteration 732/960] TRAIN loss:  0.592\n",
      "[epoch 12 Iteration 733/960] TRAIN loss:  0.616\n",
      "[epoch 12 Iteration 734/960] TRAIN loss:  0.749\n",
      "[epoch 12 Iteration 735/960] TRAIN loss:  0.928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12 Iteration 736/960] TRAIN loss:  0.650\n",
      "[epoch 12 Iteration 737/960] TRAIN loss:  0.596\n",
      "[epoch 12 Iteration 738/960] TRAIN loss:  0.504\n",
      "[epoch 12 Iteration 739/960] TRAIN loss:  0.719\n",
      "[epoch 12 Iteration 740/960] TRAIN loss:  0.813\n",
      "[epoch 12 Iteration 741/960] TRAIN loss:  0.748\n",
      "[epoch 12 Iteration 742/960] TRAIN loss:  0.658\n",
      "[epoch 12 Iteration 743/960] TRAIN loss:  0.609\n",
      "[epoch 12 Iteration 744/960] TRAIN loss:  0.639\n",
      "[epoch 12 Iteration 745/960] TRAIN loss:  0.469\n",
      "[epoch 12 Iteration 746/960] TRAIN loss:  0.414\n",
      "[epoch 12 Iteration 747/960] TRAIN loss:  0.766\n",
      "[epoch 12 Iteration 748/960] TRAIN loss:  0.613\n",
      "[epoch 12 Iteration 749/960] TRAIN loss:  0.730\n",
      "[epoch 12 Iteration 750/960] TRAIN loss:  0.444\n",
      "[epoch 12 Iteration 751/960] TRAIN loss:  0.662\n",
      "[epoch 12 Iteration 752/960] TRAIN loss:  0.654\n",
      "[epoch 12 Iteration 753/960] TRAIN loss:  0.564\n",
      "[epoch 12 Iteration 754/960] TRAIN loss:  0.515\n",
      "[epoch 12 Iteration 755/960] TRAIN loss:  0.546\n",
      "[epoch 12 Iteration 756/960] TRAIN loss:  0.799\n",
      "[epoch 12 Iteration 757/960] TRAIN loss:  0.456\n",
      "[epoch 12 Iteration 758/960] TRAIN loss:  0.641\n",
      "[epoch 12 Iteration 759/960] TRAIN loss:  0.749\n",
      "[epoch 12 Iteration 760/960] TRAIN loss:  0.577\n",
      "[epoch 12 Iteration 761/960] TRAIN loss:  0.833\n",
      "[epoch 12 Iteration 762/960] TRAIN loss:  0.520\n",
      "[epoch 12 Iteration 763/960] TRAIN loss:  0.612\n",
      "[epoch 12 Iteration 764/960] TRAIN loss:  0.592\n",
      "[epoch 12 Iteration 765/960] TRAIN loss:  0.640\n",
      "[epoch 12 Iteration 766/960] TRAIN loss:  0.417\n",
      "[epoch 12 Iteration 767/960] TRAIN loss:  0.715\n",
      "[epoch 12 Iteration 768/960] TRAIN loss:  0.828\n",
      "[epoch 12 Iteration 769/960] TRAIN loss:  0.751\n",
      "[epoch 12 Iteration 770/960] TRAIN loss:  0.598\n",
      "[epoch 12 Iteration 771/960] TRAIN loss:  0.744\n",
      "[epoch 12 Iteration 772/960] TRAIN loss:  0.862\n",
      "[epoch 12 Iteration 773/960] TRAIN loss:  0.725\n",
      "[epoch 12 Iteration 774/960] TRAIN loss:  0.504\n",
      "[epoch 12 Iteration 775/960] TRAIN loss:  0.562\n",
      "[epoch 12 Iteration 776/960] TRAIN loss:  0.730\n",
      "[epoch 12 Iteration 777/960] TRAIN loss:  0.621\n",
      "[epoch 12 Iteration 778/960] TRAIN loss:  0.519\n",
      "[epoch 12 Iteration 779/960] TRAIN loss:  0.732\n",
      "[epoch 12 Iteration 780/960] TRAIN loss:  0.497\n",
      "[epoch 12 Iteration 781/960] TRAIN loss:  0.923\n",
      "[epoch 12 Iteration 782/960] TRAIN loss:  0.651\n",
      "[epoch 12 Iteration 783/960] TRAIN loss:  0.729\n",
      "[epoch 12 Iteration 784/960] TRAIN loss:  0.594\n",
      "[epoch 12 Iteration 785/960] TRAIN loss:  0.661\n",
      "[epoch 12 Iteration 786/960] TRAIN loss:  0.701\n",
      "[epoch 12 Iteration 787/960] TRAIN loss:  0.595\n",
      "[epoch 12 Iteration 788/960] TRAIN loss:  0.614\n",
      "[epoch 12 Iteration 789/960] TRAIN loss:  0.707\n",
      "[epoch 12 Iteration 790/960] TRAIN loss:  0.630\n",
      "[epoch 12 Iteration 791/960] TRAIN loss:  0.966\n",
      "[epoch 12 Iteration 792/960] TRAIN loss:  0.717\n",
      "[epoch 12 Iteration 793/960] TRAIN loss:  0.511\n",
      "[epoch 12 Iteration 794/960] TRAIN loss:  0.476\n",
      "[epoch 12 Iteration 795/960] TRAIN loss:  0.528\n",
      "[epoch 12 Iteration 796/960] TRAIN loss:  0.528\n",
      "[epoch 12 Iteration 797/960] TRAIN loss:  0.705\n",
      "[epoch 12 Iteration 798/960] TRAIN loss:  0.722\n",
      "[epoch 12 Iteration 799/960] TRAIN loss:  0.892\n",
      "[epoch 12 Iteration 800/960] TRAIN loss:  0.665\n",
      "[epoch 12 Iteration 801/960] TRAIN loss:  0.585\n",
      "[epoch 12 Iteration 802/960] TRAIN loss:  0.639\n",
      "[epoch 12 Iteration 803/960] TRAIN loss:  0.577\n",
      "[epoch 12 Iteration 804/960] TRAIN loss:  0.599\n",
      "[epoch 12 Iteration 805/960] TRAIN loss:  0.786\n",
      "[epoch 12 Iteration 806/960] TRAIN loss:  0.591\n",
      "[epoch 12 Iteration 807/960] TRAIN loss:  0.599\n",
      "[epoch 12 Iteration 808/960] TRAIN loss:  0.710\n",
      "[epoch 12 Iteration 809/960] TRAIN loss:  0.541\n",
      "[epoch 12 Iteration 810/960] TRAIN loss:  0.642\n",
      "[epoch 12 Iteration 811/960] TRAIN loss:  0.565\n",
      "[epoch 12 Iteration 812/960] TRAIN loss:  0.659\n",
      "[epoch 12 Iteration 813/960] TRAIN loss:  0.654\n",
      "[epoch 12 Iteration 814/960] TRAIN loss:  0.748\n",
      "[epoch 12 Iteration 815/960] TRAIN loss:  0.722\n",
      "[epoch 12 Iteration 816/960] TRAIN loss:  0.654\n",
      "[epoch 12 Iteration 817/960] TRAIN loss:  0.684\n",
      "[epoch 12 Iteration 818/960] TRAIN loss:  0.754\n",
      "[epoch 12 Iteration 819/960] TRAIN loss:  0.707\n",
      "[epoch 12 Iteration 820/960] TRAIN loss:  0.757\n",
      "[epoch 12 Iteration 821/960] TRAIN loss:  0.496\n",
      "[epoch 12 Iteration 822/960] TRAIN loss:  0.703\n",
      "[epoch 12 Iteration 823/960] TRAIN loss:  0.679\n",
      "[epoch 12 Iteration 824/960] TRAIN loss:  0.609\n",
      "[epoch 12 Iteration 825/960] TRAIN loss:  0.600\n",
      "[epoch 12 Iteration 826/960] TRAIN loss:  0.703\n",
      "[epoch 12 Iteration 827/960] TRAIN loss:  0.614\n",
      "[epoch 12 Iteration 828/960] TRAIN loss:  0.898\n",
      "[epoch 12 Iteration 829/960] TRAIN loss:  0.602\n",
      "[epoch 12 Iteration 830/960] TRAIN loss:  0.779\n",
      "[epoch 12 Iteration 831/960] TRAIN loss:  0.750\n",
      "[epoch 12 Iteration 832/960] TRAIN loss:  0.763\n",
      "[epoch 12 Iteration 833/960] TRAIN loss:  0.699\n",
      "[epoch 12 Iteration 834/960] TRAIN loss:  0.661\n",
      "[epoch 12 Iteration 835/960] TRAIN loss:  0.543\n",
      "[epoch 12 Iteration 836/960] TRAIN loss:  0.558\n",
      "[epoch 12 Iteration 837/960] TRAIN loss:  0.639\n",
      "[epoch 12 Iteration 838/960] TRAIN loss:  0.718\n",
      "[epoch 12 Iteration 839/960] TRAIN loss:  0.897\n",
      "[epoch 12 Iteration 840/960] TRAIN loss:  0.650\n",
      "[epoch 12 Iteration 841/960] TRAIN loss:  0.381\n",
      "[epoch 12 Iteration 842/960] TRAIN loss:  0.658\n",
      "[epoch 12 Iteration 843/960] TRAIN loss:  0.577\n",
      "[epoch 12 Iteration 844/960] TRAIN loss:  0.476\n",
      "[epoch 12 Iteration 845/960] TRAIN loss:  0.664\n",
      "[epoch 12 Iteration 846/960] TRAIN loss:  0.723\n",
      "[epoch 12 Iteration 847/960] TRAIN loss:  0.702\n",
      "[epoch 12 Iteration 848/960] TRAIN loss:  0.772\n",
      "[epoch 12 Iteration 849/960] TRAIN loss:  0.944\n",
      "[epoch 12 Iteration 850/960] TRAIN loss:  0.767\n",
      "[epoch 12 Iteration 851/960] TRAIN loss:  0.638\n",
      "[epoch 12 Iteration 852/960] TRAIN loss:  0.640\n",
      "[epoch 12 Iteration 853/960] TRAIN loss:  0.758\n",
      "[epoch 12 Iteration 854/960] TRAIN loss:  0.606\n",
      "[epoch 12 Iteration 855/960] TRAIN loss:  0.679\n",
      "[epoch 12 Iteration 856/960] TRAIN loss:  0.763\n",
      "[epoch 12 Iteration 857/960] TRAIN loss:  0.643\n",
      "[epoch 12 Iteration 858/960] TRAIN loss:  0.946\n",
      "[epoch 12 Iteration 859/960] TRAIN loss:  0.548\n",
      "[epoch 12 Iteration 860/960] TRAIN loss:  0.801\n",
      "[epoch 12 Iteration 861/960] TRAIN loss:  0.818\n",
      "[epoch 12 Iteration 862/960] TRAIN loss:  0.544\n",
      "[epoch 12 Iteration 863/960] TRAIN loss:  0.656\n",
      "[epoch 12 Iteration 864/960] TRAIN loss:  0.809\n",
      "[epoch 12 Iteration 865/960] TRAIN loss:  0.649\n",
      "[epoch 12 Iteration 866/960] TRAIN loss:  0.682\n",
      "[epoch 12 Iteration 867/960] TRAIN loss:  0.683\n",
      "[epoch 12 Iteration 868/960] TRAIN loss:  0.492\n",
      "[epoch 12 Iteration 869/960] TRAIN loss:  0.866\n",
      "[epoch 12 Iteration 870/960] TRAIN loss:  0.621\n",
      "[epoch 12 Iteration 871/960] TRAIN loss:  0.596\n",
      "[epoch 12 Iteration 872/960] TRAIN loss:  0.456\n",
      "[epoch 12 Iteration 873/960] TRAIN loss:  0.687\n",
      "[epoch 12 Iteration 874/960] TRAIN loss:  0.763\n",
      "[epoch 12 Iteration 875/960] TRAIN loss:  0.622\n",
      "[epoch 12 Iteration 876/960] TRAIN loss:  0.646\n",
      "[epoch 12 Iteration 877/960] TRAIN loss:  0.724\n",
      "[epoch 12 Iteration 878/960] TRAIN loss:  0.677\n",
      "[epoch 12 Iteration 879/960] TRAIN loss:  0.537\n",
      "[epoch 12 Iteration 880/960] TRAIN loss:  0.513\n",
      "[epoch 12 Iteration 881/960] TRAIN loss:  0.554\n",
      "[epoch 12 Iteration 882/960] TRAIN loss:  0.475\n",
      "[epoch 12 Iteration 883/960] TRAIN loss:  0.564\n",
      "[epoch 12 Iteration 884/960] TRAIN loss:  0.697\n",
      "[epoch 12 Iteration 885/960] TRAIN loss:  0.435\n",
      "[epoch 12 Iteration 886/960] TRAIN loss:  0.549\n",
      "[epoch 12 Iteration 887/960] TRAIN loss:  0.522\n",
      "[epoch 12 Iteration 888/960] TRAIN loss:  0.600\n",
      "[epoch 12 Iteration 889/960] TRAIN loss:  0.711\n",
      "[epoch 12 Iteration 890/960] TRAIN loss:  0.765\n",
      "[epoch 12 Iteration 891/960] TRAIN loss:  0.631\n",
      "[epoch 12 Iteration 892/960] TRAIN loss:  0.568\n",
      "[epoch 12 Iteration 893/960] TRAIN loss:  0.516\n",
      "[epoch 12 Iteration 894/960] TRAIN loss:  0.810\n",
      "[epoch 12 Iteration 895/960] TRAIN loss:  0.477\n",
      "[epoch 12 Iteration 896/960] TRAIN loss:  0.614\n",
      "[epoch 12 Iteration 897/960] TRAIN loss:  0.488\n",
      "[epoch 12 Iteration 898/960] TRAIN loss:  0.376\n",
      "[epoch 12 Iteration 899/960] TRAIN loss:  0.581\n",
      "[epoch 12 Iteration 900/960] TRAIN loss:  0.725\n",
      "[epoch 12 Iteration 901/960] TRAIN loss:  0.543\n",
      "[epoch 12 Iteration 902/960] TRAIN loss:  0.879\n",
      "[epoch 12 Iteration 903/960] TRAIN loss:  0.723\n",
      "[epoch 12 Iteration 904/960] TRAIN loss:  0.580\n",
      "[epoch 12 Iteration 905/960] TRAIN loss:  0.542\n",
      "[epoch 12 Iteration 906/960] TRAIN loss:  0.683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 12 Iteration 907/960] TRAIN loss:  0.789\n",
      "[epoch 12 Iteration 908/960] TRAIN loss:  0.747\n",
      "[epoch 12 Iteration 909/960] TRAIN loss:  0.567\n",
      "[epoch 12 Iteration 910/960] TRAIN loss:  0.818\n",
      "[epoch 12 Iteration 911/960] TRAIN loss:  0.742\n",
      "[epoch 12 Iteration 912/960] TRAIN loss:  0.790\n",
      "[epoch 12 Iteration 913/960] TRAIN loss:  0.502\n",
      "[epoch 12 Iteration 914/960] TRAIN loss:  0.624\n",
      "[epoch 12 Iteration 915/960] TRAIN loss:  0.827\n",
      "[epoch 12 Iteration 916/960] TRAIN loss:  0.612\n",
      "[epoch 12 Iteration 917/960] TRAIN loss:  0.692\n",
      "[epoch 12 Iteration 918/960] TRAIN loss:  0.736\n",
      "[epoch 12 Iteration 919/960] TRAIN loss:  0.655\n",
      "[epoch 12 Iteration 920/960] TRAIN loss:  0.732\n",
      "[epoch 12 Iteration 921/960] TRAIN loss:  0.359\n",
      "[epoch 12 Iteration 922/960] TRAIN loss:  0.947\n",
      "[epoch 12 Iteration 923/960] TRAIN loss:  0.757\n",
      "[epoch 12 Iteration 924/960] TRAIN loss:  0.669\n",
      "[epoch 12 Iteration 925/960] TRAIN loss:  0.611\n",
      "[epoch 12 Iteration 926/960] TRAIN loss:  0.707\n",
      "[epoch 12 Iteration 927/960] TRAIN loss:  0.714\n",
      "[epoch 12 Iteration 928/960] TRAIN loss:  0.679\n",
      "[epoch 12 Iteration 929/960] TRAIN loss:  0.757\n",
      "[epoch 12 Iteration 930/960] TRAIN loss:  0.718\n",
      "[epoch 12 Iteration 931/960] TRAIN loss:  0.538\n",
      "[epoch 12 Iteration 932/960] TRAIN loss:  1.058\n",
      "[epoch 12 Iteration 933/960] TRAIN loss:  0.568\n",
      "[epoch 12 Iteration 934/960] TRAIN loss:  0.621\n",
      "[epoch 12 Iteration 935/960] TRAIN loss:  0.584\n",
      "[epoch 12 Iteration 936/960] TRAIN loss:  0.738\n",
      "[epoch 12 Iteration 937/960] TRAIN loss:  0.647\n",
      "[epoch 12 Iteration 938/960] TRAIN loss:  0.660\n",
      "[epoch 12 Iteration 939/960] TRAIN loss:  0.710\n",
      "[epoch 12 Iteration 940/960] TRAIN loss:  0.584\n",
      "[epoch 12 Iteration 941/960] TRAIN loss:  0.778\n",
      "[epoch 12 Iteration 942/960] TRAIN loss:  0.495\n",
      "[epoch 12 Iteration 943/960] TRAIN loss:  0.636\n",
      "[epoch 12 Iteration 944/960] TRAIN loss:  0.512\n",
      "[epoch 12 Iteration 945/960] TRAIN loss:  0.872\n",
      "[epoch 12 Iteration 946/960] TRAIN loss:  0.495\n",
      "[epoch 12 Iteration 947/960] TRAIN loss:  0.599\n",
      "[epoch 12 Iteration 948/960] TRAIN loss:  0.894\n",
      "[epoch 12 Iteration 949/960] TRAIN loss:  0.786\n",
      "[epoch 12 Iteration 950/960] TRAIN loss:  0.656\n",
      "[epoch 12 Iteration 951/960] TRAIN loss:  0.829\n",
      "[epoch 12 Iteration 952/960] TRAIN loss:  0.760\n",
      "[epoch 12 Iteration 953/960] TRAIN loss:  0.722\n",
      "[epoch 12 Iteration 954/960] TRAIN loss:  0.484\n",
      "[epoch 12 Iteration 955/960] TRAIN loss:  0.834\n",
      "[epoch 12 Iteration 956/960] TRAIN loss:  0.594\n",
      "[epoch 12 Iteration 957/960] TRAIN loss:  1.076\n",
      "[epoch 12 Iteration 958/960] TRAIN loss:  0.583\n",
      "[epoch 12 Iteration 959/960] TRAIN loss:  0.482\n",
      "[epoch 12/15] TRAIN acc/loss:  0.776/0.482\n",
      "[epoch 12/15] VAL acc/loss:  0.661/0.568\n",
      "[epoch 13 Iteration 0/960] TRAIN loss:  0.491\n",
      "[epoch 13 Iteration 1/960] TRAIN loss:  0.518\n",
      "[epoch 13 Iteration 2/960] TRAIN loss:  0.531\n",
      "[epoch 13 Iteration 3/960] TRAIN loss:  0.534\n",
      "[epoch 13 Iteration 4/960] TRAIN loss:  0.720\n",
      "[epoch 13 Iteration 5/960] TRAIN loss:  0.678\n",
      "[epoch 13 Iteration 6/960] TRAIN loss:  0.358\n",
      "[epoch 13 Iteration 7/960] TRAIN loss:  0.524\n",
      "[epoch 13 Iteration 8/960] TRAIN loss:  0.662\n",
      "[epoch 13 Iteration 9/960] TRAIN loss:  0.461\n",
      "[epoch 13 Iteration 10/960] TRAIN loss:  0.351\n",
      "[epoch 13 Iteration 11/960] TRAIN loss:  0.746\n",
      "[epoch 13 Iteration 12/960] TRAIN loss:  0.448\n",
      "[epoch 13 Iteration 13/960] TRAIN loss:  0.455\n",
      "[epoch 13 Iteration 14/960] TRAIN loss:  0.498\n",
      "[epoch 13 Iteration 15/960] TRAIN loss:  0.665\n",
      "[epoch 13 Iteration 16/960] TRAIN loss:  0.451\n",
      "[epoch 13 Iteration 17/960] TRAIN loss:  0.572\n",
      "[epoch 13 Iteration 18/960] TRAIN loss:  0.557\n",
      "[epoch 13 Iteration 19/960] TRAIN loss:  0.423\n",
      "[epoch 13 Iteration 20/960] TRAIN loss:  0.361\n",
      "[epoch 13 Iteration 21/960] TRAIN loss:  0.761\n",
      "[epoch 13 Iteration 22/960] TRAIN loss:  0.580\n",
      "[epoch 13 Iteration 23/960] TRAIN loss:  0.609\n",
      "[epoch 13 Iteration 24/960] TRAIN loss:  0.489\n",
      "[epoch 13 Iteration 25/960] TRAIN loss:  0.611\n",
      "[epoch 13 Iteration 26/960] TRAIN loss:  0.408\n",
      "[epoch 13 Iteration 27/960] TRAIN loss:  0.490\n",
      "[epoch 13 Iteration 28/960] TRAIN loss:  0.456\n",
      "[epoch 13 Iteration 29/960] TRAIN loss:  0.634\n",
      "[epoch 13 Iteration 30/960] TRAIN loss:  0.593\n",
      "[epoch 13 Iteration 31/960] TRAIN loss:  0.551\n",
      "[epoch 13 Iteration 32/960] TRAIN loss:  0.421\n",
      "[epoch 13 Iteration 33/960] TRAIN loss:  0.754\n",
      "[epoch 13 Iteration 34/960] TRAIN loss:  0.631\n",
      "[epoch 13 Iteration 35/960] TRAIN loss:  0.601\n",
      "[epoch 13 Iteration 36/960] TRAIN loss:  0.488\n",
      "[epoch 13 Iteration 37/960] TRAIN loss:  0.519\n",
      "[epoch 13 Iteration 38/960] TRAIN loss:  0.466\n",
      "[epoch 13 Iteration 39/960] TRAIN loss:  0.390\n",
      "[epoch 13 Iteration 40/960] TRAIN loss:  0.503\n",
      "[epoch 13 Iteration 41/960] TRAIN loss:  0.534\n",
      "[epoch 13 Iteration 42/960] TRAIN loss:  0.675\n",
      "[epoch 13 Iteration 43/960] TRAIN loss:  0.621\n",
      "[epoch 13 Iteration 44/960] TRAIN loss:  0.718\n",
      "[epoch 13 Iteration 45/960] TRAIN loss:  0.410\n",
      "[epoch 13 Iteration 46/960] TRAIN loss:  0.489\n",
      "[epoch 13 Iteration 47/960] TRAIN loss:  0.536\n",
      "[epoch 13 Iteration 48/960] TRAIN loss:  0.625\n",
      "[epoch 13 Iteration 49/960] TRAIN loss:  0.489\n",
      "[epoch 13 Iteration 50/960] TRAIN loss:  0.659\n",
      "[epoch 13 Iteration 51/960] TRAIN loss:  0.514\n",
      "[epoch 13 Iteration 52/960] TRAIN loss:  0.605\n",
      "[epoch 13 Iteration 53/960] TRAIN loss:  0.458\n",
      "[epoch 13 Iteration 54/960] TRAIN loss:  0.626\n",
      "[epoch 13 Iteration 55/960] TRAIN loss:  0.650\n",
      "[epoch 13 Iteration 56/960] TRAIN loss:  0.510\n",
      "[epoch 13 Iteration 57/960] TRAIN loss:  0.660\n",
      "[epoch 13 Iteration 58/960] TRAIN loss:  0.623\n",
      "[epoch 13 Iteration 59/960] TRAIN loss:  0.413\n",
      "[epoch 13 Iteration 60/960] TRAIN loss:  0.564\n",
      "[epoch 13 Iteration 61/960] TRAIN loss:  0.478\n",
      "[epoch 13 Iteration 62/960] TRAIN loss:  0.560\n",
      "[epoch 13 Iteration 63/960] TRAIN loss:  0.411\n",
      "[epoch 13 Iteration 64/960] TRAIN loss:  0.315\n",
      "[epoch 13 Iteration 65/960] TRAIN loss:  0.638\n",
      "[epoch 13 Iteration 66/960] TRAIN loss:  0.516\n",
      "[epoch 13 Iteration 67/960] TRAIN loss:  0.667\n",
      "[epoch 13 Iteration 68/960] TRAIN loss:  0.462\n",
      "[epoch 13 Iteration 69/960] TRAIN loss:  0.518\n",
      "[epoch 13 Iteration 70/960] TRAIN loss:  0.632\n",
      "[epoch 13 Iteration 71/960] TRAIN loss:  0.513\n",
      "[epoch 13 Iteration 72/960] TRAIN loss:  0.541\n",
      "[epoch 13 Iteration 73/960] TRAIN loss:  0.597\n",
      "[epoch 13 Iteration 74/960] TRAIN loss:  0.583\n",
      "[epoch 13 Iteration 75/960] TRAIN loss:  0.448\n",
      "[epoch 13 Iteration 76/960] TRAIN loss:  0.536\n",
      "[epoch 13 Iteration 77/960] TRAIN loss:  0.586\n",
      "[epoch 13 Iteration 78/960] TRAIN loss:  0.381\n",
      "[epoch 13 Iteration 79/960] TRAIN loss:  0.516\n",
      "[epoch 13 Iteration 80/960] TRAIN loss:  0.496\n",
      "[epoch 13 Iteration 81/960] TRAIN loss:  0.624\n",
      "[epoch 13 Iteration 82/960] TRAIN loss:  0.432\n",
      "[epoch 13 Iteration 83/960] TRAIN loss:  0.478\n",
      "[epoch 13 Iteration 84/960] TRAIN loss:  0.561\n",
      "[epoch 13 Iteration 85/960] TRAIN loss:  0.552\n",
      "[epoch 13 Iteration 86/960] TRAIN loss:  0.738\n",
      "[epoch 13 Iteration 87/960] TRAIN loss:  0.516\n",
      "[epoch 13 Iteration 88/960] TRAIN loss:  0.490\n",
      "[epoch 13 Iteration 89/960] TRAIN loss:  0.558\n",
      "[epoch 13 Iteration 90/960] TRAIN loss:  0.461\n",
      "[epoch 13 Iteration 91/960] TRAIN loss:  0.561\n",
      "[epoch 13 Iteration 92/960] TRAIN loss:  0.462\n",
      "[epoch 13 Iteration 93/960] TRAIN loss:  0.671\n",
      "[epoch 13 Iteration 94/960] TRAIN loss:  0.556\n",
      "[epoch 13 Iteration 95/960] TRAIN loss:  0.517\n",
      "[epoch 13 Iteration 96/960] TRAIN loss:  0.625\n",
      "[epoch 13 Iteration 97/960] TRAIN loss:  0.478\n",
      "[epoch 13 Iteration 98/960] TRAIN loss:  0.461\n",
      "[epoch 13 Iteration 99/960] TRAIN loss:  0.674\n",
      "[epoch 13 Iteration 100/960] TRAIN loss:  0.554\n",
      "[epoch 13 Iteration 101/960] TRAIN loss:  0.666\n",
      "[epoch 13 Iteration 102/960] TRAIN loss:  0.486\n",
      "[epoch 13 Iteration 103/960] TRAIN loss:  0.546\n",
      "[epoch 13 Iteration 104/960] TRAIN loss:  0.417\n",
      "[epoch 13 Iteration 105/960] TRAIN loss:  0.571\n",
      "[epoch 13 Iteration 106/960] TRAIN loss:  0.593\n",
      "[epoch 13 Iteration 107/960] TRAIN loss:  0.500\n",
      "[epoch 13 Iteration 108/960] TRAIN loss:  0.582\n",
      "[epoch 13 Iteration 109/960] TRAIN loss:  0.506\n",
      "[epoch 13 Iteration 110/960] TRAIN loss:  0.543\n",
      "[epoch 13 Iteration 111/960] TRAIN loss:  0.637\n",
      "[epoch 13 Iteration 112/960] TRAIN loss:  0.540\n",
      "[epoch 13 Iteration 113/960] TRAIN loss:  0.746\n",
      "[epoch 13 Iteration 114/960] TRAIN loss:  0.402\n",
      "[epoch 13 Iteration 115/960] TRAIN loss:  0.556\n",
      "[epoch 13 Iteration 116/960] TRAIN loss:  0.721\n",
      "[epoch 13 Iteration 117/960] TRAIN loss:  0.684\n",
      "[epoch 13 Iteration 118/960] TRAIN loss:  0.588\n",
      "[epoch 13 Iteration 119/960] TRAIN loss:  0.477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 13 Iteration 120/960] TRAIN loss:  0.594\n",
      "[epoch 13 Iteration 121/960] TRAIN loss:  0.440\n",
      "[epoch 13 Iteration 122/960] TRAIN loss:  0.562\n",
      "[epoch 13 Iteration 123/960] TRAIN loss:  0.591\n",
      "[epoch 13 Iteration 124/960] TRAIN loss:  0.448\n",
      "[epoch 13 Iteration 125/960] TRAIN loss:  0.727\n",
      "[epoch 13 Iteration 126/960] TRAIN loss:  0.543\n",
      "[epoch 13 Iteration 127/960] TRAIN loss:  0.573\n",
      "[epoch 13 Iteration 128/960] TRAIN loss:  0.807\n",
      "[epoch 13 Iteration 129/960] TRAIN loss:  0.623\n",
      "[epoch 13 Iteration 130/960] TRAIN loss:  0.451\n",
      "[epoch 13 Iteration 131/960] TRAIN loss:  0.750\n",
      "[epoch 13 Iteration 132/960] TRAIN loss:  0.406\n",
      "[epoch 13 Iteration 133/960] TRAIN loss:  0.738\n",
      "[epoch 13 Iteration 134/960] TRAIN loss:  0.490\n",
      "[epoch 13 Iteration 135/960] TRAIN loss:  0.435\n",
      "[epoch 13 Iteration 136/960] TRAIN loss:  0.334\n",
      "[epoch 13 Iteration 137/960] TRAIN loss:  0.571\n",
      "[epoch 13 Iteration 138/960] TRAIN loss:  0.588\n",
      "[epoch 13 Iteration 139/960] TRAIN loss:  0.573\n",
      "[epoch 13 Iteration 140/960] TRAIN loss:  0.648\n",
      "[epoch 13 Iteration 141/960] TRAIN loss:  0.757\n",
      "[epoch 13 Iteration 142/960] TRAIN loss:  0.622\n",
      "[epoch 13 Iteration 143/960] TRAIN loss:  0.393\n",
      "[epoch 13 Iteration 144/960] TRAIN loss:  0.634\n",
      "[epoch 13 Iteration 145/960] TRAIN loss:  0.505\n",
      "[epoch 13 Iteration 146/960] TRAIN loss:  0.570\n",
      "[epoch 13 Iteration 147/960] TRAIN loss:  0.633\n",
      "[epoch 13 Iteration 148/960] TRAIN loss:  0.623\n",
      "[epoch 13 Iteration 149/960] TRAIN loss:  0.530\n",
      "[epoch 13 Iteration 150/960] TRAIN loss:  0.546\n",
      "[epoch 13 Iteration 151/960] TRAIN loss:  0.577\n",
      "[epoch 13 Iteration 152/960] TRAIN loss:  0.715\n",
      "[epoch 13 Iteration 153/960] TRAIN loss:  0.470\n",
      "[epoch 13 Iteration 154/960] TRAIN loss:  0.506\n",
      "[epoch 13 Iteration 155/960] TRAIN loss:  0.617\n",
      "[epoch 13 Iteration 156/960] TRAIN loss:  0.516\n",
      "[epoch 13 Iteration 157/960] TRAIN loss:  0.351\n",
      "[epoch 13 Iteration 158/960] TRAIN loss:  0.450\n",
      "[epoch 13 Iteration 159/960] TRAIN loss:  0.815\n",
      "[epoch 13 Iteration 160/960] TRAIN loss:  0.519\n",
      "[epoch 13 Iteration 161/960] TRAIN loss:  0.542\n",
      "[epoch 13 Iteration 162/960] TRAIN loss:  0.633\n",
      "[epoch 13 Iteration 163/960] TRAIN loss:  0.483\n",
      "[epoch 13 Iteration 164/960] TRAIN loss:  0.615\n",
      "[epoch 13 Iteration 165/960] TRAIN loss:  0.443\n",
      "[epoch 13 Iteration 166/960] TRAIN loss:  0.479\n",
      "[epoch 13 Iteration 167/960] TRAIN loss:  0.653\n",
      "[epoch 13 Iteration 168/960] TRAIN loss:  0.586\n",
      "[epoch 13 Iteration 169/960] TRAIN loss:  0.559\n",
      "[epoch 13 Iteration 170/960] TRAIN loss:  0.725\n",
      "[epoch 13 Iteration 171/960] TRAIN loss:  0.409\n",
      "[epoch 13 Iteration 172/960] TRAIN loss:  0.665\n",
      "[epoch 13 Iteration 173/960] TRAIN loss:  0.572\n",
      "[epoch 13 Iteration 174/960] TRAIN loss:  0.482\n",
      "[epoch 13 Iteration 175/960] TRAIN loss:  0.497\n",
      "[epoch 13 Iteration 176/960] TRAIN loss:  0.602\n",
      "[epoch 13 Iteration 177/960] TRAIN loss:  0.624\n",
      "[epoch 13 Iteration 178/960] TRAIN loss:  0.551\n",
      "[epoch 13 Iteration 179/960] TRAIN loss:  0.593\n",
      "[epoch 13 Iteration 180/960] TRAIN loss:  0.662\n",
      "[epoch 13 Iteration 181/960] TRAIN loss:  0.490\n",
      "[epoch 13 Iteration 182/960] TRAIN loss:  0.742\n",
      "[epoch 13 Iteration 183/960] TRAIN loss:  0.781\n",
      "[epoch 13 Iteration 184/960] TRAIN loss:  0.370\n",
      "[epoch 13 Iteration 185/960] TRAIN loss:  0.663\n",
      "[epoch 13 Iteration 186/960] TRAIN loss:  0.381\n",
      "[epoch 13 Iteration 187/960] TRAIN loss:  0.528\n",
      "[epoch 13 Iteration 188/960] TRAIN loss:  0.696\n",
      "[epoch 13 Iteration 189/960] TRAIN loss:  0.572\n",
      "[epoch 13 Iteration 190/960] TRAIN loss:  0.595\n",
      "[epoch 13 Iteration 191/960] TRAIN loss:  0.773\n",
      "[epoch 13 Iteration 192/960] TRAIN loss:  0.494\n",
      "[epoch 13 Iteration 193/960] TRAIN loss:  0.584\n",
      "[epoch 13 Iteration 194/960] TRAIN loss:  0.552\n",
      "[epoch 13 Iteration 195/960] TRAIN loss:  0.722\n",
      "[epoch 13 Iteration 196/960] TRAIN loss:  0.713\n",
      "[epoch 13 Iteration 197/960] TRAIN loss:  0.402\n",
      "[epoch 13 Iteration 198/960] TRAIN loss:  0.536\n",
      "[epoch 13 Iteration 199/960] TRAIN loss:  0.655\n",
      "[epoch 13 Iteration 200/960] TRAIN loss:  0.789\n",
      "[epoch 13 Iteration 201/960] TRAIN loss:  0.529\n",
      "[epoch 13 Iteration 202/960] TRAIN loss:  0.887\n",
      "[epoch 13 Iteration 203/960] TRAIN loss:  0.634\n",
      "[epoch 13 Iteration 204/960] TRAIN loss:  0.830\n",
      "[epoch 13 Iteration 205/960] TRAIN loss:  0.423\n",
      "[epoch 13 Iteration 206/960] TRAIN loss:  0.518\n",
      "[epoch 13 Iteration 207/960] TRAIN loss:  0.593\n",
      "[epoch 13 Iteration 208/960] TRAIN loss:  0.634\n",
      "[epoch 13 Iteration 209/960] TRAIN loss:  0.818\n",
      "[epoch 13 Iteration 210/960] TRAIN loss:  0.539\n",
      "[epoch 13 Iteration 211/960] TRAIN loss:  0.438\n",
      "[epoch 13 Iteration 212/960] TRAIN loss:  0.608\n",
      "[epoch 13 Iteration 213/960] TRAIN loss:  0.796\n",
      "[epoch 13 Iteration 214/960] TRAIN loss:  0.619\n",
      "[epoch 13 Iteration 215/960] TRAIN loss:  0.563\n",
      "[epoch 13 Iteration 216/960] TRAIN loss:  0.783\n",
      "[epoch 13 Iteration 217/960] TRAIN loss:  0.497\n",
      "[epoch 13 Iteration 218/960] TRAIN loss:  0.506\n",
      "[epoch 13 Iteration 219/960] TRAIN loss:  0.493\n",
      "[epoch 13 Iteration 220/960] TRAIN loss:  0.441\n",
      "[epoch 13 Iteration 221/960] TRAIN loss:  0.578\n",
      "[epoch 13 Iteration 222/960] TRAIN loss:  0.755\n",
      "[epoch 13 Iteration 223/960] TRAIN loss:  0.571\n",
      "[epoch 13 Iteration 224/960] TRAIN loss:  0.521\n",
      "[epoch 13 Iteration 225/960] TRAIN loss:  0.592\n",
      "[epoch 13 Iteration 226/960] TRAIN loss:  0.561\n",
      "[epoch 13 Iteration 227/960] TRAIN loss:  0.454\n",
      "[epoch 13 Iteration 228/960] TRAIN loss:  0.577\n",
      "[epoch 13 Iteration 229/960] TRAIN loss:  0.408\n",
      "[epoch 13 Iteration 230/960] TRAIN loss:  0.640\n",
      "[epoch 13 Iteration 231/960] TRAIN loss:  0.329\n",
      "[epoch 13 Iteration 232/960] TRAIN loss:  0.600\n",
      "[epoch 13 Iteration 233/960] TRAIN loss:  0.487\n",
      "[epoch 13 Iteration 234/960] TRAIN loss:  0.502\n",
      "[epoch 13 Iteration 235/960] TRAIN loss:  0.411\n",
      "[epoch 13 Iteration 236/960] TRAIN loss:  0.492\n",
      "[epoch 13 Iteration 237/960] TRAIN loss:  0.647\n",
      "[epoch 13 Iteration 238/960] TRAIN loss:  0.488\n",
      "[epoch 13 Iteration 239/960] TRAIN loss:  0.697\n",
      "[epoch 13 Iteration 240/960] TRAIN loss:  0.657\n",
      "[epoch 13 Iteration 241/960] TRAIN loss:  0.719\n",
      "[epoch 13 Iteration 242/960] TRAIN loss:  0.903\n",
      "[epoch 13 Iteration 243/960] TRAIN loss:  0.523\n",
      "[epoch 13 Iteration 244/960] TRAIN loss:  0.517\n",
      "[epoch 13 Iteration 245/960] TRAIN loss:  0.394\n",
      "[epoch 13 Iteration 246/960] TRAIN loss:  0.510\n",
      "[epoch 13 Iteration 247/960] TRAIN loss:  0.783\n",
      "[epoch 13 Iteration 248/960] TRAIN loss:  0.423\n",
      "[epoch 13 Iteration 249/960] TRAIN loss:  0.493\n",
      "[epoch 13 Iteration 250/960] TRAIN loss:  0.394\n",
      "[epoch 13 Iteration 251/960] TRAIN loss:  0.689\n",
      "[epoch 13 Iteration 252/960] TRAIN loss:  0.561\n",
      "[epoch 13 Iteration 253/960] TRAIN loss:  0.494\n",
      "[epoch 13 Iteration 254/960] TRAIN loss:  0.585\n",
      "[epoch 13 Iteration 255/960] TRAIN loss:  0.443\n",
      "[epoch 13 Iteration 256/960] TRAIN loss:  0.660\n",
      "[epoch 13 Iteration 257/960] TRAIN loss:  0.391\n",
      "[epoch 13 Iteration 258/960] TRAIN loss:  0.533\n",
      "[epoch 13 Iteration 259/960] TRAIN loss:  0.564\n",
      "[epoch 13 Iteration 260/960] TRAIN loss:  0.464\n",
      "[epoch 13 Iteration 261/960] TRAIN loss:  0.484\n",
      "[epoch 13 Iteration 262/960] TRAIN loss:  0.253\n",
      "[epoch 13 Iteration 263/960] TRAIN loss:  0.498\n",
      "[epoch 13 Iteration 264/960] TRAIN loss:  0.665\n",
      "[epoch 13 Iteration 265/960] TRAIN loss:  0.838\n",
      "[epoch 13 Iteration 266/960] TRAIN loss:  0.414\n",
      "[epoch 13 Iteration 267/960] TRAIN loss:  0.748\n",
      "[epoch 13 Iteration 268/960] TRAIN loss:  0.555\n",
      "[epoch 13 Iteration 269/960] TRAIN loss:  0.970\n",
      "[epoch 13 Iteration 270/960] TRAIN loss:  0.467\n",
      "[epoch 13 Iteration 271/960] TRAIN loss:  0.696\n",
      "[epoch 13 Iteration 272/960] TRAIN loss:  0.418\n",
      "[epoch 13 Iteration 273/960] TRAIN loss:  0.475\n",
      "[epoch 13 Iteration 274/960] TRAIN loss:  0.552\n",
      "[epoch 13 Iteration 275/960] TRAIN loss:  0.631\n",
      "[epoch 13 Iteration 276/960] TRAIN loss:  0.677\n",
      "[epoch 13 Iteration 277/960] TRAIN loss:  0.656\n",
      "[epoch 13 Iteration 278/960] TRAIN loss:  0.520\n",
      "[epoch 13 Iteration 279/960] TRAIN loss:  0.568\n",
      "[epoch 13 Iteration 280/960] TRAIN loss:  0.572\n",
      "[epoch 13 Iteration 281/960] TRAIN loss:  0.550\n",
      "[epoch 13 Iteration 282/960] TRAIN loss:  0.617\n",
      "[epoch 13 Iteration 283/960] TRAIN loss:  0.562\n",
      "[epoch 13 Iteration 284/960] TRAIN loss:  0.772\n",
      "[epoch 13 Iteration 285/960] TRAIN loss:  0.815\n",
      "[epoch 13 Iteration 286/960] TRAIN loss:  0.355\n",
      "[epoch 13 Iteration 287/960] TRAIN loss:  0.509\n",
      "[epoch 13 Iteration 288/960] TRAIN loss:  0.468\n",
      "[epoch 13 Iteration 289/960] TRAIN loss:  0.636\n",
      "[epoch 13 Iteration 290/960] TRAIN loss:  0.835\n",
      "[epoch 13 Iteration 291/960] TRAIN loss:  0.639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 13 Iteration 292/960] TRAIN loss:  0.693\n",
      "[epoch 13 Iteration 293/960] TRAIN loss:  0.728\n",
      "[epoch 13 Iteration 294/960] TRAIN loss:  0.616\n",
      "[epoch 13 Iteration 295/960] TRAIN loss:  0.455\n",
      "[epoch 13 Iteration 296/960] TRAIN loss:  0.638\n",
      "[epoch 13 Iteration 297/960] TRAIN loss:  0.549\n",
      "[epoch 13 Iteration 298/960] TRAIN loss:  0.543\n",
      "[epoch 13 Iteration 299/960] TRAIN loss:  0.535\n",
      "[epoch 13 Iteration 300/960] TRAIN loss:  0.474\n",
      "[epoch 13 Iteration 301/960] TRAIN loss:  0.541\n",
      "[epoch 13 Iteration 302/960] TRAIN loss:  0.735\n",
      "[epoch 13 Iteration 303/960] TRAIN loss:  0.406\n",
      "[epoch 13 Iteration 304/960] TRAIN loss:  0.627\n",
      "[epoch 13 Iteration 305/960] TRAIN loss:  0.723\n",
      "[epoch 13 Iteration 306/960] TRAIN loss:  0.674\n",
      "[epoch 13 Iteration 307/960] TRAIN loss:  0.455\n",
      "[epoch 13 Iteration 308/960] TRAIN loss:  0.598\n",
      "[epoch 13 Iteration 309/960] TRAIN loss:  0.393\n",
      "[epoch 13 Iteration 310/960] TRAIN loss:  0.688\n",
      "[epoch 13 Iteration 311/960] TRAIN loss:  0.834\n",
      "[epoch 13 Iteration 312/960] TRAIN loss:  0.543\n",
      "[epoch 13 Iteration 313/960] TRAIN loss:  0.496\n",
      "[epoch 13 Iteration 314/960] TRAIN loss:  0.565\n",
      "[epoch 13 Iteration 315/960] TRAIN loss:  0.586\n",
      "[epoch 13 Iteration 316/960] TRAIN loss:  0.623\n",
      "[epoch 13 Iteration 317/960] TRAIN loss:  0.615\n",
      "[epoch 13 Iteration 318/960] TRAIN loss:  0.710\n",
      "[epoch 13 Iteration 319/960] TRAIN loss:  0.541\n",
      "[epoch 13 Iteration 320/960] TRAIN loss:  0.479\n",
      "[epoch 13 Iteration 321/960] TRAIN loss:  0.525\n",
      "[epoch 13 Iteration 322/960] TRAIN loss:  0.709\n",
      "[epoch 13 Iteration 323/960] TRAIN loss:  0.703\n",
      "[epoch 13 Iteration 324/960] TRAIN loss:  0.607\n",
      "[epoch 13 Iteration 325/960] TRAIN loss:  0.473\n",
      "[epoch 13 Iteration 326/960] TRAIN loss:  0.566\n",
      "[epoch 13 Iteration 327/960] TRAIN loss:  0.343\n",
      "[epoch 13 Iteration 328/960] TRAIN loss:  0.322\n",
      "[epoch 13 Iteration 329/960] TRAIN loss:  0.557\n",
      "[epoch 13 Iteration 330/960] TRAIN loss:  0.670\n",
      "[epoch 13 Iteration 331/960] TRAIN loss:  0.758\n",
      "[epoch 13 Iteration 332/960] TRAIN loss:  0.622\n",
      "[epoch 13 Iteration 333/960] TRAIN loss:  0.757\n",
      "[epoch 13 Iteration 334/960] TRAIN loss:  0.565\n",
      "[epoch 13 Iteration 335/960] TRAIN loss:  0.683\n",
      "[epoch 13 Iteration 336/960] TRAIN loss:  0.657\n",
      "[epoch 13 Iteration 337/960] TRAIN loss:  0.677\n",
      "[epoch 13 Iteration 338/960] TRAIN loss:  0.750\n",
      "[epoch 13 Iteration 339/960] TRAIN loss:  0.744\n",
      "[epoch 13 Iteration 340/960] TRAIN loss:  0.646\n",
      "[epoch 13 Iteration 341/960] TRAIN loss:  0.623\n",
      "[epoch 13 Iteration 342/960] TRAIN loss:  0.554\n",
      "[epoch 13 Iteration 343/960] TRAIN loss:  0.549\n",
      "[epoch 13 Iteration 344/960] TRAIN loss:  0.710\n",
      "[epoch 13 Iteration 345/960] TRAIN loss:  0.495\n",
      "[epoch 13 Iteration 346/960] TRAIN loss:  0.722\n",
      "[epoch 13 Iteration 347/960] TRAIN loss:  0.515\n",
      "[epoch 13 Iteration 348/960] TRAIN loss:  0.838\n",
      "[epoch 13 Iteration 349/960] TRAIN loss:  0.535\n",
      "[epoch 13 Iteration 350/960] TRAIN loss:  0.797\n",
      "[epoch 13 Iteration 351/960] TRAIN loss:  0.412\n",
      "[epoch 13 Iteration 352/960] TRAIN loss:  0.469\n",
      "[epoch 13 Iteration 353/960] TRAIN loss:  0.659\n",
      "[epoch 13 Iteration 354/960] TRAIN loss:  0.804\n",
      "[epoch 13 Iteration 355/960] TRAIN loss:  0.468\n",
      "[epoch 13 Iteration 356/960] TRAIN loss:  0.493\n",
      "[epoch 13 Iteration 357/960] TRAIN loss:  0.431\n",
      "[epoch 13 Iteration 358/960] TRAIN loss:  0.552\n",
      "[epoch 13 Iteration 359/960] TRAIN loss:  0.723\n",
      "[epoch 13 Iteration 360/960] TRAIN loss:  0.719\n",
      "[epoch 13 Iteration 361/960] TRAIN loss:  0.819\n",
      "[epoch 13 Iteration 362/960] TRAIN loss:  0.569\n",
      "[epoch 13 Iteration 363/960] TRAIN loss:  0.625\n",
      "[epoch 13 Iteration 364/960] TRAIN loss:  0.639\n",
      "[epoch 13 Iteration 365/960] TRAIN loss:  0.611\n",
      "[epoch 13 Iteration 366/960] TRAIN loss:  0.679\n",
      "[epoch 13 Iteration 367/960] TRAIN loss:  0.767\n",
      "[epoch 13 Iteration 368/960] TRAIN loss:  0.444\n",
      "[epoch 13 Iteration 369/960] TRAIN loss:  0.604\n",
      "[epoch 13 Iteration 370/960] TRAIN loss:  0.448\n",
      "[epoch 13 Iteration 371/960] TRAIN loss:  0.452\n",
      "[epoch 13 Iteration 372/960] TRAIN loss:  0.246\n",
      "[epoch 13 Iteration 373/960] TRAIN loss:  0.583\n",
      "[epoch 13 Iteration 374/960] TRAIN loss:  0.579\n",
      "[epoch 13 Iteration 375/960] TRAIN loss:  0.402\n",
      "[epoch 13 Iteration 376/960] TRAIN loss:  0.661\n",
      "[epoch 13 Iteration 377/960] TRAIN loss:  0.561\n",
      "[epoch 13 Iteration 378/960] TRAIN loss:  0.645\n",
      "[epoch 13 Iteration 379/960] TRAIN loss:  0.452\n",
      "[epoch 13 Iteration 380/960] TRAIN loss:  0.707\n",
      "[epoch 13 Iteration 381/960] TRAIN loss:  0.621\n",
      "[epoch 13 Iteration 382/960] TRAIN loss:  0.413\n",
      "[epoch 13 Iteration 383/960] TRAIN loss:  0.504\n",
      "[epoch 13 Iteration 384/960] TRAIN loss:  0.605\n",
      "[epoch 13 Iteration 385/960] TRAIN loss:  0.490\n",
      "[epoch 13 Iteration 386/960] TRAIN loss:  0.405\n",
      "[epoch 13 Iteration 387/960] TRAIN loss:  0.384\n",
      "[epoch 13 Iteration 388/960] TRAIN loss:  0.665\n",
      "[epoch 13 Iteration 389/960] TRAIN loss:  0.530\n",
      "[epoch 13 Iteration 390/960] TRAIN loss:  0.650\n",
      "[epoch 13 Iteration 391/960] TRAIN loss:  0.677\n",
      "[epoch 13 Iteration 392/960] TRAIN loss:  0.542\n",
      "[epoch 13 Iteration 393/960] TRAIN loss:  0.666\n",
      "[epoch 13 Iteration 394/960] TRAIN loss:  0.507\n",
      "[epoch 13 Iteration 395/960] TRAIN loss:  0.698\n",
      "[epoch 13 Iteration 396/960] TRAIN loss:  0.495\n",
      "[epoch 13 Iteration 397/960] TRAIN loss:  0.786\n",
      "[epoch 13 Iteration 398/960] TRAIN loss:  0.707\n",
      "[epoch 13 Iteration 399/960] TRAIN loss:  0.530\n",
      "[epoch 13 Iteration 400/960] TRAIN loss:  0.508\n",
      "[epoch 13 Iteration 401/960] TRAIN loss:  0.384\n",
      "[epoch 13 Iteration 402/960] TRAIN loss:  0.501\n",
      "[epoch 13 Iteration 403/960] TRAIN loss:  0.829\n",
      "[epoch 13 Iteration 404/960] TRAIN loss:  0.568\n",
      "[epoch 13 Iteration 405/960] TRAIN loss:  0.984\n",
      "[epoch 13 Iteration 406/960] TRAIN loss:  0.833\n",
      "[epoch 13 Iteration 407/960] TRAIN loss:  0.584\n",
      "[epoch 13 Iteration 408/960] TRAIN loss:  0.528\n",
      "[epoch 13 Iteration 409/960] TRAIN loss:  0.737\n",
      "[epoch 13 Iteration 410/960] TRAIN loss:  0.551\n",
      "[epoch 13 Iteration 411/960] TRAIN loss:  0.708\n",
      "[epoch 13 Iteration 412/960] TRAIN loss:  0.693\n",
      "[epoch 13 Iteration 413/960] TRAIN loss:  0.603\n",
      "[epoch 13 Iteration 414/960] TRAIN loss:  0.613\n",
      "[epoch 13 Iteration 415/960] TRAIN loss:  0.563\n",
      "[epoch 13 Iteration 416/960] TRAIN loss:  0.795\n",
      "[epoch 13 Iteration 417/960] TRAIN loss:  0.720\n",
      "[epoch 13 Iteration 418/960] TRAIN loss:  0.874\n",
      "[epoch 13 Iteration 419/960] TRAIN loss:  0.566\n",
      "[epoch 13 Iteration 420/960] TRAIN loss:  0.582\n",
      "[epoch 13 Iteration 421/960] TRAIN loss:  0.640\n",
      "[epoch 13 Iteration 422/960] TRAIN loss:  0.609\n",
      "[epoch 13 Iteration 423/960] TRAIN loss:  0.577\n",
      "[epoch 13 Iteration 424/960] TRAIN loss:  0.830\n",
      "[epoch 13 Iteration 425/960] TRAIN loss:  0.906\n",
      "[epoch 13 Iteration 426/960] TRAIN loss:  0.612\n",
      "[epoch 13 Iteration 427/960] TRAIN loss:  0.872\n",
      "[epoch 13 Iteration 428/960] TRAIN loss:  0.503\n",
      "[epoch 13 Iteration 429/960] TRAIN loss:  0.553\n",
      "[epoch 13 Iteration 430/960] TRAIN loss:  0.604\n",
      "[epoch 13 Iteration 431/960] TRAIN loss:  0.704\n",
      "[epoch 13 Iteration 432/960] TRAIN loss:  0.530\n",
      "[epoch 13 Iteration 433/960] TRAIN loss:  0.563\n",
      "[epoch 13 Iteration 434/960] TRAIN loss:  0.686\n",
      "[epoch 13 Iteration 435/960] TRAIN loss:  0.503\n",
      "[epoch 13 Iteration 436/960] TRAIN loss:  0.668\n",
      "[epoch 13 Iteration 437/960] TRAIN loss:  0.598\n",
      "[epoch 13 Iteration 438/960] TRAIN loss:  1.092\n",
      "[epoch 13 Iteration 439/960] TRAIN loss:  0.511\n",
      "[epoch 13 Iteration 440/960] TRAIN loss:  0.612\n",
      "[epoch 13 Iteration 441/960] TRAIN loss:  0.872\n",
      "[epoch 13 Iteration 442/960] TRAIN loss:  0.682\n",
      "[epoch 13 Iteration 443/960] TRAIN loss:  0.390\n",
      "[epoch 13 Iteration 444/960] TRAIN loss:  0.625\n",
      "[epoch 13 Iteration 445/960] TRAIN loss:  0.846\n",
      "[epoch 13 Iteration 446/960] TRAIN loss:  0.587\n",
      "[epoch 13 Iteration 447/960] TRAIN loss:  0.678\n",
      "[epoch 13 Iteration 448/960] TRAIN loss:  0.537\n",
      "[epoch 13 Iteration 449/960] TRAIN loss:  0.597\n",
      "[epoch 13 Iteration 450/960] TRAIN loss:  0.573\n",
      "[epoch 13 Iteration 451/960] TRAIN loss:  0.760\n",
      "[epoch 13 Iteration 452/960] TRAIN loss:  0.590\n",
      "[epoch 13 Iteration 453/960] TRAIN loss:  0.633\n",
      "[epoch 13 Iteration 454/960] TRAIN loss:  0.430\n",
      "[epoch 13 Iteration 455/960] TRAIN loss:  0.624\n",
      "[epoch 13 Iteration 456/960] TRAIN loss:  0.623\n",
      "[epoch 13 Iteration 457/960] TRAIN loss:  0.679\n",
      "[epoch 13 Iteration 458/960] TRAIN loss:  0.616\n",
      "[epoch 13 Iteration 459/960] TRAIN loss:  0.514\n",
      "[epoch 13 Iteration 460/960] TRAIN loss:  0.716\n",
      "[epoch 13 Iteration 461/960] TRAIN loss:  0.713\n",
      "[epoch 13 Iteration 462/960] TRAIN loss:  0.814\n",
      "[epoch 13 Iteration 463/960] TRAIN loss:  0.673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 13 Iteration 464/960] TRAIN loss:  0.815\n",
      "[epoch 13 Iteration 465/960] TRAIN loss:  0.454\n",
      "[epoch 13 Iteration 466/960] TRAIN loss:  0.514\n",
      "[epoch 13 Iteration 467/960] TRAIN loss:  0.551\n",
      "[epoch 13 Iteration 468/960] TRAIN loss:  0.728\n",
      "[epoch 13 Iteration 469/960] TRAIN loss:  0.466\n",
      "[epoch 13 Iteration 470/960] TRAIN loss:  0.554\n",
      "[epoch 13 Iteration 471/960] TRAIN loss:  0.659\n",
      "[epoch 13 Iteration 472/960] TRAIN loss:  0.823\n",
      "[epoch 13 Iteration 473/960] TRAIN loss:  0.610\n",
      "[epoch 13 Iteration 474/960] TRAIN loss:  0.637\n",
      "[epoch 13 Iteration 475/960] TRAIN loss:  0.563\n",
      "[epoch 13 Iteration 476/960] TRAIN loss:  0.376\n",
      "[epoch 13 Iteration 477/960] TRAIN loss:  0.756\n",
      "[epoch 13 Iteration 478/960] TRAIN loss:  0.398\n",
      "[epoch 13 Iteration 479/960] TRAIN loss:  0.431\n",
      "[epoch 13 Iteration 480/960] TRAIN loss:  0.735\n",
      "[epoch 13 Iteration 481/960] TRAIN loss:  0.496\n",
      "[epoch 13 Iteration 482/960] TRAIN loss:  0.585\n",
      "[epoch 13 Iteration 483/960] TRAIN loss:  0.374\n",
      "[epoch 13 Iteration 484/960] TRAIN loss:  0.470\n",
      "[epoch 13 Iteration 485/960] TRAIN loss:  0.546\n",
      "[epoch 13 Iteration 486/960] TRAIN loss:  0.294\n",
      "[epoch 13 Iteration 487/960] TRAIN loss:  0.669\n",
      "[epoch 13 Iteration 488/960] TRAIN loss:  0.683\n",
      "[epoch 13 Iteration 489/960] TRAIN loss:  0.601\n",
      "[epoch 13 Iteration 490/960] TRAIN loss:  0.466\n",
      "[epoch 13 Iteration 491/960] TRAIN loss:  0.582\n",
      "[epoch 13 Iteration 492/960] TRAIN loss:  0.721\n",
      "[epoch 13 Iteration 493/960] TRAIN loss:  0.734\n",
      "[epoch 13 Iteration 494/960] TRAIN loss:  0.569\n",
      "[epoch 13 Iteration 495/960] TRAIN loss:  0.554\n",
      "[epoch 13 Iteration 496/960] TRAIN loss:  0.545\n",
      "[epoch 13 Iteration 497/960] TRAIN loss:  0.566\n",
      "[epoch 13 Iteration 498/960] TRAIN loss:  0.673\n",
      "[epoch 13 Iteration 499/960] TRAIN loss:  0.960\n",
      "[epoch 13 Iteration 500/960] TRAIN loss:  0.929\n",
      "[epoch 13 Iteration 501/960] TRAIN loss:  0.569\n",
      "[epoch 13 Iteration 502/960] TRAIN loss:  0.628\n",
      "[epoch 13 Iteration 503/960] TRAIN loss:  0.425\n",
      "[epoch 13 Iteration 504/960] TRAIN loss:  0.589\n",
      "[epoch 13 Iteration 505/960] TRAIN loss:  0.601\n",
      "[epoch 13 Iteration 506/960] TRAIN loss:  0.650\n",
      "[epoch 13 Iteration 507/960] TRAIN loss:  0.738\n",
      "[epoch 13 Iteration 508/960] TRAIN loss:  0.666\n",
      "[epoch 13 Iteration 509/960] TRAIN loss:  0.701\n",
      "[epoch 13 Iteration 510/960] TRAIN loss:  0.595\n",
      "[epoch 13 Iteration 511/960] TRAIN loss:  0.621\n",
      "[epoch 13 Iteration 512/960] TRAIN loss:  0.725\n",
      "[epoch 13 Iteration 513/960] TRAIN loss:  0.477\n",
      "[epoch 13 Iteration 514/960] TRAIN loss:  0.407\n",
      "[epoch 13 Iteration 515/960] TRAIN loss:  0.376\n",
      "[epoch 13 Iteration 516/960] TRAIN loss:  0.713\n",
      "[epoch 13 Iteration 517/960] TRAIN loss:  0.524\n",
      "[epoch 13 Iteration 518/960] TRAIN loss:  0.623\n",
      "[epoch 13 Iteration 519/960] TRAIN loss:  0.573\n",
      "[epoch 13 Iteration 520/960] TRAIN loss:  0.570\n",
      "[epoch 13 Iteration 521/960] TRAIN loss:  0.859\n",
      "[epoch 13 Iteration 522/960] TRAIN loss:  0.854\n",
      "[epoch 13 Iteration 523/960] TRAIN loss:  0.675\n",
      "[epoch 13 Iteration 524/960] TRAIN loss:  0.365\n",
      "[epoch 13 Iteration 525/960] TRAIN loss:  0.618\n",
      "[epoch 13 Iteration 526/960] TRAIN loss:  0.638\n",
      "[epoch 13 Iteration 527/960] TRAIN loss:  0.635\n",
      "[epoch 13 Iteration 528/960] TRAIN loss:  0.407\n",
      "[epoch 13 Iteration 529/960] TRAIN loss:  0.612\n",
      "[epoch 13 Iteration 530/960] TRAIN loss:  0.723\n",
      "[epoch 13 Iteration 531/960] TRAIN loss:  0.543\n",
      "[epoch 13 Iteration 532/960] TRAIN loss:  0.586\n",
      "[epoch 13 Iteration 533/960] TRAIN loss:  0.584\n",
      "[epoch 13 Iteration 534/960] TRAIN loss:  0.461\n",
      "[epoch 13 Iteration 535/960] TRAIN loss:  0.597\n",
      "[epoch 13 Iteration 536/960] TRAIN loss:  0.497\n",
      "[epoch 13 Iteration 537/960] TRAIN loss:  0.561\n",
      "[epoch 13 Iteration 538/960] TRAIN loss:  0.733\n",
      "[epoch 13 Iteration 539/960] TRAIN loss:  0.687\n",
      "[epoch 13 Iteration 540/960] TRAIN loss:  0.388\n",
      "[epoch 13 Iteration 541/960] TRAIN loss:  0.877\n",
      "[epoch 13 Iteration 542/960] TRAIN loss:  0.522\n",
      "[epoch 13 Iteration 543/960] TRAIN loss:  0.549\n",
      "[epoch 13 Iteration 544/960] TRAIN loss:  0.572\n",
      "[epoch 13 Iteration 545/960] TRAIN loss:  0.488\n",
      "[epoch 13 Iteration 546/960] TRAIN loss:  0.859\n",
      "[epoch 13 Iteration 547/960] TRAIN loss:  0.679\n",
      "[epoch 13 Iteration 548/960] TRAIN loss:  0.546\n",
      "[epoch 13 Iteration 549/960] TRAIN loss:  0.599\n",
      "[epoch 13 Iteration 550/960] TRAIN loss:  0.534\n",
      "[epoch 13 Iteration 551/960] TRAIN loss:  0.756\n",
      "[epoch 13 Iteration 552/960] TRAIN loss:  0.478\n",
      "[epoch 13 Iteration 553/960] TRAIN loss:  0.515\n",
      "[epoch 13 Iteration 554/960] TRAIN loss:  0.550\n",
      "[epoch 13 Iteration 555/960] TRAIN loss:  0.792\n",
      "[epoch 13 Iteration 556/960] TRAIN loss:  0.764\n",
      "[epoch 13 Iteration 557/960] TRAIN loss:  0.955\n",
      "[epoch 13 Iteration 558/960] TRAIN loss:  0.823\n",
      "[epoch 13 Iteration 559/960] TRAIN loss:  0.565\n",
      "[epoch 13 Iteration 560/960] TRAIN loss:  0.524\n",
      "[epoch 13 Iteration 561/960] TRAIN loss:  0.582\n",
      "[epoch 13 Iteration 562/960] TRAIN loss:  0.646\n",
      "[epoch 13 Iteration 563/960] TRAIN loss:  0.587\n",
      "[epoch 13 Iteration 564/960] TRAIN loss:  0.576\n",
      "[epoch 13 Iteration 565/960] TRAIN loss:  0.444\n",
      "[epoch 13 Iteration 566/960] TRAIN loss:  0.756\n",
      "[epoch 13 Iteration 567/960] TRAIN loss:  0.707\n",
      "[epoch 13 Iteration 568/960] TRAIN loss:  0.530\n",
      "[epoch 13 Iteration 569/960] TRAIN loss:  0.416\n",
      "[epoch 13 Iteration 570/960] TRAIN loss:  0.394\n",
      "[epoch 13 Iteration 571/960] TRAIN loss:  0.660\n",
      "[epoch 13 Iteration 572/960] TRAIN loss:  0.759\n",
      "[epoch 13 Iteration 573/960] TRAIN loss:  0.527\n",
      "[epoch 13 Iteration 574/960] TRAIN loss:  0.455\n",
      "[epoch 13 Iteration 575/960] TRAIN loss:  0.413\n",
      "[epoch 13 Iteration 576/960] TRAIN loss:  0.623\n",
      "[epoch 13 Iteration 577/960] TRAIN loss:  0.510\n",
      "[epoch 13 Iteration 578/960] TRAIN loss:  0.454\n",
      "[epoch 13 Iteration 579/960] TRAIN loss:  0.576\n",
      "[epoch 13 Iteration 580/960] TRAIN loss:  0.712\n",
      "[epoch 13 Iteration 581/960] TRAIN loss:  0.517\n",
      "[epoch 13 Iteration 582/960] TRAIN loss:  0.767\n",
      "[epoch 13 Iteration 583/960] TRAIN loss:  0.559\n",
      "[epoch 13 Iteration 584/960] TRAIN loss:  0.800\n",
      "[epoch 13 Iteration 585/960] TRAIN loss:  0.685\n",
      "[epoch 13 Iteration 586/960] TRAIN loss:  0.508\n",
      "[epoch 13 Iteration 587/960] TRAIN loss:  0.682\n",
      "[epoch 13 Iteration 588/960] TRAIN loss:  0.661\n",
      "[epoch 13 Iteration 589/960] TRAIN loss:  0.480\n",
      "[epoch 13 Iteration 590/960] TRAIN loss:  0.670\n",
      "[epoch 13 Iteration 591/960] TRAIN loss:  0.549\n",
      "[epoch 13 Iteration 592/960] TRAIN loss:  0.405\n",
      "[epoch 13 Iteration 593/960] TRAIN loss:  0.956\n",
      "[epoch 13 Iteration 594/960] TRAIN loss:  0.525\n",
      "[epoch 13 Iteration 595/960] TRAIN loss:  0.597\n",
      "[epoch 13 Iteration 596/960] TRAIN loss:  0.618\n",
      "[epoch 13 Iteration 597/960] TRAIN loss:  0.637\n",
      "[epoch 13 Iteration 598/960] TRAIN loss:  0.423\n",
      "[epoch 13 Iteration 599/960] TRAIN loss:  0.591\n",
      "[epoch 13 Iteration 600/960] TRAIN loss:  0.704\n",
      "[epoch 13 Iteration 601/960] TRAIN loss:  0.451\n",
      "[epoch 13 Iteration 602/960] TRAIN loss:  0.614\n",
      "[epoch 13 Iteration 603/960] TRAIN loss:  0.650\n",
      "[epoch 13 Iteration 604/960] TRAIN loss:  0.630\n",
      "[epoch 13 Iteration 605/960] TRAIN loss:  0.790\n",
      "[epoch 13 Iteration 606/960] TRAIN loss:  0.524\n",
      "[epoch 13 Iteration 607/960] TRAIN loss:  0.551\n",
      "[epoch 13 Iteration 608/960] TRAIN loss:  0.970\n",
      "[epoch 13 Iteration 609/960] TRAIN loss:  0.665\n",
      "[epoch 13 Iteration 610/960] TRAIN loss:  0.712\n",
      "[epoch 13 Iteration 611/960] TRAIN loss:  0.637\n",
      "[epoch 13 Iteration 612/960] TRAIN loss:  0.573\n",
      "[epoch 13 Iteration 613/960] TRAIN loss:  0.987\n",
      "[epoch 13 Iteration 614/960] TRAIN loss:  0.513\n",
      "[epoch 13 Iteration 615/960] TRAIN loss:  0.570\n",
      "[epoch 13 Iteration 616/960] TRAIN loss:  0.545\n",
      "[epoch 13 Iteration 617/960] TRAIN loss:  0.660\n",
      "[epoch 13 Iteration 618/960] TRAIN loss:  0.475\n",
      "[epoch 13 Iteration 619/960] TRAIN loss:  0.449\n",
      "[epoch 13 Iteration 620/960] TRAIN loss:  0.548\n",
      "[epoch 13 Iteration 621/960] TRAIN loss:  0.623\n",
      "[epoch 13 Iteration 622/960] TRAIN loss:  0.593\n",
      "[epoch 13 Iteration 623/960] TRAIN loss:  0.700\n",
      "[epoch 13 Iteration 624/960] TRAIN loss:  0.638\n",
      "[epoch 13 Iteration 625/960] TRAIN loss:  0.462\n",
      "[epoch 13 Iteration 626/960] TRAIN loss:  0.766\n",
      "[epoch 13 Iteration 627/960] TRAIN loss:  0.394\n",
      "[epoch 13 Iteration 628/960] TRAIN loss:  1.056\n",
      "[epoch 13 Iteration 629/960] TRAIN loss:  0.450\n",
      "[epoch 13 Iteration 630/960] TRAIN loss:  0.651\n",
      "[epoch 13 Iteration 631/960] TRAIN loss:  0.824\n",
      "[epoch 13 Iteration 632/960] TRAIN loss:  0.451\n",
      "[epoch 13 Iteration 633/960] TRAIN loss:  0.510\n",
      "[epoch 13 Iteration 634/960] TRAIN loss:  0.626\n",
      "[epoch 13 Iteration 635/960] TRAIN loss:  0.413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 13 Iteration 636/960] TRAIN loss:  0.577\n",
      "[epoch 13 Iteration 637/960] TRAIN loss:  0.454\n",
      "[epoch 13 Iteration 638/960] TRAIN loss:  0.787\n",
      "[epoch 13 Iteration 639/960] TRAIN loss:  0.564\n",
      "[epoch 13 Iteration 640/960] TRAIN loss:  0.761\n",
      "[epoch 13 Iteration 641/960] TRAIN loss:  0.658\n",
      "[epoch 13 Iteration 642/960] TRAIN loss:  0.468\n",
      "[epoch 13 Iteration 643/960] TRAIN loss:  0.478\n",
      "[epoch 13 Iteration 644/960] TRAIN loss:  0.512\n",
      "[epoch 13 Iteration 645/960] TRAIN loss:  0.499\n",
      "[epoch 13 Iteration 646/960] TRAIN loss:  0.651\n",
      "[epoch 13 Iteration 647/960] TRAIN loss:  0.644\n",
      "[epoch 13 Iteration 648/960] TRAIN loss:  0.360\n",
      "[epoch 13 Iteration 649/960] TRAIN loss:  0.630\n",
      "[epoch 13 Iteration 650/960] TRAIN loss:  0.892\n",
      "[epoch 13 Iteration 651/960] TRAIN loss:  0.504\n",
      "[epoch 13 Iteration 652/960] TRAIN loss:  0.571\n",
      "[epoch 13 Iteration 653/960] TRAIN loss:  0.664\n",
      "[epoch 13 Iteration 654/960] TRAIN loss:  0.631\n",
      "[epoch 13 Iteration 655/960] TRAIN loss:  0.680\n",
      "[epoch 13 Iteration 656/960] TRAIN loss:  0.577\n",
      "[epoch 13 Iteration 657/960] TRAIN loss:  0.581\n",
      "[epoch 13 Iteration 658/960] TRAIN loss:  0.651\n",
      "[epoch 13 Iteration 659/960] TRAIN loss:  0.475\n",
      "[epoch 13 Iteration 660/960] TRAIN loss:  0.674\n",
      "[epoch 13 Iteration 661/960] TRAIN loss:  0.602\n",
      "[epoch 13 Iteration 662/960] TRAIN loss:  0.643\n",
      "[epoch 13 Iteration 663/960] TRAIN loss:  0.471\n",
      "[epoch 13 Iteration 664/960] TRAIN loss:  0.461\n",
      "[epoch 13 Iteration 665/960] TRAIN loss:  0.636\n",
      "[epoch 13 Iteration 666/960] TRAIN loss:  0.664\n",
      "[epoch 13 Iteration 667/960] TRAIN loss:  0.653\n",
      "[epoch 13 Iteration 668/960] TRAIN loss:  0.403\n",
      "[epoch 13 Iteration 669/960] TRAIN loss:  0.755\n",
      "[epoch 13 Iteration 670/960] TRAIN loss:  0.725\n",
      "[epoch 13 Iteration 671/960] TRAIN loss:  0.639\n",
      "[epoch 13 Iteration 672/960] TRAIN loss:  0.708\n",
      "[epoch 13 Iteration 673/960] TRAIN loss:  0.821\n",
      "[epoch 13 Iteration 674/960] TRAIN loss:  0.649\n",
      "[epoch 13 Iteration 675/960] TRAIN loss:  0.430\n",
      "[epoch 13 Iteration 676/960] TRAIN loss:  0.438\n",
      "[epoch 13 Iteration 677/960] TRAIN loss:  0.669\n",
      "[epoch 13 Iteration 678/960] TRAIN loss:  0.731\n",
      "[epoch 13 Iteration 679/960] TRAIN loss:  0.595\n",
      "[epoch 13 Iteration 680/960] TRAIN loss:  0.731\n",
      "[epoch 13 Iteration 681/960] TRAIN loss:  0.726\n",
      "[epoch 13 Iteration 682/960] TRAIN loss:  0.577\n",
      "[epoch 13 Iteration 683/960] TRAIN loss:  0.509\n",
      "[epoch 13 Iteration 684/960] TRAIN loss:  0.659\n",
      "[epoch 13 Iteration 685/960] TRAIN loss:  0.398\n",
      "[epoch 13 Iteration 686/960] TRAIN loss:  0.448\n",
      "[epoch 13 Iteration 687/960] TRAIN loss:  0.400\n",
      "[epoch 13 Iteration 688/960] TRAIN loss:  0.776\n",
      "[epoch 13 Iteration 689/960] TRAIN loss:  0.597\n",
      "[epoch 13 Iteration 690/960] TRAIN loss:  0.494\n",
      "[epoch 13 Iteration 691/960] TRAIN loss:  0.739\n",
      "[epoch 13 Iteration 692/960] TRAIN loss:  0.425\n",
      "[epoch 13 Iteration 693/960] TRAIN loss:  0.436\n",
      "[epoch 13 Iteration 694/960] TRAIN loss:  0.516\n",
      "[epoch 13 Iteration 695/960] TRAIN loss:  0.763\n",
      "[epoch 13 Iteration 696/960] TRAIN loss:  0.744\n",
      "[epoch 13 Iteration 697/960] TRAIN loss:  0.436\n",
      "[epoch 13 Iteration 698/960] TRAIN loss:  0.636\n",
      "[epoch 13 Iteration 699/960] TRAIN loss:  0.418\n",
      "[epoch 13 Iteration 700/960] TRAIN loss:  0.505\n",
      "[epoch 13 Iteration 701/960] TRAIN loss:  0.626\n",
      "[epoch 13 Iteration 702/960] TRAIN loss:  0.483\n",
      "[epoch 13 Iteration 703/960] TRAIN loss:  0.699\n",
      "[epoch 13 Iteration 704/960] TRAIN loss:  0.336\n",
      "[epoch 13 Iteration 705/960] TRAIN loss:  0.727\n",
      "[epoch 13 Iteration 706/960] TRAIN loss:  0.848\n",
      "[epoch 13 Iteration 707/960] TRAIN loss:  0.747\n",
      "[epoch 13 Iteration 708/960] TRAIN loss:  0.839\n",
      "[epoch 13 Iteration 709/960] TRAIN loss:  0.566\n",
      "[epoch 13 Iteration 710/960] TRAIN loss:  0.519\n",
      "[epoch 13 Iteration 711/960] TRAIN loss:  0.665\n",
      "[epoch 13 Iteration 712/960] TRAIN loss:  0.751\n",
      "[epoch 13 Iteration 713/960] TRAIN loss:  0.634\n",
      "[epoch 13 Iteration 714/960] TRAIN loss:  0.519\n",
      "[epoch 13 Iteration 715/960] TRAIN loss:  0.659\n",
      "[epoch 13 Iteration 716/960] TRAIN loss:  0.817\n",
      "[epoch 13 Iteration 717/960] TRAIN loss:  0.592\n",
      "[epoch 13 Iteration 718/960] TRAIN loss:  0.514\n",
      "[epoch 13 Iteration 719/960] TRAIN loss:  0.899\n",
      "[epoch 13 Iteration 720/960] TRAIN loss:  0.633\n",
      "[epoch 13 Iteration 721/960] TRAIN loss:  0.606\n",
      "[epoch 13 Iteration 722/960] TRAIN loss:  0.557\n",
      "[epoch 13 Iteration 723/960] TRAIN loss:  0.523\n",
      "[epoch 13 Iteration 724/960] TRAIN loss:  0.516\n",
      "[epoch 13 Iteration 725/960] TRAIN loss:  0.485\n",
      "[epoch 13 Iteration 726/960] TRAIN loss:  0.714\n",
      "[epoch 13 Iteration 727/960] TRAIN loss:  0.435\n",
      "[epoch 13 Iteration 728/960] TRAIN loss:  0.490\n",
      "[epoch 13 Iteration 729/960] TRAIN loss:  0.505\n",
      "[epoch 13 Iteration 730/960] TRAIN loss:  0.614\n",
      "[epoch 13 Iteration 731/960] TRAIN loss:  0.644\n",
      "[epoch 13 Iteration 732/960] TRAIN loss:  0.835\n",
      "[epoch 13 Iteration 733/960] TRAIN loss:  0.435\n",
      "[epoch 13 Iteration 734/960] TRAIN loss:  0.446\n",
      "[epoch 13 Iteration 735/960] TRAIN loss:  0.421\n",
      "[epoch 13 Iteration 736/960] TRAIN loss:  0.701\n",
      "[epoch 13 Iteration 737/960] TRAIN loss:  0.475\n",
      "[epoch 13 Iteration 738/960] TRAIN loss:  0.486\n",
      "[epoch 13 Iteration 739/960] TRAIN loss:  0.689\n",
      "[epoch 13 Iteration 740/960] TRAIN loss:  0.543\n",
      "[epoch 13 Iteration 741/960] TRAIN loss:  0.565\n",
      "[epoch 13 Iteration 742/960] TRAIN loss:  0.701\n",
      "[epoch 13 Iteration 743/960] TRAIN loss:  0.574\n",
      "[epoch 13 Iteration 744/960] TRAIN loss:  0.592\n",
      "[epoch 13 Iteration 745/960] TRAIN loss:  0.620\n",
      "[epoch 13 Iteration 746/960] TRAIN loss:  0.703\n",
      "[epoch 13 Iteration 747/960] TRAIN loss:  0.532\n",
      "[epoch 13 Iteration 748/960] TRAIN loss:  0.380\n",
      "[epoch 13 Iteration 749/960] TRAIN loss:  0.727\n",
      "[epoch 13 Iteration 750/960] TRAIN loss:  0.541\n",
      "[epoch 13 Iteration 751/960] TRAIN loss:  0.412\n",
      "[epoch 13 Iteration 752/960] TRAIN loss:  0.708\n",
      "[epoch 13 Iteration 753/960] TRAIN loss:  0.716\n",
      "[epoch 13 Iteration 754/960] TRAIN loss:  0.643\n",
      "[epoch 13 Iteration 755/960] TRAIN loss:  0.810\n",
      "[epoch 13 Iteration 756/960] TRAIN loss:  0.367\n",
      "[epoch 13 Iteration 757/960] TRAIN loss:  0.625\n",
      "[epoch 13 Iteration 758/960] TRAIN loss:  0.584\n",
      "[epoch 13 Iteration 759/960] TRAIN loss:  0.423\n",
      "[epoch 13 Iteration 760/960] TRAIN loss:  0.597\n",
      "[epoch 13 Iteration 761/960] TRAIN loss:  0.575\n",
      "[epoch 13 Iteration 762/960] TRAIN loss:  0.734\n",
      "[epoch 13 Iteration 763/960] TRAIN loss:  0.586\n",
      "[epoch 13 Iteration 764/960] TRAIN loss:  0.654\n",
      "[epoch 13 Iteration 765/960] TRAIN loss:  0.555\n",
      "[epoch 13 Iteration 766/960] TRAIN loss:  0.749\n",
      "[epoch 13 Iteration 767/960] TRAIN loss:  0.583\n",
      "[epoch 13 Iteration 768/960] TRAIN loss:  0.570\n",
      "[epoch 13 Iteration 769/960] TRAIN loss:  0.688\n",
      "[epoch 13 Iteration 770/960] TRAIN loss:  0.664\n",
      "[epoch 13 Iteration 771/960] TRAIN loss:  0.582\n",
      "[epoch 13 Iteration 772/960] TRAIN loss:  0.475\n",
      "[epoch 13 Iteration 773/960] TRAIN loss:  0.565\n",
      "[epoch 13 Iteration 774/960] TRAIN loss:  0.548\n",
      "[epoch 13 Iteration 775/960] TRAIN loss:  0.556\n",
      "[epoch 13 Iteration 776/960] TRAIN loss:  0.624\n",
      "[epoch 13 Iteration 777/960] TRAIN loss:  0.637\n",
      "[epoch 13 Iteration 778/960] TRAIN loss:  0.646\n",
      "[epoch 13 Iteration 779/960] TRAIN loss:  0.476\n",
      "[epoch 13 Iteration 780/960] TRAIN loss:  0.736\n",
      "[epoch 13 Iteration 781/960] TRAIN loss:  0.741\n",
      "[epoch 13 Iteration 782/960] TRAIN loss:  0.765\n",
      "[epoch 13 Iteration 783/960] TRAIN loss:  0.686\n",
      "[epoch 13 Iteration 784/960] TRAIN loss:  0.821\n",
      "[epoch 13 Iteration 785/960] TRAIN loss:  0.611\n",
      "[epoch 13 Iteration 786/960] TRAIN loss:  0.667\n",
      "[epoch 13 Iteration 787/960] TRAIN loss:  0.845\n",
      "[epoch 13 Iteration 788/960] TRAIN loss:  0.534\n",
      "[epoch 13 Iteration 789/960] TRAIN loss:  0.397\n",
      "[epoch 13 Iteration 790/960] TRAIN loss:  0.372\n",
      "[epoch 13 Iteration 791/960] TRAIN loss:  0.547\n",
      "[epoch 13 Iteration 792/960] TRAIN loss:  0.497\n",
      "[epoch 13 Iteration 793/960] TRAIN loss:  0.559\n",
      "[epoch 13 Iteration 794/960] TRAIN loss:  0.472\n",
      "[epoch 13 Iteration 795/960] TRAIN loss:  0.604\n",
      "[epoch 13 Iteration 796/960] TRAIN loss:  0.854\n",
      "[epoch 13 Iteration 797/960] TRAIN loss:  0.681\n",
      "[epoch 13 Iteration 798/960] TRAIN loss:  0.707\n",
      "[epoch 13 Iteration 799/960] TRAIN loss:  0.469\n",
      "[epoch 13 Iteration 800/960] TRAIN loss:  0.744\n",
      "[epoch 13 Iteration 801/960] TRAIN loss:  0.550\n",
      "[epoch 13 Iteration 802/960] TRAIN loss:  0.792\n",
      "[epoch 13 Iteration 803/960] TRAIN loss:  0.567\n",
      "[epoch 13 Iteration 804/960] TRAIN loss:  0.509\n",
      "[epoch 13 Iteration 805/960] TRAIN loss:  0.539\n",
      "[epoch 13 Iteration 806/960] TRAIN loss:  0.449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 13 Iteration 807/960] TRAIN loss:  0.512\n",
      "[epoch 13 Iteration 808/960] TRAIN loss:  0.535\n",
      "[epoch 13 Iteration 809/960] TRAIN loss:  0.606\n",
      "[epoch 13 Iteration 810/960] TRAIN loss:  0.534\n",
      "[epoch 13 Iteration 811/960] TRAIN loss:  0.623\n",
      "[epoch 13 Iteration 812/960] TRAIN loss:  0.757\n",
      "[epoch 13 Iteration 813/960] TRAIN loss:  0.549\n",
      "[epoch 13 Iteration 814/960] TRAIN loss:  0.460\n",
      "[epoch 13 Iteration 815/960] TRAIN loss:  0.469\n",
      "[epoch 13 Iteration 816/960] TRAIN loss:  0.587\n",
      "[epoch 13 Iteration 817/960] TRAIN loss:  0.442\n",
      "[epoch 13 Iteration 818/960] TRAIN loss:  0.564\n",
      "[epoch 13 Iteration 819/960] TRAIN loss:  0.537\n",
      "[epoch 13 Iteration 820/960] TRAIN loss:  0.626\n",
      "[epoch 13 Iteration 821/960] TRAIN loss:  0.684\n",
      "[epoch 13 Iteration 822/960] TRAIN loss:  0.524\n",
      "[epoch 13 Iteration 823/960] TRAIN loss:  0.724\n",
      "[epoch 13 Iteration 824/960] TRAIN loss:  0.641\n",
      "[epoch 13 Iteration 825/960] TRAIN loss:  0.628\n",
      "[epoch 13 Iteration 826/960] TRAIN loss:  0.601\n",
      "[epoch 13 Iteration 827/960] TRAIN loss:  0.521\n",
      "[epoch 13 Iteration 828/960] TRAIN loss:  0.570\n",
      "[epoch 13 Iteration 829/960] TRAIN loss:  0.705\n",
      "[epoch 13 Iteration 830/960] TRAIN loss:  0.501\n",
      "[epoch 13 Iteration 831/960] TRAIN loss:  0.568\n",
      "[epoch 13 Iteration 832/960] TRAIN loss:  0.622\n",
      "[epoch 13 Iteration 833/960] TRAIN loss:  0.725\n",
      "[epoch 13 Iteration 834/960] TRAIN loss:  0.526\n",
      "[epoch 13 Iteration 835/960] TRAIN loss:  0.736\n",
      "[epoch 13 Iteration 836/960] TRAIN loss:  0.866\n",
      "[epoch 13 Iteration 837/960] TRAIN loss:  0.587\n",
      "[epoch 13 Iteration 838/960] TRAIN loss:  0.699\n",
      "[epoch 13 Iteration 839/960] TRAIN loss:  0.631\n",
      "[epoch 13 Iteration 840/960] TRAIN loss:  0.646\n",
      "[epoch 13 Iteration 841/960] TRAIN loss:  0.549\n",
      "[epoch 13 Iteration 842/960] TRAIN loss:  0.594\n",
      "[epoch 13 Iteration 843/960] TRAIN loss:  0.377\n",
      "[epoch 13 Iteration 844/960] TRAIN loss:  0.481\n",
      "[epoch 13 Iteration 845/960] TRAIN loss:  0.747\n",
      "[epoch 13 Iteration 846/960] TRAIN loss:  0.516\n",
      "[epoch 13 Iteration 847/960] TRAIN loss:  0.604\n",
      "[epoch 13 Iteration 848/960] TRAIN loss:  0.292\n",
      "[epoch 13 Iteration 849/960] TRAIN loss:  0.530\n",
      "[epoch 13 Iteration 850/960] TRAIN loss:  0.374\n",
      "[epoch 13 Iteration 851/960] TRAIN loss:  0.427\n",
      "[epoch 13 Iteration 852/960] TRAIN loss:  0.650\n",
      "[epoch 13 Iteration 853/960] TRAIN loss:  0.783\n",
      "[epoch 13 Iteration 854/960] TRAIN loss:  0.921\n",
      "[epoch 13 Iteration 855/960] TRAIN loss:  0.567\n",
      "[epoch 13 Iteration 856/960] TRAIN loss:  0.662\n",
      "[epoch 13 Iteration 857/960] TRAIN loss:  0.713\n",
      "[epoch 13 Iteration 858/960] TRAIN loss:  0.620\n",
      "[epoch 13 Iteration 859/960] TRAIN loss:  0.703\n",
      "[epoch 13 Iteration 860/960] TRAIN loss:  0.769\n",
      "[epoch 13 Iteration 861/960] TRAIN loss:  0.541\n",
      "[epoch 13 Iteration 862/960] TRAIN loss:  0.729\n",
      "[epoch 13 Iteration 863/960] TRAIN loss:  0.847\n",
      "[epoch 13 Iteration 864/960] TRAIN loss:  0.631\n",
      "[epoch 13 Iteration 865/960] TRAIN loss:  0.671\n",
      "[epoch 13 Iteration 866/960] TRAIN loss:  0.405\n",
      "[epoch 13 Iteration 867/960] TRAIN loss:  0.696\n",
      "[epoch 13 Iteration 868/960] TRAIN loss:  0.614\n",
      "[epoch 13 Iteration 869/960] TRAIN loss:  0.655\n",
      "[epoch 13 Iteration 870/960] TRAIN loss:  0.504\n",
      "[epoch 13 Iteration 871/960] TRAIN loss:  0.652\n",
      "[epoch 13 Iteration 872/960] TRAIN loss:  0.811\n",
      "[epoch 13 Iteration 873/960] TRAIN loss:  0.517\n",
      "[epoch 13 Iteration 874/960] TRAIN loss:  0.784\n",
      "[epoch 13 Iteration 875/960] TRAIN loss:  0.761\n",
      "[epoch 13 Iteration 876/960] TRAIN loss:  0.676\n",
      "[epoch 13 Iteration 877/960] TRAIN loss:  0.499\n",
      "[epoch 13 Iteration 878/960] TRAIN loss:  0.906\n",
      "[epoch 13 Iteration 879/960] TRAIN loss:  0.672\n",
      "[epoch 13 Iteration 880/960] TRAIN loss:  0.519\n",
      "[epoch 13 Iteration 881/960] TRAIN loss:  0.656\n",
      "[epoch 13 Iteration 882/960] TRAIN loss:  0.669\n",
      "[epoch 13 Iteration 883/960] TRAIN loss:  0.651\n",
      "[epoch 13 Iteration 884/960] TRAIN loss:  0.737\n",
      "[epoch 13 Iteration 885/960] TRAIN loss:  0.559\n",
      "[epoch 13 Iteration 886/960] TRAIN loss:  0.582\n",
      "[epoch 13 Iteration 887/960] TRAIN loss:  0.712\n",
      "[epoch 13 Iteration 888/960] TRAIN loss:  0.849\n",
      "[epoch 13 Iteration 889/960] TRAIN loss:  0.469\n",
      "[epoch 13 Iteration 890/960] TRAIN loss:  0.623\n",
      "[epoch 13 Iteration 891/960] TRAIN loss:  0.724\n",
      "[epoch 13 Iteration 892/960] TRAIN loss:  0.487\n",
      "[epoch 13 Iteration 893/960] TRAIN loss:  0.360\n",
      "[epoch 13 Iteration 894/960] TRAIN loss:  0.897\n",
      "[epoch 13 Iteration 895/960] TRAIN loss:  0.683\n",
      "[epoch 13 Iteration 896/960] TRAIN loss:  0.626\n",
      "[epoch 13 Iteration 897/960] TRAIN loss:  0.527\n",
      "[epoch 13 Iteration 898/960] TRAIN loss:  0.453\n",
      "[epoch 13 Iteration 899/960] TRAIN loss:  0.563\n",
      "[epoch 13 Iteration 900/960] TRAIN loss:  0.706\n",
      "[epoch 13 Iteration 901/960] TRAIN loss:  0.577\n",
      "[epoch 13 Iteration 902/960] TRAIN loss:  0.728\n",
      "[epoch 13 Iteration 903/960] TRAIN loss:  0.676\n",
      "[epoch 13 Iteration 904/960] TRAIN loss:  0.430\n",
      "[epoch 13 Iteration 905/960] TRAIN loss:  0.721\n",
      "[epoch 13 Iteration 906/960] TRAIN loss:  0.665\n",
      "[epoch 13 Iteration 907/960] TRAIN loss:  0.624\n",
      "[epoch 13 Iteration 908/960] TRAIN loss:  0.801\n",
      "[epoch 13 Iteration 909/960] TRAIN loss:  0.613\n",
      "[epoch 13 Iteration 910/960] TRAIN loss:  0.760\n",
      "[epoch 13 Iteration 911/960] TRAIN loss:  1.075\n",
      "[epoch 13 Iteration 912/960] TRAIN loss:  0.847\n",
      "[epoch 13 Iteration 913/960] TRAIN loss:  0.574\n",
      "[epoch 13 Iteration 914/960] TRAIN loss:  0.712\n",
      "[epoch 13 Iteration 915/960] TRAIN loss:  0.676\n",
      "[epoch 13 Iteration 916/960] TRAIN loss:  0.629\n",
      "[epoch 13 Iteration 917/960] TRAIN loss:  0.694\n",
      "[epoch 13 Iteration 918/960] TRAIN loss:  0.779\n",
      "[epoch 13 Iteration 919/960] TRAIN loss:  0.633\n",
      "[epoch 13 Iteration 920/960] TRAIN loss:  0.665\n",
      "[epoch 13 Iteration 921/960] TRAIN loss:  0.540\n",
      "[epoch 13 Iteration 922/960] TRAIN loss:  0.645\n",
      "[epoch 13 Iteration 923/960] TRAIN loss:  0.470\n",
      "[epoch 13 Iteration 924/960] TRAIN loss:  0.688\n",
      "[epoch 13 Iteration 925/960] TRAIN loss:  0.650\n",
      "[epoch 13 Iteration 926/960] TRAIN loss:  0.621\n",
      "[epoch 13 Iteration 927/960] TRAIN loss:  0.679\n",
      "[epoch 13 Iteration 928/960] TRAIN loss:  0.689\n",
      "[epoch 13 Iteration 929/960] TRAIN loss:  0.433\n",
      "[epoch 13 Iteration 930/960] TRAIN loss:  0.599\n",
      "[epoch 13 Iteration 931/960] TRAIN loss:  0.528\n",
      "[epoch 13 Iteration 932/960] TRAIN loss:  0.596\n",
      "[epoch 13 Iteration 933/960] TRAIN loss:  0.585\n",
      "[epoch 13 Iteration 934/960] TRAIN loss:  0.812\n",
      "[epoch 13 Iteration 935/960] TRAIN loss:  0.673\n",
      "[epoch 13 Iteration 936/960] TRAIN loss:  0.710\n",
      "[epoch 13 Iteration 937/960] TRAIN loss:  0.626\n",
      "[epoch 13 Iteration 938/960] TRAIN loss:  0.575\n",
      "[epoch 13 Iteration 939/960] TRAIN loss:  0.561\n",
      "[epoch 13 Iteration 940/960] TRAIN loss:  0.758\n",
      "[epoch 13 Iteration 941/960] TRAIN loss:  0.555\n",
      "[epoch 13 Iteration 942/960] TRAIN loss:  0.681\n",
      "[epoch 13 Iteration 943/960] TRAIN loss:  0.411\n",
      "[epoch 13 Iteration 944/960] TRAIN loss:  0.603\n",
      "[epoch 13 Iteration 945/960] TRAIN loss:  0.600\n",
      "[epoch 13 Iteration 946/960] TRAIN loss:  0.726\n",
      "[epoch 13 Iteration 947/960] TRAIN loss:  0.682\n",
      "[epoch 13 Iteration 948/960] TRAIN loss:  0.587\n",
      "[epoch 13 Iteration 949/960] TRAIN loss:  0.622\n",
      "[epoch 13 Iteration 950/960] TRAIN loss:  0.735\n",
      "[epoch 13 Iteration 951/960] TRAIN loss:  0.610\n",
      "[epoch 13 Iteration 952/960] TRAIN loss:  0.726\n",
      "[epoch 13 Iteration 953/960] TRAIN loss:  0.409\n",
      "[epoch 13 Iteration 954/960] TRAIN loss:  0.709\n",
      "[epoch 13 Iteration 955/960] TRAIN loss:  0.548\n",
      "[epoch 13 Iteration 956/960] TRAIN loss:  0.436\n",
      "[epoch 13 Iteration 957/960] TRAIN loss:  0.650\n",
      "[epoch 13 Iteration 958/960] TRAIN loss:  0.635\n",
      "[epoch 13 Iteration 959/960] TRAIN loss:  0.917\n",
      "[epoch 13/15] TRAIN acc/loss:  0.790/0.917\n",
      "[epoch 13/15] VAL acc/loss:  0.664/0.575\n",
      "[epoch 14 Iteration 0/960] TRAIN loss:  0.506\n",
      "[epoch 14 Iteration 1/960] TRAIN loss:  0.637\n",
      "[epoch 14 Iteration 2/960] TRAIN loss:  0.365\n",
      "[epoch 14 Iteration 3/960] TRAIN loss:  0.553\n",
      "[epoch 14 Iteration 4/960] TRAIN loss:  0.476\n",
      "[epoch 14 Iteration 5/960] TRAIN loss:  0.529\n",
      "[epoch 14 Iteration 6/960] TRAIN loss:  0.642\n",
      "[epoch 14 Iteration 7/960] TRAIN loss:  0.477\n",
      "[epoch 14 Iteration 8/960] TRAIN loss:  0.471\n",
      "[epoch 14 Iteration 9/960] TRAIN loss:  0.443\n",
      "[epoch 14 Iteration 10/960] TRAIN loss:  0.582\n",
      "[epoch 14 Iteration 11/960] TRAIN loss:  0.318\n",
      "[epoch 14 Iteration 12/960] TRAIN loss:  0.359\n",
      "[epoch 14 Iteration 13/960] TRAIN loss:  0.540\n",
      "[epoch 14 Iteration 14/960] TRAIN loss:  0.309\n",
      "[epoch 14 Iteration 15/960] TRAIN loss:  0.430\n",
      "[epoch 14 Iteration 16/960] TRAIN loss:  0.555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 14 Iteration 17/960] TRAIN loss:  0.603\n",
      "[epoch 14 Iteration 18/960] TRAIN loss:  0.430\n",
      "[epoch 14 Iteration 19/960] TRAIN loss:  0.318\n",
      "[epoch 14 Iteration 20/960] TRAIN loss:  0.773\n",
      "[epoch 14 Iteration 21/960] TRAIN loss:  0.480\n",
      "[epoch 14 Iteration 22/960] TRAIN loss:  0.439\n",
      "[epoch 14 Iteration 23/960] TRAIN loss:  0.444\n",
      "[epoch 14 Iteration 24/960] TRAIN loss:  0.754\n",
      "[epoch 14 Iteration 25/960] TRAIN loss:  0.504\n",
      "[epoch 14 Iteration 26/960] TRAIN loss:  0.527\n",
      "[epoch 14 Iteration 27/960] TRAIN loss:  0.597\n",
      "[epoch 14 Iteration 28/960] TRAIN loss:  0.398\n",
      "[epoch 14 Iteration 29/960] TRAIN loss:  0.482\n",
      "[epoch 14 Iteration 30/960] TRAIN loss:  0.674\n",
      "[epoch 14 Iteration 31/960] TRAIN loss:  0.461\n",
      "[epoch 14 Iteration 32/960] TRAIN loss:  0.623\n",
      "[epoch 14 Iteration 33/960] TRAIN loss:  0.392\n",
      "[epoch 14 Iteration 34/960] TRAIN loss:  0.475\n",
      "[epoch 14 Iteration 35/960] TRAIN loss:  0.732\n",
      "[epoch 14 Iteration 36/960] TRAIN loss:  0.382\n",
      "[epoch 14 Iteration 37/960] TRAIN loss:  0.451\n",
      "[epoch 14 Iteration 38/960] TRAIN loss:  0.527\n",
      "[epoch 14 Iteration 39/960] TRAIN loss:  0.484\n",
      "[epoch 14 Iteration 40/960] TRAIN loss:  0.453\n",
      "[epoch 14 Iteration 41/960] TRAIN loss:  0.370\n",
      "[epoch 14 Iteration 42/960] TRAIN loss:  0.666\n",
      "[epoch 14 Iteration 43/960] TRAIN loss:  0.571\n",
      "[epoch 14 Iteration 44/960] TRAIN loss:  0.471\n",
      "[epoch 14 Iteration 45/960] TRAIN loss:  0.522\n",
      "[epoch 14 Iteration 46/960] TRAIN loss:  0.642\n",
      "[epoch 14 Iteration 47/960] TRAIN loss:  0.495\n",
      "[epoch 14 Iteration 48/960] TRAIN loss:  0.508\n",
      "[epoch 14 Iteration 49/960] TRAIN loss:  0.567\n",
      "[epoch 14 Iteration 50/960] TRAIN loss:  0.457\n",
      "[epoch 14 Iteration 51/960] TRAIN loss:  0.507\n",
      "[epoch 14 Iteration 52/960] TRAIN loss:  0.434\n",
      "[epoch 14 Iteration 53/960] TRAIN loss:  0.513\n",
      "[epoch 14 Iteration 54/960] TRAIN loss:  0.662\n",
      "[epoch 14 Iteration 55/960] TRAIN loss:  0.435\n",
      "[epoch 14 Iteration 56/960] TRAIN loss:  0.366\n",
      "[epoch 14 Iteration 57/960] TRAIN loss:  0.468\n",
      "[epoch 14 Iteration 58/960] TRAIN loss:  0.603\n",
      "[epoch 14 Iteration 59/960] TRAIN loss:  0.560\n",
      "[epoch 14 Iteration 60/960] TRAIN loss:  0.372\n",
      "[epoch 14 Iteration 61/960] TRAIN loss:  0.350\n",
      "[epoch 14 Iteration 62/960] TRAIN loss:  0.363\n",
      "[epoch 14 Iteration 63/960] TRAIN loss:  0.560\n",
      "[epoch 14 Iteration 64/960] TRAIN loss:  0.530\n",
      "[epoch 14 Iteration 65/960] TRAIN loss:  0.590\n",
      "[epoch 14 Iteration 66/960] TRAIN loss:  0.463\n",
      "[epoch 14 Iteration 67/960] TRAIN loss:  0.485\n",
      "[epoch 14 Iteration 68/960] TRAIN loss:  0.600\n",
      "[epoch 14 Iteration 69/960] TRAIN loss:  0.431\n",
      "[epoch 14 Iteration 70/960] TRAIN loss:  0.795\n",
      "[epoch 14 Iteration 71/960] TRAIN loss:  0.554\n",
      "[epoch 14 Iteration 72/960] TRAIN loss:  0.533\n",
      "[epoch 14 Iteration 73/960] TRAIN loss:  0.465\n",
      "[epoch 14 Iteration 74/960] TRAIN loss:  0.330\n",
      "[epoch 14 Iteration 75/960] TRAIN loss:  0.547\n",
      "[epoch 14 Iteration 76/960] TRAIN loss:  0.374\n",
      "[epoch 14 Iteration 77/960] TRAIN loss:  0.500\n",
      "[epoch 14 Iteration 78/960] TRAIN loss:  0.458\n",
      "[epoch 14 Iteration 79/960] TRAIN loss:  0.598\n",
      "[epoch 14 Iteration 80/960] TRAIN loss:  0.649\n",
      "[epoch 14 Iteration 81/960] TRAIN loss:  0.496\n",
      "[epoch 14 Iteration 82/960] TRAIN loss:  0.358\n",
      "[epoch 14 Iteration 83/960] TRAIN loss:  0.437\n",
      "[epoch 14 Iteration 84/960] TRAIN loss:  0.456\n",
      "[epoch 14 Iteration 85/960] TRAIN loss:  0.524\n",
      "[epoch 14 Iteration 86/960] TRAIN loss:  0.603\n",
      "[epoch 14 Iteration 87/960] TRAIN loss:  0.526\n",
      "[epoch 14 Iteration 88/960] TRAIN loss:  0.507\n",
      "[epoch 14 Iteration 89/960] TRAIN loss:  0.513\n",
      "[epoch 14 Iteration 90/960] TRAIN loss:  0.515\n",
      "[epoch 14 Iteration 91/960] TRAIN loss:  0.574\n",
      "[epoch 14 Iteration 92/960] TRAIN loss:  0.531\n",
      "[epoch 14 Iteration 93/960] TRAIN loss:  0.663\n",
      "[epoch 14 Iteration 94/960] TRAIN loss:  0.776\n",
      "[epoch 14 Iteration 95/960] TRAIN loss:  0.399\n",
      "[epoch 14 Iteration 96/960] TRAIN loss:  0.585\n",
      "[epoch 14 Iteration 97/960] TRAIN loss:  0.482\n",
      "[epoch 14 Iteration 98/960] TRAIN loss:  0.470\n",
      "[epoch 14 Iteration 99/960] TRAIN loss:  0.317\n",
      "[epoch 14 Iteration 100/960] TRAIN loss:  0.460\n",
      "[epoch 14 Iteration 101/960] TRAIN loss:  0.355\n",
      "[epoch 14 Iteration 102/960] TRAIN loss:  0.298\n",
      "[epoch 14 Iteration 103/960] TRAIN loss:  0.376\n",
      "[epoch 14 Iteration 104/960] TRAIN loss:  0.460\n",
      "[epoch 14 Iteration 105/960] TRAIN loss:  0.372\n",
      "[epoch 14 Iteration 106/960] TRAIN loss:  0.379\n",
      "[epoch 14 Iteration 107/960] TRAIN loss:  0.553\n",
      "[epoch 14 Iteration 108/960] TRAIN loss:  0.510\n",
      "[epoch 14 Iteration 109/960] TRAIN loss:  0.845\n",
      "[epoch 14 Iteration 110/960] TRAIN loss:  0.577\n",
      "[epoch 14 Iteration 111/960] TRAIN loss:  0.348\n",
      "[epoch 14 Iteration 112/960] TRAIN loss:  0.686\n",
      "[epoch 14 Iteration 113/960] TRAIN loss:  0.432\n",
      "[epoch 14 Iteration 114/960] TRAIN loss:  0.822\n",
      "[epoch 14 Iteration 115/960] TRAIN loss:  0.339\n",
      "[epoch 14 Iteration 116/960] TRAIN loss:  0.568\n",
      "[epoch 14 Iteration 117/960] TRAIN loss:  0.577\n",
      "[epoch 14 Iteration 118/960] TRAIN loss:  0.608\n",
      "[epoch 14 Iteration 119/960] TRAIN loss:  0.578\n",
      "[epoch 14 Iteration 120/960] TRAIN loss:  0.653\n",
      "[epoch 14 Iteration 121/960] TRAIN loss:  0.680\n",
      "[epoch 14 Iteration 122/960] TRAIN loss:  0.446\n",
      "[epoch 14 Iteration 123/960] TRAIN loss:  0.578\n",
      "[epoch 14 Iteration 124/960] TRAIN loss:  0.632\n",
      "[epoch 14 Iteration 125/960] TRAIN loss:  0.333\n",
      "[epoch 14 Iteration 126/960] TRAIN loss:  0.436\n",
      "[epoch 14 Iteration 127/960] TRAIN loss:  0.683\n",
      "[epoch 14 Iteration 128/960] TRAIN loss:  0.643\n",
      "[epoch 14 Iteration 129/960] TRAIN loss:  0.619\n",
      "[epoch 14 Iteration 130/960] TRAIN loss:  0.514\n",
      "[epoch 14 Iteration 131/960] TRAIN loss:  0.586\n",
      "[epoch 14 Iteration 132/960] TRAIN loss:  0.572\n",
      "[epoch 14 Iteration 133/960] TRAIN loss:  0.728\n",
      "[epoch 14 Iteration 134/960] TRAIN loss:  0.546\n",
      "[epoch 14 Iteration 135/960] TRAIN loss:  0.724\n",
      "[epoch 14 Iteration 136/960] TRAIN loss:  0.651\n",
      "[epoch 14 Iteration 137/960] TRAIN loss:  0.488\n",
      "[epoch 14 Iteration 138/960] TRAIN loss:  0.535\n",
      "[epoch 14 Iteration 139/960] TRAIN loss:  0.501\n",
      "[epoch 14 Iteration 140/960] TRAIN loss:  0.446\n",
      "[epoch 14 Iteration 141/960] TRAIN loss:  0.526\n",
      "[epoch 14 Iteration 142/960] TRAIN loss:  0.494\n",
      "[epoch 14 Iteration 143/960] TRAIN loss:  0.543\n",
      "[epoch 14 Iteration 144/960] TRAIN loss:  0.353\n",
      "[epoch 14 Iteration 145/960] TRAIN loss:  0.568\n",
      "[epoch 14 Iteration 146/960] TRAIN loss:  0.528\n",
      "[epoch 14 Iteration 147/960] TRAIN loss:  0.352\n",
      "[epoch 14 Iteration 148/960] TRAIN loss:  0.501\n",
      "[epoch 14 Iteration 149/960] TRAIN loss:  0.245\n",
      "[epoch 14 Iteration 150/960] TRAIN loss:  0.441\n",
      "[epoch 14 Iteration 151/960] TRAIN loss:  0.649\n",
      "[epoch 14 Iteration 152/960] TRAIN loss:  0.497\n",
      "[epoch 14 Iteration 153/960] TRAIN loss:  0.398\n",
      "[epoch 14 Iteration 154/960] TRAIN loss:  0.703\n",
      "[epoch 14 Iteration 155/960] TRAIN loss:  0.571\n",
      "[epoch 14 Iteration 156/960] TRAIN loss:  0.463\n",
      "[epoch 14 Iteration 157/960] TRAIN loss:  0.838\n",
      "[epoch 14 Iteration 158/960] TRAIN loss:  0.545\n",
      "[epoch 14 Iteration 159/960] TRAIN loss:  0.355\n",
      "[epoch 14 Iteration 160/960] TRAIN loss:  0.455\n",
      "[epoch 14 Iteration 161/960] TRAIN loss:  0.648\n",
      "[epoch 14 Iteration 162/960] TRAIN loss:  0.572\n",
      "[epoch 14 Iteration 163/960] TRAIN loss:  0.499\n",
      "[epoch 14 Iteration 164/960] TRAIN loss:  0.358\n",
      "[epoch 14 Iteration 165/960] TRAIN loss:  0.715\n",
      "[epoch 14 Iteration 166/960] TRAIN loss:  0.710\n",
      "[epoch 14 Iteration 167/960] TRAIN loss:  0.427\n",
      "[epoch 14 Iteration 168/960] TRAIN loss:  0.471\n",
      "[epoch 14 Iteration 169/960] TRAIN loss:  0.803\n",
      "[epoch 14 Iteration 170/960] TRAIN loss:  0.621\n",
      "[epoch 14 Iteration 171/960] TRAIN loss:  0.599\n",
      "[epoch 14 Iteration 172/960] TRAIN loss:  0.630\n",
      "[epoch 14 Iteration 173/960] TRAIN loss:  0.647\n",
      "[epoch 14 Iteration 174/960] TRAIN loss:  0.643\n",
      "[epoch 14 Iteration 175/960] TRAIN loss:  0.700\n",
      "[epoch 14 Iteration 176/960] TRAIN loss:  0.497\n",
      "[epoch 14 Iteration 177/960] TRAIN loss:  0.583\n",
      "[epoch 14 Iteration 178/960] TRAIN loss:  0.429\n",
      "[epoch 14 Iteration 179/960] TRAIN loss:  0.440\n",
      "[epoch 14 Iteration 180/960] TRAIN loss:  0.507\n",
      "[epoch 14 Iteration 181/960] TRAIN loss:  0.665\n",
      "[epoch 14 Iteration 182/960] TRAIN loss:  0.586\n",
      "[epoch 14 Iteration 183/960] TRAIN loss:  0.584\n",
      "[epoch 14 Iteration 184/960] TRAIN loss:  0.283\n",
      "[epoch 14 Iteration 185/960] TRAIN loss:  0.513\n",
      "[epoch 14 Iteration 186/960] TRAIN loss:  0.442\n",
      "[epoch 14 Iteration 187/960] TRAIN loss:  0.589\n",
      "[epoch 14 Iteration 188/960] TRAIN loss:  0.348\n",
      "[epoch 14 Iteration 189/960] TRAIN loss:  0.646\n",
      "[epoch 14 Iteration 190/960] TRAIN loss:  0.484\n",
      "[epoch 14 Iteration 191/960] TRAIN loss:  0.617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 14 Iteration 192/960] TRAIN loss:  0.567\n",
      "[epoch 14 Iteration 193/960] TRAIN loss:  0.366\n",
      "[epoch 14 Iteration 194/960] TRAIN loss:  0.453\n",
      "[epoch 14 Iteration 195/960] TRAIN loss:  0.349\n",
      "[epoch 14 Iteration 196/960] TRAIN loss:  0.373\n",
      "[epoch 14 Iteration 197/960] TRAIN loss:  0.233\n",
      "[epoch 14 Iteration 198/960] TRAIN loss:  0.450\n",
      "[epoch 14 Iteration 199/960] TRAIN loss:  0.643\n",
      "[epoch 14 Iteration 200/960] TRAIN loss:  0.748\n",
      "[epoch 14 Iteration 201/960] TRAIN loss:  0.535\n",
      "[epoch 14 Iteration 202/960] TRAIN loss:  0.532\n",
      "[epoch 14 Iteration 203/960] TRAIN loss:  0.581\n",
      "[epoch 14 Iteration 204/960] TRAIN loss:  0.508\n",
      "[epoch 14 Iteration 205/960] TRAIN loss:  0.454\n",
      "[epoch 14 Iteration 206/960] TRAIN loss:  0.514\n",
      "[epoch 14 Iteration 207/960] TRAIN loss:  0.552\n",
      "[epoch 14 Iteration 208/960] TRAIN loss:  0.600\n",
      "[epoch 14 Iteration 209/960] TRAIN loss:  0.487\n",
      "[epoch 14 Iteration 210/960] TRAIN loss:  0.522\n",
      "[epoch 14 Iteration 211/960] TRAIN loss:  0.518\n",
      "[epoch 14 Iteration 212/960] TRAIN loss:  0.506\n",
      "[epoch 14 Iteration 213/960] TRAIN loss:  0.637\n",
      "[epoch 14 Iteration 214/960] TRAIN loss:  0.622\n",
      "[epoch 14 Iteration 215/960] TRAIN loss:  0.428\n",
      "[epoch 14 Iteration 216/960] TRAIN loss:  0.641\n",
      "[epoch 14 Iteration 217/960] TRAIN loss:  0.498\n",
      "[epoch 14 Iteration 218/960] TRAIN loss:  0.548\n",
      "[epoch 14 Iteration 219/960] TRAIN loss:  0.566\n",
      "[epoch 14 Iteration 220/960] TRAIN loss:  0.780\n",
      "[epoch 14 Iteration 221/960] TRAIN loss:  0.415\n",
      "[epoch 14 Iteration 222/960] TRAIN loss:  0.700\n",
      "[epoch 14 Iteration 223/960] TRAIN loss:  0.536\n",
      "[epoch 14 Iteration 224/960] TRAIN loss:  0.663\n",
      "[epoch 14 Iteration 225/960] TRAIN loss:  0.510\n",
      "[epoch 14 Iteration 226/960] TRAIN loss:  0.454\n",
      "[epoch 14 Iteration 227/960] TRAIN loss:  0.497\n",
      "[epoch 14 Iteration 228/960] TRAIN loss:  0.464\n",
      "[epoch 14 Iteration 229/960] TRAIN loss:  0.417\n",
      "[epoch 14 Iteration 230/960] TRAIN loss:  0.523\n",
      "[epoch 14 Iteration 231/960] TRAIN loss:  0.390\n",
      "[epoch 14 Iteration 232/960] TRAIN loss:  0.516\n",
      "[epoch 14 Iteration 233/960] TRAIN loss:  0.719\n",
      "[epoch 14 Iteration 234/960] TRAIN loss:  0.554\n",
      "[epoch 14 Iteration 235/960] TRAIN loss:  0.788\n",
      "[epoch 14 Iteration 236/960] TRAIN loss:  0.433\n",
      "[epoch 14 Iteration 237/960] TRAIN loss:  0.455\n",
      "[epoch 14 Iteration 238/960] TRAIN loss:  0.598\n",
      "[epoch 14 Iteration 239/960] TRAIN loss:  0.377\n",
      "[epoch 14 Iteration 240/960] TRAIN loss:  0.544\n",
      "[epoch 14 Iteration 241/960] TRAIN loss:  0.297\n",
      "[epoch 14 Iteration 242/960] TRAIN loss:  0.535\n",
      "[epoch 14 Iteration 243/960] TRAIN loss:  0.664\n",
      "[epoch 14 Iteration 244/960] TRAIN loss:  0.536\n",
      "[epoch 14 Iteration 245/960] TRAIN loss:  0.765\n",
      "[epoch 14 Iteration 246/960] TRAIN loss:  0.281\n",
      "[epoch 14 Iteration 247/960] TRAIN loss:  0.658\n",
      "[epoch 14 Iteration 248/960] TRAIN loss:  0.463\n",
      "[epoch 14 Iteration 249/960] TRAIN loss:  0.538\n",
      "[epoch 14 Iteration 250/960] TRAIN loss:  0.902\n",
      "[epoch 14 Iteration 251/960] TRAIN loss:  0.615\n",
      "[epoch 14 Iteration 252/960] TRAIN loss:  0.367\n",
      "[epoch 14 Iteration 253/960] TRAIN loss:  0.776\n",
      "[epoch 14 Iteration 254/960] TRAIN loss:  0.524\n",
      "[epoch 14 Iteration 255/960] TRAIN loss:  0.682\n",
      "[epoch 14 Iteration 256/960] TRAIN loss:  0.731\n",
      "[epoch 14 Iteration 257/960] TRAIN loss:  0.380\n",
      "[epoch 14 Iteration 258/960] TRAIN loss:  0.560\n",
      "[epoch 14 Iteration 259/960] TRAIN loss:  0.590\n",
      "[epoch 14 Iteration 260/960] TRAIN loss:  0.498\n",
      "[epoch 14 Iteration 261/960] TRAIN loss:  0.382\n",
      "[epoch 14 Iteration 262/960] TRAIN loss:  0.634\n",
      "[epoch 14 Iteration 263/960] TRAIN loss:  0.443\n",
      "[epoch 14 Iteration 264/960] TRAIN loss:  0.649\n",
      "[epoch 14 Iteration 265/960] TRAIN loss:  0.501\n",
      "[epoch 14 Iteration 266/960] TRAIN loss:  0.561\n",
      "[epoch 14 Iteration 267/960] TRAIN loss:  0.671\n",
      "[epoch 14 Iteration 268/960] TRAIN loss:  0.485\n",
      "[epoch 14 Iteration 269/960] TRAIN loss:  0.510\n",
      "[epoch 14 Iteration 270/960] TRAIN loss:  0.466\n",
      "[epoch 14 Iteration 271/960] TRAIN loss:  0.529\n",
      "[epoch 14 Iteration 272/960] TRAIN loss:  0.586\n",
      "[epoch 14 Iteration 273/960] TRAIN loss:  0.584\n",
      "[epoch 14 Iteration 274/960] TRAIN loss:  0.495\n",
      "[epoch 14 Iteration 275/960] TRAIN loss:  0.669\n",
      "[epoch 14 Iteration 276/960] TRAIN loss:  0.565\n",
      "[epoch 14 Iteration 277/960] TRAIN loss:  0.628\n",
      "[epoch 14 Iteration 278/960] TRAIN loss:  0.868\n",
      "[epoch 14 Iteration 279/960] TRAIN loss:  0.437\n",
      "[epoch 14 Iteration 280/960] TRAIN loss:  0.757\n",
      "[epoch 14 Iteration 281/960] TRAIN loss:  0.401\n",
      "[epoch 14 Iteration 282/960] TRAIN loss:  0.550\n",
      "[epoch 14 Iteration 283/960] TRAIN loss:  0.448\n",
      "[epoch 14 Iteration 284/960] TRAIN loss:  0.596\n",
      "[epoch 14 Iteration 285/960] TRAIN loss:  0.673\n",
      "[epoch 14 Iteration 286/960] TRAIN loss:  0.347\n",
      "[epoch 14 Iteration 287/960] TRAIN loss:  0.523\n",
      "[epoch 14 Iteration 288/960] TRAIN loss:  0.722\n",
      "[epoch 14 Iteration 289/960] TRAIN loss:  0.541\n",
      "[epoch 14 Iteration 290/960] TRAIN loss:  0.349\n",
      "[epoch 14 Iteration 291/960] TRAIN loss:  0.355\n",
      "[epoch 14 Iteration 292/960] TRAIN loss:  0.477\n",
      "[epoch 14 Iteration 293/960] TRAIN loss:  0.505\n",
      "[epoch 14 Iteration 294/960] TRAIN loss:  0.399\n",
      "[epoch 14 Iteration 295/960] TRAIN loss:  0.530\n",
      "[epoch 14 Iteration 296/960] TRAIN loss:  0.541\n",
      "[epoch 14 Iteration 297/960] TRAIN loss:  0.507\n",
      "[epoch 14 Iteration 298/960] TRAIN loss:  0.618\n",
      "[epoch 14 Iteration 299/960] TRAIN loss:  0.428\n",
      "[epoch 14 Iteration 300/960] TRAIN loss:  0.627\n",
      "[epoch 14 Iteration 301/960] TRAIN loss:  0.563\n",
      "[epoch 14 Iteration 302/960] TRAIN loss:  0.641\n",
      "[epoch 14 Iteration 303/960] TRAIN loss:  0.577\n",
      "[epoch 14 Iteration 304/960] TRAIN loss:  0.667\n",
      "[epoch 14 Iteration 305/960] TRAIN loss:  0.542\n",
      "[epoch 14 Iteration 306/960] TRAIN loss:  0.503\n",
      "[epoch 14 Iteration 307/960] TRAIN loss:  0.886\n",
      "[epoch 14 Iteration 308/960] TRAIN loss:  0.465\n",
      "[epoch 14 Iteration 309/960] TRAIN loss:  0.600\n",
      "[epoch 14 Iteration 310/960] TRAIN loss:  0.386\n",
      "[epoch 14 Iteration 311/960] TRAIN loss:  0.352\n",
      "[epoch 14 Iteration 312/960] TRAIN loss:  0.406\n",
      "[epoch 14 Iteration 313/960] TRAIN loss:  0.579\n",
      "[epoch 14 Iteration 314/960] TRAIN loss:  0.730\n",
      "[epoch 14 Iteration 315/960] TRAIN loss:  0.636\n",
      "[epoch 14 Iteration 316/960] TRAIN loss:  0.677\n",
      "[epoch 14 Iteration 317/960] TRAIN loss:  0.645\n",
      "[epoch 14 Iteration 318/960] TRAIN loss:  0.606\n",
      "[epoch 14 Iteration 319/960] TRAIN loss:  0.717\n",
      "[epoch 14 Iteration 320/960] TRAIN loss:  0.399\n",
      "[epoch 14 Iteration 321/960] TRAIN loss:  0.489\n",
      "[epoch 14 Iteration 322/960] TRAIN loss:  0.494\n",
      "[epoch 14 Iteration 323/960] TRAIN loss:  0.719\n",
      "[epoch 14 Iteration 324/960] TRAIN loss:  0.292\n",
      "[epoch 14 Iteration 325/960] TRAIN loss:  0.522\n",
      "[epoch 14 Iteration 326/960] TRAIN loss:  0.734\n",
      "[epoch 14 Iteration 327/960] TRAIN loss:  0.581\n",
      "[epoch 14 Iteration 328/960] TRAIN loss:  0.573\n",
      "[epoch 14 Iteration 329/960] TRAIN loss:  0.452\n",
      "[epoch 14 Iteration 330/960] TRAIN loss:  0.509\n",
      "[epoch 14 Iteration 331/960] TRAIN loss:  0.612\n",
      "[epoch 14 Iteration 332/960] TRAIN loss:  0.416\n",
      "[epoch 14 Iteration 333/960] TRAIN loss:  0.627\n",
      "[epoch 14 Iteration 334/960] TRAIN loss:  0.548\n",
      "[epoch 14 Iteration 335/960] TRAIN loss:  0.533\n",
      "[epoch 14 Iteration 336/960] TRAIN loss:  0.481\n",
      "[epoch 14 Iteration 337/960] TRAIN loss:  0.737\n",
      "[epoch 14 Iteration 338/960] TRAIN loss:  0.580\n",
      "[epoch 14 Iteration 339/960] TRAIN loss:  0.597\n",
      "[epoch 14 Iteration 340/960] TRAIN loss:  0.422\n",
      "[epoch 14 Iteration 341/960] TRAIN loss:  0.437\n",
      "[epoch 14 Iteration 342/960] TRAIN loss:  0.378\n",
      "[epoch 14 Iteration 343/960] TRAIN loss:  0.524\n",
      "[epoch 14 Iteration 344/960] TRAIN loss:  0.415\n",
      "[epoch 14 Iteration 345/960] TRAIN loss:  0.520\n",
      "[epoch 14 Iteration 346/960] TRAIN loss:  0.468\n",
      "[epoch 14 Iteration 347/960] TRAIN loss:  0.905\n",
      "[epoch 14 Iteration 348/960] TRAIN loss:  0.658\n",
      "[epoch 14 Iteration 349/960] TRAIN loss:  0.620\n",
      "[epoch 14 Iteration 350/960] TRAIN loss:  0.555\n",
      "[epoch 14 Iteration 351/960] TRAIN loss:  0.510\n",
      "[epoch 14 Iteration 352/960] TRAIN loss:  0.648\n",
      "[epoch 14 Iteration 353/960] TRAIN loss:  0.689\n",
      "[epoch 14 Iteration 354/960] TRAIN loss:  0.637\n",
      "[epoch 14 Iteration 355/960] TRAIN loss:  0.690\n",
      "[epoch 14 Iteration 356/960] TRAIN loss:  0.608\n",
      "[epoch 14 Iteration 357/960] TRAIN loss:  0.525\n",
      "[epoch 14 Iteration 358/960] TRAIN loss:  0.588\n",
      "[epoch 14 Iteration 359/960] TRAIN loss:  0.455\n",
      "[epoch 14 Iteration 360/960] TRAIN loss:  0.839\n",
      "[epoch 14 Iteration 361/960] TRAIN loss:  0.675\n",
      "[epoch 14 Iteration 362/960] TRAIN loss:  0.672\n",
      "[epoch 14 Iteration 363/960] TRAIN loss:  0.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 14 Iteration 364/960] TRAIN loss:  0.707\n",
      "[epoch 14 Iteration 365/960] TRAIN loss:  0.582\n",
      "[epoch 14 Iteration 366/960] TRAIN loss:  0.600\n",
      "[epoch 14 Iteration 367/960] TRAIN loss:  0.661\n",
      "[epoch 14 Iteration 368/960] TRAIN loss:  0.625\n",
      "[epoch 14 Iteration 369/960] TRAIN loss:  0.678\n",
      "[epoch 14 Iteration 370/960] TRAIN loss:  0.579\n",
      "[epoch 14 Iteration 371/960] TRAIN loss:  0.435\n",
      "[epoch 14 Iteration 372/960] TRAIN loss:  0.481\n",
      "[epoch 14 Iteration 373/960] TRAIN loss:  0.449\n",
      "[epoch 14 Iteration 374/960] TRAIN loss:  0.640\n",
      "[epoch 14 Iteration 375/960] TRAIN loss:  0.745\n",
      "[epoch 14 Iteration 376/960] TRAIN loss:  0.640\n",
      "[epoch 14 Iteration 377/960] TRAIN loss:  0.362\n",
      "[epoch 14 Iteration 378/960] TRAIN loss:  0.417\n",
      "[epoch 14 Iteration 379/960] TRAIN loss:  0.492\n",
      "[epoch 14 Iteration 380/960] TRAIN loss:  0.495\n",
      "[epoch 14 Iteration 381/960] TRAIN loss:  0.582\n",
      "[epoch 14 Iteration 382/960] TRAIN loss:  0.496\n",
      "[epoch 14 Iteration 383/960] TRAIN loss:  0.615\n",
      "[epoch 14 Iteration 384/960] TRAIN loss:  0.647\n",
      "[epoch 14 Iteration 385/960] TRAIN loss:  0.887\n",
      "[epoch 14 Iteration 386/960] TRAIN loss:  0.782\n",
      "[epoch 14 Iteration 387/960] TRAIN loss:  0.528\n",
      "[epoch 14 Iteration 388/960] TRAIN loss:  0.672\n",
      "[epoch 14 Iteration 389/960] TRAIN loss:  0.563\n",
      "[epoch 14 Iteration 390/960] TRAIN loss:  0.557\n",
      "[epoch 14 Iteration 391/960] TRAIN loss:  0.390\n",
      "[epoch 14 Iteration 392/960] TRAIN loss:  0.632\n",
      "[epoch 14 Iteration 393/960] TRAIN loss:  0.484\n",
      "[epoch 14 Iteration 394/960] TRAIN loss:  0.673\n",
      "[epoch 14 Iteration 395/960] TRAIN loss:  0.384\n",
      "[epoch 14 Iteration 396/960] TRAIN loss:  0.920\n",
      "[epoch 14 Iteration 397/960] TRAIN loss:  0.316\n",
      "[epoch 14 Iteration 398/960] TRAIN loss:  0.432\n",
      "[epoch 14 Iteration 399/960] TRAIN loss:  0.405\n",
      "[epoch 14 Iteration 400/960] TRAIN loss:  0.326\n",
      "[epoch 14 Iteration 401/960] TRAIN loss:  0.390\n",
      "[epoch 14 Iteration 402/960] TRAIN loss:  0.589\n",
      "[epoch 14 Iteration 403/960] TRAIN loss:  0.653\n",
      "[epoch 14 Iteration 404/960] TRAIN loss:  0.619\n",
      "[epoch 14 Iteration 405/960] TRAIN loss:  0.660\n",
      "[epoch 14 Iteration 406/960] TRAIN loss:  0.585\n",
      "[epoch 14 Iteration 407/960] TRAIN loss:  0.891\n",
      "[epoch 14 Iteration 408/960] TRAIN loss:  0.375\n",
      "[epoch 14 Iteration 409/960] TRAIN loss:  0.538\n",
      "[epoch 14 Iteration 410/960] TRAIN loss:  0.680\n",
      "[epoch 14 Iteration 411/960] TRAIN loss:  0.582\n",
      "[epoch 14 Iteration 412/960] TRAIN loss:  0.729\n",
      "[epoch 14 Iteration 413/960] TRAIN loss:  0.587\n",
      "[epoch 14 Iteration 414/960] TRAIN loss:  0.451\n",
      "[epoch 14 Iteration 415/960] TRAIN loss:  0.500\n",
      "[epoch 14 Iteration 416/960] TRAIN loss:  0.387\n",
      "[epoch 14 Iteration 417/960] TRAIN loss:  0.824\n",
      "[epoch 14 Iteration 418/960] TRAIN loss:  0.492\n",
      "[epoch 14 Iteration 419/960] TRAIN loss:  0.642\n",
      "[epoch 14 Iteration 420/960] TRAIN loss:  0.546\n",
      "[epoch 14 Iteration 421/960] TRAIN loss:  0.645\n",
      "[epoch 14 Iteration 422/960] TRAIN loss:  0.718\n",
      "[epoch 14 Iteration 423/960] TRAIN loss:  0.416\n",
      "[epoch 14 Iteration 424/960] TRAIN loss:  0.621\n",
      "[epoch 14 Iteration 425/960] TRAIN loss:  0.472\n",
      "[epoch 14 Iteration 426/960] TRAIN loss:  0.502\n",
      "[epoch 14 Iteration 427/960] TRAIN loss:  0.498\n",
      "[epoch 14 Iteration 428/960] TRAIN loss:  0.446\n",
      "[epoch 14 Iteration 429/960] TRAIN loss:  0.488\n",
      "[epoch 14 Iteration 430/960] TRAIN loss:  0.745\n",
      "[epoch 14 Iteration 431/960] TRAIN loss:  0.652\n",
      "[epoch 14 Iteration 432/960] TRAIN loss:  0.552\n",
      "[epoch 14 Iteration 433/960] TRAIN loss:  0.581\n",
      "[epoch 14 Iteration 434/960] TRAIN loss:  0.525\n",
      "[epoch 14 Iteration 435/960] TRAIN loss:  0.642\n",
      "[epoch 14 Iteration 436/960] TRAIN loss:  0.688\n",
      "[epoch 14 Iteration 437/960] TRAIN loss:  0.615\n",
      "[epoch 14 Iteration 438/960] TRAIN loss:  0.483\n",
      "[epoch 14 Iteration 439/960] TRAIN loss:  0.494\n",
      "[epoch 14 Iteration 440/960] TRAIN loss:  0.500\n",
      "[epoch 14 Iteration 441/960] TRAIN loss:  0.562\n",
      "[epoch 14 Iteration 442/960] TRAIN loss:  0.536\n",
      "[epoch 14 Iteration 443/960] TRAIN loss:  0.546\n",
      "[epoch 14 Iteration 444/960] TRAIN loss:  0.685\n",
      "[epoch 14 Iteration 445/960] TRAIN loss:  0.434\n",
      "[epoch 14 Iteration 446/960] TRAIN loss:  0.584\n",
      "[epoch 14 Iteration 447/960] TRAIN loss:  0.672\n",
      "[epoch 14 Iteration 448/960] TRAIN loss:  0.439\n",
      "[epoch 14 Iteration 449/960] TRAIN loss:  0.551\n",
      "[epoch 14 Iteration 450/960] TRAIN loss:  0.423\n",
      "[epoch 14 Iteration 451/960] TRAIN loss:  0.718\n",
      "[epoch 14 Iteration 452/960] TRAIN loss:  0.413\n",
      "[epoch 14 Iteration 453/960] TRAIN loss:  0.397\n",
      "[epoch 14 Iteration 454/960] TRAIN loss:  0.587\n",
      "[epoch 14 Iteration 455/960] TRAIN loss:  0.551\n",
      "[epoch 14 Iteration 456/960] TRAIN loss:  0.432\n",
      "[epoch 14 Iteration 457/960] TRAIN loss:  0.552\n",
      "[epoch 14 Iteration 458/960] TRAIN loss:  0.471\n",
      "[epoch 14 Iteration 459/960] TRAIN loss:  0.599\n",
      "[epoch 14 Iteration 460/960] TRAIN loss:  0.528\n",
      "[epoch 14 Iteration 461/960] TRAIN loss:  0.521\n",
      "[epoch 14 Iteration 462/960] TRAIN loss:  0.519\n",
      "[epoch 14 Iteration 463/960] TRAIN loss:  0.569\n",
      "[epoch 14 Iteration 464/960] TRAIN loss:  0.721\n",
      "[epoch 14 Iteration 465/960] TRAIN loss:  0.330\n",
      "[epoch 14 Iteration 466/960] TRAIN loss:  0.684\n",
      "[epoch 14 Iteration 467/960] TRAIN loss:  0.653\n",
      "[epoch 14 Iteration 468/960] TRAIN loss:  0.516\n",
      "[epoch 14 Iteration 469/960] TRAIN loss:  0.791\n",
      "[epoch 14 Iteration 470/960] TRAIN loss:  0.560\n",
      "[epoch 14 Iteration 471/960] TRAIN loss:  0.692\n",
      "[epoch 14 Iteration 472/960] TRAIN loss:  0.456\n",
      "[epoch 14 Iteration 473/960] TRAIN loss:  0.559\n",
      "[epoch 14 Iteration 474/960] TRAIN loss:  0.570\n",
      "[epoch 14 Iteration 475/960] TRAIN loss:  0.692\n",
      "[epoch 14 Iteration 476/960] TRAIN loss:  0.577\n",
      "[epoch 14 Iteration 477/960] TRAIN loss:  0.622\n",
      "[epoch 14 Iteration 478/960] TRAIN loss:  0.723\n",
      "[epoch 14 Iteration 479/960] TRAIN loss:  0.481\n",
      "[epoch 14 Iteration 480/960] TRAIN loss:  0.734\n",
      "[epoch 14 Iteration 481/960] TRAIN loss:  0.613\n",
      "[epoch 14 Iteration 482/960] TRAIN loss:  0.370\n",
      "[epoch 14 Iteration 483/960] TRAIN loss:  0.530\n",
      "[epoch 14 Iteration 484/960] TRAIN loss:  0.612\n",
      "[epoch 14 Iteration 485/960] TRAIN loss:  0.561\n",
      "[epoch 14 Iteration 486/960] TRAIN loss:  0.490\n",
      "[epoch 14 Iteration 487/960] TRAIN loss:  0.453\n",
      "[epoch 14 Iteration 488/960] TRAIN loss:  0.648\n",
      "[epoch 14 Iteration 489/960] TRAIN loss:  0.370\n",
      "[epoch 14 Iteration 490/960] TRAIN loss:  0.556\n",
      "[epoch 14 Iteration 491/960] TRAIN loss:  0.826\n",
      "[epoch 14 Iteration 492/960] TRAIN loss:  0.376\n",
      "[epoch 14 Iteration 493/960] TRAIN loss:  0.518\n",
      "[epoch 14 Iteration 494/960] TRAIN loss:  0.497\n",
      "[epoch 14 Iteration 495/960] TRAIN loss:  0.487\n",
      "[epoch 14 Iteration 496/960] TRAIN loss:  0.525\n",
      "[epoch 14 Iteration 497/960] TRAIN loss:  0.610\n",
      "[epoch 14 Iteration 498/960] TRAIN loss:  0.477\n",
      "[epoch 14 Iteration 499/960] TRAIN loss:  0.546\n",
      "[epoch 14 Iteration 500/960] TRAIN loss:  0.551\n",
      "[epoch 14 Iteration 501/960] TRAIN loss:  0.413\n",
      "[epoch 14 Iteration 502/960] TRAIN loss:  0.495\n",
      "[epoch 14 Iteration 503/960] TRAIN loss:  0.623\n",
      "[epoch 14 Iteration 504/960] TRAIN loss:  0.492\n",
      "[epoch 14 Iteration 505/960] TRAIN loss:  0.466\n",
      "[epoch 14 Iteration 506/960] TRAIN loss:  0.474\n",
      "[epoch 14 Iteration 507/960] TRAIN loss:  0.606\n",
      "[epoch 14 Iteration 508/960] TRAIN loss:  0.654\n",
      "[epoch 14 Iteration 509/960] TRAIN loss:  0.700\n",
      "[epoch 14 Iteration 510/960] TRAIN loss:  0.465\n",
      "[epoch 14 Iteration 511/960] TRAIN loss:  0.336\n",
      "[epoch 14 Iteration 512/960] TRAIN loss:  0.512\n",
      "[epoch 14 Iteration 513/960] TRAIN loss:  0.502\n",
      "[epoch 14 Iteration 514/960] TRAIN loss:  0.381\n",
      "[epoch 14 Iteration 515/960] TRAIN loss:  0.581\n",
      "[epoch 14 Iteration 516/960] TRAIN loss:  0.495\n",
      "[epoch 14 Iteration 517/960] TRAIN loss:  1.021\n",
      "[epoch 14 Iteration 518/960] TRAIN loss:  0.614\n",
      "[epoch 14 Iteration 519/960] TRAIN loss:  0.666\n",
      "[epoch 14 Iteration 520/960] TRAIN loss:  0.416\n",
      "[epoch 14 Iteration 521/960] TRAIN loss:  0.626\n",
      "[epoch 14 Iteration 522/960] TRAIN loss:  0.386\n",
      "[epoch 14 Iteration 523/960] TRAIN loss:  0.605\n",
      "[epoch 14 Iteration 524/960] TRAIN loss:  0.461\n",
      "[epoch 14 Iteration 525/960] TRAIN loss:  0.432\n",
      "[epoch 14 Iteration 526/960] TRAIN loss:  0.592\n",
      "[epoch 14 Iteration 527/960] TRAIN loss:  0.534\n",
      "[epoch 14 Iteration 528/960] TRAIN loss:  0.310\n",
      "[epoch 14 Iteration 529/960] TRAIN loss:  0.814\n",
      "[epoch 14 Iteration 530/960] TRAIN loss:  0.662\n",
      "[epoch 14 Iteration 531/960] TRAIN loss:  0.683\n",
      "[epoch 14 Iteration 532/960] TRAIN loss:  0.465\n",
      "[epoch 14 Iteration 533/960] TRAIN loss:  0.480\n",
      "[epoch 14 Iteration 534/960] TRAIN loss:  0.623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 14 Iteration 535/960] TRAIN loss:  0.502\n",
      "[epoch 14 Iteration 536/960] TRAIN loss:  0.388\n",
      "[epoch 14 Iteration 537/960] TRAIN loss:  0.540\n",
      "[epoch 14 Iteration 538/960] TRAIN loss:  0.458\n",
      "[epoch 14 Iteration 539/960] TRAIN loss:  0.706\n",
      "[epoch 14 Iteration 540/960] TRAIN loss:  0.626\n",
      "[epoch 14 Iteration 541/960] TRAIN loss:  0.744\n",
      "[epoch 14 Iteration 542/960] TRAIN loss:  0.567\n",
      "[epoch 14 Iteration 543/960] TRAIN loss:  0.520\n",
      "[epoch 14 Iteration 544/960] TRAIN loss:  0.538\n",
      "[epoch 14 Iteration 545/960] TRAIN loss:  0.617\n",
      "[epoch 14 Iteration 546/960] TRAIN loss:  0.395\n",
      "[epoch 14 Iteration 547/960] TRAIN loss:  0.539\n",
      "[epoch 14 Iteration 548/960] TRAIN loss:  0.530\n",
      "[epoch 14 Iteration 549/960] TRAIN loss:  0.657\n",
      "[epoch 14 Iteration 550/960] TRAIN loss:  0.697\n",
      "[epoch 14 Iteration 551/960] TRAIN loss:  0.511\n",
      "[epoch 14 Iteration 552/960] TRAIN loss:  0.637\n",
      "[epoch 14 Iteration 553/960] TRAIN loss:  0.630\n",
      "[epoch 14 Iteration 554/960] TRAIN loss:  0.446\n",
      "[epoch 14 Iteration 555/960] TRAIN loss:  0.800\n",
      "[epoch 14 Iteration 556/960] TRAIN loss:  0.533\n",
      "[epoch 14 Iteration 557/960] TRAIN loss:  0.629\n",
      "[epoch 14 Iteration 558/960] TRAIN loss:  0.728\n",
      "[epoch 14 Iteration 559/960] TRAIN loss:  0.553\n",
      "[epoch 14 Iteration 560/960] TRAIN loss:  0.727\n",
      "[epoch 14 Iteration 561/960] TRAIN loss:  0.736\n",
      "[epoch 14 Iteration 562/960] TRAIN loss:  0.543\n",
      "[epoch 14 Iteration 563/960] TRAIN loss:  0.383\n",
      "[epoch 14 Iteration 564/960] TRAIN loss:  0.525\n",
      "[epoch 14 Iteration 565/960] TRAIN loss:  0.462\n",
      "[epoch 14 Iteration 566/960] TRAIN loss:  0.363\n",
      "[epoch 14 Iteration 567/960] TRAIN loss:  0.576\n",
      "[epoch 14 Iteration 568/960] TRAIN loss:  0.746\n",
      "[epoch 14 Iteration 569/960] TRAIN loss:  0.875\n",
      "[epoch 14 Iteration 570/960] TRAIN loss:  0.563\n",
      "[epoch 14 Iteration 571/960] TRAIN loss:  0.653\n",
      "[epoch 14 Iteration 572/960] TRAIN loss:  0.652\n",
      "[epoch 14 Iteration 573/960] TRAIN loss:  0.917\n",
      "[epoch 14 Iteration 574/960] TRAIN loss:  0.534\n",
      "[epoch 14 Iteration 575/960] TRAIN loss:  0.371\n",
      "[epoch 14 Iteration 576/960] TRAIN loss:  0.583\n",
      "[epoch 14 Iteration 577/960] TRAIN loss:  0.440\n",
      "[epoch 14 Iteration 578/960] TRAIN loss:  0.547\n",
      "[epoch 14 Iteration 579/960] TRAIN loss:  0.547\n",
      "[epoch 14 Iteration 580/960] TRAIN loss:  0.452\n",
      "[epoch 14 Iteration 581/960] TRAIN loss:  0.449\n",
      "[epoch 14 Iteration 582/960] TRAIN loss:  0.387\n",
      "[epoch 14 Iteration 583/960] TRAIN loss:  0.564\n",
      "[epoch 14 Iteration 584/960] TRAIN loss:  0.654\n",
      "[epoch 14 Iteration 585/960] TRAIN loss:  0.575\n",
      "[epoch 14 Iteration 586/960] TRAIN loss:  0.686\n",
      "[epoch 14 Iteration 587/960] TRAIN loss:  0.521\n",
      "[epoch 14 Iteration 588/960] TRAIN loss:  0.337\n",
      "[epoch 14 Iteration 589/960] TRAIN loss:  0.506\n",
      "[epoch 14 Iteration 590/960] TRAIN loss:  0.517\n",
      "[epoch 14 Iteration 591/960] TRAIN loss:  0.829\n",
      "[epoch 14 Iteration 592/960] TRAIN loss:  0.581\n",
      "[epoch 14 Iteration 593/960] TRAIN loss:  0.353\n",
      "[epoch 14 Iteration 594/960] TRAIN loss:  0.687\n",
      "[epoch 14 Iteration 595/960] TRAIN loss:  0.809\n",
      "[epoch 14 Iteration 596/960] TRAIN loss:  1.020\n",
      "[epoch 14 Iteration 597/960] TRAIN loss:  0.587\n",
      "[epoch 14 Iteration 598/960] TRAIN loss:  0.758\n",
      "[epoch 14 Iteration 599/960] TRAIN loss:  0.513\n",
      "[epoch 14 Iteration 600/960] TRAIN loss:  0.540\n",
      "[epoch 14 Iteration 601/960] TRAIN loss:  0.496\n",
      "[epoch 14 Iteration 602/960] TRAIN loss:  0.732\n",
      "[epoch 14 Iteration 603/960] TRAIN loss:  0.396\n",
      "[epoch 14 Iteration 604/960] TRAIN loss:  0.598\n",
      "[epoch 14 Iteration 605/960] TRAIN loss:  0.511\n",
      "[epoch 14 Iteration 606/960] TRAIN loss:  0.581\n",
      "[epoch 14 Iteration 607/960] TRAIN loss:  0.373\n",
      "[epoch 14 Iteration 608/960] TRAIN loss:  0.551\n",
      "[epoch 14 Iteration 609/960] TRAIN loss:  0.497\n",
      "[epoch 14 Iteration 610/960] TRAIN loss:  0.460\n",
      "[epoch 14 Iteration 611/960] TRAIN loss:  0.661\n",
      "[epoch 14 Iteration 612/960] TRAIN loss:  0.580\n",
      "[epoch 14 Iteration 613/960] TRAIN loss:  0.631\n",
      "[epoch 14 Iteration 614/960] TRAIN loss:  0.379\n",
      "[epoch 14 Iteration 615/960] TRAIN loss:  0.851\n",
      "[epoch 14 Iteration 616/960] TRAIN loss:  0.706\n",
      "[epoch 14 Iteration 617/960] TRAIN loss:  0.521\n",
      "[epoch 14 Iteration 618/960] TRAIN loss:  0.744\n",
      "[epoch 14 Iteration 619/960] TRAIN loss:  0.663\n",
      "[epoch 14 Iteration 620/960] TRAIN loss:  0.604\n",
      "[epoch 14 Iteration 621/960] TRAIN loss:  0.770\n",
      "[epoch 14 Iteration 622/960] TRAIN loss:  0.367\n",
      "[epoch 14 Iteration 623/960] TRAIN loss:  0.459\n",
      "[epoch 14 Iteration 624/960] TRAIN loss:  0.346\n",
      "[epoch 14 Iteration 625/960] TRAIN loss:  0.719\n",
      "[epoch 14 Iteration 626/960] TRAIN loss:  0.337\n",
      "[epoch 14 Iteration 627/960] TRAIN loss:  0.523\n",
      "[epoch 14 Iteration 628/960] TRAIN loss:  0.527\n",
      "[epoch 14 Iteration 629/960] TRAIN loss:  0.518\n",
      "[epoch 14 Iteration 630/960] TRAIN loss:  0.672\n",
      "[epoch 14 Iteration 631/960] TRAIN loss:  0.613\n",
      "[epoch 14 Iteration 632/960] TRAIN loss:  0.446\n",
      "[epoch 14 Iteration 633/960] TRAIN loss:  0.481\n",
      "[epoch 14 Iteration 634/960] TRAIN loss:  0.549\n",
      "[epoch 14 Iteration 635/960] TRAIN loss:  0.523\n",
      "[epoch 14 Iteration 636/960] TRAIN loss:  0.403\n",
      "[epoch 14 Iteration 637/960] TRAIN loss:  0.506\n",
      "[epoch 14 Iteration 638/960] TRAIN loss:  0.460\n",
      "[epoch 14 Iteration 639/960] TRAIN loss:  0.650\n",
      "[epoch 14 Iteration 640/960] TRAIN loss:  0.684\n",
      "[epoch 14 Iteration 641/960] TRAIN loss:  0.533\n",
      "[epoch 14 Iteration 642/960] TRAIN loss:  0.549\n",
      "[epoch 14 Iteration 643/960] TRAIN loss:  0.660\n",
      "[epoch 14 Iteration 644/960] TRAIN loss:  0.791\n",
      "[epoch 14 Iteration 645/960] TRAIN loss:  0.686\n",
      "[epoch 14 Iteration 646/960] TRAIN loss:  0.665\n",
      "[epoch 14 Iteration 647/960] TRAIN loss:  0.543\n",
      "[epoch 14 Iteration 648/960] TRAIN loss:  0.513\n",
      "[epoch 14 Iteration 649/960] TRAIN loss:  0.758\n",
      "[epoch 14 Iteration 650/960] TRAIN loss:  0.666\n",
      "[epoch 14 Iteration 651/960] TRAIN loss:  0.438\n",
      "[epoch 14 Iteration 652/960] TRAIN loss:  0.440\n",
      "[epoch 14 Iteration 653/960] TRAIN loss:  0.738\n",
      "[epoch 14 Iteration 654/960] TRAIN loss:  0.564\n",
      "[epoch 14 Iteration 655/960] TRAIN loss:  0.465\n",
      "[epoch 14 Iteration 656/960] TRAIN loss:  0.350\n",
      "[epoch 14 Iteration 657/960] TRAIN loss:  0.244\n",
      "[epoch 14 Iteration 658/960] TRAIN loss:  0.750\n",
      "[epoch 14 Iteration 659/960] TRAIN loss:  0.655\n",
      "[epoch 14 Iteration 660/960] TRAIN loss:  0.544\n",
      "[epoch 14 Iteration 661/960] TRAIN loss:  0.447\n",
      "[epoch 14 Iteration 662/960] TRAIN loss:  0.394\n",
      "[epoch 14 Iteration 663/960] TRAIN loss:  0.595\n",
      "[epoch 14 Iteration 664/960] TRAIN loss:  0.928\n",
      "[epoch 14 Iteration 665/960] TRAIN loss:  0.433\n",
      "[epoch 14 Iteration 666/960] TRAIN loss:  0.547\n",
      "[epoch 14 Iteration 667/960] TRAIN loss:  0.463\n",
      "[epoch 14 Iteration 668/960] TRAIN loss:  0.599\n",
      "[epoch 14 Iteration 669/960] TRAIN loss:  0.635\n",
      "[epoch 14 Iteration 670/960] TRAIN loss:  0.504\n",
      "[epoch 14 Iteration 671/960] TRAIN loss:  0.467\n",
      "[epoch 14 Iteration 672/960] TRAIN loss:  0.753\n",
      "[epoch 14 Iteration 673/960] TRAIN loss:  0.321\n",
      "[epoch 14 Iteration 674/960] TRAIN loss:  0.550\n",
      "[epoch 14 Iteration 675/960] TRAIN loss:  0.491\n",
      "[epoch 14 Iteration 676/960] TRAIN loss:  0.467\n",
      "[epoch 14 Iteration 677/960] TRAIN loss:  0.560\n",
      "[epoch 14 Iteration 678/960] TRAIN loss:  0.634\n",
      "[epoch 14 Iteration 679/960] TRAIN loss:  0.456\n",
      "[epoch 14 Iteration 680/960] TRAIN loss:  0.907\n",
      "[epoch 14 Iteration 681/960] TRAIN loss:  0.585\n",
      "[epoch 14 Iteration 682/960] TRAIN loss:  0.503\n",
      "[epoch 14 Iteration 683/960] TRAIN loss:  0.566\n",
      "[epoch 14 Iteration 684/960] TRAIN loss:  0.378\n",
      "[epoch 14 Iteration 685/960] TRAIN loss:  0.424\n",
      "[epoch 14 Iteration 686/960] TRAIN loss:  0.467\n",
      "[epoch 14 Iteration 687/960] TRAIN loss:  0.602\n",
      "[epoch 14 Iteration 688/960] TRAIN loss:  0.609\n",
      "[epoch 14 Iteration 689/960] TRAIN loss:  0.553\n",
      "[epoch 14 Iteration 690/960] TRAIN loss:  0.857\n",
      "[epoch 14 Iteration 691/960] TRAIN loss:  0.575\n",
      "[epoch 14 Iteration 692/960] TRAIN loss:  0.385\n",
      "[epoch 14 Iteration 693/960] TRAIN loss:  0.716\n",
      "[epoch 14 Iteration 694/960] TRAIN loss:  0.437\n",
      "[epoch 14 Iteration 695/960] TRAIN loss:  0.697\n",
      "[epoch 14 Iteration 696/960] TRAIN loss:  0.778\n",
      "[epoch 14 Iteration 697/960] TRAIN loss:  0.664\n",
      "[epoch 14 Iteration 698/960] TRAIN loss:  0.612\n",
      "[epoch 14 Iteration 699/960] TRAIN loss:  0.637\n",
      "[epoch 14 Iteration 700/960] TRAIN loss:  0.591\n",
      "[epoch 14 Iteration 701/960] TRAIN loss:  0.536\n",
      "[epoch 14 Iteration 702/960] TRAIN loss:  0.416\n",
      "[epoch 14 Iteration 703/960] TRAIN loss:  0.916\n",
      "[epoch 14 Iteration 704/960] TRAIN loss:  0.490\n",
      "[epoch 14 Iteration 705/960] TRAIN loss:  0.563\n",
      "[epoch 14 Iteration 706/960] TRAIN loss:  0.540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 14 Iteration 707/960] TRAIN loss:  0.558\n",
      "[epoch 14 Iteration 708/960] TRAIN loss:  0.669\n",
      "[epoch 14 Iteration 709/960] TRAIN loss:  0.579\n",
      "[epoch 14 Iteration 710/960] TRAIN loss:  0.577\n",
      "[epoch 14 Iteration 711/960] TRAIN loss:  0.714\n",
      "[epoch 14 Iteration 712/960] TRAIN loss:  0.831\n",
      "[epoch 14 Iteration 713/960] TRAIN loss:  0.643\n",
      "[epoch 14 Iteration 714/960] TRAIN loss:  0.622\n",
      "[epoch 14 Iteration 715/960] TRAIN loss:  0.701\n",
      "[epoch 14 Iteration 716/960] TRAIN loss:  0.685\n",
      "[epoch 14 Iteration 717/960] TRAIN loss:  0.591\n",
      "[epoch 14 Iteration 718/960] TRAIN loss:  0.600\n",
      "[epoch 14 Iteration 719/960] TRAIN loss:  0.604\n",
      "[epoch 14 Iteration 720/960] TRAIN loss:  0.513\n",
      "[epoch 14 Iteration 721/960] TRAIN loss:  0.568\n",
      "[epoch 14 Iteration 722/960] TRAIN loss:  0.616\n",
      "[epoch 14 Iteration 723/960] TRAIN loss:  0.668\n",
      "[epoch 14 Iteration 724/960] TRAIN loss:  0.512\n",
      "[epoch 14 Iteration 725/960] TRAIN loss:  0.695\n",
      "[epoch 14 Iteration 726/960] TRAIN loss:  0.430\n",
      "[epoch 14 Iteration 727/960] TRAIN loss:  0.663\n",
      "[epoch 14 Iteration 728/960] TRAIN loss:  0.336\n",
      "[epoch 14 Iteration 729/960] TRAIN loss:  0.560\n",
      "[epoch 14 Iteration 730/960] TRAIN loss:  0.579\n",
      "[epoch 14 Iteration 731/960] TRAIN loss:  0.415\n",
      "[epoch 14 Iteration 732/960] TRAIN loss:  0.662\n",
      "[epoch 14 Iteration 733/960] TRAIN loss:  0.743\n",
      "[epoch 14 Iteration 734/960] TRAIN loss:  0.591\n",
      "[epoch 14 Iteration 735/960] TRAIN loss:  0.763\n",
      "[epoch 14 Iteration 736/960] TRAIN loss:  0.494\n",
      "[epoch 14 Iteration 737/960] TRAIN loss:  0.380\n",
      "[epoch 14 Iteration 738/960] TRAIN loss:  0.736\n",
      "[epoch 14 Iteration 739/960] TRAIN loss:  0.725\n",
      "[epoch 14 Iteration 740/960] TRAIN loss:  0.594\n",
      "[epoch 14 Iteration 741/960] TRAIN loss:  0.959\n",
      "[epoch 14 Iteration 742/960] TRAIN loss:  0.679\n",
      "[epoch 14 Iteration 743/960] TRAIN loss:  0.628\n",
      "[epoch 14 Iteration 744/960] TRAIN loss:  0.557\n",
      "[epoch 14 Iteration 745/960] TRAIN loss:  0.557\n",
      "[epoch 14 Iteration 746/960] TRAIN loss:  0.538\n",
      "[epoch 14 Iteration 747/960] TRAIN loss:  0.647\n",
      "[epoch 14 Iteration 748/960] TRAIN loss:  0.672\n",
      "[epoch 14 Iteration 749/960] TRAIN loss:  0.611\n",
      "[epoch 14 Iteration 750/960] TRAIN loss:  0.782\n",
      "[epoch 14 Iteration 751/960] TRAIN loss:  0.459\n",
      "[epoch 14 Iteration 752/960] TRAIN loss:  0.588\n",
      "[epoch 14 Iteration 753/960] TRAIN loss:  0.553\n",
      "[epoch 14 Iteration 754/960] TRAIN loss:  0.534\n",
      "[epoch 14 Iteration 755/960] TRAIN loss:  0.561\n",
      "[epoch 14 Iteration 756/960] TRAIN loss:  0.953\n",
      "[epoch 14 Iteration 757/960] TRAIN loss:  0.628\n",
      "[epoch 14 Iteration 758/960] TRAIN loss:  0.485\n",
      "[epoch 14 Iteration 759/960] TRAIN loss:  0.774\n",
      "[epoch 14 Iteration 760/960] TRAIN loss:  0.622\n",
      "[epoch 14 Iteration 761/960] TRAIN loss:  0.621\n",
      "[epoch 14 Iteration 762/960] TRAIN loss:  0.497\n",
      "[epoch 14 Iteration 763/960] TRAIN loss:  0.464\n",
      "[epoch 14 Iteration 764/960] TRAIN loss:  0.709\n",
      "[epoch 14 Iteration 765/960] TRAIN loss:  0.668\n",
      "[epoch 14 Iteration 766/960] TRAIN loss:  0.600\n",
      "[epoch 14 Iteration 767/960] TRAIN loss:  0.546\n",
      "[epoch 14 Iteration 768/960] TRAIN loss:  0.775\n",
      "[epoch 14 Iteration 769/960] TRAIN loss:  0.744\n",
      "[epoch 14 Iteration 770/960] TRAIN loss:  0.517\n",
      "[epoch 14 Iteration 771/960] TRAIN loss:  0.448\n",
      "[epoch 14 Iteration 772/960] TRAIN loss:  0.669\n",
      "[epoch 14 Iteration 773/960] TRAIN loss:  0.608\n",
      "[epoch 14 Iteration 774/960] TRAIN loss:  0.743\n",
      "[epoch 14 Iteration 775/960] TRAIN loss:  0.561\n",
      "[epoch 14 Iteration 776/960] TRAIN loss:  0.464\n",
      "[epoch 14 Iteration 777/960] TRAIN loss:  0.621\n",
      "[epoch 14 Iteration 778/960] TRAIN loss:  0.860\n",
      "[epoch 14 Iteration 779/960] TRAIN loss:  0.644\n",
      "[epoch 14 Iteration 780/960] TRAIN loss:  0.451\n",
      "[epoch 14 Iteration 781/960] TRAIN loss:  0.516\n",
      "[epoch 14 Iteration 782/960] TRAIN loss:  0.599\n",
      "[epoch 14 Iteration 783/960] TRAIN loss:  0.501\n",
      "[epoch 14 Iteration 784/960] TRAIN loss:  0.677\n",
      "[epoch 14 Iteration 785/960] TRAIN loss:  0.893\n",
      "[epoch 14 Iteration 786/960] TRAIN loss:  0.539\n",
      "[epoch 14 Iteration 787/960] TRAIN loss:  0.784\n",
      "[epoch 14 Iteration 788/960] TRAIN loss:  0.502\n",
      "[epoch 14 Iteration 789/960] TRAIN loss:  0.544\n",
      "[epoch 14 Iteration 790/960] TRAIN loss:  0.813\n",
      "[epoch 14 Iteration 791/960] TRAIN loss:  0.691\n",
      "[epoch 14 Iteration 792/960] TRAIN loss:  0.575\n",
      "[epoch 14 Iteration 793/960] TRAIN loss:  0.719\n",
      "[epoch 14 Iteration 794/960] TRAIN loss:  0.392\n",
      "[epoch 14 Iteration 795/960] TRAIN loss:  0.559\n",
      "[epoch 14 Iteration 796/960] TRAIN loss:  0.804\n",
      "[epoch 14 Iteration 797/960] TRAIN loss:  0.554\n",
      "[epoch 14 Iteration 798/960] TRAIN loss:  0.597\n",
      "[epoch 14 Iteration 799/960] TRAIN loss:  0.529\n",
      "[epoch 14 Iteration 800/960] TRAIN loss:  0.633\n",
      "[epoch 14 Iteration 801/960] TRAIN loss:  0.511\n",
      "[epoch 14 Iteration 802/960] TRAIN loss:  0.665\n",
      "[epoch 14 Iteration 803/960] TRAIN loss:  0.483\n",
      "[epoch 14 Iteration 804/960] TRAIN loss:  0.791\n",
      "[epoch 14 Iteration 805/960] TRAIN loss:  0.758\n",
      "[epoch 14 Iteration 806/960] TRAIN loss:  0.562\n",
      "[epoch 14 Iteration 807/960] TRAIN loss:  0.596\n",
      "[epoch 14 Iteration 808/960] TRAIN loss:  0.638\n",
      "[epoch 14 Iteration 809/960] TRAIN loss:  0.653\n",
      "[epoch 14 Iteration 810/960] TRAIN loss:  0.616\n",
      "[epoch 14 Iteration 811/960] TRAIN loss:  0.489\n",
      "[epoch 14 Iteration 812/960] TRAIN loss:  0.552\n",
      "[epoch 14 Iteration 813/960] TRAIN loss:  0.687\n",
      "[epoch 14 Iteration 814/960] TRAIN loss:  0.547\n",
      "[epoch 14 Iteration 815/960] TRAIN loss:  0.578\n",
      "[epoch 14 Iteration 816/960] TRAIN loss:  0.556\n",
      "[epoch 14 Iteration 817/960] TRAIN loss:  0.524\n",
      "[epoch 14 Iteration 818/960] TRAIN loss:  0.847\n",
      "[epoch 14 Iteration 819/960] TRAIN loss:  0.920\n",
      "[epoch 14 Iteration 820/960] TRAIN loss:  0.618\n",
      "[epoch 14 Iteration 821/960] TRAIN loss:  0.675\n",
      "[epoch 14 Iteration 822/960] TRAIN loss:  0.431\n",
      "[epoch 14 Iteration 823/960] TRAIN loss:  0.599\n",
      "[epoch 14 Iteration 824/960] TRAIN loss:  0.646\n",
      "[epoch 14 Iteration 825/960] TRAIN loss:  0.553\n",
      "[epoch 14 Iteration 826/960] TRAIN loss:  0.856\n",
      "[epoch 14 Iteration 827/960] TRAIN loss:  0.545\n",
      "[epoch 14 Iteration 828/960] TRAIN loss:  0.743\n",
      "[epoch 14 Iteration 829/960] TRAIN loss:  0.621\n",
      "[epoch 14 Iteration 830/960] TRAIN loss:  0.570\n",
      "[epoch 14 Iteration 831/960] TRAIN loss:  0.737\n",
      "[epoch 14 Iteration 832/960] TRAIN loss:  0.464\n",
      "[epoch 14 Iteration 833/960] TRAIN loss:  0.404\n",
      "[epoch 14 Iteration 834/960] TRAIN loss:  0.621\n",
      "[epoch 14 Iteration 835/960] TRAIN loss:  0.559\n",
      "[epoch 14 Iteration 836/960] TRAIN loss:  0.601\n",
      "[epoch 14 Iteration 837/960] TRAIN loss:  0.524\n",
      "[epoch 14 Iteration 838/960] TRAIN loss:  0.527\n",
      "[epoch 14 Iteration 839/960] TRAIN loss:  0.475\n",
      "[epoch 14 Iteration 840/960] TRAIN loss:  0.640\n",
      "[epoch 14 Iteration 841/960] TRAIN loss:  0.598\n",
      "[epoch 14 Iteration 842/960] TRAIN loss:  0.471\n",
      "[epoch 14 Iteration 843/960] TRAIN loss:  0.602\n",
      "[epoch 14 Iteration 844/960] TRAIN loss:  0.634\n",
      "[epoch 14 Iteration 845/960] TRAIN loss:  0.671\n",
      "[epoch 14 Iteration 846/960] TRAIN loss:  0.716\n",
      "[epoch 14 Iteration 847/960] TRAIN loss:  0.369\n",
      "[epoch 14 Iteration 848/960] TRAIN loss:  0.621\n",
      "[epoch 14 Iteration 849/960] TRAIN loss:  0.553\n",
      "[epoch 14 Iteration 850/960] TRAIN loss:  0.453\n",
      "[epoch 14 Iteration 851/960] TRAIN loss:  0.528\n",
      "[epoch 14 Iteration 852/960] TRAIN loss:  0.768\n",
      "[epoch 14 Iteration 853/960] TRAIN loss:  0.884\n",
      "[epoch 14 Iteration 854/960] TRAIN loss:  0.522\n",
      "[epoch 14 Iteration 855/960] TRAIN loss:  0.378\n",
      "[epoch 14 Iteration 856/960] TRAIN loss:  0.706\n",
      "[epoch 14 Iteration 857/960] TRAIN loss:  0.526\n",
      "[epoch 14 Iteration 858/960] TRAIN loss:  0.609\n",
      "[epoch 14 Iteration 859/960] TRAIN loss:  0.627\n",
      "[epoch 14 Iteration 860/960] TRAIN loss:  0.528\n",
      "[epoch 14 Iteration 861/960] TRAIN loss:  0.617\n",
      "[epoch 14 Iteration 862/960] TRAIN loss:  0.564\n",
      "[epoch 14 Iteration 863/960] TRAIN loss:  0.580\n",
      "[epoch 14 Iteration 864/960] TRAIN loss:  0.552\n",
      "[epoch 14 Iteration 865/960] TRAIN loss:  0.436\n",
      "[epoch 14 Iteration 866/960] TRAIN loss:  0.955\n",
      "[epoch 14 Iteration 867/960] TRAIN loss:  0.759\n",
      "[epoch 14 Iteration 868/960] TRAIN loss:  0.597\n",
      "[epoch 14 Iteration 869/960] TRAIN loss:  0.393\n",
      "[epoch 14 Iteration 870/960] TRAIN loss:  0.670\n",
      "[epoch 14 Iteration 871/960] TRAIN loss:  0.680\n",
      "[epoch 14 Iteration 872/960] TRAIN loss:  0.781\n",
      "[epoch 14 Iteration 873/960] TRAIN loss:  0.699\n",
      "[epoch 14 Iteration 874/960] TRAIN loss:  0.763\n",
      "[epoch 14 Iteration 875/960] TRAIN loss:  0.603\n",
      "[epoch 14 Iteration 876/960] TRAIN loss:  0.698\n",
      "[epoch 14 Iteration 877/960] TRAIN loss:  0.705\n",
      "[epoch 14 Iteration 878/960] TRAIN loss:  0.548\n",
      "[epoch 14 Iteration 879/960] TRAIN loss:  0.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 14 Iteration 880/960] TRAIN loss:  0.698\n",
      "[epoch 14 Iteration 881/960] TRAIN loss:  0.571\n",
      "[epoch 14 Iteration 882/960] TRAIN loss:  0.791\n",
      "[epoch 14 Iteration 883/960] TRAIN loss:  0.520\n",
      "[epoch 14 Iteration 884/960] TRAIN loss:  0.799\n",
      "[epoch 14 Iteration 885/960] TRAIN loss:  0.616\n",
      "[epoch 14 Iteration 886/960] TRAIN loss:  0.641\n",
      "[epoch 14 Iteration 887/960] TRAIN loss:  0.537\n",
      "[epoch 14 Iteration 888/960] TRAIN loss:  0.445\n",
      "[epoch 14 Iteration 889/960] TRAIN loss:  0.818\n",
      "[epoch 14 Iteration 890/960] TRAIN loss:  0.651\n",
      "[epoch 14 Iteration 891/960] TRAIN loss:  0.388\n",
      "[epoch 14 Iteration 892/960] TRAIN loss:  0.559\n",
      "[epoch 14 Iteration 893/960] TRAIN loss:  0.769\n",
      "[epoch 14 Iteration 894/960] TRAIN loss:  0.570\n",
      "[epoch 14 Iteration 895/960] TRAIN loss:  0.497\n",
      "[epoch 14 Iteration 896/960] TRAIN loss:  0.408\n",
      "[epoch 14 Iteration 897/960] TRAIN loss:  0.720\n",
      "[epoch 14 Iteration 898/960] TRAIN loss:  0.858\n",
      "[epoch 14 Iteration 899/960] TRAIN loss:  0.491\n",
      "[epoch 14 Iteration 900/960] TRAIN loss:  0.628\n",
      "[epoch 14 Iteration 901/960] TRAIN loss:  0.610\n",
      "[epoch 14 Iteration 902/960] TRAIN loss:  0.736\n",
      "[epoch 14 Iteration 903/960] TRAIN loss:  0.634\n",
      "[epoch 14 Iteration 904/960] TRAIN loss:  0.399\n",
      "[epoch 14 Iteration 905/960] TRAIN loss:  0.847\n",
      "[epoch 14 Iteration 906/960] TRAIN loss:  0.402\n",
      "[epoch 14 Iteration 907/960] TRAIN loss:  0.443\n",
      "[epoch 14 Iteration 908/960] TRAIN loss:  0.641\n",
      "[epoch 14 Iteration 909/960] TRAIN loss:  0.649\n",
      "[epoch 14 Iteration 910/960] TRAIN loss:  0.633\n",
      "[epoch 14 Iteration 911/960] TRAIN loss:  0.686\n",
      "[epoch 14 Iteration 912/960] TRAIN loss:  0.434\n",
      "[epoch 14 Iteration 913/960] TRAIN loss:  0.904\n",
      "[epoch 14 Iteration 914/960] TRAIN loss:  0.586\n",
      "[epoch 14 Iteration 915/960] TRAIN loss:  0.699\n",
      "[epoch 14 Iteration 916/960] TRAIN loss:  0.732\n",
      "[epoch 14 Iteration 917/960] TRAIN loss:  0.510\n",
      "[epoch 14 Iteration 918/960] TRAIN loss:  0.461\n",
      "[epoch 14 Iteration 919/960] TRAIN loss:  0.896\n",
      "[epoch 14 Iteration 920/960] TRAIN loss:  0.515\n",
      "[epoch 14 Iteration 921/960] TRAIN loss:  0.676\n",
      "[epoch 14 Iteration 922/960] TRAIN loss:  0.458\n",
      "[epoch 14 Iteration 923/960] TRAIN loss:  0.396\n",
      "[epoch 14 Iteration 924/960] TRAIN loss:  0.494\n",
      "[epoch 14 Iteration 925/960] TRAIN loss:  0.719\n",
      "[epoch 14 Iteration 926/960] TRAIN loss:  0.885\n",
      "[epoch 14 Iteration 927/960] TRAIN loss:  0.617\n",
      "[epoch 14 Iteration 928/960] TRAIN loss:  0.586\n",
      "[epoch 14 Iteration 929/960] TRAIN loss:  0.682\n",
      "[epoch 14 Iteration 930/960] TRAIN loss:  0.714\n",
      "[epoch 14 Iteration 931/960] TRAIN loss:  0.531\n",
      "[epoch 14 Iteration 932/960] TRAIN loss:  0.397\n",
      "[epoch 14 Iteration 933/960] TRAIN loss:  0.362\n",
      "[epoch 14 Iteration 934/960] TRAIN loss:  0.582\n",
      "[epoch 14 Iteration 935/960] TRAIN loss:  0.515\n",
      "[epoch 14 Iteration 936/960] TRAIN loss:  0.576\n",
      "[epoch 14 Iteration 937/960] TRAIN loss:  0.465\n",
      "[epoch 14 Iteration 938/960] TRAIN loss:  0.699\n",
      "[epoch 14 Iteration 939/960] TRAIN loss:  0.427\n",
      "[epoch 14 Iteration 940/960] TRAIN loss:  0.579\n",
      "[epoch 14 Iteration 941/960] TRAIN loss:  0.478\n",
      "[epoch 14 Iteration 942/960] TRAIN loss:  0.644\n",
      "[epoch 14 Iteration 943/960] TRAIN loss:  0.530\n",
      "[epoch 14 Iteration 944/960] TRAIN loss:  0.546\n",
      "[epoch 14 Iteration 945/960] TRAIN loss:  0.648\n",
      "[epoch 14 Iteration 946/960] TRAIN loss:  0.586\n",
      "[epoch 14 Iteration 947/960] TRAIN loss:  0.504\n",
      "[epoch 14 Iteration 948/960] TRAIN loss:  0.437\n",
      "[epoch 14 Iteration 949/960] TRAIN loss:  0.434\n",
      "[epoch 14 Iteration 950/960] TRAIN loss:  0.439\n",
      "[epoch 14 Iteration 951/960] TRAIN loss:  0.456\n",
      "[epoch 14 Iteration 952/960] TRAIN loss:  0.532\n",
      "[epoch 14 Iteration 953/960] TRAIN loss:  0.606\n",
      "[epoch 14 Iteration 954/960] TRAIN loss:  0.609\n",
      "[epoch 14 Iteration 955/960] TRAIN loss:  0.673\n",
      "[epoch 14 Iteration 956/960] TRAIN loss:  0.492\n",
      "[epoch 14 Iteration 957/960] TRAIN loss:  0.605\n",
      "[epoch 14 Iteration 958/960] TRAIN loss:  0.636\n",
      "[epoch 14 Iteration 959/960] TRAIN loss:  0.556\n",
      "[epoch 14/15] TRAIN acc/loss:  0.800/0.556\n",
      "[epoch 14/15] VAL acc/loss:  0.656/0.539\n",
      "FINISH.\n"
     ]
    }
   ],
   "source": [
    "from dl4cv.classifiers.classification_cnn import ClassificationCNN\n",
    "from dl4cv.solver import Solver\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=50, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=50, shuffle=False, num_workers=4)\n",
    "\n",
    "########################################################################\n",
    "# TODO: Initialize a model and train it using your Solver class. Start #\n",
    "# with the previously given set of hyperparameters.                    #\n",
    "########################################################################\n",
    "model = ClassificationCNN(kernel_size=5, hidden_dim=200)\n",
    "solver = Solver(optim_args={\"lr\": 1e-3})\n",
    "solver.train(model, train_loader, val_loader, log_nth=1, num_epochs=15)\n",
    "\n",
    "########################################################################\n",
    "#                             END OF YOUR CODE                         #\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Filters\n",
    "You can visualize the first-layer convolutional filters from the trained network by running the following. If your kernel visualizations do not exhibit clear structures try optimizing the weight scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAFpCAYAAABajglzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4065b8a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dl4cv.vis_utils import visualize_grid\n",
    "\n",
    "# first (next) parameter should be convolutional\n",
    "conv_params = next(model.parameters()).data.numpy()\n",
    "grid = visualize_grid(conv_params.transpose(0, 2, 3, 1))\n",
    "plt.imshow(grid.astype('uint8'))\n",
    "plt.axis('off')\n",
    "plt.gcf().set_size_inches(6, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your Model\n",
    "Run your best model on the test set. You should easily achieve a score above 10% (random guessing for a classification task with 10 classes) accuracy on the given test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.554000\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=50, shuffle=False, num_workers=4)\n",
    "\n",
    "scores = []\n",
    "model = overfit_model\n",
    "for inputs, target in test_loader:\n",
    "    inputs, targets = Variable(inputs), Variable(target)\n",
    "    if model.is_cuda:\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    scores.extend((preds == targets).data.cpu().numpy())\n",
    "    \n",
    "print('Test set accuracy: %f' % np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "\n",
    "When you are satisfied with your training, you can save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model... models/classification_cnn.model\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/classification_cnn.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scoring function\n",
    "We will score the model you have just saved based on the classification accuracy on our test dataset. The scoring function should represent the difficulty of obtaining a good test accuracy and should therefore give 0 points for worse results than random guessing, should be linear in a first regime and exponential beyond that. The onset of exponential growth depends on the problem. In that region you get twice as many points for an additional 10% accuracy.\n",
    "\n",
    "For this problem we specifically use the following scoring function:\n",
    "\n",
    "$$f(x) = \\left\\{\n",
    "\t\\begin{array}{ll}\n",
    "\t\t0  & \\mbox{if } x \\leq 0.1 \\\\\n",
    "\t\t100x & \\mbox{if } 0.1 < x \\leq 0.58 \\\\\n",
    "        \\left(\\frac{58}{\\exp(0.58 \\ln(2)/0.1)}\\right) \\exp(x \\ln(2)/0.1) & \\mbox{if } 0.58 < x \\leq 1\n",
    "\t\\end{array}\n",
    "\\right.$$\n",
    "\n",
    "The function can be plotted in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAHwCAYAAAAfLOO9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP6fRvqVDEkK1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0a2e9e5278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dl4cv.data_utils import scoring_function\n",
    "\n",
    "x = np.linspace(0, 1, num=1000)\n",
    "plt.plot(x, scoring_function(x, lin_exp_boundary=0.58, doubling_rate=0.1))\n",
    "plt.title('Scoring Function')\n",
    "plt.xlabel('Test Accuracy')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Next Steps\n",
    "\n",
    "1. Hyperparameter optimization\n",
    "2. Data augmentation ([PyTorch tutorial](http://pytorch.org/tutorials/beginner/data_loading_tutorial.html))\n",
    "3. Improve your network architecture\n",
    "    1. Increase network depth\n",
    "    2. Make network convolutional\n",
    "    2. Add additional layers such as [Batch normalization](https://gab41.lab41.org/batch-normalization-what-the-hey-d480039a9e3b#).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
